03:30:16,387 INFO  [org.radargun.RemoteMasterConnection] (main) Attempting to connect to master results:2103
03:30:16,406 INFO  [org.radargun.RemoteMasterConnection] (main) Successfully established connection with master at: results:2103
03:30:16,413 INFO  [org.radargun.Slave] (main) Received slave index 0
03:30:16,413 INFO  [org.radargun.Slave] (main) Received slave count 3
03:30:16,890 INFO  [org.radargun.ServiceHelper] (sc-main) ServiceContext properties: {}
03:30:17,136 INFO  [org.radargun.Slave] (sc-main) Eager Service Infinispan92EmbeddedService {batching=false, cache=testCache, channelRetrievalTimeout=2 mins 0 secs, enableDiagnostics=null, explicitLocking=false, file=/mnt/workspace/results/dist-sync.xml, internalsExpositionEnabled=false, jgroupsDumperEnabled=false, jgroupsDumperInterval=10.000 secs, keysPerThread=-1, mapReduceDistributedReducePhase=false, mapReduceUseIntermediateSharedCache=false, removedCaches=[  ], threadsPerNode=-1 } loaded.
03:30:18,642 INFO  [org.radargun.Slave] (sc-main) Starting stage ScenarioInit
03:30:18,663 INFO  [org.radargun.Slave] (sc-main) Finished stage ScenarioInit
03:30:18,668 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
03:30:18,674 INFO  [org.radargun.Slave] (sc-main) Starting stage BeforeServiceStart
03:30:18,675 INFO  [org.radargun.Slave] (sc-main) Finished stage BeforeServiceStart
03:30:18,676 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
03:30:18,687 INFO  [org.radargun.Slave] (sc-main) Starting stage ServiceStart
03:30:18,688 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Startup staggering, this is the slave with index 0, not sleeping
03:30:18,688 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 0
03:30:18,693 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) Infinispan version: Infinispan 'Gaina' 9.2.0.Final
03:30:18,708 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) JGroups version: JGroups 4.0.10.Final (Schiener Berg)
03:30:19,127 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (sc-main) ISPN000078: Starting JGroups channel results
03:30:19,208 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the send buffer of socket MulticastSocket was set to 1.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
03:30:19,208 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the receive buffer of socket MulticastSocket was set to 20.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
03:30:19,209 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the send buffer of socket MulticastSocket was set to 1.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
03:30:19,209 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the receive buffer of socket MulticastSocket was set to 25.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
03:30:24,259 INFO  [org.infinispan.CLUSTER] (sc-main) ISPN000094: Received new cluster view for channel results: [fedora-48457|0] (1) [fedora-48457]
03:30:24,355 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (sc-main) ISPN000079: Channel results local address is fedora-48457, physical addresses are [192.168.121.241:38236]
03:30:24,357 INFO  [org.infinispan.factories.GlobalComponentRegistry] (sc-main) ISPN000128: Infinispan version: Infinispan 'Gaina' 9.2.0.Final
03:30:24,654 INFO  [org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup] (sc-main) ISPN000107: Retrieving transaction manager Transaction: unknown
03:30:24,718 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) No RELAY2 protocol in XS service
03:30:24,718 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) No RELAY2 protocol in XS service
03:30:24,719 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) ([fedora-48457(local=true, coord=true)]) Number of members=1 is not the one expected: 3
03:30:25,096 INFO  [org.infinispan.CLUSTER] (jgroups-6,fedora-48457) ISPN000094: Received new cluster view for channel results: [fedora-48457|1] (2) [fedora-48457, fedora-1829]
03:30:25,100 INFO  [org.infinispan.CLUSTER] (jgroups-6,fedora-48457) ISPN100000: Node fedora-1829 joined the cluster
03:30:25,434 INFO  [org.infinispan.CLUSTER] (jgroups-8,fedora-48457) ISPN000094: Received new cluster view for channel results: [fedora-48457|2] (3) [fedora-48457, fedora-1829, fedora-53683]
03:30:25,436 INFO  [org.infinispan.CLUSTER] (jgroups-8,fedora-48457) ISPN100000: Node fedora-53683 joined the cluster
03:30:25,515 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-48457: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-48457: 126, fedora-1829: 130]}, unionCH=null, actualMembers=[fedora-48457, fedora-1829], persistentUUIDs=[34877509-e906-446f-b692-d0037acbb266, 99c2fe80-3380-4e5f-bbf8-f45b891c39ca]}
03:30:25,517 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-48457]ISPN100002: Started rebalance with topology id 2
03:30:25,533 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-48457: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-48457: 126, fedora-1829: 130]}, unionCH=null, actualMembers=[fedora-48457, fedora-1829], persistentUUIDs=[34877509-e906-446f-b692-d0037acbb266, 99c2fe80-3380-4e5f-bbf8-f45b891c39ca]}
03:30:25,540 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-48457]ISPN100002: Started rebalance with topology id 2
03:30:25,553 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=org.infinispan.CONFIG][Scope=fedora-48457]ISPN100003: Node fedora-48457 finished rebalance phase with topology id 2
03:30:25,562 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t24) [Context=___counter_configuration][Scope=fedora-48457]ISPN100003: Node fedora-48457 finished rebalance phase with topology id 2
03:30:25,601 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-1829]ISPN100003: Node fedora-1829 finished rebalance phase with topology id 2
03:30:25,601 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 2
03:30:25,604 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t2) [Context=___counter_configuration][Scope=fedora-48457]ISPN100003: Node fedora-48457 finished rebalance phase with topology id 3
03:30:25,628 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-1829]ISPN100003: Node fedora-1829 finished rebalance phase with topology id 3
03:30:25,630 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t5) [Context=___counter_configuration][Scope=fedora-48457]ISPN100003: Node fedora-48457 finished rebalance phase with topology id 4
03:30:25,644 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-1829]ISPN100003: Node fedora-1829 finished rebalance phase with topology id 4
03:30:25,694 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=DefaultConsistentHash{ns=256, owners = (1)[fedora-48457: 256+0]}, pendingCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-48457: 126+130, fedora-1829: 130+126]}, unionCH=null, actualMembers=[fedora-48457, fedora-1829], persistentUUIDs=[34877509-e906-446f-b692-d0037acbb266, 99c2fe80-3380-4e5f-bbf8-f45b891c39ca]}
03:30:25,694 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-48457]ISPN100002: Started rebalance with topology id 2
03:30:25,695 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t12) [Context=___counters][Scope=fedora-48457]ISPN100003: Node fedora-48457 finished rebalance phase with topology id 2
03:30:25,698 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-1829]ISPN100003: Node fedora-1829 finished rebalance phase with topology id 2
03:30:25,699 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 2
03:30:25,700 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t15) [Context=org.infinispan.CONFIG][Scope=fedora-48457]ISPN100003: Node fedora-48457 finished rebalance phase with topology id 3
03:30:25,702 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-1829]ISPN100003: Node fedora-1829 finished rebalance phase with topology id 3
03:30:25,704 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t18) [Context=org.infinispan.CONFIG][Scope=fedora-48457]ISPN100003: Node fedora-48457 finished rebalance phase with topology id 4
03:30:25,709 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-1829]ISPN100003: Node fedora-1829 finished rebalance phase with topology id 4
03:30:25,720 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) Number of members is the one expected: 3
03:30:25,720 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Successfully started cache service infinispan92/embedded on slave 0
03:30:25,737 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-1829]ISPN100003: Node fedora-1829 finished rebalance phase with topology id 2
03:30:25,737 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___counters, topology id = 2
03:30:25,738 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t3) [Context=___counters][Scope=fedora-48457]ISPN100003: Node fedora-48457 finished rebalance phase with topology id 3
03:30:25,748 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-1829]ISPN100003: Node fedora-1829 finished rebalance phase with topology id 3
03:30:25,749 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t6) [Context=___counters][Scope=fedora-48457]ISPN100003: Node fedora-48457 finished rebalance phase with topology id 4
03:30:25,752 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-1829]ISPN100003: Node fedora-1829 finished rebalance phase with topology id 4
03:30:25,773 ERROR [org.radargun.service.ConfigDumpHelper] (sc-main) Error while dumping ___protobuf_metadata cache config as properties
javax.management.AttributeNotFoundException: Unknown attribute 'configurationAsProperties'. Known attributes names are: [rebalancingEnabled, cacheStatus, cacheName, cacheAvailability, version, configurationAsProperties]
	at org.infinispan.jmx.ResourceDMBean.getAttribute(ResourceDMBean.java:181) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:636) ~[?:?]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:679) ~[?:?]
	at org.radargun.service.ConfigDumpHelper60.dumpCache(ConfigDumpHelper60.java:44) [plugin-infinispan60-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.service.EmbeddedConfigurationProvider.getNormalizedConfigs(EmbeddedConfigurationProvider.java:33) [plugin-infinispan52-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.stages.lifecycle.ServiceStartStage.executeOnSlave(ServiceStartStage.java:92) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase.scenarioLoop(SlaveBase.java:102) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase$ScenarioRunner.run(SlaveBase.java:203) [radargun-core-3.0.0-SNAPSHOT.jar:?]
03:30:25,783 ERROR [org.radargun.service.ConfigDumpHelper] (sc-main) Error while dumping ___protobuf_metadata cache config as properties
javax.management.AttributeNotFoundException: Unknown attribute 'configurationAsProperties'. Known attributes names are: [rebalancingEnabled, cacheStatus, cacheName, cacheAvailability, version, configurationAsProperties]
	at org.infinispan.jmx.ResourceDMBean.getAttribute(ResourceDMBean.java:181) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:636) ~[?:?]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:679) ~[?:?]
	at org.radargun.service.ConfigDumpHelper60.dumpCache(ConfigDumpHelper60.java:44) [plugin-infinispan60-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.service.EmbeddedConfigurationProvider.getNormalizedConfigs(EmbeddedConfigurationProvider.java:33) [plugin-infinispan52-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.stages.lifecycle.ServiceStartStage.executeOnSlave(ServiceStartStage.java:92) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase.scenarioLoop(SlaveBase.java:102) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase$ScenarioRunner.run(SlaveBase.java:203) [radargun-core-3.0.0-SNAPSHOT.jar:?]
03:30:25,797 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-48457: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-48457: 126, fedora-1829: 130]}, unionCH=null, actualMembers=[fedora-48457, fedora-1829], persistentUUIDs=[34877509-e906-446f-b692-d0037acbb266, 99c2fe80-3380-4e5f-bbf8-f45b891c39ca]}
03:30:25,797 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-48457]ISPN100002: Started rebalance with topology id 2
03:30:25,802 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t12) [Context=___protobuf_metadata][Scope=fedora-48457]ISPN100003: Node fedora-48457 finished rebalance phase with topology id 2
03:30:25,829 INFO  [org.radargun.Slave] (sc-main) Finished stage ServiceStart
03:30:25,851 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=DefaultConsistentHash{ns=512, owners = (1)[fedora-48457: 512+0]}, pendingCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-48457: 260+252, fedora-1829: 252+260]}, unionCH=null, actualMembers=[fedora-48457, fedora-1829], persistentUUIDs=[34877509-e906-446f-b692-d0037acbb266, 99c2fe80-3380-4e5f-bbf8-f45b891c39ca]}
03:30:25,851 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-48457]ISPN100002: Started rebalance with topology id 2
03:30:25,857 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
03:30:25,862 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t15) [Context=testCache][Scope=fedora-48457]ISPN100003: Node fedora-48457 finished rebalance phase with topology id 2
03:30:25,872 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-1829]ISPN100003: Node fedora-1829 finished rebalance phase with topology id 2
03:30:25,872 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 2
03:30:25,874 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t18) [Context=___protobuf_metadata][Scope=fedora-48457]ISPN100003: Node fedora-48457 finished rebalance phase with topology id 3
03:30:25,878 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-1829]ISPN100003: Node fedora-1829 finished rebalance phase with topology id 3
03:30:25,880 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t22) [Context=___protobuf_metadata][Scope=fedora-48457]ISPN100003: Node fedora-48457 finished rebalance phase with topology id 4
03:30:25,880 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-1829]ISPN100003: Node fedora-1829 finished rebalance phase with topology id 4
03:30:25,894 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-1829]ISPN100003: Node fedora-1829 finished rebalance phase with topology id 2
03:30:25,895 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache testCache, topology id = 2
03:30:25,899 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t6) [Context=testCache][Scope=fedora-48457]ISPN100003: Node fedora-48457 finished rebalance phase with topology id 3
03:30:25,905 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-1829]ISPN100003: Node fedora-1829 finished rebalance phase with topology id 3
03:30:25,908 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t8) [Context=testCache][Scope=fedora-48457]ISPN100003: Node fedora-48457 finished rebalance phase with topology id 4
03:30:25,913 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-1829]ISPN100003: Node fedora-1829 finished rebalance phase with topology id 4
03:30:25,996 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-48457: 126, fedora-1829: 130]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-48457: 85, fedora-1829: 84, fedora-53683: 87]}, unionCH=null, actualMembers=[fedora-48457, fedora-1829, fedora-53683], persistentUUIDs=[34877509-e906-446f-b692-d0037acbb266, 99c2fe80-3380-4e5f-bbf8-f45b891c39ca, 4c710c66-266a-4c2a-ab01-67ace3e22b3c]}
03:30:25,998 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-48457]ISPN100002: Started rebalance with topology id 6
03:30:26,000 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t17) [Context=org.infinispan.CONFIG][Scope=fedora-48457]ISPN100003: Node fedora-48457 finished rebalance phase with topology id 6
03:30:26,004 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-1829]ISPN100003: Node fedora-1829 finished rebalance phase with topology id 6
03:30:26,005 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-48457: 126, fedora-1829: 130]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-48457: 85, fedora-1829: 84, fedora-53683: 87]}, unionCH=null, actualMembers=[fedora-48457, fedora-1829, fedora-53683], persistentUUIDs=[34877509-e906-446f-b692-d0037acbb266, 99c2fe80-3380-4e5f-bbf8-f45b891c39ca, 4c710c66-266a-4c2a-ab01-67ace3e22b3c]}
03:30:26,006 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-48457]ISPN100002: Started rebalance with topology id 6
03:30:26,007 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t19) [Context=___counter_configuration][Scope=fedora-48457]ISPN100003: Node fedora-48457 finished rebalance phase with topology id 6
03:30:26,012 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-1829]ISPN100003: Node fedora-1829 finished rebalance phase with topology id 6
03:30:26,093 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-53683]ISPN100003: Node fedora-53683 finished rebalance phase with topology id 6
03:30:26,094 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 6
03:30:26,094 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-53683]ISPN100003: Node fedora-53683 finished rebalance phase with topology id 6
03:30:26,094 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 6
03:30:26,095 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t22) [Context=org.infinispan.CONFIG][Scope=fedora-48457]ISPN100003: Node fedora-48457 finished rebalance phase with topology id 7
03:30:26,098 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-1829]ISPN100003: Node fedora-1829 finished rebalance phase with topology id 7
03:30:26,096 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t25) [Context=___counter_configuration][Scope=fedora-48457]ISPN100003: Node fedora-48457 finished rebalance phase with topology id 7
03:30:26,100 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-1829]ISPN100003: Node fedora-1829 finished rebalance phase with topology id 7
03:30:26,105 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-53683]ISPN100003: Node fedora-53683 finished rebalance phase with topology id 7
03:30:26,106 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=org.infinispan.CONFIG][Scope=fedora-48457]ISPN100003: Node fedora-48457 finished rebalance phase with topology id 8
03:30:26,106 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-53683]ISPN100003: Node fedora-53683 finished rebalance phase with topology id 7
03:30:26,108 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t6) [Context=___counter_configuration][Scope=fedora-48457]ISPN100003: Node fedora-48457 finished rebalance phase with topology id 8
03:30:26,108 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-1829]ISPN100003: Node fedora-1829 finished rebalance phase with topology id 8
03:30:26,109 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-1829]ISPN100003: Node fedora-1829 finished rebalance phase with topology id 8
03:30:26,109 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-53683]ISPN100003: Node fedora-53683 finished rebalance phase with topology id 8
03:30:26,112 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-53683]ISPN100003: Node fedora-53683 finished rebalance phase with topology id 8
03:30:26,131 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-48457: 126+130, fedora-1829: 130+126]}, pendingCH=DefaultConsistentHash{ns=256, owners = (3)[fedora-48457: 85+67, fedora-1829: 84+89, fedora-53683: 87+100]}, unionCH=null, actualMembers=[fedora-48457, fedora-1829, fedora-53683], persistentUUIDs=[34877509-e906-446f-b692-d0037acbb266, 99c2fe80-3380-4e5f-bbf8-f45b891c39ca, 4c710c66-266a-4c2a-ab01-67ace3e22b3c]}
03:30:26,132 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-48457]ISPN100002: Started rebalance with topology id 6
03:30:26,134 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t17) [Context=___counters][Scope=fedora-48457]ISPN100003: Node fedora-48457 finished rebalance phase with topology id 6
03:30:26,136 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-1829]ISPN100003: Node fedora-1829 finished rebalance phase with topology id 6
03:30:26,146 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-53683]ISPN100003: Node fedora-53683 finished rebalance phase with topology id 6
03:30:26,147 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache ___counters, topology id = 6
03:30:26,148 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t18) [Context=___counters][Scope=fedora-48457]ISPN100003: Node fedora-48457 finished rebalance phase with topology id 7
03:30:26,150 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-1829]ISPN100003: Node fedora-1829 finished rebalance phase with topology id 7
03:30:26,150 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-53683]ISPN100003: Node fedora-53683 finished rebalance phase with topology id 7
03:30:26,152 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t4) [Context=___counters][Scope=fedora-48457]ISPN100003: Node fedora-48457 finished rebalance phase with topology id 8
03:30:26,153 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-1829]ISPN100003: Node fedora-1829 finished rebalance phase with topology id 8
03:30:26,154 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-53683]ISPN100003: Node fedora-53683 finished rebalance phase with topology id 8
03:30:26,190 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-48457: 126, fedora-1829: 130]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-48457: 85, fedora-1829: 84, fedora-53683: 87]}, unionCH=null, actualMembers=[fedora-48457, fedora-1829, fedora-53683], persistentUUIDs=[34877509-e906-446f-b692-d0037acbb266, 99c2fe80-3380-4e5f-bbf8-f45b891c39ca, 4c710c66-266a-4c2a-ab01-67ace3e22b3c]}
03:30:26,191 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-48457]ISPN100002: Started rebalance with topology id 6
03:30:26,192 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=___protobuf_metadata][Scope=fedora-48457]ISPN100003: Node fedora-48457 finished rebalance phase with topology id 6
03:30:26,199 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-1829]ISPN100003: Node fedora-1829 finished rebalance phase with topology id 6
03:30:26,215 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-48457: 260+252, fedora-1829: 252+260]}, pendingCH=DefaultConsistentHash{ns=512, owners = (3)[fedora-48457: 173+161, fedora-1829: 166+159, fedora-53683: 173+192]}, unionCH=null, actualMembers=[fedora-48457, fedora-1829, fedora-53683], persistentUUIDs=[34877509-e906-446f-b692-d0037acbb266, 99c2fe80-3380-4e5f-bbf8-f45b891c39ca, 4c710c66-266a-4c2a-ab01-67ace3e22b3c]}
03:30:26,216 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-48457]ISPN100002: Started rebalance with topology id 6
03:30:26,218 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t6) [Context=testCache][Scope=fedora-48457]ISPN100003: Node fedora-48457 finished rebalance phase with topology id 6
03:30:26,223 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-1829]ISPN100003: Node fedora-1829 finished rebalance phase with topology id 6
03:30:26,223 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-53683]ISPN100003: Node fedora-53683 finished rebalance phase with topology id 6
03:30:26,223 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 6
03:30:26,224 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t8) [Context=___protobuf_metadata][Scope=fedora-48457]ISPN100003: Node fedora-48457 finished rebalance phase with topology id 7
03:30:26,228 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-1829]ISPN100003: Node fedora-1829 finished rebalance phase with topology id 7
03:30:26,232 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-53683]ISPN100003: Node fedora-53683 finished rebalance phase with topology id 7
03:30:26,233 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t16) [Context=___protobuf_metadata][Scope=fedora-48457]ISPN100003: Node fedora-48457 finished rebalance phase with topology id 8
03:30:26,237 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-1829]ISPN100003: Node fedora-1829 finished rebalance phase with topology id 8
03:30:26,243 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-53683]ISPN100003: Node fedora-53683 finished rebalance phase with topology id 8
03:30:26,244 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-53683]ISPN100003: Node fedora-53683 finished rebalance phase with topology id 6
03:30:26,244 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache testCache, topology id = 6
03:30:26,252 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-53683]ISPN100003: Node fedora-53683 finished rebalance phase with topology id 7
03:30:26,253 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-1829]ISPN100003: Node fedora-1829 finished rebalance phase with topology id 7
03:30:26,253 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t23) [Context=testCache][Scope=fedora-48457]ISPN100003: Node fedora-48457 finished rebalance phase with topology id 7
03:30:26,255 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t3) [Context=testCache][Scope=fedora-48457]ISPN100003: Node fedora-48457 finished rebalance phase with topology id 8
03:30:26,259 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-1829]ISPN100003: Node fedora-1829 finished rebalance phase with topology id 8
03:30:26,259 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-53683]ISPN100003: Node fedora-53683 finished rebalance phase with topology id 8
03:30:26,366 INFO  [org.radargun.Slave] (sc-main) Starting stage AfterServiceStart
03:30:26,367 INFO  [org.radargun.Slave] (sc-main) Finished stage AfterServiceStart
03:30:26,369 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
03:30:26,503 INFO  [org.radargun.Slave] (sc-main) Starting stage MonitorStart
03:30:26,506 INFO  [org.radargun.sysmonitor.AbstractMonitors] (sc-main) Gathering statistics every 1000 ms
03:30:26,506 INFO  [org.radargun.Slave] (sc-main) Finished stage MonitorStart
03:30:26,507 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
03:30:26,544 INFO  [org.radargun.Slave] (sc-main) Starting stage Load
03:30:31,826 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) This node loaded 10000 entries (~10000000 bytes)
03:30:35,265 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) This node loaded 20000 entries (~20000000 bytes)
03:30:37,548 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) This node loaded 30000 entries (~30000000 bytes)
03:30:37,976 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) Finished loading entries
03:30:37,981 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) Finished loading entries
03:30:37,993 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) Finished loading entries
03:30:38,004 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) Finished loading entries
03:30:38,021 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) Finished loading entries
03:30:38,027 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) Finished loading entries
03:30:38,047 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) Finished loading entries
03:30:38,057 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) Finished loading entries
03:30:38,069 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) Finished loading entries
03:30:38,083 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) Finished loading entries
03:30:38,084 INFO  [org.radargun.Slave] (sc-main) Finished stage Load
03:30:38,085 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
03:30:38,255 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.stages.cache.test.BasicOperationsTestStage.init() overrides public void org.radargun.stages.test.TestStage.init() but both are declared with @Init annotation: calling only once
03:30:38,258 INFO  [org.radargun.Slave] (sc-main) Starting stage BasicOperationsTest
03:30:38,261 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using key generator org.radargun.stages.cache.generators.StringKeyGenerator {format=null }
03:30:38,261 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using value generator org.radargun.stages.cache.generators.ByteArrayValueGenerator { }
03:30:38,261 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using cache selector Default { }
03:30:38,262 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Starting test warmup
03:30:38,270 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Started 4 stressor threads.
03:31:38,276 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Finished test. Test duration is: 1 mins 0 secs
03:31:38,278 INFO  [org.radargun.Slave] (sc-main) Finished stage BasicOperationsTest
03:31:38,287 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
03:31:38,299 INFO  [org.radargun.Slave] (sc-main) Starting stage Clear
03:31:38,302 INFO  [org.radargun.stages.cache.ClearStage] (sc-main) Before executing clear, memory looks like this: 
Runtime free: 469,615 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,591 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,700 kb
MX Metaspace(Non-heap memory): used: 35,906 kb, init: 0 kb, committed: 36,480 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 11,744 kb, init: 2,496 kb, committed: 11,776 kb, max: 120,028 kb
MX Compressed Class Space(Non-heap memory): used: 4,200 kb, init: 0 kb, committed: 4,480 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 740,352 kb, init: 69,632 kb, committed: 824,320 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 131,982 kb, init: 1,329,152 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 56,320 kb, init: 0 kb, committed: 56,320 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 6,468 kb, init: 2,496 kb, committed: 6,528 kb, max: 120,032 kb
03:31:38,478 INFO  [org.radargun.stages.cache.ClearStage] (sc-main) After executing clear, memory looks like this: 
Runtime free: 1,380,098 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,591 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,700 kb
MX Metaspace(Non-heap memory): used: 35,906 kb, init: 0 kb, committed: 36,480 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 11,582 kb, init: 2,496 kb, committed: 11,840 kb, max: 120,028 kb
MX Compressed Class Space(Non-heap memory): used: 4,197 kb, init: 0 kb, committed: 4,480 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 0 kb, init: 69,632 kb, committed: 880,640 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 18,173 kb, init: 1,329,152 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 0 kb, init: 0 kb, committed: 0 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 6,460 kb, init: 2,496 kb, committed: 6,528 kb, max: 120,032 kb
03:31:38,479 INFO  [org.radargun.Slave] (sc-main) Finished stage Clear
03:31:38,479 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
03:31:38,485 INFO  [org.radargun.Slave] (sc-main) Starting stage Load
03:31:39,821 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) This node loaded 10000 entries (~10000000 bytes)
03:31:41,283 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) This node loaded 20000 entries (~20000000 bytes)
03:31:42,638 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) This node loaded 30000 entries (~30000000 bytes)
03:31:42,931 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) Finished loading entries
03:31:42,936 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) Finished loading entries
03:31:42,938 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) Finished loading entries
03:31:42,946 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) Finished loading entries
03:31:42,949 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) Finished loading entries
03:31:42,957 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) Finished loading entries
03:31:42,959 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) Finished loading entries
03:31:42,959 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) Finished loading entries
03:31:42,965 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) Finished loading entries
03:31:42,968 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) Finished loading entries
03:31:42,968 INFO  [org.radargun.Slave] (sc-main) Finished stage Load
03:31:42,968 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
03:31:43,117 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.stages.cache.test.BasicOperationsTestStage.init() overrides public void org.radargun.stages.test.TestStage.init() but both are declared with @Init annotation: calling only once
03:31:43,127 INFO  [org.radargun.Slave] (sc-main) Starting stage BasicOperationsTest
03:31:43,128 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using key generator org.radargun.stages.cache.generators.StringKeyGenerator {format=null }
03:31:43,129 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using value generator org.radargun.stages.cache.generators.ByteArrayValueGenerator { }
03:31:43,133 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using cache selector Default { }
03:31:43,133 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Starting test stress-test
03:31:43,166 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Started 4 stressor threads.
03:41:43,168 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Finished test. Test duration is: 10 mins 0 secs
03:41:43,170 INFO  [org.radargun.Slave] (sc-main) Finished stage BasicOperationsTest
03:41:43,268 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
03:41:43,563 INFO  [org.radargun.Slave] (sc-main) Starting stage MonitorStop
03:41:43,563 INFO  [org.radargun.Slave] (sc-main) Finished stage MonitorStop
03:41:43,564 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
03:41:43,570 INFO  [org.radargun.Slave] (sc-main) Starting stage ScenarioDestroy
03:41:43,570 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Scenario finished, destroying...
03:41:43,571 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Memory before cleanup: 
Runtime free: 621,762 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,595 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,700 kb
MX Metaspace(Non-heap memory): used: 36,586 kb, init: 0 kb, committed: 37,120 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 9,925 kb, init: 2,496 kb, committed: 13,632 kb, max: 120,028 kb
MX Compressed Class Space(Non-heap memory): used: 4,233 kb, init: 0 kb, committed: 4,480 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 553,984 kb, init: 69,632 kb, committed: 824,320 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 166,625 kb, init: 1,329,152 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 56,320 kb, init: 0 kb, committed: 56,320 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 6,064 kb, init: 2,496 kb, committed: 7,616 kb, max: 120,032 kb
03:41:43,571 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) Stopping service.
03:41:43,580 INFO  [org.infinispan.CLUSTER] (StopThread) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-1829: 240+85, fedora-53683: 272+93]}, pendingCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-1829: 256+256, fedora-53683: 256+256]}, unionCH=null, actualMembers=[fedora-1829, fedora-53683], persistentUUIDs=[99c2fe80-3380-4e5f-bbf8-f45b891c39ca, 4c710c66-266a-4c2a-ab01-67ace3e22b3c]}
03:41:43,581 INFO  [org.infinispan.CLUSTER] (StopThread) [Context=testCache][Scope=fedora-48457]ISPN100002: Started rebalance with topology id 11
03:41:43,588 WARN  [org.infinispan.CLUSTER] (remote-thread--p2-t34) [Context=testCache]ISPN000312: Lost data because of graceful leaver fedora-1829
03:41:43,619 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t10) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-48457: 118+34, fedora-1829: 138+35]}, pendingCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-48457: 126+130, fedora-1829: 130+126]}, unionCH=null, actualMembers=[fedora-48457, fedora-1829], persistentUUIDs=[34877509-e906-446f-b692-d0037acbb266, 99c2fe80-3380-4e5f-bbf8-f45b891c39ca]}
03:41:43,619 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t10) [Context=___counters][Scope=fedora-48457]ISPN100002: Started rebalance with topology id 11
03:41:43,623 WARN  [org.infinispan.CLUSTER] (remote-thread--p2-t10) [Context=___counters]ISPN000312: Lost data because of graceful leaver fedora-1829
03:41:43,636 ERROR [org.infinispan.statetransfer.StateConsumerImpl] (transport-thread--p4-t20) ISPN000208: No live owners found for segments {11-12 15-26 30-34 39 45 53-54 62 71-77 86-88 95 108-110 117-121 129 132-135 144 149-154 157 160-162 166-171 174 177 180-194 206-208 211-214 219-222 225 229-231 235-236 249-253} of cache ___counters. Excluded owners: []
03:41:43,640 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=___counters][Scope=fedora-48457]ISPN100003: Node fedora-48457 finished rebalance phase with topology id 12
03:41:43,640 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (transport-thread--p4-t21) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___counters, type=REBALANCE_PHASE_CONFIRM, sender=fedora-48457, joinInfo=null, topologyId=12, rebalanceId=4, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-48457 for cache ___counters, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.commands.ReplicableCommand.invoke(ReplicableCommand.java:44) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.LocalTopologyManagerImpl.lambda$executeOnCoordinatorAsync$4(LocalTopologyManagerImpl.java:717) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
03:41:43,643 INFO  [org.infinispan.CLUSTER] (jgroups-15,fedora-48457) ISPN000094: Received new cluster view for channel results: [fedora-48457|3] (2) [fedora-48457, fedora-53683]
03:41:43,645 INFO  [org.infinispan.CLUSTER] (jgroups-15,fedora-48457) ISPN100001: Node fedora-1829 left the cluster
03:41:43,643 WARN  [org.infinispan.statetransfer.InboundTransferTask] (stateTransferExecutor-thread--p6-t1) ISPN000210: Failed to request state of cache ___counters from node fedora-1829, segments {11-12 15-26 30-34 39 45 53-54 62 71-77 86-88 95 108-110 117-121 129 132-135 144 149-154 157 160-162 166-171 174 177 180-194 206-208 211-214 219-222 225 229-231 235-236 249-253}
org.infinispan.remoting.transport.jgroups.SuspectException: ISPN000400: Node fedora-1829 was suspected
	at org.infinispan.remoting.transport.ResponseCollectors.remoteNodeSuspected(ResponseCollectors.java:33) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleResponseCollector.targetNotFound(SingleResponseCollector.java:31) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleResponseCollector.targetNotFound(SingleResponseCollector.java:17) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.ValidSingleResponseCollector.addResponse(ValidSingleResponseCollector.java:23) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleTargetRequest.receiveResponse(SingleTargetRequest.java:51) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleTargetRequest.onResponse(SingleTargetRequest.java:35) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.RequestRepository.addResponse(RequestRepository.java:53) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.processResponse(JGroupsTransport.java:1302) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.processMessage(JGroupsTransport.java:1205) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.access$200(JGroupsTransport.java:123) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport$ChannelCallbacks.receive(JGroupsTransport.java:1340) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.jgroups.JChannel.up(JChannel.java:819) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.stack.ProtocolStack.up(ProtocolStack.java:893) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FRAG3.up(FRAG3.java:171) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FlowControl.up(FlowControl.java:343) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FlowControl.up(FlowControl.java:343) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.GMS.up(GMS.java:864) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.STABLE.up(STABLE.java:240) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.deliverMessage(UNICAST3.java:1002) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.handleDataReceived(UNICAST3.java:728) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.up(UNICAST3.java:383) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.NAKACK2.up(NAKACK2.java:600) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.VERIFY_SUSPECT.up(VERIFY_SUSPECT.java:119) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FD_ALL.up(FD_ALL.java:199) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FD_SOCK.up(FD_SOCK.java:252) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.MERGE3.up(MERGE3.java:276) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.Discovery.up(Discovery.java:267) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.TP.passMessageUp(TP.java:1248) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.util.SubmitToThreadPool$SingleMessageHandler.run(SubmitToThreadPool.java:87) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
03:41:43,664 INFO  [org.infinispan.CLUSTER] (jgroups-15,fedora-48457) ISPN000094: Received new cluster view for channel results: [fedora-48457|4] (1) [fedora-48457]
03:41:43,665 INFO  [org.infinispan.CLUSTER] (jgroups-15,fedora-48457) ISPN100001: Node fedora-53683 left the cluster
03:41:43,688 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (StopThread) ISPN000080: Disconnecting JGroups channel results
03:41:43,702 INFO  [org.radargun.service.Infinispan90Lifecycle] (StopThread) Stopped, previous view is [fedora-48457, fedora-1829, fedora-53683]
03:41:43,702 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Service successfully stopped.
03:41:43,702 INFO  [org.radargun.Slave] (sc-main) Finished stage ScenarioDestroy
03:41:43,703 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
03:41:43,709 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.service.Infinispan80EmbeddedService.destroy() overrides public void org.radargun.service.Infinispan60EmbeddedService.destroy() but both are declared with @Destroy annotation: calling only once
03:41:43,710 INFO  [org.radargun.Slave] (main) Starting stage ScenarioCleanup
03:41:43,755 INFO  [org.radargun.stages.ScenarioCleanupStage] (main) Memory after cleanup: 
Runtime free: 1,379,250 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,597 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,700 kb
MX Metaspace(Non-heap memory): used: 36,720 kb, init: 0 kb, committed: 37,184 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 8,960 kb, init: 2,496 kb, committed: 13,632 kb, max: 120,028 kb
MX Compressed Class Space(Non-heap memory): used: 4,258 kb, init: 0 kb, committed: 4,480 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 0 kb, init: 69,632 kb, committed: 880,640 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 19,017 kb, init: 1,329,152 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 0 kb, init: 0 kb, committed: 0 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 5,688 kb, init: 2,496 kb, committed: 7,616 kb, max: 120,032 kb
03:41:43,759 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
03:41:48,802 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
03:41:51,516 INFO  [org.radargun.Slave] (main) Master shutdown!
03:41:51,517 INFO  [org.radargun.ShutDownHook] (Thread-0) Slave process is being shutdown
