16:42:33,036 INFO  [org.radargun.RemoteMasterConnection] (main) Attempting to connect to master results:2103
16:42:33,045 INFO  [org.radargun.RemoteMasterConnection] (main) Successfully established connection with master at: results:2103
16:42:33,047 INFO  [org.radargun.Slave] (main) Received slave index 0
16:42:33,047 INFO  [org.radargun.Slave] (main) Received slave count 3
16:42:33,377 INFO  [org.radargun.ServiceHelper] (sc-main) ServiceContext properties: {}
16:42:33,525 INFO  [org.radargun.Slave] (sc-main) Eager Service Infinispan92EmbeddedService {batching=false, cache=testCache, channelRetrievalTimeout=2 mins 0 secs, enableDiagnostics=null, explicitLocking=false, file=/mnt/workspace/results/dist-sync.xml, internalsExpositionEnabled=false, jgroupsDumperEnabled=false, jgroupsDumperInterval=10.000 secs, keysPerThread=-1, mapReduceDistributedReducePhase=false, mapReduceUseIntermediateSharedCache=false, removedCaches=[  ], threadsPerNode=-1 } loaded.
16:42:35,229 INFO  [org.radargun.Slave] (sc-main) Starting stage ScenarioInit
16:42:35,252 INFO  [org.radargun.Slave] (sc-main) Finished stage ScenarioInit
16:42:35,255 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
16:42:35,335 INFO  [org.radargun.Slave] (sc-main) Starting stage BeforeServiceStart
16:42:35,335 INFO  [org.radargun.Slave] (sc-main) Finished stage BeforeServiceStart
16:42:35,336 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
16:42:35,349 INFO  [org.radargun.Slave] (sc-main) Starting stage ServiceStart
16:42:35,350 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Startup staggering, this is the slave with index 0, not sleeping
16:42:35,350 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 0
16:42:35,354 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) Infinispan version: Infinispan 'Gaina' 9.2.0.Final
16:42:35,382 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) JGroups version: JGroups 4.0.10.Final (Schiener Berg)
16:42:35,903 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (sc-main) ISPN000078: Starting JGroups channel results
16:42:35,969 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the send buffer of socket MulticastSocket was set to 1.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
16:42:35,970 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the receive buffer of socket MulticastSocket was set to 20.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
16:42:35,970 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the send buffer of socket MulticastSocket was set to 1.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
16:42:35,971 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the receive buffer of socket MulticastSocket was set to 25.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
16:42:40,990 INFO  [org.infinispan.CLUSTER] (sc-main) ISPN000094: Received new cluster view for channel results: [fedora-43638|0] (1) [fedora-43638]
16:42:41,072 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (sc-main) ISPN000079: Channel results local address is fedora-43638, physical addresses are [192.168.121.30:50455]
16:42:41,075 INFO  [org.infinispan.factories.GlobalComponentRegistry] (sc-main) ISPN000128: Infinispan version: Infinispan 'Gaina' 9.2.0.Final
16:42:41,617 INFO  [org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup] (sc-main) ISPN000107: Retrieving transaction manager Transaction: unknown
16:42:41,718 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) No RELAY2 protocol in XS service
16:42:41,719 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) No RELAY2 protocol in XS service
16:42:41,720 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) ([fedora-43638(local=true, coord=true)]) Number of members=1 is not the one expected: 3
16:42:41,768 INFO  [org.infinispan.CLUSTER] (jgroups-6,fedora-43638) ISPN000094: Received new cluster view for channel results: [fedora-43638|1] (2) [fedora-43638, fedora-2913]
16:42:41,774 INFO  [org.infinispan.CLUSTER] (jgroups-6,fedora-43638) ISPN100000: Node fedora-2913 joined the cluster
16:42:42,337 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-43638: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-43638: 123, fedora-2913: 133]}, unionCH=null, actualMembers=[fedora-43638, fedora-2913], persistentUUIDs=[dfcb413d-208b-47b1-8423-ddcb67e7cb85, 4e6b6493-9144-4e47-be1b-001578f94645]}
16:42:42,338 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-43638: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-43638: 123, fedora-2913: 133]}, unionCH=null, actualMembers=[fedora-43638, fedora-2913], persistentUUIDs=[dfcb413d-208b-47b1-8423-ddcb67e7cb85, 4e6b6493-9144-4e47-be1b-001578f94645]}
16:42:42,340 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-43638]ISPN100002: Started rebalance with topology id 2
16:42:42,345 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-43638]ISPN100002: Started rebalance with topology id 2
16:42:42,354 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=org.infinispan.CONFIG][Scope=fedora-43638]ISPN100003: Node fedora-43638 finished rebalance phase with topology id 2
16:42:42,357 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t22) [Context=___counter_configuration][Scope=fedora-43638]ISPN100003: Node fedora-43638 finished rebalance phase with topology id 2
16:42:42,417 INFO  [org.infinispan.CLUSTER] (jgroups-10,fedora-43638) ISPN000094: Received new cluster view for channel results: [fedora-43638|2] (3) [fedora-43638, fedora-2913, fedora-13272]
16:42:42,418 INFO  [org.infinispan.CLUSTER] (jgroups-10,fedora-43638) ISPN100000: Node fedora-13272 joined the cluster
16:42:42,511 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-2913]ISPN100003: Node fedora-2913 finished rebalance phase with topology id 2
16:42:42,512 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 2
16:42:42,515 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t1) [Context=___counter_configuration][Scope=fedora-43638]ISPN100003: Node fedora-43638 finished rebalance phase with topology id 3
16:42:42,520 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-2913]ISPN100003: Node fedora-2913 finished rebalance phase with topology id 3
16:42:42,523 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-2913]ISPN100003: Node fedora-2913 finished rebalance phase with topology id 2
16:42:42,524 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t6) [Context=___counter_configuration][Scope=fedora-43638]ISPN100003: Node fedora-43638 finished rebalance phase with topology id 4
16:42:42,524 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 2
16:42:42,526 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-2913]ISPN100003: Node fedora-2913 finished rebalance phase with topology id 4
16:42:42,525 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=org.infinispan.CONFIG][Scope=fedora-43638]ISPN100003: Node fedora-43638 finished rebalance phase with topology id 3
16:42:42,532 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-2913]ISPN100003: Node fedora-2913 finished rebalance phase with topology id 3
16:42:42,534 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t16) [Context=org.infinispan.CONFIG][Scope=fedora-43638]ISPN100003: Node fedora-43638 finished rebalance phase with topology id 4
16:42:42,543 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-2913]ISPN100003: Node fedora-2913 finished rebalance phase with topology id 4
16:42:42,581 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=DefaultConsistentHash{ns=256, owners = (1)[fedora-43638: 256+0]}, pendingCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-43638: 123+133, fedora-2913: 133+123]}, unionCH=null, actualMembers=[fedora-43638, fedora-2913], persistentUUIDs=[dfcb413d-208b-47b1-8423-ddcb67e7cb85, 4e6b6493-9144-4e47-be1b-001578f94645]}
16:42:42,582 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-43638]ISPN100002: Started rebalance with topology id 2
16:42:42,585 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=___counters][Scope=fedora-43638]ISPN100003: Node fedora-43638 finished rebalance phase with topology id 2
16:42:42,598 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-2913]ISPN100003: Node fedora-2913 finished rebalance phase with topology id 2
16:42:42,599 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___counters, topology id = 2
16:42:42,600 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t3) [Context=___counters][Scope=fedora-43638]ISPN100003: Node fedora-43638 finished rebalance phase with topology id 3
16:42:42,603 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-2913]ISPN100003: Node fedora-2913 finished rebalance phase with topology id 3
16:42:42,606 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t5) [Context=___counters][Scope=fedora-43638]ISPN100003: Node fedora-43638 finished rebalance phase with topology id 4
16:42:42,621 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-2913]ISPN100003: Node fedora-2913 finished rebalance phase with topology id 4
16:42:42,675 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-43638: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-43638: 123, fedora-2913: 133]}, unionCH=null, actualMembers=[fedora-43638, fedora-2913], persistentUUIDs=[dfcb413d-208b-47b1-8423-ddcb67e7cb85, 4e6b6493-9144-4e47-be1b-001578f94645]}
16:42:42,676 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-43638]ISPN100002: Started rebalance with topology id 2
16:42:42,683 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t10) [Context=___protobuf_metadata][Scope=fedora-43638]ISPN100003: Node fedora-43638 finished rebalance phase with topology id 2
16:42:42,702 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-2913]ISPN100003: Node fedora-2913 finished rebalance phase with topology id 2
16:42:42,703 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 2
16:42:42,705 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t14) [Context=___protobuf_metadata][Scope=fedora-43638]ISPN100003: Node fedora-43638 finished rebalance phase with topology id 3
16:42:42,711 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-2913]ISPN100003: Node fedora-2913 finished rebalance phase with topology id 3
16:42:42,713 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t17) [Context=___protobuf_metadata][Scope=fedora-43638]ISPN100003: Node fedora-43638 finished rebalance phase with topology id 4
16:42:42,721 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) Number of members is the one expected: 3
16:42:42,721 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-2913]ISPN100003: Node fedora-2913 finished rebalance phase with topology id 4
16:42:42,721 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Successfully started cache service infinispan92/embedded on slave 0
16:42:42,730 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=DefaultConsistentHash{ns=512, owners = (1)[fedora-43638: 512+0]}, pendingCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-43638: 259+253, fedora-2913: 253+259]}, unionCH=null, actualMembers=[fedora-43638, fedora-2913], persistentUUIDs=[dfcb413d-208b-47b1-8423-ddcb67e7cb85, 4e6b6493-9144-4e47-be1b-001578f94645]}
16:42:42,730 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-43638]ISPN100002: Started rebalance with topology id 2
16:42:42,734 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t2) [Context=testCache][Scope=fedora-43638]ISPN100003: Node fedora-43638 finished rebalance phase with topology id 2
16:42:42,768 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-2913]ISPN100003: Node fedora-2913 finished rebalance phase with topology id 2
16:42:42,772 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache testCache, topology id = 2
16:42:42,774 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t1) [Context=testCache][Scope=fedora-43638]ISPN100003: Node fedora-43638 finished rebalance phase with topology id 3
16:42:42,776 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-2913]ISPN100003: Node fedora-2913 finished rebalance phase with topology id 3
16:42:42,782 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t6) [Context=testCache][Scope=fedora-43638]ISPN100003: Node fedora-43638 finished rebalance phase with topology id 4
16:42:42,785 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-2913]ISPN100003: Node fedora-2913 finished rebalance phase with topology id 4
16:42:42,814 ERROR [org.radargun.service.ConfigDumpHelper] (sc-main) Error while dumping ___protobuf_metadata cache config as properties
javax.management.AttributeNotFoundException: Unknown attribute 'configurationAsProperties'. Known attributes names are: [rebalancingEnabled, cacheStatus, cacheName, cacheAvailability, version, configurationAsProperties]
	at org.infinispan.jmx.ResourceDMBean.getAttribute(ResourceDMBean.java:181) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:641) ~[?:?]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:678) ~[?:?]
	at org.radargun.service.ConfigDumpHelper60.dumpCache(ConfigDumpHelper60.java:44) [plugin-infinispan60-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.service.EmbeddedConfigurationProvider.getNormalizedConfigs(EmbeddedConfigurationProvider.java:33) [plugin-infinispan52-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.stages.lifecycle.ServiceStartStage.executeOnSlave(ServiceStartStage.java:92) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase.scenarioLoop(SlaveBase.java:102) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase$ScenarioRunner.run(SlaveBase.java:203) [radargun-core-3.0.0-SNAPSHOT.jar:?]
16:42:42,830 ERROR [org.radargun.service.ConfigDumpHelper] (sc-main) Error while dumping ___protobuf_metadata cache config as properties
javax.management.AttributeNotFoundException: Unknown attribute 'configurationAsProperties'. Known attributes names are: [rebalancingEnabled, cacheStatus, cacheName, cacheAvailability, version, configurationAsProperties]
	at org.infinispan.jmx.ResourceDMBean.getAttribute(ResourceDMBean.java:181) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:641) ~[?:?]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:678) ~[?:?]
	at org.radargun.service.ConfigDumpHelper60.dumpCache(ConfigDumpHelper60.java:44) [plugin-infinispan60-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.service.EmbeddedConfigurationProvider.getNormalizedConfigs(EmbeddedConfigurationProvider.java:33) [plugin-infinispan52-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.stages.lifecycle.ServiceStartStage.executeOnSlave(ServiceStartStage.java:92) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase.scenarioLoop(SlaveBase.java:102) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase$ScenarioRunner.run(SlaveBase.java:203) [radargun-core-3.0.0-SNAPSHOT.jar:?]
16:42:42,874 INFO  [org.radargun.Slave] (sc-main) Finished stage ServiceStart
16:42:42,892 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
16:42:42,995 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-43638: 123, fedora-2913: 133]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-43638: 82, fedora-2913: 84, fedora-13272: 90]}, unionCH=null, actualMembers=[fedora-43638, fedora-2913, fedora-13272], persistentUUIDs=[dfcb413d-208b-47b1-8423-ddcb67e7cb85, 4e6b6493-9144-4e47-be1b-001578f94645, 0aa5eb0c-7e45-4044-8188-d51889736cc1]}
16:42:42,996 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-43638]ISPN100002: Started rebalance with topology id 6
16:42:42,997 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-43638: 123, fedora-2913: 133]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-43638: 82, fedora-2913: 84, fedora-13272: 90]}, unionCH=null, actualMembers=[fedora-43638, fedora-2913, fedora-13272], persistentUUIDs=[dfcb413d-208b-47b1-8423-ddcb67e7cb85, 4e6b6493-9144-4e47-be1b-001578f94645, 0aa5eb0c-7e45-4044-8188-d51889736cc1]}
16:42:42,998 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-2913]ISPN100003: Node fedora-2913 finished rebalance phase with topology id 6
16:42:42,998 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t10) [Context=___counter_configuration][Scope=fedora-43638]ISPN100003: Node fedora-43638 finished rebalance phase with topology id 6
16:42:43,003 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-43638]ISPN100002: Started rebalance with topology id 6
16:42:43,011 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t14) [Context=org.infinispan.CONFIG][Scope=fedora-43638]ISPN100003: Node fedora-43638 finished rebalance phase with topology id 6
16:42:43,012 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-2913]ISPN100003: Node fedora-2913 finished rebalance phase with topology id 6
16:42:43,093 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-13272]ISPN100003: Node fedora-13272 finished rebalance phase with topology id 6
16:42:43,094 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 6
16:42:43,095 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t17) [Context=org.infinispan.CONFIG][Scope=fedora-43638]ISPN100003: Node fedora-43638 finished rebalance phase with topology id 7
16:42:43,097 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-2913]ISPN100003: Node fedora-2913 finished rebalance phase with topology id 7
16:42:43,100 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-13272]ISPN100003: Node fedora-13272 finished rebalance phase with topology id 7
16:42:43,101 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t25) [Context=org.infinispan.CONFIG][Scope=fedora-43638]ISPN100003: Node fedora-43638 finished rebalance phase with topology id 8
16:42:43,103 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-13272]ISPN100003: Node fedora-13272 finished rebalance phase with topology id 8
16:42:43,105 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-2913]ISPN100003: Node fedora-2913 finished rebalance phase with topology id 8
16:42:43,185 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-13272]ISPN100003: Node fedora-13272 finished rebalance phase with topology id 6
16:42:43,185 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 6
16:42:43,187 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t3) [Context=___counter_configuration][Scope=fedora-43638]ISPN100003: Node fedora-43638 finished rebalance phase with topology id 7
16:42:43,189 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-13272]ISPN100003: Node fedora-13272 finished rebalance phase with topology id 7
16:42:43,190 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-2913]ISPN100003: Node fedora-2913 finished rebalance phase with topology id 7
16:42:43,192 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t5) [Context=___counter_configuration][Scope=fedora-43638]ISPN100003: Node fedora-43638 finished rebalance phase with topology id 8
16:42:43,195 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-2913]ISPN100003: Node fedora-2913 finished rebalance phase with topology id 8
16:42:43,197 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-13272]ISPN100003: Node fedora-13272 finished rebalance phase with topology id 8
16:42:43,212 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-43638: 123+133, fedora-2913: 133+123]}, pendingCH=DefaultConsistentHash{ns=256, owners = (3)[fedora-43638: 82+88, fedora-2913: 84+79, fedora-13272: 90+89]}, unionCH=null, actualMembers=[fedora-43638, fedora-2913, fedora-13272], persistentUUIDs=[dfcb413d-208b-47b1-8423-ddcb67e7cb85, 4e6b6493-9144-4e47-be1b-001578f94645, 0aa5eb0c-7e45-4044-8188-d51889736cc1]}
16:42:43,212 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-43638]ISPN100002: Started rebalance with topology id 6
16:42:43,214 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t13) [Context=___counters][Scope=fedora-43638]ISPN100003: Node fedora-43638 finished rebalance phase with topology id 6
16:42:43,218 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-43638: 123, fedora-2913: 133]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-43638: 82, fedora-2913: 84, fedora-13272: 90]}, unionCH=null, actualMembers=[fedora-43638, fedora-2913, fedora-13272], persistentUUIDs=[dfcb413d-208b-47b1-8423-ddcb67e7cb85, 4e6b6493-9144-4e47-be1b-001578f94645, 0aa5eb0c-7e45-4044-8188-d51889736cc1]}
16:42:43,218 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-43638]ISPN100002: Started rebalance with topology id 6
16:42:43,218 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-2913]ISPN100003: Node fedora-2913 finished rebalance phase with topology id 6
16:42:43,222 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t16) [Context=___protobuf_metadata][Scope=fedora-43638]ISPN100003: Node fedora-43638 finished rebalance phase with topology id 6
16:42:43,227 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-2913]ISPN100003: Node fedora-2913 finished rebalance phase with topology id 6
16:42:43,267 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=fedora-13272]ISPN100003: Node fedora-13272 finished rebalance phase with topology id 6
16:42:43,267 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 6
16:42:43,269 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t17) [Context=___protobuf_metadata][Scope=fedora-43638]ISPN100003: Node fedora-43638 finished rebalance phase with topology id 7
16:42:43,270 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=fedora-13272]ISPN100003: Node fedora-13272 finished rebalance phase with topology id 6
16:42:43,270 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000336: Finished cluster-wide rebalance for cache ___counters, topology id = 6
16:42:43,271 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-2913]ISPN100003: Node fedora-2913 finished rebalance phase with topology id 7
16:42:43,271 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t25) [Context=___counters][Scope=fedora-43638]ISPN100003: Node fedora-43638 finished rebalance phase with topology id 7
16:42:43,275 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=fedora-2913]ISPN100003: Node fedora-2913 finished rebalance phase with topology id 7
16:42:43,280 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=fedora-13272]ISPN100003: Node fedora-13272 finished rebalance phase with topology id 7
16:42:43,282 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t2) [Context=___protobuf_metadata][Scope=fedora-43638]ISPN100003: Node fedora-43638 finished rebalance phase with topology id 8
16:42:43,283 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-43638: 259+253, fedora-2913: 253+259]}, pendingCH=DefaultConsistentHash{ns=512, owners = (3)[fedora-43638: 173+157, fedora-2913: 162+170, fedora-13272: 177+185]}, unionCH=null, actualMembers=[fedora-43638, fedora-2913, fedora-13272], persistentUUIDs=[dfcb413d-208b-47b1-8423-ddcb67e7cb85, 4e6b6493-9144-4e47-be1b-001578f94645, 0aa5eb0c-7e45-4044-8188-d51889736cc1]}
16:42:43,284 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-43638]ISPN100002: Started rebalance with topology id 6
16:42:43,287 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t6) [Context=testCache][Scope=fedora-43638]ISPN100003: Node fedora-43638 finished rebalance phase with topology id 6
16:42:43,292 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-2913]ISPN100003: Node fedora-2913 finished rebalance phase with topology id 6
16:42:43,290 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=fedora-2913]ISPN100003: Node fedora-2913 finished rebalance phase with topology id 8
16:42:43,295 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=fedora-13272]ISPN100003: Node fedora-13272 finished rebalance phase with topology id 8
16:42:43,297 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-13272]ISPN100003: Node fedora-13272 finished rebalance phase with topology id 7
16:42:43,299 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t15) [Context=___counters][Scope=fedora-43638]ISPN100003: Node fedora-43638 finished rebalance phase with topology id 8
16:42:43,301 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-2913]ISPN100003: Node fedora-2913 finished rebalance phase with topology id 8
16:42:43,306 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-13272]ISPN100003: Node fedora-13272 finished rebalance phase with topology id 8
16:42:43,323 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-13272]ISPN100003: Node fedora-13272 finished rebalance phase with topology id 6
16:42:43,323 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache testCache, topology id = 6
16:42:43,325 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t22) [Context=testCache][Scope=fedora-43638]ISPN100003: Node fedora-43638 finished rebalance phase with topology id 7
16:42:43,330 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-2913]ISPN100003: Node fedora-2913 finished rebalance phase with topology id 7
16:42:43,332 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-13272]ISPN100003: Node fedora-13272 finished rebalance phase with topology id 7
16:42:43,334 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=testCache][Scope=fedora-43638]ISPN100003: Node fedora-43638 finished rebalance phase with topology id 8
16:42:43,336 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-2913]ISPN100003: Node fedora-2913 finished rebalance phase with topology id 8
16:42:43,341 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-13272]ISPN100003: Node fedora-13272 finished rebalance phase with topology id 8
16:42:43,428 INFO  [org.radargun.Slave] (sc-main) Starting stage AfterServiceStart
16:42:43,429 INFO  [org.radargun.Slave] (sc-main) Finished stage AfterServiceStart
16:42:43,431 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
16:42:43,521 INFO  [org.radargun.Slave] (sc-main) Starting stage MonitorStart
16:42:43,525 INFO  [org.radargun.sysmonitor.AbstractMonitors] (sc-main) Gathering statistics every 1000 ms
16:42:43,526 INFO  [org.radargun.Slave] (sc-main) Finished stage MonitorStart
16:42:43,527 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
16:42:43,549 INFO  [org.radargun.Slave] (sc-main) Starting stage Load
16:42:48,667 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) This node loaded 10000 entries (~10000000 bytes)
16:42:51,967 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) This node loaded 20000 entries (~20000000 bytes)
16:42:53,759 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) This node loaded 30000 entries (~30000000 bytes)
16:42:54,213 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) Finished loading entries
16:42:54,215 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) Finished loading entries
16:42:54,251 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) Finished loading entries
16:42:54,253 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) Finished loading entries
16:42:54,266 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) Finished loading entries
16:42:54,294 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) Finished loading entries
16:42:54,302 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) Finished loading entries
16:42:54,324 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) Finished loading entries
16:42:54,331 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) Finished loading entries
16:42:54,361 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) Finished loading entries
16:42:54,362 INFO  [org.radargun.Slave] (sc-main) Finished stage Load
16:42:54,362 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
16:42:54,664 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.stages.cache.test.BasicOperationsTestStage.init() overrides public void org.radargun.stages.test.TestStage.init() but both are declared with @Init annotation: calling only once
16:42:54,668 INFO  [org.radargun.Slave] (sc-main) Starting stage BasicOperationsTest
16:42:54,669 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using key generator org.radargun.stages.cache.generators.StringKeyGenerator {format=null }
16:42:54,671 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using value generator org.radargun.stages.cache.generators.ByteArrayValueGenerator { }
16:42:54,672 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using cache selector Default { }
16:42:54,675 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Starting test warmup
16:42:54,702 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Started 4 stressor threads.
16:43:54,709 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Finished test. Test duration is: 1 mins 0 secs
16:43:54,710 INFO  [org.radargun.Slave] (sc-main) Finished stage BasicOperationsTest
16:43:54,715 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
16:43:54,722 INFO  [org.radargun.Slave] (sc-main) Starting stage Clear
16:43:54,725 INFO  [org.radargun.stages.cache.ClearStage] (sc-main) Before executing clear, memory looks like this: 
Runtime free: 543,558 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,326 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,696 kb
MX Metaspace(Non-heap memory): used: 43,994 kb, init: 0 kb, committed: 45,340 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 12,217 kb, init: 2,496 kb, committed: 12,224 kb, max: 120,032 kb
MX Compressed Class Space(Non-heap memory): used: 4,970 kb, init: 0 kb, committed: 5,504 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 675,840 kb, init: 73,728 kb, committed: 824,320 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 122,041 kb, init: 1,325,056 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 56,320 kb, init: 0 kb, committed: 56,320 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 5,183 kb, init: 2,496 kb, committed: 5,184 kb, max: 120,032 kb
16:43:54,897 INFO  [org.radargun.stages.cache.ClearStage] (sc-main) After executing clear, memory looks like this: 
Runtime free: 1,381,622 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,326 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,696 kb
MX Metaspace(Non-heap memory): used: 43,939 kb, init: 0 kb, committed: 45,340 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 12,307 kb, init: 2,496 kb, committed: 12,352 kb, max: 120,032 kb
MX Compressed Class Space(Non-heap memory): used: 4,946 kb, init: 0 kb, committed: 5,504 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 0 kb, init: 73,728 kb, committed: 880,640 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 16,649 kb, init: 1,325,056 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 0 kb, init: 0 kb, committed: 0 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 5,212 kb, init: 2,496 kb, committed: 5,248 kb, max: 120,032 kb
16:43:54,897 INFO  [org.radargun.Slave] (sc-main) Finished stage Clear
16:43:54,898 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
16:43:54,901 INFO  [org.radargun.Slave] (sc-main) Starting stage Load
16:43:56,269 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) This node loaded 10000 entries (~10000000 bytes)
16:43:57,589 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) This node loaded 20000 entries (~20000000 bytes)
16:43:59,074 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) This node loaded 30000 entries (~30000000 bytes)
16:43:59,477 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) Finished loading entries
16:43:59,478 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) Finished loading entries
16:43:59,505 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) Finished loading entries
16:43:59,507 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) Finished loading entries
16:43:59,510 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) Finished loading entries
16:43:59,515 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) Finished loading entries
16:43:59,527 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) Finished loading entries
16:43:59,530 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) Finished loading entries
16:43:59,533 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) Finished loading entries
16:43:59,533 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) Finished loading entries
16:43:59,534 INFO  [org.radargun.Slave] (sc-main) Finished stage Load
16:43:59,535 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
16:43:59,733 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.stages.cache.test.BasicOperationsTestStage.init() overrides public void org.radargun.stages.test.TestStage.init() but both are declared with @Init annotation: calling only once
16:43:59,741 INFO  [org.radargun.Slave] (sc-main) Starting stage BasicOperationsTest
16:43:59,741 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using key generator org.radargun.stages.cache.generators.StringKeyGenerator {format=null }
16:43:59,742 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using value generator org.radargun.stages.cache.generators.ByteArrayValueGenerator { }
16:43:59,742 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using cache selector Default { }
16:43:59,742 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Starting test stress-test
16:43:59,773 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Started 4 stressor threads.
16:53:59,779 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Finished test. Test duration is: 10 mins 0 secs
16:53:59,781 INFO  [org.radargun.Slave] (sc-main) Finished stage BasicOperationsTest
16:53:59,906 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
16:54:00,038 INFO  [org.radargun.Slave] (sc-main) Starting stage MonitorStop
16:54:00,039 INFO  [org.radargun.Slave] (sc-main) Finished stage MonitorStop
16:54:00,040 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
16:54:00,046 INFO  [org.radargun.Slave] (sc-main) Starting stage ScenarioDestroy
16:54:00,046 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Scenario finished, destroying...
16:54:00,047 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Memory before cleanup: 
Runtime free: 610,719 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,328 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,696 kb
MX Metaspace(Non-heap memory): used: 44,666 kb, init: 0 kb, committed: 46,236 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 14,186 kb, init: 2,496 kb, committed: 14,208 kb, max: 120,032 kb
MX Compressed Class Space(Non-heap memory): used: 4,987 kb, init: 0 kb, committed: 5,632 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 529,408 kb, init: 73,728 kb, committed: 824,320 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 200,798 kb, init: 1,325,056 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 56,320 kb, init: 0 kb, committed: 56,320 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 6,239 kb, init: 2,496 kb, committed: 6,272 kb, max: 120,032 kb
16:54:00,047 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) Stopping service.
16:54:00,055 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t19) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-43638: 263+67, fedora-2913: 249+83]}, pendingCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-43638: 259+253, fedora-2913: 253+259]}, unionCH=null, actualMembers=[fedora-43638, fedora-2913], persistentUUIDs=[dfcb413d-208b-47b1-8423-ddcb67e7cb85, 4e6b6493-9144-4e47-be1b-001578f94645]}
16:54:00,056 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t19) [Context=testCache][Scope=fedora-43638]ISPN100002: Started rebalance with topology id 11
16:54:00,070 WARN  [org.infinispan.CLUSTER] (remote-thread--p2-t19) [Context=testCache]ISPN000312: Lost data because of graceful leaver fedora-2913
16:54:00,082 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t19) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-43638: 127+43, fedora-2913: 129+34]}, pendingCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-43638: 123+133, fedora-2913: 133+123]}, unionCH=null, actualMembers=[fedora-43638, fedora-2913], persistentUUIDs=[dfcb413d-208b-47b1-8423-ddcb67e7cb85, 4e6b6493-9144-4e47-be1b-001578f94645]}
16:54:00,083 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t19) [Context=___counters][Scope=fedora-43638]ISPN100002: Started rebalance with topology id 11
16:54:00,101 INFO  [org.infinispan.CLUSTER] (jgroups-32,fedora-43638) ISPN000094: Received new cluster view for channel results: [fedora-43638|3] (2) [fedora-43638, fedora-2913]
16:54:00,102 INFO  [org.infinispan.CLUSTER] (jgroups-32,fedora-43638) ISPN100001: Node fedora-13272 left the cluster
16:54:00,143 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t17) [Context=testCache][Scope=fedora-43638]ISPN100003: Node fedora-43638 finished rebalance phase with topology id 11
16:54:00,144 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=testCache][Scope=fedora-43638]ISPN100003: Node fedora-43638 finished rebalance phase with topology id 12
16:54:00,146 WARN  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters]ISPN000312: Lost data because of graceful leaver fedora-2913
16:54:00,149 ERROR [org.infinispan.statetransfer.StateConsumerImpl] (transport-thread--p4-t24) ISPN000208: No live owners found for segments {15 26 34 47-49 53 71-80 88-90 93-97 103 106-108 123-127 137-140 146-148 157-161 172 178-182 192 195 201-202 210-212 218-220 223-230 241 244-246 250-252 255} of cache ___counters. Excluded owners: []
16:54:00,150 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t25) [Context=___counters][Scope=fedora-43638]ISPN100003: Node fedora-43638 finished rebalance phase with topology id 12
16:54:00,150 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (transport-thread--p4-t25) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___counters, type=REBALANCE_PHASE_CONFIRM, sender=fedora-43638, joinInfo=null, topologyId=12, rebalanceId=4, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=3}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-43638 for cache ___counters, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.commands.ReplicableCommand.invoke(ReplicableCommand.java:44) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.LocalTopologyManagerImpl.lambda$executeOnCoordinatorAsync$4(LocalTopologyManagerImpl.java:717) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
16:54:00,153 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-2913]ISPN100003: Node fedora-2913 finished rebalance phase with topology id 11
16:54:00,154 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (remote-thread--p2-t1) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___counters, type=REBALANCE_PHASE_CONFIRM, sender=fedora-2913, joinInfo=null, topologyId=11, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=3}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-2913 for cache ___counters, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.invokeReplicableCommand(GlobalInboundInvocationHandler.java:169) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.runReplicableCommand(GlobalInboundInvocationHandler.java:150) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.lambda$handleReplicableCommand$1(GlobalInboundInvocationHandler.java:144) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.util.concurrent.BlockingTaskAwareExecutorServiceImpl$RunnableWrapper.run(BlockingTaskAwareExecutorServiceImpl.java:212) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
16:54:00,183 INFO  [org.infinispan.CLUSTER] (jgroups-32,fedora-43638) ISPN000094: Received new cluster view for channel results: [fedora-43638|4] (1) [fedora-43638]
16:54:00,187 INFO  [org.infinispan.CLUSTER] (jgroups-32,fedora-43638) ISPN100001: Node fedora-2913 left the cluster
16:54:00,191 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (StopThread) ISPN000080: Disconnecting JGroups channel results
16:54:00,240 INFO  [org.radargun.service.Infinispan90Lifecycle] (StopThread) Stopped, previous view is [fedora-43638, fedora-2913, fedora-13272]
16:54:00,240 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Service successfully stopped.
16:54:00,240 INFO  [org.radargun.Slave] (sc-main) Finished stage ScenarioDestroy
16:54:00,241 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
16:54:00,247 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.service.Infinispan80EmbeddedService.destroy() overrides public void org.radargun.service.Infinispan60EmbeddedService.destroy() but both are declared with @Destroy annotation: calling only once
16:54:00,248 INFO  [org.radargun.Slave] (main) Starting stage ScenarioCleanup
16:54:00,248 WARN  [org.radargun.stages.ScenarioCleanupStage] (main) Unfinished thread ForkJoinPool.commonPool-worker-3 (id=33, state=WAITING)
	at java.base@11.0.17-internal/jdk.internal.misc.Unsafe.park(Native Method)
	at java.base@11.0.17-internal/java.util.concurrent.locks.LockSupport.park(LockSupport.java:194)
	at java.base@11.0.17-internal/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1628)
	at java.base@11.0.17-internal/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
16:54:00,249 INFO  [org.radargun.stages.ScenarioCleanupStage] (main) Interrupting thread ForkJoinPool.commonPool-worker-3 (id=33, state=WAITING)
16:54:05,250 INFO  [org.radargun.stages.ScenarioCleanupStage] (main) Stopping thread ForkJoinPool.commonPool-worker-3 (id=33, state=WAITING)
16:54:05,254 INFO  [org.radargun.stages.ScenarioCleanupStage] (main) Is thread ForkJoinPool.commonPool-worker-3 (id=33, state=TERMINATED)) alive? false
16:54:05,381 INFO  [org.radargun.stages.ScenarioCleanupStage] (main) Memory after cleanup: 
Runtime free: 1,380,565 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,330 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,696 kb
MX Metaspace(Non-heap memory): used: 44,819 kb, init: 0 kb, committed: 46,236 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 14,410 kb, init: 2,496 kb, committed: 14,464 kb, max: 120,032 kb
MX Compressed Class Space(Non-heap memory): used: 5,011 kb, init: 0 kb, committed: 5,632 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 0 kb, init: 73,728 kb, committed: 880,640 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 17,706 kb, init: 1,325,056 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 0 kb, init: 0 kb, committed: 0 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 6,347 kb, init: 2,496 kb, committed: 6,400 kb, max: 120,032 kb
16:54:05,384 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
16:54:05,418 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
16:54:08,886 INFO  [org.radargun.Slave] (main) Master shutdown!
16:54:08,888 INFO  [org.radargun.ShutDownHook] (Thread-0) Slave process is being shutdown
