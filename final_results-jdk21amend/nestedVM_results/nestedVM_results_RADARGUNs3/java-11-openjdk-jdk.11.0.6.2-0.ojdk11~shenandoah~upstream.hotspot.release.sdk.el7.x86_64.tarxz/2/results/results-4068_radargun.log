04:18:02,571 INFO  [org.radargun.RemoteMasterConnection] (main) Attempting to connect to master results:2103
04:18:02,583 INFO  [org.radargun.RemoteMasterConnection] (main) Successfully established connection with master at: results:2103
04:18:02,585 INFO  [org.radargun.Slave] (main) Received slave index 0
04:18:02,585 INFO  [org.radargun.Slave] (main) Received slave count 3
04:18:02,799 INFO  [org.radargun.ServiceHelper] (sc-main) ServiceContext properties: {}
04:18:03,250 INFO  [org.radargun.Slave] (sc-main) Eager Service Infinispan92EmbeddedService {batching=false, cache=testCache, channelRetrievalTimeout=2 mins 0 secs, enableDiagnostics=null, explicitLocking=false, file=/mnt/workspace/results/dist-sync.xml, internalsExpositionEnabled=false, jgroupsDumperEnabled=false, jgroupsDumperInterval=10.000 secs, keysPerThread=-1, mapReduceDistributedReducePhase=false, mapReduceUseIntermediateSharedCache=false, removedCaches=[  ], threadsPerNode=-1 } loaded.
04:18:05,410 INFO  [org.radargun.Slave] (sc-main) Starting stage ScenarioInit
04:18:05,482 INFO  [org.radargun.Slave] (sc-main) Finished stage ScenarioInit
04:18:05,486 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
04:18:05,498 INFO  [org.radargun.Slave] (sc-main) Starting stage BeforeServiceStart
04:18:05,508 INFO  [org.radargun.Slave] (sc-main) Finished stage BeforeServiceStart
04:18:05,510 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
04:18:05,516 INFO  [org.radargun.Slave] (sc-main) Starting stage ServiceStart
04:18:05,519 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Startup staggering, this is the slave with index 0, not sleeping
04:18:05,519 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 0
04:18:05,523 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) Infinispan version: Infinispan 'Gaina' 9.2.0.Final
04:18:05,553 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) JGroups version: JGroups 4.0.10.Final (Schiener Berg)
04:18:06,175 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (sc-main) ISPN000078: Starting JGroups channel results
04:18:06,256 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the send buffer of socket MulticastSocket was set to 1.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
04:18:06,257 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the receive buffer of socket MulticastSocket was set to 20.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
04:18:06,258 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the send buffer of socket MulticastSocket was set to 1.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
04:18:06,258 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the receive buffer of socket MulticastSocket was set to 25.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
04:18:11,277 INFO  [org.infinispan.CLUSTER] (sc-main) ISPN000094: Received new cluster view for channel results: [fedora-63052|0] (1) [fedora-63052]
04:18:11,354 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (sc-main) ISPN000079: Channel results local address is fedora-63052, physical addresses are [192.168.124.203:54848]
04:18:11,363 INFO  [org.infinispan.factories.GlobalComponentRegistry] (sc-main) ISPN000128: Infinispan version: Infinispan 'Gaina' 9.2.0.Final
04:18:12,095 INFO  [org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup] (sc-main) ISPN000107: Retrieving transaction manager Transaction: unknown
04:18:12,297 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) No RELAY2 protocol in XS service
04:18:12,298 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) No RELAY2 protocol in XS service
04:18:12,303 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) ([fedora-63052(local=true, coord=true)]) Number of members=1 is not the one expected: 3
04:18:12,561 INFO  [org.infinispan.CLUSTER] (jgroups-7,fedora-63052) ISPN000094: Received new cluster view for channel results: [fedora-63052|1] (2) [fedora-63052, fedora-12442]
04:18:12,568 INFO  [org.infinispan.CLUSTER] (jgroups-7,fedora-63052) ISPN100000: Node fedora-12442 joined the cluster
04:18:13,080 INFO  [org.infinispan.CLUSTER] (jgroups-9,fedora-63052) ISPN000094: Received new cluster view for channel results: [fedora-63052|2] (3) [fedora-63052, fedora-12442, fedora-14064]
04:18:13,081 INFO  [org.infinispan.CLUSTER] (jgroups-9,fedora-63052) ISPN100000: Node fedora-14064 joined the cluster
04:18:13,212 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-63052: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-63052: 122, fedora-12442: 134]}, unionCH=null, actualMembers=[fedora-63052, fedora-12442], persistentUUIDs=[9d7f2ddd-46f1-4ecb-a6e7-43b04101303d, 3367a0a1-6751-4b02-9332-277aa9772cfa]}
04:18:13,214 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-63052]ISPN100002: Started rebalance with topology id 2
04:18:13,225 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-63052: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-63052: 122, fedora-12442: 134]}, unionCH=null, actualMembers=[fedora-63052, fedora-12442], persistentUUIDs=[9d7f2ddd-46f1-4ecb-a6e7-43b04101303d, 3367a0a1-6751-4b02-9332-277aa9772cfa]}
04:18:13,225 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-63052]ISPN100002: Started rebalance with topology id 2
04:18:13,268 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t23) [Context=___counter_configuration][Scope=fedora-63052]ISPN100003: Node fedora-63052 finished rebalance phase with topology id 2
04:18:13,270 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t24) [Context=org.infinispan.CONFIG][Scope=fedora-63052]ISPN100003: Node fedora-63052 finished rebalance phase with topology id 2
04:18:13,304 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) Number of members is the one expected: 3
04:18:13,306 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Successfully started cache service infinispan92/embedded on slave 0
04:18:13,364 ERROR [org.radargun.service.ConfigDumpHelper] (sc-main) Error while dumping ___protobuf_metadata cache config as properties
javax.management.AttributeNotFoundException: Unknown attribute 'configurationAsProperties'. Known attributes names are: [rebalancingEnabled, cacheStatus, cacheName, cacheAvailability, version, configurationAsProperties]
	at org.infinispan.jmx.ResourceDMBean.getAttribute(ResourceDMBean.java:181) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:641) ~[?:?]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:678) ~[?:?]
	at org.radargun.service.ConfigDumpHelper60.dumpCache(ConfigDumpHelper60.java:44) [plugin-infinispan60-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.service.EmbeddedConfigurationProvider.getNormalizedConfigs(EmbeddedConfigurationProvider.java:33) [plugin-infinispan52-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.stages.lifecycle.ServiceStartStage.executeOnSlave(ServiceStartStage.java:92) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase.scenarioLoop(SlaveBase.java:102) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase$ScenarioRunner.run(SlaveBase.java:203) [radargun-core-3.0.0-SNAPSHOT.jar:?]
04:18:13,400 ERROR [org.radargun.service.ConfigDumpHelper] (sc-main) Error while dumping ___protobuf_metadata cache config as properties
javax.management.AttributeNotFoundException: Unknown attribute 'configurationAsProperties'. Known attributes names are: [rebalancingEnabled, cacheStatus, cacheName, cacheAvailability, version, configurationAsProperties]
	at org.infinispan.jmx.ResourceDMBean.getAttribute(ResourceDMBean.java:181) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:641) ~[?:?]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:678) ~[?:?]
	at org.radargun.service.ConfigDumpHelper60.dumpCache(ConfigDumpHelper60.java:44) [plugin-infinispan60-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.service.EmbeddedConfigurationProvider.getNormalizedConfigs(EmbeddedConfigurationProvider.java:33) [plugin-infinispan52-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.stages.lifecycle.ServiceStartStage.executeOnSlave(ServiceStartStage.java:92) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase.scenarioLoop(SlaveBase.java:102) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase$ScenarioRunner.run(SlaveBase.java:203) [radargun-core-3.0.0-SNAPSHOT.jar:?]
04:18:13,445 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-12442]ISPN100003: Node fedora-12442 finished rebalance phase with topology id 2
04:18:13,453 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 2
04:18:13,463 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t2) [Context=___counter_configuration][Scope=fedora-63052]ISPN100003: Node fedora-63052 finished rebalance phase with topology id 3
04:18:13,473 INFO  [org.radargun.Slave] (sc-main) Finished stage ServiceStart
04:18:13,476 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-12442]ISPN100003: Node fedora-12442 finished rebalance phase with topology id 3
04:18:13,484 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t5) [Context=___counter_configuration][Scope=fedora-63052]ISPN100003: Node fedora-63052 finished rebalance phase with topology id 4
04:18:13,503 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
04:18:13,506 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-12442]ISPN100003: Node fedora-12442 finished rebalance phase with topology id 2
04:18:13,507 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-12442]ISPN100003: Node fedora-12442 finished rebalance phase with topology id 4
04:18:13,512 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 2
04:18:13,513 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t8) [Context=org.infinispan.CONFIG][Scope=fedora-63052]ISPN100003: Node fedora-63052 finished rebalance phase with topology id 3
04:18:13,523 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-12442]ISPN100003: Node fedora-12442 finished rebalance phase with topology id 3
04:18:13,526 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t14) [Context=org.infinispan.CONFIG][Scope=fedora-63052]ISPN100003: Node fedora-63052 finished rebalance phase with topology id 4
04:18:13,563 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-12442]ISPN100003: Node fedora-12442 finished rebalance phase with topology id 4
04:18:13,615 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=DefaultConsistentHash{ns=256, owners = (1)[fedora-63052: 256+0]}, pendingCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-63052: 122+134, fedora-12442: 134+122]}, unionCH=null, actualMembers=[fedora-63052, fedora-12442], persistentUUIDs=[9d7f2ddd-46f1-4ecb-a6e7-43b04101303d, 3367a0a1-6751-4b02-9332-277aa9772cfa]}
04:18:13,616 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-63052]ISPN100002: Started rebalance with topology id 2
04:18:13,622 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t23) [Context=___counters][Scope=fedora-63052]ISPN100003: Node fedora-63052 finished rebalance phase with topology id 2
04:18:13,735 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-12442]ISPN100003: Node fedora-12442 finished rebalance phase with topology id 2
04:18:13,738 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache ___counters, topology id = 2
04:18:13,740 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t24) [Context=___counters][Scope=fedora-63052]ISPN100003: Node fedora-63052 finished rebalance phase with topology id 3
04:18:13,747 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-12442]ISPN100003: Node fedora-12442 finished rebalance phase with topology id 3
04:18:13,750 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t4) [Context=___counters][Scope=fedora-63052]ISPN100003: Node fedora-63052 finished rebalance phase with topology id 4
04:18:13,754 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-12442]ISPN100003: Node fedora-12442 finished rebalance phase with topology id 4
04:18:13,811 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-63052: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-63052: 122, fedora-12442: 134]}, unionCH=null, actualMembers=[fedora-63052, fedora-12442], persistentUUIDs=[9d7f2ddd-46f1-4ecb-a6e7-43b04101303d, 3367a0a1-6751-4b02-9332-277aa9772cfa]}
04:18:13,811 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-63052]ISPN100002: Started rebalance with topology id 2
04:18:13,817 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t9) [Context=___protobuf_metadata][Scope=fedora-63052]ISPN100003: Node fedora-63052 finished rebalance phase with topology id 2
04:18:13,828 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-12442]ISPN100003: Node fedora-12442 finished rebalance phase with topology id 2
04:18:13,831 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 2
04:18:13,833 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t16) [Context=___protobuf_metadata][Scope=fedora-63052]ISPN100003: Node fedora-63052 finished rebalance phase with topology id 3
04:18:13,836 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-12442]ISPN100003: Node fedora-12442 finished rebalance phase with topology id 3
04:18:13,839 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t18) [Context=___protobuf_metadata][Scope=fedora-63052]ISPN100003: Node fedora-63052 finished rebalance phase with topology id 4
04:18:13,841 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-12442]ISPN100003: Node fedora-12442 finished rebalance phase with topology id 4
04:18:13,867 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=DefaultConsistentHash{ns=512, owners = (1)[fedora-63052: 512+0]}, pendingCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-63052: 259+253, fedora-12442: 253+259]}, unionCH=null, actualMembers=[fedora-63052, fedora-12442], persistentUUIDs=[9d7f2ddd-46f1-4ecb-a6e7-43b04101303d, 3367a0a1-6751-4b02-9332-277aa9772cfa]}
04:18:13,868 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-63052]ISPN100002: Started rebalance with topology id 2
04:18:13,891 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t1) [Context=testCache][Scope=fedora-63052]ISPN100003: Node fedora-63052 finished rebalance phase with topology id 2
04:18:13,902 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-12442]ISPN100003: Node fedora-12442 finished rebalance phase with topology id 2
04:18:13,903 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache testCache, topology id = 2
04:18:13,905 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t24) [Context=testCache][Scope=fedora-63052]ISPN100003: Node fedora-63052 finished rebalance phase with topology id 3
04:18:13,913 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-12442]ISPN100003: Node fedora-12442 finished rebalance phase with topology id 3
04:18:13,916 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t5) [Context=testCache][Scope=fedora-63052]ISPN100003: Node fedora-63052 finished rebalance phase with topology id 4
04:18:13,918 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-12442]ISPN100003: Node fedora-12442 finished rebalance phase with topology id 4
04:18:13,947 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-63052: 122, fedora-12442: 134]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-63052: 81, fedora-12442: 90, fedora-14064: 85]}, unionCH=null, actualMembers=[fedora-63052, fedora-12442, fedora-14064], persistentUUIDs=[9d7f2ddd-46f1-4ecb-a6e7-43b04101303d, 3367a0a1-6751-4b02-9332-277aa9772cfa, 34011229-68bb-46a7-9e0f-dede612806dd]}
04:18:13,948 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-63052]ISPN100002: Started rebalance with topology id 6
04:18:13,952 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t9) [Context=org.infinispan.CONFIG][Scope=fedora-63052]ISPN100003: Node fedora-63052 finished rebalance phase with topology id 6
04:18:13,957 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-12442]ISPN100003: Node fedora-12442 finished rebalance phase with topology id 6
04:18:13,975 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-63052: 122, fedora-12442: 134]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-63052: 81, fedora-12442: 90, fedora-14064: 85]}, unionCH=null, actualMembers=[fedora-63052, fedora-12442, fedora-14064], persistentUUIDs=[9d7f2ddd-46f1-4ecb-a6e7-43b04101303d, 3367a0a1-6751-4b02-9332-277aa9772cfa, 34011229-68bb-46a7-9e0f-dede612806dd]}
04:18:13,979 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-63052]ISPN100002: Started rebalance with topology id 6
04:18:13,981 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t15) [Context=___counter_configuration][Scope=fedora-63052]ISPN100003: Node fedora-63052 finished rebalance phase with topology id 6
04:18:13,989 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-12442]ISPN100003: Node fedora-12442 finished rebalance phase with topology id 6
04:18:14,139 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-14064]ISPN100003: Node fedora-14064 finished rebalance phase with topology id 6
04:18:14,140 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 6
04:18:14,142 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t18) [Context=___counter_configuration][Scope=fedora-63052]ISPN100003: Node fedora-63052 finished rebalance phase with topology id 7
04:18:14,147 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-12442]ISPN100003: Node fedora-12442 finished rebalance phase with topology id 7
04:18:14,151 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-14064]ISPN100003: Node fedora-14064 finished rebalance phase with topology id 7
04:18:14,152 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t19) [Context=___counter_configuration][Scope=fedora-63052]ISPN100003: Node fedora-63052 finished rebalance phase with topology id 8
04:18:14,156 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-12442]ISPN100003: Node fedora-12442 finished rebalance phase with topology id 8
04:18:14,158 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-14064]ISPN100003: Node fedora-14064 finished rebalance phase with topology id 8
04:18:14,189 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-63052: 122+134, fedora-12442: 134+122]}, pendingCH=DefaultConsistentHash{ns=256, owners = (3)[fedora-63052: 81+85, fedora-12442: 90+98, fedora-14064: 85+73]}, unionCH=null, actualMembers=[fedora-63052, fedora-12442, fedora-14064], persistentUUIDs=[9d7f2ddd-46f1-4ecb-a6e7-43b04101303d, 3367a0a1-6751-4b02-9332-277aa9772cfa, 34011229-68bb-46a7-9e0f-dede612806dd]}
04:18:14,191 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-63052]ISPN100002: Started rebalance with topology id 6
04:18:14,193 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t6) [Context=___counters][Scope=fedora-63052]ISPN100003: Node fedora-63052 finished rebalance phase with topology id 6
04:18:14,197 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-12442]ISPN100003: Node fedora-12442 finished rebalance phase with topology id 6
04:18:14,244 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-14064]ISPN100003: Node fedora-14064 finished rebalance phase with topology id 6
04:18:14,244 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___counters, topology id = 6
04:18:14,246 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t25) [Context=___counters][Scope=fedora-63052]ISPN100003: Node fedora-63052 finished rebalance phase with topology id 7
04:18:14,248 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-14064]ISPN100003: Node fedora-14064 finished rebalance phase with topology id 6
04:18:14,249 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 6
04:18:14,249 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-12442]ISPN100003: Node fedora-12442 finished rebalance phase with topology id 7
04:18:14,252 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t11) [Context=org.infinispan.CONFIG][Scope=fedora-63052]ISPN100003: Node fedora-63052 finished rebalance phase with topology id 7
04:18:14,257 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-12442]ISPN100003: Node fedora-12442 finished rebalance phase with topology id 7
04:18:14,257 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-14064]ISPN100003: Node fedora-14064 finished rebalance phase with topology id 7
04:18:14,263 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-14064]ISPN100003: Node fedora-14064 finished rebalance phase with topology id 7
04:18:14,269 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t9) [Context=___counters][Scope=fedora-63052]ISPN100003: Node fedora-63052 finished rebalance phase with topology id 8
04:18:14,272 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=org.infinispan.CONFIG][Scope=fedora-14064]ISPN100003: Node fedora-14064 finished rebalance phase with topology id 8
04:18:14,274 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t17) [Context=org.infinispan.CONFIG][Scope=fedora-63052]ISPN100003: Node fedora-63052 finished rebalance phase with topology id 8
04:18:14,275 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-12442]ISPN100003: Node fedora-12442 finished rebalance phase with topology id 8
04:18:14,275 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-12442]ISPN100003: Node fedora-12442 finished rebalance phase with topology id 8
04:18:14,278 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=fedora-14064]ISPN100003: Node fedora-14064 finished rebalance phase with topology id 8
04:18:14,408 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-63052: 122, fedora-12442: 134]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-63052: 81, fedora-12442: 90, fedora-14064: 85]}, unionCH=null, actualMembers=[fedora-63052, fedora-12442, fedora-14064], persistentUUIDs=[9d7f2ddd-46f1-4ecb-a6e7-43b04101303d, 3367a0a1-6751-4b02-9332-277aa9772cfa, 34011229-68bb-46a7-9e0f-dede612806dd]}
04:18:14,409 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=fedora-63052]ISPN100002: Started rebalance with topology id 6
04:18:14,411 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t24) [Context=___protobuf_metadata][Scope=fedora-63052]ISPN100003: Node fedora-63052 finished rebalance phase with topology id 6
04:18:14,423 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=fedora-12442]ISPN100003: Node fedora-12442 finished rebalance phase with topology id 6
04:18:14,451 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-63052: 259+253, fedora-12442: 253+259]}, pendingCH=DefaultConsistentHash{ns=512, owners = (3)[fedora-63052: 168+153, fedora-12442: 173+178, fedora-14064: 171+181]}, unionCH=null, actualMembers=[fedora-63052, fedora-12442, fedora-14064], persistentUUIDs=[9d7f2ddd-46f1-4ecb-a6e7-43b04101303d, 3367a0a1-6751-4b02-9332-277aa9772cfa, 34011229-68bb-46a7-9e0f-dede612806dd]}
04:18:14,455 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-63052]ISPN100002: Started rebalance with topology id 6
04:18:14,457 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t10) [Context=testCache][Scope=fedora-63052]ISPN100003: Node fedora-63052 finished rebalance phase with topology id 6
04:18:14,462 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-12442]ISPN100003: Node fedora-12442 finished rebalance phase with topology id 6
04:18:14,464 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=fedora-14064]ISPN100003: Node fedora-14064 finished rebalance phase with topology id 6
04:18:14,465 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 6
04:18:14,467 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t5) [Context=___protobuf_metadata][Scope=fedora-63052]ISPN100003: Node fedora-63052 finished rebalance phase with topology id 7
04:18:14,473 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=fedora-12442]ISPN100003: Node fedora-12442 finished rebalance phase with topology id 7
04:18:14,501 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=fedora-14064]ISPN100003: Node fedora-14064 finished rebalance phase with topology id 7
04:18:14,503 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t11) [Context=___protobuf_metadata][Scope=fedora-63052]ISPN100003: Node fedora-63052 finished rebalance phase with topology id 8
04:18:14,508 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=fedora-12442]ISPN100003: Node fedora-12442 finished rebalance phase with topology id 8
04:18:14,511 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=fedora-14064]ISPN100003: Node fedora-14064 finished rebalance phase with topology id 8
04:18:14,527 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-14064]ISPN100003: Node fedora-14064 finished rebalance phase with topology id 6
04:18:14,528 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000336: Finished cluster-wide rebalance for cache testCache, topology id = 6
04:18:14,536 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t22) [Context=testCache][Scope=fedora-63052]ISPN100003: Node fedora-63052 finished rebalance phase with topology id 7
04:18:14,539 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-12442]ISPN100003: Node fedora-12442 finished rebalance phase with topology id 7
04:18:14,542 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-14064]ISPN100003: Node fedora-14064 finished rebalance phase with topology id 7
04:18:14,546 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t19) [Context=testCache][Scope=fedora-63052]ISPN100003: Node fedora-63052 finished rebalance phase with topology id 8
04:18:14,549 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-12442]ISPN100003: Node fedora-12442 finished rebalance phase with topology id 8
04:18:14,552 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-14064]ISPN100003: Node fedora-14064 finished rebalance phase with topology id 8
04:18:14,692 INFO  [org.radargun.Slave] (sc-main) Starting stage AfterServiceStart
04:18:14,692 INFO  [org.radargun.Slave] (sc-main) Finished stage AfterServiceStart
04:18:14,695 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
04:18:14,786 INFO  [org.radargun.Slave] (sc-main) Starting stage MonitorStart
04:18:14,800 INFO  [org.radargun.sysmonitor.AbstractMonitors] (sc-main) Gathering statistics every 1000 ms
04:18:14,800 INFO  [org.radargun.Slave] (sc-main) Finished stage MonitorStart
04:18:14,801 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
04:18:14,825 INFO  [org.radargun.Slave] (sc-main) Starting stage Load
04:18:23,701 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) This node loaded 10000 entries (~10000000 bytes)
04:18:31,036 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) This node loaded 20000 entries (~20000000 bytes)
04:18:34,852 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) This node loaded 30000 entries (~30000000 bytes)
04:18:35,276 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) Finished loading entries
04:18:35,332 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) Finished loading entries
04:18:35,336 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) Finished loading entries
04:18:35,342 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) Finished loading entries
04:18:35,359 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) Finished loading entries
04:18:35,385 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) Finished loading entries
04:18:35,389 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) Finished loading entries
04:18:35,391 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) Finished loading entries
04:18:35,401 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) Finished loading entries
04:18:35,402 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) Finished loading entries
04:18:35,403 INFO  [org.radargun.Slave] (sc-main) Finished stage Load
04:18:35,404 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
04:18:35,464 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.stages.cache.test.BasicOperationsTestStage.init() overrides public void org.radargun.stages.test.TestStage.init() but both are declared with @Init annotation: calling only once
04:18:35,489 INFO  [org.radargun.Slave] (sc-main) Starting stage BasicOperationsTest
04:18:35,490 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using key generator org.radargun.stages.cache.generators.StringKeyGenerator {format=null }
04:18:35,491 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using value generator org.radargun.stages.cache.generators.ByteArrayValueGenerator { }
04:18:35,491 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using cache selector Default { }
04:18:35,491 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Starting test warmup
04:18:35,525 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Started 4 stressor threads.
04:19:35,529 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Finished test. Test duration is: 1 mins 0 secs
04:19:35,531 INFO  [org.radargun.Slave] (sc-main) Finished stage BasicOperationsTest
04:19:35,541 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
04:19:35,585 INFO  [org.radargun.Slave] (sc-main) Starting stage Clear
04:19:35,596 INFO  [org.radargun.stages.cache.ClearStage] (sc-main) Before executing clear, memory looks like this: 
Runtime free: 817,836 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,230 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,696 kb
MX Metaspace(Non-heap memory): used: 43,839 kb, init: 0 kb, committed: 45,436 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 11,187 kb, init: 2,496 kb, committed: 11,264 kb, max: 120,032 kb
MX Compressed Class Space(Non-heap memory): used: 4,996 kb, init: 0 kb, committed: 5,580 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 421,888 kb, init: 73,728 kb, committed: 831,488 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 121,171 kb, init: 1,325,056 kb, committed: 530,432 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 36,864 kb, init: 0 kb, committed: 36,864 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 4,804 kb, init: 2,496 kb, committed: 4,864 kb, max: 120,032 kb
04:19:35,787 INFO  [org.radargun.stages.cache.ClearStage] (sc-main) After executing clear, memory looks like this: 
Runtime free: 1,381,539 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,236 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,696 kb
MX Metaspace(Non-heap memory): used: 43,831 kb, init: 0 kb, committed: 45,436 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 11,300 kb, init: 2,496 kb, committed: 11,392 kb, max: 120,032 kb
MX Compressed Class Space(Non-heap memory): used: 4,986 kb, init: 0 kb, committed: 5,580 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 0 kb, init: 73,728 kb, committed: 880,640 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 16,732 kb, init: 1,325,056 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 0 kb, init: 0 kb, committed: 0 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 4,814 kb, init: 2,496 kb, committed: 4,864 kb, max: 120,032 kb
04:19:35,787 INFO  [org.radargun.Slave] (sc-main) Finished stage Clear
04:19:35,788 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
04:19:35,808 INFO  [org.radargun.Slave] (sc-main) Starting stage Load
04:19:39,094 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) This node loaded 10000 entries (~10000000 bytes)
04:19:42,353 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) This node loaded 20000 entries (~20000000 bytes)
04:19:45,564 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) This node loaded 30000 entries (~30000000 bytes)
04:19:46,352 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) Finished loading entries
04:19:46,364 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) Finished loading entries
04:19:46,395 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) Finished loading entries
04:19:46,401 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) Finished loading entries
04:19:46,406 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) Finished loading entries
04:19:46,409 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) Finished loading entries
04:19:46,414 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) Finished loading entries
04:19:46,422 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) Finished loading entries
04:19:46,425 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) Finished loading entries
04:19:46,433 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) Finished loading entries
04:19:46,433 INFO  [org.radargun.Slave] (sc-main) Finished stage Load
04:19:46,434 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
04:19:46,842 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.stages.cache.test.BasicOperationsTestStage.init() overrides public void org.radargun.stages.test.TestStage.init() but both are declared with @Init annotation: calling only once
04:19:46,845 INFO  [org.radargun.Slave] (sc-main) Starting stage BasicOperationsTest
04:19:46,847 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using key generator org.radargun.stages.cache.generators.StringKeyGenerator {format=null }
04:19:46,850 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using value generator org.radargun.stages.cache.generators.ByteArrayValueGenerator { }
04:19:46,851 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using cache selector Default { }
04:19:46,854 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Starting test stress-test
04:19:46,898 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Started 4 stressor threads.
04:29:46,902 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Finished test. Test duration is: 10 mins 0 secs
04:29:46,904 INFO  [org.radargun.Slave] (sc-main) Finished stage BasicOperationsTest
04:29:46,980 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
04:29:47,089 INFO  [org.radargun.Slave] (sc-main) Starting stage MonitorStop
04:29:47,090 INFO  [org.radargun.Slave] (sc-main) Finished stage MonitorStop
04:29:47,090 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
04:29:47,099 INFO  [org.radargun.Slave] (sc-main) Starting stage ScenarioDestroy
04:29:47,100 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Scenario finished, destroying...
04:29:47,100 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Memory before cleanup: 
Runtime free: 680,800 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,232 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,696 kb
MX Metaspace(Non-heap memory): used: 44,550 kb, init: 0 kb, committed: 45,948 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 9,090 kb, init: 2,496 kb, committed: 13,120 kb, max: 120,032 kb
MX Compressed Class Space(Non-heap memory): used: 5,027 kb, init: 0 kb, committed: 5,580 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 405,504 kb, init: 73,728 kb, committed: 820,224 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 250,525 kb, init: 1,325,056 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 60,416 kb, init: 0 kb, committed: 60,416 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 4,374 kb, init: 2,496 kb, committed: 5,568 kb, max: 120,032 kb
04:29:47,101 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) Stopping service.
04:29:47,110 INFO  [org.infinispan.CLUSTER] (StopThread) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-12442: 259+92, fedora-14064: 253+99]}, pendingCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-12442: 255+257, fedora-14064: 257+255]}, unionCH=null, actualMembers=[fedora-12442, fedora-14064], persistentUUIDs=[3367a0a1-6751-4b02-9332-277aa9772cfa, 34011229-68bb-46a7-9e0f-dede612806dd]}
04:29:47,111 INFO  [org.infinispan.CLUSTER] (StopThread) [Context=testCache][Scope=fedora-63052]ISPN100002: Started rebalance with topology id 11
04:29:47,115 WARN  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=testCache]ISPN000312: Lost data because of graceful leaver fedora-14064
04:29:47,140 INFO  [org.infinispan.CLUSTER] (StopThread) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-12442: 127, fedora-14064: 129]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-12442: 128, fedora-14064: 128]}, unionCH=null, actualMembers=[fedora-12442, fedora-14064], persistentUUIDs=[3367a0a1-6751-4b02-9332-277aa9772cfa, 34011229-68bb-46a7-9e0f-dede612806dd]}
04:29:47,142 INFO  [org.infinispan.CLUSTER] (StopThread) [Context=___protobuf_metadata][Scope=fedora-63052]ISPN100002: Started rebalance with topology id 11
04:29:47,150 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t6) [Context=___protobuf_metadata][Scope=fedora-14064]ISPN100003: Node fedora-14064 finished rebalance phase with topology id 11
04:29:47,150 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t31) [Context=___protobuf_metadata][Scope=fedora-12442]ISPN100003: Node fedora-12442 finished rebalance phase with topology id 11
04:29:47,153 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t6) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 11
04:29:47,156 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=___protobuf_metadata][Scope=fedora-12442]ISPN100003: Node fedora-12442 finished rebalance phase with topology id 12
04:29:47,156 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (remote-thread--p2-t5) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___protobuf_metadata, type=REBALANCE_PHASE_CONFIRM, sender=fedora-12442, joinInfo=null, topologyId=12, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-12442 for cache ___protobuf_metadata, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.invokeReplicableCommand(GlobalInboundInvocationHandler.java:169) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.runReplicableCommand(GlobalInboundInvocationHandler.java:150) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.lambda$handleReplicableCommand$1(GlobalInboundInvocationHandler.java:144) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.util.concurrent.BlockingTaskAwareExecutorServiceImpl$RunnableWrapper.run(BlockingTaskAwareExecutorServiceImpl.java:212) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
04:29:47,158 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=___protobuf_metadata][Scope=fedora-12442]ISPN100003: Node fedora-12442 finished rebalance phase with topology id 13
04:29:47,159 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (remote-thread--p2-t5) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___protobuf_metadata, type=REBALANCE_PHASE_CONFIRM, sender=fedora-12442, joinInfo=null, topologyId=13, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-12442 for cache ___protobuf_metadata, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.invokeReplicableCommand(GlobalInboundInvocationHandler.java:169) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.runReplicableCommand(GlobalInboundInvocationHandler.java:150) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.lambda$handleReplicableCommand$1(GlobalInboundInvocationHandler.java:144) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.util.concurrent.BlockingTaskAwareExecutorServiceImpl$RunnableWrapper.run(BlockingTaskAwareExecutorServiceImpl.java:212) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
04:29:47,172 INFO  [org.infinispan.CLUSTER] (StopThread) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-12442: 134+54, fedora-14064: 122+36]}, pendingCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-12442: 128+128, fedora-14064: 128+128]}, unionCH=null, actualMembers=[fedora-12442, fedora-14064], persistentUUIDs=[3367a0a1-6751-4b02-9332-277aa9772cfa, 34011229-68bb-46a7-9e0f-dede612806dd]}
04:29:47,176 INFO  [org.infinispan.CLUSTER] (StopThread) [Context=___counters][Scope=fedora-63052]ISPN100002: Started rebalance with topology id 11
04:29:47,179 WARN  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=___counters]ISPN000312: Lost data because of graceful leaver fedora-14064
04:29:47,185 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t6) [Context=___counters][Scope=fedora-12442]ISPN100003: Node fedora-12442 finished rebalance phase with topology id 12
04:29:47,185 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (remote-thread--p2-t6) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___counters, type=REBALANCE_PHASE_CONFIRM, sender=fedora-12442, joinInfo=null, topologyId=12, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-12442 for cache ___counters, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.invokeReplicableCommand(GlobalInboundInvocationHandler.java:169) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.runReplicableCommand(GlobalInboundInvocationHandler.java:150) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.lambda$handleReplicableCommand$1(GlobalInboundInvocationHandler.java:144) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.util.concurrent.BlockingTaskAwareExecutorServiceImpl$RunnableWrapper.run(BlockingTaskAwareExecutorServiceImpl.java:212) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
04:29:47,186 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-63052: 124, fedora-12442: 132]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-63052: 122, fedora-12442: 134]}, unionCH=null, actualMembers=[fedora-63052, fedora-12442], persistentUUIDs=[9d7f2ddd-46f1-4ecb-a6e7-43b04101303d, 3367a0a1-6751-4b02-9332-277aa9772cfa]}
04:29:47,188 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=org.infinispan.CONFIG][Scope=fedora-63052]ISPN100002: Started rebalance with topology id 11
04:29:47,192 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=12, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-63052: 124, fedora-12442: 132]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-63052: 122, fedora-12442: 134]}, unionCH=null, actualMembers=[fedora-63052, fedora-12442], persistentUUIDs=[9d7f2ddd-46f1-4ecb-a6e7-43b04101303d, 3367a0a1-6751-4b02-9332-277aa9772cfa]}
04:29:47,192 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=___counter_configuration][Scope=fedora-63052]ISPN100002: Started rebalance with topology id 12
04:29:47,193 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t23) [Context=___counter_configuration][Scope=fedora-63052]ISPN100003: Node fedora-63052 finished rebalance phase with topology id 12
04:29:47,201 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=org.infinispan.CONFIG][Scope=fedora-12442]ISPN100003: Node fedora-12442 finished rebalance phase with topology id 12
04:29:47,201 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t6) [Context=org.infinispan.CONFIG][Scope=fedora-12442]ISPN100003: Node fedora-12442 finished rebalance phase with topology id 11
04:29:47,203 INFO  [org.infinispan.CLUSTER] (jgroups-47,fedora-63052) ISPN000094: Received new cluster view for channel results: [fedora-63052|3] (2) [fedora-63052, fedora-12442]
04:29:47,203 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (remote-thread--p2-t5) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=org.infinispan.CONFIG, type=REBALANCE_PHASE_CONFIRM, sender=fedora-12442, joinInfo=null, topologyId=12, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-12442 for cache org.infinispan.CONFIG, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.invokeReplicableCommand(GlobalInboundInvocationHandler.java:169) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.runReplicableCommand(GlobalInboundInvocationHandler.java:150) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.lambda$handleReplicableCommand$1(GlobalInboundInvocationHandler.java:144) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.util.concurrent.BlockingTaskAwareExecutorServiceImpl$RunnableWrapper.run(BlockingTaskAwareExecutorServiceImpl.java:212) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
04:29:47,204 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (remote-thread--p2-t6) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=org.infinispan.CONFIG, type=REBALANCE_PHASE_CONFIRM, sender=fedora-12442, joinInfo=null, topologyId=11, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-12442 for cache org.infinispan.CONFIG, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.invokeReplicableCommand(GlobalInboundInvocationHandler.java:169) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.runReplicableCommand(GlobalInboundInvocationHandler.java:150) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.lambda$handleReplicableCommand$1(GlobalInboundInvocationHandler.java:144) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.util.concurrent.BlockingTaskAwareExecutorServiceImpl$RunnableWrapper.run(BlockingTaskAwareExecutorServiceImpl.java:212) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
04:29:47,204 INFO  [org.infinispan.CLUSTER] (jgroups-47,fedora-63052) ISPN100001: Node fedora-14064 left the cluster
04:29:47,207 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t6) [Context=___counter_configuration][Scope=fedora-12442]ISPN100003: Node fedora-12442 finished rebalance phase with topology id 12
04:29:47,208 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t6) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 12
04:29:47,209 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t24) [Context=___counter_configuration][Scope=fedora-63052]ISPN100003: Node fedora-63052 finished rebalance phase with topology id 13
04:29:47,218 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t6) [Context=___counter_configuration][Scope=fedora-12442]ISPN100003: Node fedora-12442 finished rebalance phase with topology id 13
04:29:47,227 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t31) [Context=___counter_configuration][Scope=fedora-12442]ISPN100003: Node fedora-12442 finished rebalance phase with topology id 14
04:29:47,231 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=___counter_configuration][Scope=fedora-12442]ISPN100003: Node fedora-12442 finished rebalance phase with topology id 15
04:29:47,232 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (remote-thread--p2-t5) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___counter_configuration, type=REBALANCE_PHASE_CONFIRM, sender=fedora-12442, joinInfo=null, topologyId=15, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=3}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-12442 for cache ___counter_configuration, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.invokeReplicableCommand(GlobalInboundInvocationHandler.java:169) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.runReplicableCommand(GlobalInboundInvocationHandler.java:150) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.lambda$handleReplicableCommand$1(GlobalInboundInvocationHandler.java:144) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.util.concurrent.BlockingTaskAwareExecutorServiceImpl$RunnableWrapper.run(BlockingTaskAwareExecutorServiceImpl.java:212) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
04:29:47,232 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (remote-thread--p2-t31) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___counter_configuration, type=REBALANCE_PHASE_CONFIRM, sender=fedora-12442, joinInfo=null, topologyId=14, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=3}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-12442 for cache ___counter_configuration, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.invokeReplicableCommand(GlobalInboundInvocationHandler.java:169) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.runReplicableCommand(GlobalInboundInvocationHandler.java:150) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.lambda$handleReplicableCommand$1(GlobalInboundInvocationHandler.java:144) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.util.concurrent.BlockingTaskAwareExecutorServiceImpl$RunnableWrapper.run(BlockingTaskAwareExecutorServiceImpl.java:212) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
04:29:47,232 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (remote-thread--p2-t6) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___counter_configuration, type=REBALANCE_PHASE_CONFIRM, sender=fedora-12442, joinInfo=null, topologyId=13, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=3}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-12442 for cache ___counter_configuration, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.invokeReplicableCommand(GlobalInboundInvocationHandler.java:169) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.runReplicableCommand(GlobalInboundInvocationHandler.java:150) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.lambda$handleReplicableCommand$1(GlobalInboundInvocationHandler.java:144) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.util.concurrent.BlockingTaskAwareExecutorServiceImpl$RunnableWrapper.run(BlockingTaskAwareExecutorServiceImpl.java:212) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
04:29:47,236 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (StopThread) ISPN000080: Disconnecting JGroups channel results
04:29:47,270 WARN  [org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler] (remote-thread--p2-t6) ISPN000219: Shutdown while handling command CacheTopologyControlCommand{cache=___protobuf_metadata, type=LEAVE, sender=fedora-12442, joinInfo=null, topologyId=0, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=3}
04:29:47,275 INFO  [org.radargun.service.Infinispan90Lifecycle] (StopThread) Stopped, previous view is [fedora-63052, fedora-12442, fedora-14064]
04:29:47,276 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Service successfully stopped.
04:29:47,277 INFO  [org.radargun.Slave] (sc-main) Finished stage ScenarioDestroy
04:29:47,278 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
04:29:47,334 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.service.Infinispan80EmbeddedService.destroy() overrides public void org.radargun.service.Infinispan60EmbeddedService.destroy() but both are declared with @Destroy annotation: calling only once
04:29:47,335 INFO  [org.radargun.Slave] (main) Starting stage ScenarioCleanup
04:29:47,336 WARN  [org.radargun.stages.ScenarioCleanupStage] (main) Unfinished thread ForkJoinPool.commonPool-worker-3 (id=34, state=WAITING)
	at java.base@11.0.6-internal/jdk.internal.misc.Unsafe.park(Native Method)
	at java.base@11.0.6-internal/java.util.concurrent.locks.LockSupport.park(LockSupport.java:194)
	at java.base@11.0.6-internal/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1628)
	at java.base@11.0.6-internal/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:177)
04:29:47,337 INFO  [org.radargun.stages.ScenarioCleanupStage] (main) Interrupting thread ForkJoinPool.commonPool-worker-3 (id=34, state=WAITING)
04:29:52,338 INFO  [org.radargun.stages.ScenarioCleanupStage] (main) Stopping thread ForkJoinPool.commonPool-worker-3 (id=34, state=WAITING)
04:29:52,343 INFO  [org.radargun.stages.ScenarioCleanupStage] (main) Is thread ForkJoinPool.commonPool-worker-3 (id=34, state=TERMINATED)) alive? false
04:29:52,461 INFO  [org.radargun.stages.ScenarioCleanupStage] (main) Memory after cleanup: 
Runtime free: 1,380,646 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,233 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,696 kb
MX Metaspace(Non-heap memory): used: 44,700 kb, init: 0 kb, committed: 46,204 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 9,235 kb, init: 2,496 kb, committed: 13,120 kb, max: 120,032 kb
MX Compressed Class Space(Non-heap memory): used: 5,045 kb, init: 0 kb, committed: 5,580 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 0 kb, init: 73,728 kb, committed: 880,640 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 17,625 kb, init: 1,325,056 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 0 kb, init: 0 kb, committed: 0 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 4,473 kb, init: 2,496 kb, committed: 5,568 kb, max: 120,032 kb
04:29:52,463 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
04:29:52,518 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
04:30:02,146 INFO  [org.radargun.Slave] (main) Master shutdown!
04:30:02,148 INFO  [org.radargun.ShutDownHook] (Thread-0) Slave process is being shutdown
