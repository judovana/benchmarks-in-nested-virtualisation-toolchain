18:43:22,006 INFO  [org.radargun.RemoteMasterConnection] (main) Attempting to connect to master results:2103
18:43:22,017 INFO  [org.radargun.RemoteMasterConnection] (main) Successfully established connection with master at: results:2103
18:43:22,027 INFO  [org.radargun.Slave] (main) Received slave index 0
18:43:22,027 INFO  [org.radargun.Slave] (main) Received slave count 3
18:43:22,356 INFO  [org.radargun.ServiceHelper] (sc-main) ServiceContext properties: {}
18:43:22,436 INFO  [org.radargun.Slave] (sc-main) Eager Service Infinispan92EmbeddedService {batching=false, cache=testCache, channelRetrievalTimeout=2 mins 0 secs, enableDiagnostics=null, explicitLocking=false, file=/mnt/workspace/results/dist-sync.xml, internalsExpositionEnabled=false, jgroupsDumperEnabled=false, jgroupsDumperInterval=10.000 secs, keysPerThread=-1, mapReduceDistributedReducePhase=false, mapReduceUseIntermediateSharedCache=false, removedCaches=[  ], threadsPerNode=-1 } loaded.
18:43:24,208 INFO  [org.radargun.Slave] (sc-main) Starting stage ScenarioInit
18:43:24,264 INFO  [org.radargun.Slave] (sc-main) Finished stage ScenarioInit
18:43:24,284 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
18:43:24,486 INFO  [org.radargun.Slave] (sc-main) Starting stage BeforeServiceStart
18:43:24,486 INFO  [org.radargun.Slave] (sc-main) Finished stage BeforeServiceStart
18:43:24,487 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
18:43:24,512 INFO  [org.radargun.Slave] (sc-main) Starting stage ServiceStart
18:43:24,513 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Startup staggering, this is the slave with index 0, not sleeping
18:43:24,513 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 0
18:43:24,519 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) Infinispan version: Infinispan 'Gaina' 9.2.0.Final
18:43:24,534 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) JGroups version: JGroups 4.0.10.Final (Schiener Berg)
18:43:25,063 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (sc-main) ISPN000078: Starting JGroups channel results
18:43:25,154 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the send buffer of socket MulticastSocket was set to 1.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
18:43:25,154 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the receive buffer of socket MulticastSocket was set to 20.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
18:43:25,155 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the send buffer of socket MulticastSocket was set to 1.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
18:43:25,156 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the receive buffer of socket MulticastSocket was set to 25.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
18:43:30,182 INFO  [org.infinispan.CLUSTER] (sc-main) ISPN000094: Received new cluster view for channel results: [fedora-52069|0] (1) [fedora-52069]
18:43:30,280 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (sc-main) ISPN000079: Channel results local address is fedora-52069, physical addresses are [192.168.124.65:41339]
18:43:30,283 INFO  [org.infinispan.factories.GlobalComponentRegistry] (sc-main) ISPN000128: Infinispan version: Infinispan 'Gaina' 9.2.0.Final
18:43:30,692 INFO  [org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup] (sc-main) ISPN000107: Retrieving transaction manager Transaction: unknown
18:43:30,789 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) No RELAY2 protocol in XS service
18:43:30,790 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) No RELAY2 protocol in XS service
18:43:30,793 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) ([fedora-52069(local=true, coord=true)]) Number of members=1 is not the one expected: 3
18:43:31,240 INFO  [org.infinispan.CLUSTER] (jgroups-6,fedora-52069) ISPN000094: Received new cluster view for channel results: [fedora-52069|1] (2) [fedora-52069, fedora-14835]
18:43:31,256 INFO  [org.infinispan.CLUSTER] (jgroups-6,fedora-52069) ISPN100000: Node fedora-14835 joined the cluster
18:43:31,622 INFO  [org.infinispan.CLUSTER] (jgroups-12,fedora-52069) ISPN000094: Received new cluster view for channel results: [fedora-52069|2] (3) [fedora-52069, fedora-14835, fedora-33178]
18:43:31,626 INFO  [org.infinispan.CLUSTER] (jgroups-12,fedora-52069) ISPN100000: Node fedora-33178 joined the cluster
18:43:31,697 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-52069: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-52069: 123, fedora-14835: 133]}, unionCH=null, actualMembers=[fedora-52069, fedora-14835], persistentUUIDs=[f4f19f47-22fe-490b-82ed-ace621639cd7, 457758fb-63fc-462b-972b-00a4c6481915]}
18:43:31,699 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-52069]ISPN100002: Started rebalance with topology id 2
18:43:31,697 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-52069: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-52069: 123, fedora-14835: 133]}, unionCH=null, actualMembers=[fedora-52069, fedora-14835], persistentUUIDs=[f4f19f47-22fe-490b-82ed-ace621639cd7, 457758fb-63fc-462b-972b-00a4c6481915]}
18:43:31,704 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-52069]ISPN100002: Started rebalance with topology id 2
18:43:31,734 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=___counter_configuration][Scope=fedora-52069]ISPN100003: Node fedora-52069 finished rebalance phase with topology id 2
18:43:31,759 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t23) [Context=org.infinispan.CONFIG][Scope=fedora-52069]ISPN100003: Node fedora-52069 finished rebalance phase with topology id 2
18:43:31,794 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) Number of members is the one expected: 3
18:43:31,794 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Successfully started cache service infinispan92/embedded on slave 0
18:43:31,887 ERROR [org.radargun.service.ConfigDumpHelper] (sc-main) Error while dumping ___protobuf_metadata cache config as properties
javax.management.AttributeNotFoundException: Unknown attribute 'configurationAsProperties'. Known attributes names are: [rebalancingEnabled, cacheStatus, cacheName, cacheAvailability, version, configurationAsProperties]
	at org.infinispan.jmx.ResourceDMBean.getAttribute(ResourceDMBean.java:181) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:636) ~[?:?]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:679) ~[?:?]
	at org.radargun.service.ConfigDumpHelper60.dumpCache(ConfigDumpHelper60.java:44) [plugin-infinispan60-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.service.EmbeddedConfigurationProvider.getNormalizedConfigs(EmbeddedConfigurationProvider.java:33) [plugin-infinispan52-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.stages.lifecycle.ServiceStartStage.executeOnSlave(ServiceStartStage.java:92) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase.scenarioLoop(SlaveBase.java:102) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase$ScenarioRunner.run(SlaveBase.java:203) [radargun-core-3.0.0-SNAPSHOT.jar:?]
18:43:31,919 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-14835]ISPN100003: Node fedora-14835 finished rebalance phase with topology id 2
18:43:31,920 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 2
18:43:31,926 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-14835]ISPN100003: Node fedora-14835 finished rebalance phase with topology id 2
18:43:31,934 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 2
18:43:31,923 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t1) [Context=___counter_configuration][Scope=fedora-52069]ISPN100003: Node fedora-52069 finished rebalance phase with topology id 3
18:43:31,938 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t5) [Context=org.infinispan.CONFIG][Scope=fedora-52069]ISPN100003: Node fedora-52069 finished rebalance phase with topology id 3
18:43:31,947 ERROR [org.radargun.service.ConfigDumpHelper] (sc-main) Error while dumping ___protobuf_metadata cache config as properties
javax.management.AttributeNotFoundException: Unknown attribute 'configurationAsProperties'. Known attributes names are: [rebalancingEnabled, cacheStatus, cacheName, cacheAvailability, version, configurationAsProperties]
	at org.infinispan.jmx.ResourceDMBean.getAttribute(ResourceDMBean.java:181) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:636) ~[?:?]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:679) ~[?:?]
	at org.radargun.service.ConfigDumpHelper60.dumpCache(ConfigDumpHelper60.java:44) [plugin-infinispan60-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.service.EmbeddedConfigurationProvider.getNormalizedConfigs(EmbeddedConfigurationProvider.java:33) [plugin-infinispan52-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.stages.lifecycle.ServiceStartStage.executeOnSlave(ServiceStartStage.java:92) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase.scenarioLoop(SlaveBase.java:102) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase$ScenarioRunner.run(SlaveBase.java:203) [radargun-core-3.0.0-SNAPSHOT.jar:?]
18:43:31,950 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-14835]ISPN100003: Node fedora-14835 finished rebalance phase with topology id 3
18:43:31,952 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=org.infinispan.CONFIG][Scope=fedora-52069]ISPN100003: Node fedora-52069 finished rebalance phase with topology id 4
18:43:31,954 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-14835]ISPN100003: Node fedora-14835 finished rebalance phase with topology id 3
18:43:31,956 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t10) [Context=___counter_configuration][Scope=fedora-52069]ISPN100003: Node fedora-52069 finished rebalance phase with topology id 4
18:43:31,979 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-14835]ISPN100003: Node fedora-14835 finished rebalance phase with topology id 4
18:43:31,979 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-14835]ISPN100003: Node fedora-14835 finished rebalance phase with topology id 4
18:43:32,028 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=DefaultConsistentHash{ns=256, owners = (1)[fedora-52069: 256+0]}, pendingCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-52069: 123+133, fedora-14835: 133+123]}, unionCH=null, actualMembers=[fedora-52069, fedora-14835], persistentUUIDs=[f4f19f47-22fe-490b-82ed-ace621639cd7, 457758fb-63fc-462b-972b-00a4c6481915]}
18:43:32,029 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-52069]ISPN100002: Started rebalance with topology id 2
18:43:32,031 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=___counters][Scope=fedora-52069]ISPN100003: Node fedora-52069 finished rebalance phase with topology id 2
18:43:32,038 INFO  [org.radargun.Slave] (sc-main) Finished stage ServiceStart
18:43:32,073 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-52069: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-52069: 123, fedora-14835: 133]}, unionCH=null, actualMembers=[fedora-52069, fedora-14835], persistentUUIDs=[f4f19f47-22fe-490b-82ed-ace621639cd7, 457758fb-63fc-462b-972b-00a4c6481915]}
18:43:32,078 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-52069]ISPN100002: Started rebalance with topology id 2
18:43:32,075 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
18:43:32,093 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t25) [Context=___protobuf_metadata][Scope=fedora-52069]ISPN100003: Node fedora-52069 finished rebalance phase with topology id 2
18:43:32,098 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-14835]ISPN100003: Node fedora-14835 finished rebalance phase with topology id 2
18:43:32,099 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache ___counters, topology id = 2
18:43:32,101 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t24) [Context=___counters][Scope=fedora-52069]ISPN100003: Node fedora-52069 finished rebalance phase with topology id 3
18:43:32,111 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-14835]ISPN100003: Node fedora-14835 finished rebalance phase with topology id 3
18:43:32,114 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t6) [Context=___counters][Scope=fedora-52069]ISPN100003: Node fedora-52069 finished rebalance phase with topology id 4
18:43:32,123 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-14835]ISPN100003: Node fedora-14835 finished rebalance phase with topology id 4
18:43:32,141 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-14835]ISPN100003: Node fedora-14835 finished rebalance phase with topology id 2
18:43:32,142 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=DefaultConsistentHash{ns=512, owners = (1)[fedora-52069: 512+0]}, pendingCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-52069: 249+263, fedora-14835: 263+249]}, unionCH=null, actualMembers=[fedora-52069, fedora-14835], persistentUUIDs=[f4f19f47-22fe-490b-82ed-ace621639cd7, 457758fb-63fc-462b-972b-00a4c6481915]}
18:43:32,143 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 2
18:43:32,144 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-52069]ISPN100002: Started rebalance with topology id 2
18:43:32,146 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t15) [Context=testCache][Scope=fedora-52069]ISPN100003: Node fedora-52069 finished rebalance phase with topology id 2
18:43:32,148 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t19) [Context=___protobuf_metadata][Scope=fedora-52069]ISPN100003: Node fedora-52069 finished rebalance phase with topology id 3
18:43:32,153 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-14835]ISPN100003: Node fedora-14835 finished rebalance phase with topology id 3
18:43:32,155 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=___protobuf_metadata][Scope=fedora-52069]ISPN100003: Node fedora-52069 finished rebalance phase with topology id 4
18:43:32,162 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-14835]ISPN100003: Node fedora-14835 finished rebalance phase with topology id 4
18:43:32,186 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-14835]ISPN100003: Node fedora-14835 finished rebalance phase with topology id 2
18:43:32,187 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache testCache, topology id = 2
18:43:32,190 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t1) [Context=testCache][Scope=fedora-52069]ISPN100003: Node fedora-52069 finished rebalance phase with topology id 3
18:43:32,194 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-14835]ISPN100003: Node fedora-14835 finished rebalance phase with topology id 3
18:43:32,196 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t24) [Context=testCache][Scope=fedora-52069]ISPN100003: Node fedora-52069 finished rebalance phase with topology id 4
18:43:32,199 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-14835]ISPN100003: Node fedora-14835 finished rebalance phase with topology id 4
18:43:32,331 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-52069: 123, fedora-14835: 133]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-52069: 85, fedora-14835: 90, fedora-33178: 81]}, unionCH=null, actualMembers=[fedora-52069, fedora-14835, fedora-33178], persistentUUIDs=[f4f19f47-22fe-490b-82ed-ace621639cd7, 457758fb-63fc-462b-972b-00a4c6481915, 8efb2bc0-e64d-4390-a07a-3d00183c77be]}
18:43:32,332 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-52069: 123, fedora-14835: 133]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-52069: 85, fedora-14835: 90, fedora-33178: 81]}, unionCH=null, actualMembers=[fedora-52069, fedora-14835, fedora-33178], persistentUUIDs=[f4f19f47-22fe-490b-82ed-ace621639cd7, 457758fb-63fc-462b-972b-00a4c6481915, 8efb2bc0-e64d-4390-a07a-3d00183c77be]}
18:43:32,332 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-52069]ISPN100002: Started rebalance with topology id 6
18:43:32,332 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-52069]ISPN100002: Started rebalance with topology id 6
18:43:32,335 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t10) [Context=org.infinispan.CONFIG][Scope=fedora-52069]ISPN100003: Node fedora-52069 finished rebalance phase with topology id 6
18:43:32,336 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t12) [Context=___counter_configuration][Scope=fedora-52069]ISPN100003: Node fedora-52069 finished rebalance phase with topology id 6
18:43:32,339 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-14835]ISPN100003: Node fedora-14835 finished rebalance phase with topology id 6
18:43:32,340 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-14835]ISPN100003: Node fedora-14835 finished rebalance phase with topology id 6
18:43:32,448 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-33178]ISPN100003: Node fedora-33178 finished rebalance phase with topology id 6
18:43:32,449 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 6
18:43:32,450 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t18) [Context=org.infinispan.CONFIG][Scope=fedora-52069]ISPN100003: Node fedora-52069 finished rebalance phase with topology id 7
18:43:32,453 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-14835]ISPN100003: Node fedora-14835 finished rebalance phase with topology id 7
18:43:32,461 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-33178]ISPN100003: Node fedora-33178 finished rebalance phase with topology id 7
18:43:32,463 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=org.infinispan.CONFIG][Scope=fedora-52069]ISPN100003: Node fedora-52069 finished rebalance phase with topology id 8
18:43:32,463 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-33178]ISPN100003: Node fedora-33178 finished rebalance phase with topology id 6
18:43:32,464 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 6
18:43:32,465 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=___counter_configuration][Scope=fedora-52069]ISPN100003: Node fedora-52069 finished rebalance phase with topology id 7
18:43:32,467 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-14835]ISPN100003: Node fedora-14835 finished rebalance phase with topology id 8
18:43:32,469 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-33178]ISPN100003: Node fedora-33178 finished rebalance phase with topology id 7
18:43:32,471 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-33178]ISPN100003: Node fedora-33178 finished rebalance phase with topology id 8
18:43:32,473 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-14835]ISPN100003: Node fedora-14835 finished rebalance phase with topology id 7
18:43:32,474 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t24) [Context=___counter_configuration][Scope=fedora-52069]ISPN100003: Node fedora-52069 finished rebalance phase with topology id 8
18:43:32,479 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-14835]ISPN100003: Node fedora-14835 finished rebalance phase with topology id 8
18:43:32,498 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-33178]ISPN100003: Node fedora-33178 finished rebalance phase with topology id 8
18:43:32,514 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-52069: 123+133, fedora-14835: 133+123]}, pendingCH=DefaultConsistentHash{ns=256, owners = (3)[fedora-52069: 85+79, fedora-14835: 90+83, fedora-33178: 81+94]}, unionCH=null, actualMembers=[fedora-52069, fedora-14835, fedora-33178], persistentUUIDs=[f4f19f47-22fe-490b-82ed-ace621639cd7, 457758fb-63fc-462b-972b-00a4c6481915, 8efb2bc0-e64d-4390-a07a-3d00183c77be]}
18:43:32,515 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-52069]ISPN100002: Started rebalance with topology id 6
18:43:32,517 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t17) [Context=___counters][Scope=fedora-52069]ISPN100003: Node fedora-52069 finished rebalance phase with topology id 6
18:43:32,521 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-14835]ISPN100003: Node fedora-14835 finished rebalance phase with topology id 6
18:43:32,544 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-33178]ISPN100003: Node fedora-33178 finished rebalance phase with topology id 6
18:43:32,544 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___counters, topology id = 6
18:43:32,546 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t14) [Context=___counters][Scope=fedora-52069]ISPN100003: Node fedora-52069 finished rebalance phase with topology id 7
18:43:32,548 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-14835]ISPN100003: Node fedora-14835 finished rebalance phase with topology id 7
18:43:32,551 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-33178]ISPN100003: Node fedora-33178 finished rebalance phase with topology id 7
18:43:32,552 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t18) [Context=___counters][Scope=fedora-52069]ISPN100003: Node fedora-52069 finished rebalance phase with topology id 8
18:43:32,554 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-14835]ISPN100003: Node fedora-14835 finished rebalance phase with topology id 8
18:43:32,557 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-33178]ISPN100003: Node fedora-33178 finished rebalance phase with topology id 8
18:43:32,582 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-52069: 123, fedora-14835: 133]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-52069: 85, fedora-14835: 90, fedora-33178: 81]}, unionCH=null, actualMembers=[fedora-52069, fedora-14835, fedora-33178], persistentUUIDs=[f4f19f47-22fe-490b-82ed-ace621639cd7, 457758fb-63fc-462b-972b-00a4c6481915, 8efb2bc0-e64d-4390-a07a-3d00183c77be]}
18:43:32,582 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-52069]ISPN100002: Started rebalance with topology id 6
18:43:32,583 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t4) [Context=___protobuf_metadata][Scope=fedora-52069]ISPN100003: Node fedora-52069 finished rebalance phase with topology id 6
18:43:32,589 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-14835]ISPN100003: Node fedora-14835 finished rebalance phase with topology id 6
18:43:32,609 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-33178]ISPN100003: Node fedora-33178 finished rebalance phase with topology id 6
18:43:32,609 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 6
18:43:32,612 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t5) [Context=___protobuf_metadata][Scope=fedora-52069]ISPN100003: Node fedora-52069 finished rebalance phase with topology id 7
18:43:32,615 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-14835]ISPN100003: Node fedora-14835 finished rebalance phase with topology id 7
18:43:32,618 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-33178]ISPN100003: Node fedora-33178 finished rebalance phase with topology id 7
18:43:32,620 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=___protobuf_metadata][Scope=fedora-52069]ISPN100003: Node fedora-52069 finished rebalance phase with topology id 8
18:43:32,624 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-33178]ISPN100003: Node fedora-33178 finished rebalance phase with topology id 8
18:43:32,624 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-14835]ISPN100003: Node fedora-14835 finished rebalance phase with topology id 8
18:43:32,635 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-52069: 249+263, fedora-14835: 263+249]}, pendingCH=DefaultConsistentHash{ns=512, owners = (3)[fedora-52069: 172+164, fedora-14835: 180+178, fedora-33178: 160+170]}, unionCH=null, actualMembers=[fedora-52069, fedora-14835, fedora-33178], persistentUUIDs=[f4f19f47-22fe-490b-82ed-ace621639cd7, 457758fb-63fc-462b-972b-00a4c6481915, 8efb2bc0-e64d-4390-a07a-3d00183c77be]}
18:43:32,635 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-52069]ISPN100002: Started rebalance with topology id 6
18:43:32,637 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t17) [Context=testCache][Scope=fedora-52069]ISPN100003: Node fedora-52069 finished rebalance phase with topology id 6
18:43:32,641 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-14835]ISPN100003: Node fedora-14835 finished rebalance phase with topology id 6
18:43:32,656 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-33178]ISPN100003: Node fedora-33178 finished rebalance phase with topology id 6
18:43:32,656 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache testCache, topology id = 6
18:43:32,659 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t14) [Context=testCache][Scope=fedora-52069]ISPN100003: Node fedora-52069 finished rebalance phase with topology id 7
18:43:32,661 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-14835]ISPN100003: Node fedora-14835 finished rebalance phase with topology id 7
18:43:32,665 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-33178]ISPN100003: Node fedora-33178 finished rebalance phase with topology id 7
18:43:32,667 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t25) [Context=testCache][Scope=fedora-52069]ISPN100003: Node fedora-52069 finished rebalance phase with topology id 8
18:43:32,670 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-14835]ISPN100003: Node fedora-14835 finished rebalance phase with topology id 8
18:43:32,675 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-33178]ISPN100003: Node fedora-33178 finished rebalance phase with topology id 8
18:43:32,798 INFO  [org.radargun.Slave] (sc-main) Starting stage AfterServiceStart
18:43:32,799 INFO  [org.radargun.Slave] (sc-main) Finished stage AfterServiceStart
18:43:32,801 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
18:43:32,925 INFO  [org.radargun.Slave] (sc-main) Starting stage MonitorStart
18:43:32,930 INFO  [org.radargun.sysmonitor.AbstractMonitors] (sc-main) Gathering statistics every 1000 ms
18:43:32,931 INFO  [org.radargun.Slave] (sc-main) Finished stage MonitorStart
18:43:32,931 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
18:43:32,969 INFO  [org.radargun.Slave] (sc-main) Starting stage Load
18:43:40,747 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) This node loaded 10000 entries (~10000000 bytes)
18:43:46,812 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) This node loaded 20000 entries (~20000000 bytes)
18:43:51,628 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) This node loaded 30000 entries (~30000000 bytes)
18:43:52,423 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) Finished loading entries
18:43:52,467 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) Finished loading entries
18:43:52,475 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) Finished loading entries
18:43:52,481 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) Finished loading entries
18:43:52,492 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) Finished loading entries
18:43:52,494 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) Finished loading entries
18:43:52,498 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) Finished loading entries
18:43:52,505 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) Finished loading entries
18:43:52,507 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) Finished loading entries
18:43:52,512 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) Finished loading entries
18:43:52,513 INFO  [org.radargun.Slave] (sc-main) Finished stage Load
18:43:52,513 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
18:43:52,543 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.stages.cache.test.BasicOperationsTestStage.init() overrides public void org.radargun.stages.test.TestStage.init() but both are declared with @Init annotation: calling only once
18:43:52,547 INFO  [org.radargun.Slave] (sc-main) Starting stage BasicOperationsTest
18:43:52,549 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using key generator org.radargun.stages.cache.generators.StringKeyGenerator {format=null }
18:43:52,550 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using value generator org.radargun.stages.cache.generators.ByteArrayValueGenerator { }
18:43:52,550 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using cache selector Default { }
18:43:52,551 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Starting test warmup
18:43:52,566 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Started 4 stressor threads.
18:44:52,570 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Finished test. Test duration is: 1 mins 0 secs
18:44:52,573 INFO  [org.radargun.Slave] (sc-main) Finished stage BasicOperationsTest
18:44:52,596 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
18:44:52,613 INFO  [org.radargun.Slave] (sc-main) Starting stage Clear
18:44:52,615 INFO  [org.radargun.stages.cache.ClearStage] (sc-main) Before executing clear, memory looks like this: 
Runtime free: 1,031,138 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,595 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,700 kb
MX Metaspace(Non-heap memory): used: 36,038 kb, init: 0 kb, committed: 36,608 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 12,002 kb, init: 2,496 kb, committed: 12,032 kb, max: 120,028 kb
MX Compressed Class Space(Non-heap memory): used: 4,216 kb, init: 0 kb, committed: 4,480 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 195,584 kb, init: 69,632 kb, committed: 818,176 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 108,573 kb, init: 1,329,152 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 62,464 kb, init: 0 kb, committed: 62,464 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 6,464 kb, init: 2,496 kb, committed: 6,528 kb, max: 120,032 kb
18:44:52,795 INFO  [org.radargun.stages.cache.ClearStage] (sc-main) After executing clear, memory looks like this: 
Runtime free: 1,380,221 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,595 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,700 kb
MX Metaspace(Non-heap memory): used: 36,041 kb, init: 0 kb, committed: 36,608 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 11,836 kb, init: 2,496 kb, committed: 12,096 kb, max: 120,028 kb
MX Compressed Class Space(Non-heap memory): used: 4,211 kb, init: 0 kb, committed: 4,480 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 0 kb, init: 69,632 kb, committed: 880,640 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 18,050 kb, init: 1,329,152 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 0 kb, init: 0 kb, committed: 0 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 6,474 kb, init: 2,496 kb, committed: 6,528 kb, max: 120,032 kb
18:44:52,797 INFO  [org.radargun.Slave] (sc-main) Finished stage Clear
18:44:52,799 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
18:44:52,820 INFO  [org.radargun.Slave] (sc-main) Starting stage Load
18:44:55,185 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) This node loaded 10000 entries (~10000000 bytes)
18:44:57,596 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) This node loaded 20000 entries (~20000000 bytes)
18:44:59,900 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) This node loaded 30000 entries (~30000000 bytes)
18:45:00,562 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) Finished loading entries
18:45:00,609 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) Finished loading entries
18:45:00,610 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) Finished loading entries
18:45:00,611 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) Finished loading entries
18:45:00,613 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) Finished loading entries
18:45:00,616 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) Finished loading entries
18:45:00,622 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) Finished loading entries
18:45:00,628 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) Finished loading entries
18:45:00,634 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) Finished loading entries
18:45:00,637 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) Finished loading entries
18:45:00,638 INFO  [org.radargun.Slave] (sc-main) Finished stage Load
18:45:00,639 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
18:45:00,879 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.stages.cache.test.BasicOperationsTestStage.init() overrides public void org.radargun.stages.test.TestStage.init() but both are declared with @Init annotation: calling only once
18:45:00,881 INFO  [org.radargun.Slave] (sc-main) Starting stage BasicOperationsTest
18:45:00,882 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using key generator org.radargun.stages.cache.generators.StringKeyGenerator {format=null }
18:45:00,882 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using value generator org.radargun.stages.cache.generators.ByteArrayValueGenerator { }
18:45:00,883 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using cache selector Default { }
18:45:00,883 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Starting test stress-test
18:45:00,923 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Started 4 stressor threads.
18:55:00,939 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Finished test. Test duration is: 10 mins 0 secs
18:55:00,940 INFO  [org.radargun.Slave] (sc-main) Finished stage BasicOperationsTest
18:55:01,093 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
18:55:01,294 INFO  [org.radargun.Slave] (sc-main) Starting stage MonitorStop
18:55:01,295 INFO  [org.radargun.Slave] (sc-main) Finished stage MonitorStop
18:55:01,296 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
18:55:01,301 INFO  [org.radargun.Slave] (sc-main) Starting stage ScenarioDestroy
18:55:01,302 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Scenario finished, destroying...
18:55:01,302 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Memory before cleanup: 
Runtime free: 367,653 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,598 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,700 kb
MX Metaspace(Non-heap memory): used: 36,707 kb, init: 0 kb, committed: 37,248 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 13,821 kb, init: 2,496 kb, committed: 13,824 kb, max: 120,028 kb
MX Compressed Class Space(Non-heap memory): used: 4,245 kb, init: 0 kb, committed: 4,480 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 575,488 kb, init: 69,632 kb, committed: 824,320 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 397,274 kb, init: 1,329,152 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 56,320 kb, init: 0 kb, committed: 56,320 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 7,676 kb, init: 2,496 kb, committed: 7,680 kb, max: 120,032 kb
18:55:01,303 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) Stopping service.
18:55:01,312 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t32) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-52069: 249+87, fedora-14835: 263+95]}, pendingCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-52069: 249+263, fedora-14835: 263+249]}, unionCH=null, actualMembers=[fedora-52069, fedora-14835], persistentUUIDs=[f4f19f47-22fe-490b-82ed-ace621639cd7, 457758fb-63fc-462b-972b-00a4c6481915]}
18:55:01,325 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t32) [Context=testCache][Scope=fedora-52069]ISPN100002: Started rebalance with topology id 11
18:55:01,328 WARN  [org.infinispan.CLUSTER] (remote-thread--p2-t24) [Context=testCache]ISPN000312: Lost data because of graceful leaver fedora-14835
18:55:01,350 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t24) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-52069: 124, fedora-14835: 132]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-52069: 123, fedora-14835: 133]}, unionCH=null, actualMembers=[fedora-52069, fedora-14835], persistentUUIDs=[f4f19f47-22fe-490b-82ed-ace621639cd7, 457758fb-63fc-462b-972b-00a4c6481915]}
18:55:01,351 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t24) [Context=___protobuf_metadata][Scope=fedora-52069]ISPN100002: Started rebalance with topology id 11
18:55:01,352 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t13) [Context=___protobuf_metadata][Scope=fedora-52069]ISPN100003: Node fedora-52069 finished rebalance phase with topology id 11
18:55:01,360 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t24) [Context=___protobuf_metadata][Scope=fedora-14835]ISPN100003: Node fedora-14835 finished rebalance phase with topology id 11
18:55:01,360 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t32) [Context=___protobuf_metadata][Scope=fedora-14835]ISPN100003: Node fedora-14835 finished rebalance phase with topology id 12
18:55:01,360 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (remote-thread--p2-t24) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___protobuf_metadata, type=REBALANCE_PHASE_CONFIRM, sender=fedora-14835, joinInfo=null, topologyId=11, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-14835 for cache ___protobuf_metadata, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.invokeReplicableCommand(GlobalInboundInvocationHandler.java:169) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.runReplicableCommand(GlobalInboundInvocationHandler.java:150) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.lambda$handleReplicableCommand$1(GlobalInboundInvocationHandler.java:144) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.util.concurrent.BlockingTaskAwareExecutorServiceImpl$RunnableWrapper.run(BlockingTaskAwareExecutorServiceImpl.java:212) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
18:55:01,361 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (remote-thread--p2-t32) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___protobuf_metadata, type=REBALANCE_PHASE_CONFIRM, sender=fedora-14835, joinInfo=null, topologyId=12, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-14835 for cache ___protobuf_metadata, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.invokeReplicableCommand(GlobalInboundInvocationHandler.java:169) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.runReplicableCommand(GlobalInboundInvocationHandler.java:150) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.lambda$handleReplicableCommand$1(GlobalInboundInvocationHandler.java:144) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.util.concurrent.BlockingTaskAwareExecutorServiceImpl$RunnableWrapper.run(BlockingTaskAwareExecutorServiceImpl.java:212) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
18:55:01,368 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t24) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-52069: 128+36, fedora-14835: 128+45]}, pendingCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-52069: 123+133, fedora-14835: 133+123]}, unionCH=null, actualMembers=[fedora-52069, fedora-14835], persistentUUIDs=[f4f19f47-22fe-490b-82ed-ace621639cd7, 457758fb-63fc-462b-972b-00a4c6481915]}
18:55:01,369 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t24) [Context=___counters][Scope=fedora-52069]ISPN100002: Started rebalance with topology id 11
18:55:01,369 WARN  [org.infinispan.CLUSTER] (remote-thread--p2-t32) [Context=___counters]ISPN000312: Lost data because of graceful leaver fedora-14835
18:55:01,375 INFO  [org.infinispan.CLUSTER] (StopThread) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-14835: 130, fedora-33178: 126]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-14835: 131, fedora-33178: 125]}, unionCH=null, actualMembers=[fedora-14835, fedora-33178], persistentUUIDs=[457758fb-63fc-462b-972b-00a4c6481915, 8efb2bc0-e64d-4390-a07a-3d00183c77be]}
18:55:01,378 INFO  [org.infinispan.CLUSTER] (StopThread) [Context=org.infinispan.CONFIG][Scope=fedora-52069]ISPN100002: Started rebalance with topology id 11
18:55:01,388 INFO  [org.infinispan.CLUSTER] (StopThread) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=12, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-14835: 130, fedora-33178: 126]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-14835: 131, fedora-33178: 125]}, unionCH=null, actualMembers=[fedora-14835, fedora-33178], persistentUUIDs=[457758fb-63fc-462b-972b-00a4c6481915, 8efb2bc0-e64d-4390-a07a-3d00183c77be]}
18:55:01,388 INFO  [org.infinispan.CLUSTER] (StopThread) [Context=___counter_configuration][Scope=fedora-52069]ISPN100002: Started rebalance with topology id 12
18:55:01,399 INFO  [org.infinispan.CLUSTER] (jgroups-36,fedora-52069) ISPN000094: Received new cluster view for channel results: [fedora-52069|3] (2) [fedora-52069, fedora-14835]
18:55:01,400 INFO  [org.infinispan.CLUSTER] (jgroups-36,fedora-52069) ISPN100001: Node fedora-33178 left the cluster
18:55:01,402 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (StopThread) ISPN000080: Disconnecting JGroups channel results
18:55:01,441 INFO  [org.radargun.service.Infinispan90Lifecycle] (StopThread) Stopped, previous view is [fedora-52069, fedora-14835, fedora-33178]
18:55:01,441 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Service successfully stopped.
18:55:01,441 INFO  [org.radargun.Slave] (sc-main) Finished stage ScenarioDestroy
18:55:01,442 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
18:55:02,424 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.service.Infinispan80EmbeddedService.destroy() overrides public void org.radargun.service.Infinispan60EmbeddedService.destroy() but both are declared with @Destroy annotation: calling only once
18:55:02,425 INFO  [org.radargun.Slave] (main) Starting stage ScenarioCleanup
18:55:02,472 INFO  [org.radargun.stages.ScenarioCleanupStage] (main) Memory after cleanup: 
Runtime free: 1,379,279 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,599 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,700 kb
MX Metaspace(Non-heap memory): used: 36,822 kb, init: 0 kb, committed: 37,376 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 10,027 kb, init: 2,496 kb, committed: 13,952 kb, max: 120,028 kb
MX Compressed Class Space(Non-heap memory): used: 4,266 kb, init: 0 kb, committed: 4,544 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 0 kb, init: 69,632 kb, committed: 880,640 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 18,992 kb, init: 1,329,152 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 0 kb, init: 0 kb, committed: 0 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 6,062 kb, init: 2,496 kb, committed: 7,744 kb, max: 120,032 kb
18:55:02,480 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
18:55:07,486 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
18:55:12,157 INFO  [org.radargun.Slave] (main) Master shutdown!
