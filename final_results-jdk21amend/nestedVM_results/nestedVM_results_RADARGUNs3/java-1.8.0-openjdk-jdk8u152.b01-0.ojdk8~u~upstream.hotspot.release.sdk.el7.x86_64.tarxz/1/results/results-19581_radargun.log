10:44:38,747 INFO  [org.radargun.RemoteMasterConnection] (main) Attempting to connect to master results:2103
10:44:38,755 INFO  [org.radargun.RemoteMasterConnection] (main) Successfully established connection with master at: results:2103
10:44:38,759 INFO  [org.radargun.Slave] (main) Received slave index 0
10:44:38,759 INFO  [org.radargun.Slave] (main) Received slave count 3
10:44:39,456 INFO  [org.radargun.ServiceHelper] (sc-main) ServiceContext properties: {}
10:44:39,680 INFO  [org.radargun.Slave] (sc-main) Eager Service Infinispan92EmbeddedService {batching=false, cache=testCache, channelRetrievalTimeout=2 mins 0 secs, enableDiagnostics=null, explicitLocking=false, file=/mnt/workspace/results/dist-sync.xml, internalsExpositionEnabled=false, jgroupsDumperEnabled=false, jgroupsDumperInterval=10.000 secs, keysPerThread=-1, mapReduceDistributedReducePhase=false, mapReduceUseIntermediateSharedCache=false, removedCaches=[  ], threadsPerNode=-1 } loaded.
10:44:41,735 INFO  [org.radargun.Slave] (sc-main) Starting stage ScenarioInit
10:44:41,786 INFO  [org.radargun.Slave] (sc-main) Finished stage ScenarioInit
10:44:41,791 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
10:44:41,795 INFO  [org.radargun.Slave] (sc-main) Starting stage BeforeServiceStart
10:44:41,795 INFO  [org.radargun.Slave] (sc-main) Finished stage BeforeServiceStart
10:44:41,796 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
10:44:41,812 INFO  [org.radargun.Slave] (sc-main) Starting stage ServiceStart
10:44:41,813 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Startup staggering, this is the slave with index 0, not sleeping
10:44:41,813 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 0
10:44:41,817 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) Infinispan version: Infinispan 'Gaina' 9.2.0.Final
10:44:41,830 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) JGroups version: JGroups 4.0.10.Final (Schiener Berg)
10:44:42,431 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (sc-main) ISPN000078: Starting JGroups channel results
10:44:42,516 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the send buffer of socket MulticastSocket was set to 1.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
10:44:42,516 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the receive buffer of socket MulticastSocket was set to 20.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
10:44:42,516 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the send buffer of socket MulticastSocket was set to 1.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
10:44:42,517 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the receive buffer of socket MulticastSocket was set to 25.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
10:44:47,550 INFO  [org.infinispan.CLUSTER] (sc-main) ISPN000094: Received new cluster view for channel results: [fedora-41269|0] (1) [fedora-41269]
10:44:47,613 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (sc-main) ISPN000079: Channel results local address is fedora-41269, physical addresses are [192.168.124.76:33637]
10:44:47,615 INFO  [org.infinispan.factories.GlobalComponentRegistry] (sc-main) ISPN000128: Infinispan version: Infinispan 'Gaina' 9.2.0.Final
10:44:48,270 INFO  [org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup] (sc-main) ISPN000107: Retrieving transaction manager Transaction: unknown
10:44:48,403 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) No RELAY2 protocol in XS service
10:44:48,404 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) No RELAY2 protocol in XS service
10:44:48,405 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) ([fedora-41269(local=true, coord=true)]) Number of members=1 is not the one expected: 3
10:44:48,634 INFO  [org.infinispan.CLUSTER] (jgroups-6,fedora-41269) ISPN000094: Received new cluster view for channel results: [fedora-41269|1] (2) [fedora-41269, fedora-24344]
10:44:48,641 INFO  [org.infinispan.CLUSTER] (jgroups-6,fedora-41269) ISPN100000: Node fedora-24344 joined the cluster
10:44:49,022 INFO  [org.infinispan.CLUSTER] (jgroups-11,fedora-41269) ISPN000094: Received new cluster view for channel results: [fedora-41269|2] (3) [fedora-41269, fedora-24344, fedora-38800]
10:44:49,027 INFO  [org.infinispan.CLUSTER] (jgroups-11,fedora-41269) ISPN100000: Node fedora-38800 joined the cluster
10:44:49,367 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-41269: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-41269: 129, fedora-24344: 127]}, unionCH=null, actualMembers=[fedora-41269, fedora-24344], persistentUUIDs=[f826e98b-b1da-4e51-9c2d-e1c557323cff, 820a45a5-541e-4702-aaaf-dd2fa86d3863]}
10:44:49,369 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-41269]ISPN100002: Started rebalance with topology id 2
10:44:49,389 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-41269: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-41269: 129, fedora-24344: 127]}, unionCH=null, actualMembers=[fedora-41269, fedora-24344], persistentUUIDs=[f826e98b-b1da-4e51-9c2d-e1c557323cff, 820a45a5-541e-4702-aaaf-dd2fa86d3863]}
10:44:49,391 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-41269]ISPN100002: Started rebalance with topology id 2
10:44:49,407 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) Number of members is the one expected: 3
10:44:49,409 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Successfully started cache service infinispan92/embedded on slave 0
10:44:49,409 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t23) [Context=org.infinispan.CONFIG][Scope=fedora-41269]ISPN100003: Node fedora-41269 finished rebalance phase with topology id 2
10:44:49,448 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t24) [Context=___counter_configuration][Scope=fedora-41269]ISPN100003: Node fedora-41269 finished rebalance phase with topology id 2
10:44:49,503 ERROR [org.radargun.service.ConfigDumpHelper] (sc-main) Error while dumping ___protobuf_metadata cache config as properties
javax.management.AttributeNotFoundException: Unknown attribute 'configurationAsProperties'. Known attributes names are: [rebalancingEnabled, cacheStatus, cacheName, cacheAvailability, version, configurationAsProperties]
	at org.infinispan.jmx.ResourceDMBean.getAttribute(ResourceDMBean.java:181) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:647) ~[?:1.8.0-internal]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:678) ~[?:1.8.0-internal]
	at org.radargun.service.ConfigDumpHelper60.dumpCache(ConfigDumpHelper60.java:44) [plugin-infinispan60-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.service.EmbeddedConfigurationProvider.getNormalizedConfigs(EmbeddedConfigurationProvider.java:33) [plugin-infinispan52-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.stages.lifecycle.ServiceStartStage.executeOnSlave(ServiceStartStage.java:92) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase.scenarioLoop(SlaveBase.java:102) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase$ScenarioRunner.run(SlaveBase.java:203) [radargun-core-3.0.0-SNAPSHOT.jar:?]
10:44:49,511 ERROR [org.radargun.service.ConfigDumpHelper] (sc-main) Error while dumping ___protobuf_metadata cache config as properties
javax.management.AttributeNotFoundException: Unknown attribute 'configurationAsProperties'. Known attributes names are: [rebalancingEnabled, cacheStatus, cacheName, cacheAvailability, version, configurationAsProperties]
	at org.infinispan.jmx.ResourceDMBean.getAttribute(ResourceDMBean.java:181) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:647) ~[?:1.8.0-internal]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:678) ~[?:1.8.0-internal]
	at org.radargun.service.ConfigDumpHelper60.dumpCache(ConfigDumpHelper60.java:44) [plugin-infinispan60-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.service.EmbeddedConfigurationProvider.getNormalizedConfigs(EmbeddedConfigurationProvider.java:33) [plugin-infinispan52-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.stages.lifecycle.ServiceStartStage.executeOnSlave(ServiceStartStage.java:92) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase.scenarioLoop(SlaveBase.java:102) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase$ScenarioRunner.run(SlaveBase.java:203) [radargun-core-3.0.0-SNAPSHOT.jar:?]
10:44:49,573 INFO  [org.radargun.Slave] (sc-main) Finished stage ServiceStart
10:44:49,582 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
10:44:49,634 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-24344]ISPN100003: Node fedora-24344 finished rebalance phase with topology id 2
10:44:49,636 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 2
10:44:49,640 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t3) [Context=___counter_configuration][Scope=fedora-41269]ISPN100003: Node fedora-41269 finished rebalance phase with topology id 3
10:44:49,663 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-24344]ISPN100003: Node fedora-24344 finished rebalance phase with topology id 2
10:44:49,664 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 2
10:44:49,666 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t5) [Context=org.infinispan.CONFIG][Scope=fedora-41269]ISPN100003: Node fedora-41269 finished rebalance phase with topology id 3
10:44:49,678 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-24344]ISPN100003: Node fedora-24344 finished rebalance phase with topology id 3
10:44:49,680 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t8) [Context=___counter_configuration][Scope=fedora-41269]ISPN100003: Node fedora-41269 finished rebalance phase with topology id 4
10:44:49,687 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-24344]ISPN100003: Node fedora-24344 finished rebalance phase with topology id 3
10:44:49,689 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t11) [Context=org.infinispan.CONFIG][Scope=fedora-41269]ISPN100003: Node fedora-41269 finished rebalance phase with topology id 4
10:44:49,691 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-24344]ISPN100003: Node fedora-24344 finished rebalance phase with topology id 4
10:44:49,708 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-24344]ISPN100003: Node fedora-24344 finished rebalance phase with topology id 4
10:44:49,764 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=DefaultConsistentHash{ns=256, owners = (1)[fedora-41269: 256+0]}, pendingCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-41269: 129+127, fedora-24344: 127+129]}, unionCH=null, actualMembers=[fedora-41269, fedora-24344], persistentUUIDs=[f826e98b-b1da-4e51-9c2d-e1c557323cff, 820a45a5-541e-4702-aaaf-dd2fa86d3863]}
10:44:49,765 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-41269]ISPN100002: Started rebalance with topology id 2
10:44:49,771 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t24) [Context=___counters][Scope=fedora-41269]ISPN100003: Node fedora-41269 finished rebalance phase with topology id 2
10:44:49,862 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-24344]ISPN100003: Node fedora-24344 finished rebalance phase with topology id 2
10:44:49,863 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache ___counters, topology id = 2
10:44:49,864 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t4) [Context=___counters][Scope=fedora-41269]ISPN100003: Node fedora-41269 finished rebalance phase with topology id 3
10:44:49,880 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-41269: 129, fedora-24344: 127]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-41269: 87, fedora-24344: 81, fedora-38800: 88]}, unionCH=null, actualMembers=[fedora-41269, fedora-24344, fedora-38800], persistentUUIDs=[f826e98b-b1da-4e51-9c2d-e1c557323cff, 820a45a5-541e-4702-aaaf-dd2fa86d3863, bf0929df-4f25-4f91-a0be-05af35343103]}
10:44:49,882 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-41269]ISPN100002: Started rebalance with topology id 6
10:44:49,884 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=___counter_configuration][Scope=fedora-41269]ISPN100003: Node fedora-41269 finished rebalance phase with topology id 6
10:44:49,886 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-41269: 129, fedora-24344: 127]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-41269: 87, fedora-24344: 81, fedora-38800: 88]}, unionCH=null, actualMembers=[fedora-41269, fedora-24344, fedora-38800], persistentUUIDs=[f826e98b-b1da-4e51-9c2d-e1c557323cff, 820a45a5-541e-4702-aaaf-dd2fa86d3863, bf0929df-4f25-4f91-a0be-05af35343103]}
10:44:49,888 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-41269]ISPN100002: Started rebalance with topology id 6
10:44:49,889 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t25) [Context=org.infinispan.CONFIG][Scope=fedora-41269]ISPN100003: Node fedora-41269 finished rebalance phase with topology id 6
10:44:49,895 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-24344]ISPN100003: Node fedora-24344 finished rebalance phase with topology id 3
10:44:49,897 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t8) [Context=___counters][Scope=fedora-41269]ISPN100003: Node fedora-41269 finished rebalance phase with topology id 4
10:44:49,917 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-24344]ISPN100003: Node fedora-24344 finished rebalance phase with topology id 6
10:44:49,918 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-41269: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-41269: 129, fedora-24344: 127]}, unionCH=null, actualMembers=[fedora-41269, fedora-24344], persistentUUIDs=[f826e98b-b1da-4e51-9c2d-e1c557323cff, 820a45a5-541e-4702-aaaf-dd2fa86d3863]}
10:44:49,919 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-41269]ISPN100002: Started rebalance with topology id 2
10:44:49,922 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-24344]ISPN100003: Node fedora-24344 finished rebalance phase with topology id 6
10:44:49,925 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=fedora-24344]ISPN100003: Node fedora-24344 finished rebalance phase with topology id 4
10:44:49,926 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t16) [Context=___protobuf_metadata][Scope=fedora-41269]ISPN100003: Node fedora-41269 finished rebalance phase with topology id 2
10:44:49,979 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=fedora-24344]ISPN100003: Node fedora-24344 finished rebalance phase with topology id 2
10:44:49,980 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 2
10:44:49,983 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t22) [Context=___protobuf_metadata][Scope=fedora-41269]ISPN100003: Node fedora-41269 finished rebalance phase with topology id 3
10:44:49,992 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=fedora-24344]ISPN100003: Node fedora-24344 finished rebalance phase with topology id 3
10:44:49,994 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t24) [Context=___protobuf_metadata][Scope=fedora-41269]ISPN100003: Node fedora-41269 finished rebalance phase with topology id 4
10:44:49,996 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=fedora-24344]ISPN100003: Node fedora-24344 finished rebalance phase with topology id 4
10:44:50,014 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=DefaultConsistentHash{ns=512, owners = (1)[fedora-41269: 512+0]}, pendingCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-41269: 257+255, fedora-24344: 255+257]}, unionCH=null, actualMembers=[fedora-41269, fedora-24344], persistentUUIDs=[f826e98b-b1da-4e51-9c2d-e1c557323cff, 820a45a5-541e-4702-aaaf-dd2fa86d3863]}
10:44:50,014 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-41269]ISPN100002: Started rebalance with topology id 2
10:44:50,020 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t5) [Context=testCache][Scope=fedora-41269]ISPN100003: Node fedora-41269 finished rebalance phase with topology id 2
10:44:50,048 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-24344]ISPN100003: Node fedora-24344 finished rebalance phase with topology id 2
10:44:50,049 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000336: Finished cluster-wide rebalance for cache testCache, topology id = 2
10:44:50,051 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t25) [Context=testCache][Scope=fedora-41269]ISPN100003: Node fedora-41269 finished rebalance phase with topology id 3
10:44:50,056 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-24344]ISPN100003: Node fedora-24344 finished rebalance phase with topology id 3
10:44:50,061 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t8) [Context=testCache][Scope=fedora-41269]ISPN100003: Node fedora-41269 finished rebalance phase with topology id 4
10:44:50,062 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-24344]ISPN100003: Node fedora-24344 finished rebalance phase with topology id 4
10:44:50,143 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counter_configuration][Scope=fedora-38800]ISPN100003: Node fedora-38800 finished rebalance phase with topology id 6
10:44:50,143 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 6
10:44:50,146 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t18) [Context=___counter_configuration][Scope=fedora-41269]ISPN100003: Node fedora-41269 finished rebalance phase with topology id 7
10:44:50,155 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counter_configuration][Scope=fedora-24344]ISPN100003: Node fedora-24344 finished rebalance phase with topology id 7
10:44:50,165 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-38800]ISPN100003: Node fedora-38800 finished rebalance phase with topology id 7
10:44:50,167 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t23) [Context=___counter_configuration][Scope=fedora-41269]ISPN100003: Node fedora-41269 finished rebalance phase with topology id 8
10:44:50,169 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-24344]ISPN100003: Node fedora-24344 finished rebalance phase with topology id 8
10:44:50,172 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-38800]ISPN100003: Node fedora-38800 finished rebalance phase with topology id 8
10:44:50,204 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-41269: 129+127, fedora-24344: 127+129]}, pendingCH=DefaultConsistentHash{ns=256, owners = (3)[fedora-41269: 87+84, fedora-24344: 81+81, fedora-38800: 88+91]}, unionCH=null, actualMembers=[fedora-41269, fedora-24344, fedora-38800], persistentUUIDs=[f826e98b-b1da-4e51-9c2d-e1c557323cff, 820a45a5-541e-4702-aaaf-dd2fa86d3863, bf0929df-4f25-4f91-a0be-05af35343103]}
10:44:50,204 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-41269]ISPN100002: Started rebalance with topology id 6
10:44:50,209 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t4) [Context=___counters][Scope=fedora-41269]ISPN100003: Node fedora-41269 finished rebalance phase with topology id 6
10:44:50,213 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-24344]ISPN100003: Node fedora-24344 finished rebalance phase with topology id 6
10:44:50,303 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-38800]ISPN100003: Node fedora-38800 finished rebalance phase with topology id 6
10:44:50,304 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache ___counters, topology id = 6
10:44:50,305 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t5) [Context=___counters][Scope=fedora-41269]ISPN100003: Node fedora-41269 finished rebalance phase with topology id 7
10:44:50,310 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-24344]ISPN100003: Node fedora-24344 finished rebalance phase with topology id 7
10:44:50,314 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-38800]ISPN100003: Node fedora-38800 finished rebalance phase with topology id 7
10:44:50,318 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t25) [Context=___counters][Scope=fedora-41269]ISPN100003: Node fedora-41269 finished rebalance phase with topology id 8
10:44:50,319 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-24344]ISPN100003: Node fedora-24344 finished rebalance phase with topology id 8
10:44:50,323 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-38800]ISPN100003: Node fedora-38800 finished rebalance phase with topology id 6
10:44:50,324 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 6
10:44:50,326 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t11) [Context=org.infinispan.CONFIG][Scope=fedora-41269]ISPN100003: Node fedora-41269 finished rebalance phase with topology id 7
10:44:50,327 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-24344]ISPN100003: Node fedora-24344 finished rebalance phase with topology id 7
10:44:50,328 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-38800]ISPN100003: Node fedora-38800 finished rebalance phase with topology id 8
10:44:50,329 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=org.infinispan.CONFIG][Scope=fedora-38800]ISPN100003: Node fedora-38800 finished rebalance phase with topology id 7
10:44:50,331 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=org.infinispan.CONFIG][Scope=fedora-41269]ISPN100003: Node fedora-41269 finished rebalance phase with topology id 8
10:44:50,340 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-24344]ISPN100003: Node fedora-24344 finished rebalance phase with topology id 8
10:44:50,343 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-41269: 129, fedora-24344: 127]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-41269: 87, fedora-24344: 81, fedora-38800: 88]}, unionCH=null, actualMembers=[fedora-41269, fedora-24344, fedora-38800], persistentUUIDs=[f826e98b-b1da-4e51-9c2d-e1c557323cff, 820a45a5-541e-4702-aaaf-dd2fa86d3863, bf0929df-4f25-4f91-a0be-05af35343103]}
10:44:50,343 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=fedora-41269]ISPN100002: Started rebalance with topology id 6
10:44:50,344 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-38800]ISPN100003: Node fedora-38800 finished rebalance phase with topology id 8
10:44:50,350 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t6) [Context=___protobuf_metadata][Scope=fedora-41269]ISPN100003: Node fedora-41269 finished rebalance phase with topology id 6
10:44:50,355 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=fedora-24344]ISPN100003: Node fedora-24344 finished rebalance phase with topology id 6
10:44:50,375 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=fedora-38800]ISPN100003: Node fedora-38800 finished rebalance phase with topology id 6
10:44:50,375 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 6
10:44:50,377 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t4) [Context=___protobuf_metadata][Scope=fedora-41269]ISPN100003: Node fedora-41269 finished rebalance phase with topology id 7
10:44:50,380 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=fedora-24344]ISPN100003: Node fedora-24344 finished rebalance phase with topology id 7
10:44:50,383 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=fedora-38800]ISPN100003: Node fedora-38800 finished rebalance phase with topology id 7
10:44:50,387 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=fedora-24344]ISPN100003: Node fedora-24344 finished rebalance phase with topology id 8
10:44:50,386 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t12) [Context=___protobuf_metadata][Scope=fedora-41269]ISPN100003: Node fedora-41269 finished rebalance phase with topology id 8
10:44:50,389 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=fedora-38800]ISPN100003: Node fedora-38800 finished rebalance phase with topology id 8
10:44:50,405 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-41269: 257+255, fedora-24344: 255+257]}, pendingCH=DefaultConsistentHash{ns=512, owners = (3)[fedora-41269: 164+179, fedora-24344: 170+159, fedora-38800: 178+174]}, unionCH=null, actualMembers=[fedora-41269, fedora-24344, fedora-38800], persistentUUIDs=[f826e98b-b1da-4e51-9c2d-e1c557323cff, 820a45a5-541e-4702-aaaf-dd2fa86d3863, bf0929df-4f25-4f91-a0be-05af35343103]}
10:44:50,405 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-41269]ISPN100002: Started rebalance with topology id 6
10:44:50,409 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t14) [Context=testCache][Scope=fedora-41269]ISPN100003: Node fedora-41269 finished rebalance phase with topology id 6
10:44:50,410 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-24344]ISPN100003: Node fedora-24344 finished rebalance phase with topology id 6
10:44:50,437 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-38800]ISPN100003: Node fedora-38800 finished rebalance phase with topology id 6
10:44:50,437 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache testCache, topology id = 6
10:44:50,439 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=testCache][Scope=fedora-41269]ISPN100003: Node fedora-41269 finished rebalance phase with topology id 7
10:44:50,443 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-24344]ISPN100003: Node fedora-24344 finished rebalance phase with topology id 7
10:44:50,444 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-38800]ISPN100003: Node fedora-38800 finished rebalance phase with topology id 7
10:44:50,446 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t1) [Context=testCache][Scope=fedora-41269]ISPN100003: Node fedora-41269 finished rebalance phase with topology id 8
10:44:50,448 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-24344]ISPN100003: Node fedora-24344 finished rebalance phase with topology id 8
10:44:50,452 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-38800]ISPN100003: Node fedora-38800 finished rebalance phase with topology id 8
10:44:50,549 INFO  [org.radargun.Slave] (sc-main) Starting stage AfterServiceStart
10:44:50,549 INFO  [org.radargun.Slave] (sc-main) Finished stage AfterServiceStart
10:44:50,552 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
10:44:50,612 INFO  [org.radargun.Slave] (sc-main) Starting stage MonitorStart
10:44:50,618 INFO  [org.radargun.sysmonitor.AbstractMonitors] (sc-main) Gathering statistics every 1000 ms
10:44:50,619 INFO  [org.radargun.Slave] (sc-main) Finished stage MonitorStart
10:44:50,619 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
10:44:50,640 INFO  [org.radargun.Slave] (sc-main) Starting stage Load
10:44:57,661 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) This node loaded 10000 entries (~10000000 bytes)
10:45:01,957 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) This node loaded 20000 entries (~20000000 bytes)
10:45:05,594 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) This node loaded 30000 entries (~30000000 bytes)
10:45:06,615 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) Finished loading entries
10:45:06,631 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) Finished loading entries
10:45:06,660 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) Finished loading entries
10:45:06,683 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) Finished loading entries
10:45:06,702 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) Finished loading entries
10:45:06,703 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) Finished loading entries
10:45:06,715 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) Finished loading entries
10:45:06,729 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) Finished loading entries
10:45:06,779 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) Finished loading entries
10:45:06,811 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) Finished loading entries
10:45:06,811 INFO  [org.radargun.Slave] (sc-main) Finished stage Load
10:45:06,812 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
10:45:06,891 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.stages.cache.test.BasicOperationsTestStage.init() overrides public void org.radargun.stages.test.TestStage.init() but both are declared with @Init annotation: calling only once
10:45:06,898 INFO  [org.radargun.Slave] (sc-main) Starting stage BasicOperationsTest
10:45:06,899 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using key generator org.radargun.stages.cache.generators.StringKeyGenerator {format=null }
10:45:06,899 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using value generator org.radargun.stages.cache.generators.ByteArrayValueGenerator { }
10:45:06,899 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using cache selector Default { }
10:45:06,899 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Starting test warmup
10:45:06,909 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Started 4 stressor threads.
10:46:06,917 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Finished test. Test duration is: 1 mins 0 secs
10:46:06,920 INFO  [org.radargun.Slave] (sc-main) Finished stage BasicOperationsTest
10:46:06,927 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
10:46:06,958 INFO  [org.radargun.Slave] (sc-main) Starting stage Clear
10:46:06,961 INFO  [org.radargun.stages.cache.ClearStage] (sc-main) Before executing clear, memory looks like this: 
Runtime free: 1,068,682 kb
Runtime max:1,292,288 kb
Runtime total:1,292,288 kb
MX Code Cache(Non-heap memory): used: 12,848 kb, init: 2,496 kb, committed: 13,632 kb, max: 245,760 kb
MX Metaspace(Non-heap memory): used: 37,314 kb, init: 0 kb, committed: 39,168 kb, max: 0 kb
MX Compressed Class Space(Non-heap memory): used: 4,421 kb, init: 0 kb, committed: 4,864 kb, max: 1,048,576 kb
MX PS Eden Space(Heap memory): used: 53,787 kb, init: 350,208 kb, committed: 257,536 kb, max: 267,776 kb
MX PS Survivor Space(Heap memory): used: 46,368 kb, init: 57,856 kb, committed: 101,888 kb, max: 101,888 kb
MX PS Old Gen(Heap memory): used: 123,449 kb, init: 932,864 kb, committed: 932,864 kb, max: 932,864 kb
10:46:07,209 INFO  [org.radargun.stages.cache.ClearStage] (sc-main) After executing clear, memory looks like this: 
Runtime free: 1,292,554 kb
Runtime max:1,306,624 kb
Runtime total:1,306,624 kb
MX Code Cache(Non-heap memory): used: 12,937 kb, init: 2,496 kb, committed: 13,632 kb, max: 245,760 kb
MX Metaspace(Non-heap memory): used: 37,287 kb, init: 0 kb, committed: 39,168 kb, max: 0 kb
MX Compressed Class Space(Non-heap memory): used: 4,407 kb, init: 0 kb, committed: 4,864 kb, max: 1,048,576 kb
MX PS Eden Space(Heap memory): used: 1,666 kb, init: 350,208 kb, committed: 277,504 kb, max: 277,504 kb
MX PS Survivor Space(Heap memory): used: 0 kb, init: 57,856 kb, committed: 96,256 kb, max: 96,256 kb
MX PS Old Gen(Heap memory): used: 12,412 kb, init: 932,864 kb, committed: 932,864 kb, max: 932,864 kb
10:46:07,209 INFO  [org.radargun.Slave] (sc-main) Finished stage Clear
10:46:07,210 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
10:46:07,262 INFO  [org.radargun.Slave] (sc-main) Starting stage Load
10:46:10,687 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) This node loaded 10000 entries (~10000000 bytes)
10:46:14,031 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) This node loaded 20000 entries (~20000000 bytes)
10:46:17,350 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) This node loaded 30000 entries (~30000000 bytes)
10:46:18,221 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) Finished loading entries
10:46:18,298 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) Finished loading entries
10:46:18,316 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) Finished loading entries
10:46:18,324 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) Finished loading entries
10:46:18,332 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) Finished loading entries
10:46:18,337 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) Finished loading entries
10:46:18,339 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) Finished loading entries
10:46:18,342 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) Finished loading entries
10:46:18,344 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) Finished loading entries
10:46:18,354 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) Finished loading entries
10:46:18,355 INFO  [org.radargun.Slave] (sc-main) Finished stage Load
10:46:18,355 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
10:46:18,818 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.stages.cache.test.BasicOperationsTestStage.init() overrides public void org.radargun.stages.test.TestStage.init() but both are declared with @Init annotation: calling only once
10:46:18,822 INFO  [org.radargun.Slave] (sc-main) Starting stage BasicOperationsTest
10:46:18,822 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using key generator org.radargun.stages.cache.generators.StringKeyGenerator {format=null }
10:46:18,822 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using value generator org.radargun.stages.cache.generators.ByteArrayValueGenerator { }
10:46:18,822 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using cache selector Default { }
10:46:18,823 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Starting test stress-test
10:46:18,850 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Started 4 stressor threads.
10:56:18,853 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Finished test. Test duration is: 10 mins 0 secs
10:56:18,855 INFO  [org.radargun.Slave] (sc-main) Finished stage BasicOperationsTest
10:56:19,042 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
10:56:19,154 INFO  [org.radargun.Slave] (sc-main) Starting stage MonitorStop
10:56:19,155 INFO  [org.radargun.Slave] (sc-main) Finished stage MonitorStop
10:56:19,156 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
10:56:19,162 INFO  [org.radargun.Slave] (sc-main) Starting stage ScenarioDestroy
10:56:19,162 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Scenario finished, destroying...
10:56:19,163 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Memory before cleanup: 
Runtime free: 1,218,570 kb
Runtime max:1,328,640 kb
Runtime total:1,328,640 kb
MX Code Cache(Non-heap memory): used: 14,760 kb, init: 2,496 kb, committed: 15,040 kb, max: 245,760 kb
MX Metaspace(Non-heap memory): used: 37,842 kb, init: 0 kb, committed: 39,680 kb, max: 0 kb
MX Compressed Class Space(Non-heap memory): used: 4,441 kb, init: 0 kb, committed: 4,864 kb, max: 1,048,576 kb
MX PS Eden Space(Heap memory): used: 3,650 kb, init: 350,208 kb, committed: 325,632 kb, max: 325,632 kb
MX PS Survivor Space(Heap memory): used: 69,902 kb, init: 57,856 kb, committed: 70,144 kb, max: 70,144 kb
MX PS Old Gen(Heap memory): used: 36,516 kb, init: 932,864 kb, committed: 932,864 kb, max: 932,864 kb
10:56:19,164 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) Stopping service.
10:56:19,172 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t28) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-41269: 241+102, fedora-38800: 271+81]}, pendingCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-41269: 246+266, fedora-38800: 266+246]}, unionCH=null, actualMembers=[fedora-41269, fedora-38800], persistentUUIDs=[f826e98b-b1da-4e51-9c2d-e1c557323cff, bf0929df-4f25-4f91-a0be-05af35343103]}
10:56:19,179 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t28) [Context=testCache][Scope=fedora-41269]ISPN100002: Started rebalance with topology id 11
10:56:19,212 WARN  [org.infinispan.CLUSTER] (remote-thread--p2-t29) [Context=testCache]ISPN000312: Lost data because of graceful leaver fedora-38800
10:56:19,219 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t28) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-41269: 120, fedora-38800: 136]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-41269: 122, fedora-38800: 134]}, unionCH=null, actualMembers=[fedora-41269, fedora-38800], persistentUUIDs=[f826e98b-b1da-4e51-9c2d-e1c557323cff, bf0929df-4f25-4f91-a0be-05af35343103]}
10:56:19,220 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t3) [Context=testCache][Scope=fedora-41269]ISPN100003: Node fedora-41269 finished rebalance phase with topology id 11
10:56:19,221 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t28) [Context=___protobuf_metadata][Scope=fedora-41269]ISPN100002: Started rebalance with topology id 11
10:56:19,223 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t13) [Context=___protobuf_metadata][Scope=fedora-41269]ISPN100003: Node fedora-41269 finished rebalance phase with topology id 11
10:56:19,236 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t28) [Context=___protobuf_metadata][Scope=fedora-38800]ISPN100003: Node fedora-38800 finished rebalance phase with topology id 11
10:56:19,236 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t28) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 11
10:56:19,238 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t11) [Context=___protobuf_metadata][Scope=fedora-41269]ISPN100003: Node fedora-41269 finished rebalance phase with topology id 12
10:56:19,241 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t29) [Context=___protobuf_metadata][Scope=fedora-38800]ISPN100003: Node fedora-38800 finished rebalance phase with topology id 12
10:56:19,245 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t29) [Context=___protobuf_metadata][Scope=fedora-38800]ISPN100003: Node fedora-38800 finished rebalance phase with topology id 13
10:56:19,247 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t28) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-41269: 132+39, fedora-38800: 124+55]}, pendingCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-41269: 122+134, fedora-38800: 134+122]}, unionCH=null, actualMembers=[fedora-41269, fedora-38800], persistentUUIDs=[f826e98b-b1da-4e51-9c2d-e1c557323cff, bf0929df-4f25-4f91-a0be-05af35343103]}
10:56:19,247 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t14) [Context=___protobuf_metadata][Scope=fedora-41269]ISPN100003: Node fedora-41269 finished rebalance phase with topology id 13
10:56:19,248 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t28) [Context=___counters][Scope=fedora-41269]ISPN100002: Started rebalance with topology id 11
10:56:19,255 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (transport-thread--p4-t14) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___protobuf_metadata, type=REBALANCE_PHASE_CONFIRM, sender=fedora-41269, joinInfo=null, topologyId=13, rebalanceId=4, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-41269 for cache ___protobuf_metadata, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.commands.ReplicableCommand.invoke(ReplicableCommand.java:44) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.LocalTopologyManagerImpl.lambda$executeOnCoordinatorAsync$4(LocalTopologyManagerImpl.java:717) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0-internal]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0-internal]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0-internal]
10:56:19,256 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t28) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-41269: 120, fedora-38800: 136]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-41269: 122, fedora-38800: 134]}, unionCH=null, actualMembers=[fedora-41269, fedora-38800], persistentUUIDs=[f826e98b-b1da-4e51-9c2d-e1c557323cff, bf0929df-4f25-4f91-a0be-05af35343103]}
10:56:19,257 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t28) [Context=org.infinispan.CONFIG][Scope=fedora-41269]ISPN100002: Started rebalance with topology id 11
10:56:19,257 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=org.infinispan.CONFIG][Scope=fedora-41269]ISPN100003: Node fedora-41269 finished rebalance phase with topology id 11
10:56:19,264 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t28) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=12, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-41269: 120, fedora-38800: 136]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-41269: 122, fedora-38800: 134]}, unionCH=null, actualMembers=[fedora-41269, fedora-38800], persistentUUIDs=[f826e98b-b1da-4e51-9c2d-e1c557323cff, bf0929df-4f25-4f91-a0be-05af35343103]}
10:56:19,265 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t28) [Context=___counter_configuration][Scope=fedora-41269]ISPN100002: Started rebalance with topology id 12
10:56:19,276 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t28) [Context=___protobuf_metadata][Scope=fedora-38800]ISPN100003: Node fedora-38800 finished rebalance phase with topology id 14
10:56:19,276 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t13) [Context=___counter_configuration][Scope=fedora-41269]ISPN100003: Node fedora-41269 finished rebalance phase with topology id 12
10:56:19,277 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (remote-thread--p2-t28) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___protobuf_metadata, type=REBALANCE_PHASE_CONFIRM, sender=fedora-38800, joinInfo=null, topologyId=14, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-38800 for cache ___protobuf_metadata, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.invokeReplicableCommand(GlobalInboundInvocationHandler.java:169) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.runReplicableCommand(GlobalInboundInvocationHandler.java:150) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.lambda$handleReplicableCommand$1(GlobalInboundInvocationHandler.java:144) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.util.concurrent.BlockingTaskAwareExecutorServiceImpl$RunnableWrapper.run(BlockingTaskAwareExecutorServiceImpl.java:212) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0-internal]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0-internal]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0-internal]
10:56:19,280 INFO  [org.infinispan.CLUSTER] (jgroups-30,fedora-41269) ISPN000094: Received new cluster view for channel results: [fedora-41269|3] (2) [fedora-41269, fedora-38800]
10:56:19,281 INFO  [org.infinispan.CLUSTER] (jgroups-30,fedora-41269) ISPN100001: Node fedora-24344 left the cluster
10:56:19,285 WARN  [org.infinispan.CLUSTER] (StopThread) [Context=___counters]ISPN000312: Lost data because of graceful leaver fedora-41269
10:56:19,298 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t29) [Context=org.infinispan.CONFIG][Scope=fedora-38800]ISPN100003: Node fedora-38800 finished rebalance phase with topology id 11
10:56:19,305 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (remote-thread--p2-t29) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=org.infinispan.CONFIG, type=REBALANCE_PHASE_CONFIRM, sender=fedora-38800, joinInfo=null, topologyId=11, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-38800 for cache org.infinispan.CONFIG, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.invokeReplicableCommand(GlobalInboundInvocationHandler.java:169) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.runReplicableCommand(GlobalInboundInvocationHandler.java:150) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.lambda$handleReplicableCommand$1(GlobalInboundInvocationHandler.java:144) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.util.concurrent.BlockingTaskAwareExecutorServiceImpl$RunnableWrapper.run(BlockingTaskAwareExecutorServiceImpl.java:212) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0-internal]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0-internal]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0-internal]
10:56:19,309 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t29) [Context=___counter_configuration][Scope=fedora-38800]ISPN100003: Node fedora-38800 finished rebalance phase with topology id 12
10:56:19,318 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (remote-thread--p2-t29) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___counter_configuration, type=REBALANCE_PHASE_CONFIRM, sender=fedora-38800, joinInfo=null, topologyId=12, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-38800 for cache ___counter_configuration, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.invokeReplicableCommand(GlobalInboundInvocationHandler.java:169) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.runReplicableCommand(GlobalInboundInvocationHandler.java:150) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.lambda$handleReplicableCommand$1(GlobalInboundInvocationHandler.java:144) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.util.concurrent.BlockingTaskAwareExecutorServiceImpl$RunnableWrapper.run(BlockingTaskAwareExecutorServiceImpl.java:212) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0-internal]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0-internal]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0-internal]
10:56:19,327 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t29) [Context=___counter_configuration][Scope=fedora-38800]ISPN100003: Node fedora-38800 finished rebalance phase with topology id 14
10:56:19,327 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t14) [Context=org.infinispan.CONFIG][Scope=fedora-38800]ISPN100003: Node fedora-38800 finished rebalance phase with topology id 12
10:56:19,327 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t28) [Context=___counter_configuration][Scope=fedora-38800]ISPN100003: Node fedora-38800 finished rebalance phase with topology id 13
10:56:19,329 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (remote-thread--p2-t14) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=org.infinispan.CONFIG, type=REBALANCE_PHASE_CONFIRM, sender=fedora-38800, joinInfo=null, topologyId=12, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=3}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-38800 for cache org.infinispan.CONFIG, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.invokeReplicableCommand(GlobalInboundInvocationHandler.java:169) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.runReplicableCommand(GlobalInboundInvocationHandler.java:150) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.lambda$handleReplicableCommand$1(GlobalInboundInvocationHandler.java:144) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.util.concurrent.BlockingTaskAwareExecutorServiceImpl$RunnableWrapper.run(BlockingTaskAwareExecutorServiceImpl.java:212) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0-internal]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0-internal]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0-internal]
10:56:19,330 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (remote-thread--p2-t28) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___counter_configuration, type=REBALANCE_PHASE_CONFIRM, sender=fedora-38800, joinInfo=null, topologyId=13, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=3}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-38800 for cache ___counter_configuration, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.invokeReplicableCommand(GlobalInboundInvocationHandler.java:169) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.runReplicableCommand(GlobalInboundInvocationHandler.java:150) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.lambda$handleReplicableCommand$1(GlobalInboundInvocationHandler.java:144) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.util.concurrent.BlockingTaskAwareExecutorServiceImpl$RunnableWrapper.run(BlockingTaskAwareExecutorServiceImpl.java:212) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0-internal]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0-internal]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0-internal]
10:56:19,329 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (remote-thread--p2-t29) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___counter_configuration, type=REBALANCE_PHASE_CONFIRM, sender=fedora-38800, joinInfo=null, topologyId=14, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=3}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-38800 for cache ___counter_configuration, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.invokeReplicableCommand(GlobalInboundInvocationHandler.java:169) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.runReplicableCommand(GlobalInboundInvocationHandler.java:150) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.lambda$handleReplicableCommand$1(GlobalInboundInvocationHandler.java:144) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.util.concurrent.BlockingTaskAwareExecutorServiceImpl$RunnableWrapper.run(BlockingTaskAwareExecutorServiceImpl.java:212) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0-internal]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0-internal]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0-internal]
10:56:19,331 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (StopThread) ISPN000080: Disconnecting JGroups channel results
10:56:19,385 WARN  [org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler] (remote-thread--p2-t29) ISPN000219: Shutdown while handling command CacheTopologyControlCommand{cache=org.infinispan.CONFIG, type=LEAVE, sender=fedora-38800, joinInfo=null, topologyId=0, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=3}
10:56:19,389 INFO  [org.radargun.service.Infinispan90Lifecycle] (StopThread) Stopped, previous view is [fedora-41269, fedora-24344, fedora-38800]
10:56:19,390 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Service successfully stopped.
10:56:19,393 INFO  [org.radargun.Slave] (sc-main) Finished stage ScenarioDestroy
10:56:19,397 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
10:56:19,406 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.service.Infinispan80EmbeddedService.destroy() overrides public void org.radargun.service.Infinispan60EmbeddedService.destroy() but both are declared with @Destroy annotation: calling only once
10:56:19,408 INFO  [org.radargun.Slave] (main) Starting stage ScenarioCleanup
10:56:19,496 INFO  [org.radargun.stages.ScenarioCleanupStage] (main) Memory after cleanup: 
Runtime free: 1,307,245 kb
Runtime max:1,326,592 kb
Runtime total:1,326,592 kb
MX Code Cache(Non-heap memory): used: 14,723 kb, init: 2,496 kb, committed: 15,040 kb, max: 245,760 kb
MX Metaspace(Non-heap memory): used: 37,977 kb, init: 0 kb, committed: 39,936 kb, max: 0 kb
MX Compressed Class Space(Non-heap memory): used: 4,461 kb, init: 0 kb, committed: 4,864 kb, max: 1,048,576 kb
MX PS Eden Space(Heap memory): used: 6,924 kb, init: 350,208 kb, committed: 323,584 kb, max: 324,608 kb
MX PS Survivor Space(Heap memory): used: 0 kb, init: 57,856 kb, committed: 70,144 kb, max: 70,144 kb
MX PS Old Gen(Heap memory): used: 12,421 kb, init: 932,864 kb, committed: 932,864 kb, max: 932,864 kb
10:56:19,498 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
10:56:24,714 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
10:56:28,516 INFO  [org.radargun.Slave] (main) Master shutdown!
10:56:28,519 INFO  [org.radargun.ShutDownHook] (Thread-0) Slave process is being shutdown
