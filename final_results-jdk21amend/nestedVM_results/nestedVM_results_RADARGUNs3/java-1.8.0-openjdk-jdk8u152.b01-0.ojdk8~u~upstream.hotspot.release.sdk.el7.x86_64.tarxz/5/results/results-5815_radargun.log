12:20:32,011 INFO  [org.radargun.RemoteMasterConnection] (main) Attempting to connect to master results:2103
12:20:32,021 INFO  [org.radargun.RemoteMasterConnection] (main) Successfully established connection with master at: results:2103
12:20:32,023 INFO  [org.radargun.Slave] (main) Received slave index 0
12:20:32,024 INFO  [org.radargun.Slave] (main) Received slave count 3
12:20:32,328 INFO  [org.radargun.ServiceHelper] (sc-main) ServiceContext properties: {}
12:20:32,435 INFO  [org.radargun.Slave] (sc-main) Eager Service Infinispan92EmbeddedService {batching=false, cache=testCache, channelRetrievalTimeout=2 mins 0 secs, enableDiagnostics=null, explicitLocking=false, file=/mnt/workspace/results/dist-sync.xml, internalsExpositionEnabled=false, jgroupsDumperEnabled=false, jgroupsDumperInterval=10.000 secs, keysPerThread=-1, mapReduceDistributedReducePhase=false, mapReduceUseIntermediateSharedCache=false, removedCaches=[  ], threadsPerNode=-1 } loaded.
12:20:34,644 INFO  [org.radargun.Slave] (sc-main) Starting stage ScenarioInit
12:20:34,683 INFO  [org.radargun.Slave] (sc-main) Finished stage ScenarioInit
12:20:34,686 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
12:20:34,694 INFO  [org.radargun.Slave] (sc-main) Starting stage BeforeServiceStart
12:20:34,695 INFO  [org.radargun.Slave] (sc-main) Finished stage BeforeServiceStart
12:20:34,695 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
12:20:34,704 INFO  [org.radargun.Slave] (sc-main) Starting stage ServiceStart
12:20:34,705 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Startup staggering, this is the slave with index 0, not sleeping
12:20:34,705 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 0
12:20:34,708 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) Infinispan version: Infinispan 'Gaina' 9.2.0.Final
12:20:34,723 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) JGroups version: JGroups 4.0.10.Final (Schiener Berg)
12:20:35,316 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (sc-main) ISPN000078: Starting JGroups channel results
12:20:35,405 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the send buffer of socket MulticastSocket was set to 1.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
12:20:35,405 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the receive buffer of socket MulticastSocket was set to 20.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
12:20:35,406 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the send buffer of socket MulticastSocket was set to 1.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
12:20:35,406 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the receive buffer of socket MulticastSocket was set to 25.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
12:20:40,459 INFO  [org.infinispan.CLUSTER] (sc-main) ISPN000094: Received new cluster view for channel results: [fedora-20962|0] (1) [fedora-20962]
12:20:40,529 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (sc-main) ISPN000079: Channel results local address is fedora-20962, physical addresses are [192.168.124.121:46690]
12:20:40,532 INFO  [org.infinispan.factories.GlobalComponentRegistry] (sc-main) ISPN000128: Infinispan version: Infinispan 'Gaina' 9.2.0.Final
12:20:41,182 INFO  [org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup] (sc-main) ISPN000107: Retrieving transaction manager Transaction: unknown
12:20:41,259 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) No RELAY2 protocol in XS service
12:20:41,270 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) No RELAY2 protocol in XS service
12:20:41,271 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) ([fedora-20962(local=true, coord=true)]) Number of members=1 is not the one expected: 3
12:20:41,427 INFO  [org.infinispan.CLUSTER] (jgroups-6,fedora-20962) ISPN000094: Received new cluster view for channel results: [fedora-20962|1] (2) [fedora-20962, fedora-64492]
12:20:41,445 INFO  [org.infinispan.CLUSTER] (jgroups-6,fedora-20962) ISPN100000: Node fedora-64492 joined the cluster
12:20:41,904 INFO  [org.infinispan.CLUSTER] (jgroups-12,fedora-20962) ISPN000094: Received new cluster view for channel results: [fedora-20962|2] (3) [fedora-20962, fedora-64492, fedora-6960]
12:20:41,906 INFO  [org.infinispan.CLUSTER] (jgroups-12,fedora-20962) ISPN100000: Node fedora-6960 joined the cluster
12:20:42,272 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) Number of members is the one expected: 3
12:20:42,272 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Successfully started cache service infinispan92/embedded on slave 0
12:20:42,279 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-20962: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-20962: 127, fedora-64492: 129]}, unionCH=null, actualMembers=[fedora-20962, fedora-64492], persistentUUIDs=[d87936eb-19d8-4769-9d28-98f1e068a64c, 8b597f18-fa66-4b80-a268-b3e80da1cbc1]}
12:20:42,281 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-20962: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-20962: 127, fedora-64492: 129]}, unionCH=null, actualMembers=[fedora-20962, fedora-64492], persistentUUIDs=[d87936eb-19d8-4769-9d28-98f1e068a64c, 8b597f18-fa66-4b80-a268-b3e80da1cbc1]}
12:20:42,281 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-20962]ISPN100002: Started rebalance with topology id 2
12:20:42,284 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-20962]ISPN100002: Started rebalance with topology id 2
12:20:42,327 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t22) [Context=___counter_configuration][Scope=fedora-20962]ISPN100003: Node fedora-20962 finished rebalance phase with topology id 2
12:20:42,344 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t24) [Context=org.infinispan.CONFIG][Scope=fedora-20962]ISPN100003: Node fedora-20962 finished rebalance phase with topology id 2
12:20:42,393 ERROR [org.radargun.service.ConfigDumpHelper] (sc-main) Error while dumping ___protobuf_metadata cache config as properties
javax.management.AttributeNotFoundException: Unknown attribute 'configurationAsProperties'. Known attributes names are: [rebalancingEnabled, cacheStatus, cacheName, cacheAvailability, version, configurationAsProperties]
	at org.infinispan.jmx.ResourceDMBean.getAttribute(ResourceDMBean.java:181) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:647) ~[?:1.8.0-internal]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:678) ~[?:1.8.0-internal]
	at org.radargun.service.ConfigDumpHelper60.dumpCache(ConfigDumpHelper60.java:44) [plugin-infinispan60-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.service.EmbeddedConfigurationProvider.getNormalizedConfigs(EmbeddedConfigurationProvider.java:33) [plugin-infinispan52-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.stages.lifecycle.ServiceStartStage.executeOnSlave(ServiceStartStage.java:92) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase.scenarioLoop(SlaveBase.java:102) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase$ScenarioRunner.run(SlaveBase.java:203) [radargun-core-3.0.0-SNAPSHOT.jar:?]
12:20:42,434 ERROR [org.radargun.service.ConfigDumpHelper] (sc-main) Error while dumping ___protobuf_metadata cache config as properties
javax.management.AttributeNotFoundException: Unknown attribute 'configurationAsProperties'. Known attributes names are: [rebalancingEnabled, cacheStatus, cacheName, cacheAvailability, version, configurationAsProperties]
	at org.infinispan.jmx.ResourceDMBean.getAttribute(ResourceDMBean.java:181) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:647) ~[?:1.8.0-internal]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:678) ~[?:1.8.0-internal]
	at org.radargun.service.ConfigDumpHelper60.dumpCache(ConfigDumpHelper60.java:44) [plugin-infinispan60-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.service.EmbeddedConfigurationProvider.getNormalizedConfigs(EmbeddedConfigurationProvider.java:33) [plugin-infinispan52-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.stages.lifecycle.ServiceStartStage.executeOnSlave(ServiceStartStage.java:92) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase.scenarioLoop(SlaveBase.java:102) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase$ScenarioRunner.run(SlaveBase.java:203) [radargun-core-3.0.0-SNAPSHOT.jar:?]
12:20:42,490 INFO  [org.radargun.Slave] (sc-main) Finished stage ServiceStart
12:20:42,509 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
12:20:42,575 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-64492]ISPN100003: Node fedora-64492 finished rebalance phase with topology id 2
12:20:42,576 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 2
12:20:42,580 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t3) [Context=org.infinispan.CONFIG][Scope=fedora-20962]ISPN100003: Node fedora-20962 finished rebalance phase with topology id 3
12:20:42,615 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-64492]ISPN100003: Node fedora-64492 finished rebalance phase with topology id 3
12:20:42,617 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t4) [Context=org.infinispan.CONFIG][Scope=fedora-20962]ISPN100003: Node fedora-20962 finished rebalance phase with topology id 4
12:20:42,631 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-64492]ISPN100003: Node fedora-64492 finished rebalance phase with topology id 4
12:20:42,638 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-64492]ISPN100003: Node fedora-64492 finished rebalance phase with topology id 2
12:20:42,638 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 2
12:20:42,640 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t12) [Context=___counter_configuration][Scope=fedora-20962]ISPN100003: Node fedora-20962 finished rebalance phase with topology id 3
12:20:42,647 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-20962: 127, fedora-64492: 129]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-20962: 84, fedora-64492: 82, fedora-6960: 90]}, unionCH=null, actualMembers=[fedora-20962, fedora-64492, fedora-6960], persistentUUIDs=[d87936eb-19d8-4769-9d28-98f1e068a64c, 8b597f18-fa66-4b80-a268-b3e80da1cbc1, 5522d009-7670-40e7-8e12-6a42dc692803]}
12:20:42,647 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-20962]ISPN100002: Started rebalance with topology id 6
12:20:42,652 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t15) [Context=org.infinispan.CONFIG][Scope=fedora-20962]ISPN100003: Node fedora-20962 finished rebalance phase with topology id 6
12:20:42,679 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-64492]ISPN100003: Node fedora-64492 finished rebalance phase with topology id 3
12:20:42,679 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-6960]ISPN100003: Node fedora-6960 finished rebalance phase with topology id 3
12:20:42,689 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (remote-thread--p2-t1) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___counter_configuration, type=REBALANCE_PHASE_CONFIRM, sender=fedora-6960, joinInfo=null, topologyId=3, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-6960 for cache ___counter_configuration, expecting topology id 4 but got 3
	at org.infinispan.topology.RebalanceConfirmationCollector.confirmPhase(RebalanceConfirmationCollector.java:41) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:337) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.invokeReplicableCommand(GlobalInboundInvocationHandler.java:169) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.runReplicableCommand(GlobalInboundInvocationHandler.java:150) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.lambda$handleReplicableCommand$1(GlobalInboundInvocationHandler.java:144) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.util.concurrent.BlockingTaskAwareExecutorServiceImpl$RunnableWrapper.run(BlockingTaskAwareExecutorServiceImpl.java:212) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0-internal]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0-internal]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0-internal]
12:20:42,692 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=org.infinispan.CONFIG][Scope=fedora-64492]ISPN100003: Node fedora-64492 finished rebalance phase with topology id 6
12:20:42,693 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t18) [Context=___counter_configuration][Scope=fedora-20962]ISPN100003: Node fedora-20962 finished rebalance phase with topology id 4
12:20:42,714 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___counter_configuration][Scope=fedora-6960]ISPN100003: Node fedora-6960 finished rebalance phase with topology id 4
12:20:42,748 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___counter_configuration][Scope=fedora-64492]ISPN100003: Node fedora-64492 finished rebalance phase with topology id 4
12:20:42,753 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-20962: 127, fedora-64492: 129]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-20962: 84, fedora-64492: 82, fedora-6960: 90]}, unionCH=null, actualMembers=[fedora-20962, fedora-64492, fedora-6960], persistentUUIDs=[d87936eb-19d8-4769-9d28-98f1e068a64c, 8b597f18-fa66-4b80-a268-b3e80da1cbc1, 5522d009-7670-40e7-8e12-6a42dc692803]}
12:20:42,757 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___counter_configuration][Scope=fedora-20962]ISPN100002: Started rebalance with topology id 6
12:20:42,759 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t24) [Context=___counter_configuration][Scope=fedora-20962]ISPN100003: Node fedora-20962 finished rebalance phase with topology id 6
12:20:42,773 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___counter_configuration][Scope=fedora-64492]ISPN100003: Node fedora-64492 finished rebalance phase with topology id 6
12:20:42,800 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=DefaultConsistentHash{ns=256, owners = (1)[fedora-20962: 256+0]}, pendingCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-20962: 127+129, fedora-64492: 129+127]}, unionCH=null, actualMembers=[fedora-20962, fedora-64492], persistentUUIDs=[d87936eb-19d8-4769-9d28-98f1e068a64c, 8b597f18-fa66-4b80-a268-b3e80da1cbc1]}
12:20:42,801 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___counters][Scope=fedora-20962]ISPN100002: Started rebalance with topology id 2
12:20:42,804 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t3) [Context=___counters][Scope=fedora-20962]ISPN100003: Node fedora-20962 finished rebalance phase with topology id 2
12:20:42,822 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-20962: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-20962: 127, fedora-64492: 129]}, unionCH=null, actualMembers=[fedora-20962, fedora-64492], persistentUUIDs=[d87936eb-19d8-4769-9d28-98f1e068a64c, 8b597f18-fa66-4b80-a268-b3e80da1cbc1]}
12:20:42,823 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___protobuf_metadata][Scope=fedora-20962]ISPN100002: Started rebalance with topology id 2
12:20:42,833 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t8) [Context=___protobuf_metadata][Scope=fedora-20962]ISPN100003: Node fedora-20962 finished rebalance phase with topology id 2
12:20:42,885 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___protobuf_metadata][Scope=fedora-64492]ISPN100003: Node fedora-64492 finished rebalance phase with topology id 2
12:20:42,887 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 2
12:20:42,889 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t25) [Context=___protobuf_metadata][Scope=fedora-20962]ISPN100003: Node fedora-20962 finished rebalance phase with topology id 3
12:20:42,898 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=DefaultConsistentHash{ns=512, owners = (1)[fedora-20962: 512+0]}, pendingCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-20962: 269+243, fedora-64492: 243+269]}, unionCH=null, actualMembers=[fedora-20962, fedora-64492], persistentUUIDs=[d87936eb-19d8-4769-9d28-98f1e068a64c, 8b597f18-fa66-4b80-a268-b3e80da1cbc1]}
12:20:42,899 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=fedora-64492]ISPN100003: Node fedora-64492 finished rebalance phase with topology id 3
12:20:42,899 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=testCache][Scope=fedora-20962]ISPN100002: Started rebalance with topology id 2
12:20:42,901 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t19) [Context=___protobuf_metadata][Scope=fedora-20962]ISPN100003: Node fedora-20962 finished rebalance phase with topology id 4
12:20:42,908 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=fedora-64492]ISPN100003: Node fedora-64492 finished rebalance phase with topology id 4
12:20:42,914 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t16) [Context=testCache][Scope=fedora-20962]ISPN100003: Node fedora-20962 finished rebalance phase with topology id 2
12:20:42,956 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=fedora-64492]ISPN100003: Node fedora-64492 finished rebalance phase with topology id 2
12:20:42,956 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000336: Finished cluster-wide rebalance for cache ___counters, topology id = 2
12:20:42,958 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t2) [Context=___counters][Scope=fedora-20962]ISPN100003: Node fedora-20962 finished rebalance phase with topology id 3
12:20:42,988 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=fedora-64492]ISPN100003: Node fedora-64492 finished rebalance phase with topology id 3
12:20:42,990 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t6) [Context=___counters][Scope=fedora-20962]ISPN100003: Node fedora-20962 finished rebalance phase with topology id 4
12:20:42,992 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=fedora-64492]ISPN100003: Node fedora-64492 finished rebalance phase with topology id 4
12:20:43,010 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-64492]ISPN100003: Node fedora-64492 finished rebalance phase with topology id 2
12:20:43,010 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000336: Finished cluster-wide rebalance for cache testCache, topology id = 2
12:20:43,013 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t17) [Context=testCache][Scope=fedora-20962]ISPN100003: Node fedora-20962 finished rebalance phase with topology id 3
12:20:43,017 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-64492]ISPN100003: Node fedora-64492 finished rebalance phase with topology id 3
12:20:43,019 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t15) [Context=testCache][Scope=fedora-20962]ISPN100003: Node fedora-20962 finished rebalance phase with topology id 4
12:20:43,023 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-64492]ISPN100003: Node fedora-64492 finished rebalance phase with topology id 4
12:20:43,044 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=org.infinispan.CONFIG][Scope=fedora-6960]ISPN100003: Node fedora-6960 finished rebalance phase with topology id 6
12:20:43,044 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 6
12:20:43,045 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=org.infinispan.CONFIG][Scope=fedora-20962]ISPN100003: Node fedora-20962 finished rebalance phase with topology id 7
12:20:43,049 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=org.infinispan.CONFIG][Scope=fedora-64492]ISPN100003: Node fedora-64492 finished rebalance phase with topology id 7
12:20:43,082 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=org.infinispan.CONFIG][Scope=fedora-6960]ISPN100003: Node fedora-6960 finished rebalance phase with topology id 7
12:20:43,085 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=org.infinispan.CONFIG][Scope=fedora-64492]ISPN100003: Node fedora-64492 finished rebalance phase with topology id 8
12:20:43,084 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=org.infinispan.CONFIG][Scope=fedora-20962]ISPN100003: Node fedora-20962 finished rebalance phase with topology id 8
12:20:43,091 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=org.infinispan.CONFIG][Scope=fedora-6960]ISPN100003: Node fedora-6960 finished rebalance phase with topology id 8
12:20:43,092 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___counter_configuration][Scope=fedora-6960]ISPN100003: Node fedora-6960 finished rebalance phase with topology id 6
12:20:43,092 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 6
12:20:43,095 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___counter_configuration][Scope=fedora-64492]ISPN100003: Node fedora-64492 finished rebalance phase with topology id 7
12:20:43,095 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t2) [Context=___counter_configuration][Scope=fedora-20962]ISPN100003: Node fedora-20962 finished rebalance phase with topology id 7
12:20:43,121 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___counter_configuration][Scope=fedora-6960]ISPN100003: Node fedora-6960 finished rebalance phase with topology id 7
12:20:43,122 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=___counter_configuration][Scope=fedora-20962]ISPN100003: Node fedora-20962 finished rebalance phase with topology id 8
12:20:43,124 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___counter_configuration][Scope=fedora-64492]ISPN100003: Node fedora-64492 finished rebalance phase with topology id 8
12:20:43,127 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___counter_configuration][Scope=fedora-6960]ISPN100003: Node fedora-6960 finished rebalance phase with topology id 8
12:20:43,174 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-20962: 127+129, fedora-64492: 129+127]}, pendingCH=DefaultConsistentHash{ns=256, owners = (3)[fedora-20962: 84+75, fedora-64492: 82+101, fedora-6960: 90+80]}, unionCH=null, actualMembers=[fedora-20962, fedora-64492, fedora-6960], persistentUUIDs=[d87936eb-19d8-4769-9d28-98f1e068a64c, 8b597f18-fa66-4b80-a268-b3e80da1cbc1, 5522d009-7670-40e7-8e12-6a42dc692803]}
12:20:43,174 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___counters][Scope=fedora-20962]ISPN100002: Started rebalance with topology id 6
12:20:43,176 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t17) [Context=___counters][Scope=fedora-20962]ISPN100003: Node fedora-20962 finished rebalance phase with topology id 6
12:20:43,179 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___counters][Scope=fedora-64492]ISPN100003: Node fedora-64492 finished rebalance phase with topology id 6
12:20:43,180 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-20962: 127, fedora-64492: 129]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-20962: 84, fedora-64492: 82, fedora-6960: 90]}, unionCH=null, actualMembers=[fedora-20962, fedora-64492, fedora-6960], persistentUUIDs=[d87936eb-19d8-4769-9d28-98f1e068a64c, 8b597f18-fa66-4b80-a268-b3e80da1cbc1, 5522d009-7670-40e7-8e12-6a42dc692803]}
12:20:43,181 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=fedora-20962]ISPN100002: Started rebalance with topology id 6
12:20:43,185 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t15) [Context=___protobuf_metadata][Scope=fedora-20962]ISPN100003: Node fedora-20962 finished rebalance phase with topology id 6
12:20:43,196 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___protobuf_metadata][Scope=fedora-64492]ISPN100003: Node fedora-64492 finished rebalance phase with topology id 6
12:20:43,213 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___counters][Scope=fedora-6960]ISPN100003: Node fedora-6960 finished rebalance phase with topology id 6
12:20:43,214 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) ISPN000336: Finished cluster-wide rebalance for cache ___counters, topology id = 6
12:20:43,215 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t23) [Context=___counters][Scope=fedora-20962]ISPN100003: Node fedora-20962 finished rebalance phase with topology id 7
12:20:43,216 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___counters][Scope=fedora-64492]ISPN100003: Node fedora-64492 finished rebalance phase with topology id 7
12:20:43,222 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___counters][Scope=fedora-6960]ISPN100003: Node fedora-6960 finished rebalance phase with topology id 7
12:20:43,227 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___counters][Scope=fedora-64492]ISPN100003: Node fedora-64492 finished rebalance phase with topology id 8
12:20:43,228 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t5) [Context=___counters][Scope=fedora-20962]ISPN100003: Node fedora-20962 finished rebalance phase with topology id 8
12:20:43,236 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___counters][Scope=fedora-6960]ISPN100003: Node fedora-6960 finished rebalance phase with topology id 8
12:20:43,253 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=fedora-6960]ISPN100003: Node fedora-6960 finished rebalance phase with topology id 6
12:20:43,256 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 6
12:20:43,254 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-20962: 269+243, fedora-64492: 243+269]}, pendingCH=DefaultConsistentHash{ns=512, owners = (3)[fedora-20962: 174+152, fedora-64492: 166+167, fedora-6960: 172+193]}, unionCH=null, actualMembers=[fedora-20962, fedora-64492, fedora-6960], persistentUUIDs=[d87936eb-19d8-4769-9d28-98f1e068a64c, 8b597f18-fa66-4b80-a268-b3e80da1cbc1, 5522d009-7670-40e7-8e12-6a42dc692803]}
12:20:43,257 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=testCache][Scope=fedora-20962]ISPN100002: Started rebalance with topology id 6
12:20:43,258 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t8) [Context=___protobuf_metadata][Scope=fedora-20962]ISPN100003: Node fedora-20962 finished rebalance phase with topology id 7
12:20:43,261 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t2) [Context=testCache][Scope=fedora-20962]ISPN100003: Node fedora-20962 finished rebalance phase with topology id 6
12:20:43,263 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___protobuf_metadata][Scope=fedora-64492]ISPN100003: Node fedora-64492 finished rebalance phase with topology id 7
12:20:43,263 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-64492]ISPN100003: Node fedora-64492 finished rebalance phase with topology id 6
12:20:43,268 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=fedora-6960]ISPN100003: Node fedora-6960 finished rebalance phase with topology id 7
12:20:43,270 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t12) [Context=___protobuf_metadata][Scope=fedora-20962]ISPN100003: Node fedora-20962 finished rebalance phase with topology id 8
12:20:43,273 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=fedora-64492]ISPN100003: Node fedora-64492 finished rebalance phase with topology id 8
12:20:43,276 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=fedora-6960]ISPN100003: Node fedora-6960 finished rebalance phase with topology id 8
12:20:43,290 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-6960]ISPN100003: Node fedora-6960 finished rebalance phase with topology id 6
12:20:43,293 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000336: Finished cluster-wide rebalance for cache testCache, topology id = 6
12:20:43,295 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t15) [Context=testCache][Scope=fedora-20962]ISPN100003: Node fedora-20962 finished rebalance phase with topology id 7
12:20:43,298 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=testCache][Scope=fedora-6960]ISPN100003: Node fedora-6960 finished rebalance phase with topology id 7
12:20:43,298 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-64492]ISPN100003: Node fedora-64492 finished rebalance phase with topology id 7
12:20:43,300 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=testCache][Scope=fedora-20962]ISPN100003: Node fedora-20962 finished rebalance phase with topology id 8
12:20:43,307 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=testCache][Scope=fedora-6960]ISPN100003: Node fedora-6960 finished rebalance phase with topology id 8
12:20:43,307 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-64492]ISPN100003: Node fedora-64492 finished rebalance phase with topology id 8
12:20:43,395 INFO  [org.radargun.Slave] (sc-main) Starting stage AfterServiceStart
12:20:43,396 INFO  [org.radargun.Slave] (sc-main) Finished stage AfterServiceStart
12:20:43,399 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
12:20:43,444 INFO  [org.radargun.Slave] (sc-main) Starting stage MonitorStart
12:20:43,454 INFO  [org.radargun.sysmonitor.AbstractMonitors] (sc-main) Gathering statistics every 1000 ms
12:20:43,454 INFO  [org.radargun.Slave] (sc-main) Finished stage MonitorStart
12:20:43,455 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
12:20:43,484 INFO  [org.radargun.Slave] (sc-main) Starting stage Load
12:20:50,470 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) This node loaded 10000 entries (~10000000 bytes)
12:20:55,172 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) This node loaded 20000 entries (~20000000 bytes)
12:20:58,864 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) This node loaded 30000 entries (~30000000 bytes)
12:20:59,805 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) Finished loading entries
12:20:59,827 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) Finished loading entries
12:20:59,843 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) Finished loading entries
12:20:59,846 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) Finished loading entries
12:20:59,862 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) Finished loading entries
12:20:59,965 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) Finished loading entries
12:21:00,024 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) Finished loading entries
12:21:00,039 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) Finished loading entries
12:21:00,079 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) Finished loading entries
12:21:00,129 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) Finished loading entries
12:21:00,129 INFO  [org.radargun.Slave] (sc-main) Finished stage Load
12:21:00,131 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
12:21:00,386 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.stages.cache.test.BasicOperationsTestStage.init() overrides public void org.radargun.stages.test.TestStage.init() but both are declared with @Init annotation: calling only once
12:21:00,390 INFO  [org.radargun.Slave] (sc-main) Starting stage BasicOperationsTest
12:21:00,392 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using key generator org.radargun.stages.cache.generators.StringKeyGenerator {format=null }
12:21:00,392 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using value generator org.radargun.stages.cache.generators.ByteArrayValueGenerator { }
12:21:00,392 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using cache selector Default { }
12:21:00,393 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Starting test warmup
12:21:00,411 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Started 4 stressor threads.
12:22:00,427 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Finished test. Test duration is: 1 mins 0 secs
12:22:00,429 INFO  [org.radargun.Slave] (sc-main) Finished stage BasicOperationsTest
12:22:00,439 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
12:22:00,458 INFO  [org.radargun.Slave] (sc-main) Starting stage Clear
12:22:00,468 INFO  [org.radargun.stages.cache.ClearStage] (sc-main) Before executing clear, memory looks like this: 
Runtime free: 1,024,817 kb
Runtime max:1,299,968 kb
Runtime total:1,299,968 kb
MX Code Cache(Non-heap memory): used: 13,617 kb, init: 2,496 kb, committed: 14,400 kb, max: 245,760 kb
MX Metaspace(Non-heap memory): used: 37,369 kb, init: 0 kb, committed: 39,424 kb, max: 0 kb
MX Compressed Class Space(Non-heap memory): used: 4,430 kb, init: 0 kb, committed: 4,864 kb, max: 1,048,576 kb
MX PS Eden Space(Heap memory): used: 130,938 kb, init: 350,208 kb, committed: 271,872 kb, max: 277,504 kb
MX PS Survivor Space(Heap memory): used: 56,192 kb, init: 57,856 kb, committed: 95,232 kb, max: 95,232 kb
MX PS Old Gen(Heap memory): used: 88,059 kb, init: 932,864 kb, committed: 932,864 kb, max: 932,864 kb
12:22:00,756 INFO  [org.radargun.stages.cache.ClearStage] (sc-main) After executing clear, memory looks like this: 
Runtime free: 1,293,537 kb
Runtime max:1,307,648 kb
Runtime total:1,307,648 kb
MX Code Cache(Non-heap memory): used: 13,712 kb, init: 2,496 kb, committed: 14,400 kb, max: 245,760 kb
MX Metaspace(Non-heap memory): used: 37,312 kb, init: 0 kb, committed: 39,424 kb, max: 0 kb
MX Compressed Class Space(Non-heap memory): used: 4,406 kb, init: 0 kb, committed: 4,864 kb, max: 1,048,576 kb
MX PS Eden Space(Heap memory): used: 1,676 kb, init: 350,208 kb, committed: 281,600 kb, max: 281,600 kb
MX PS Survivor Space(Heap memory): used: 0 kb, init: 57,856 kb, committed: 93,184 kb, max: 93,184 kb
MX PS Old Gen(Heap memory): used: 12,444 kb, init: 932,864 kb, committed: 932,864 kb, max: 932,864 kb
12:22:00,766 INFO  [org.radargun.Slave] (sc-main) Finished stage Clear
12:22:00,767 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
12:22:00,771 INFO  [org.radargun.Slave] (sc-main) Starting stage Load
12:22:04,003 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) This node loaded 10000 entries (~10000000 bytes)
12:22:07,338 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) This node loaded 20000 entries (~20000000 bytes)
12:22:10,621 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) This node loaded 30000 entries (~30000000 bytes)
12:22:11,602 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) Finished loading entries
12:22:11,638 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) Finished loading entries
12:22:11,642 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) Finished loading entries
12:22:11,650 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) Finished loading entries
12:22:11,650 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) Finished loading entries
12:22:11,654 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) Finished loading entries
12:22:11,657 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) Finished loading entries
12:22:11,669 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) Finished loading entries
12:22:11,677 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) Finished loading entries
12:22:11,680 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) Finished loading entries
12:22:11,680 INFO  [org.radargun.Slave] (sc-main) Finished stage Load
12:22:11,681 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
12:22:12,063 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.stages.cache.test.BasicOperationsTestStage.init() overrides public void org.radargun.stages.test.TestStage.init() but both are declared with @Init annotation: calling only once
12:22:12,064 INFO  [org.radargun.Slave] (sc-main) Starting stage BasicOperationsTest
12:22:12,064 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using key generator org.radargun.stages.cache.generators.StringKeyGenerator {format=null }
12:22:12,076 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using value generator org.radargun.stages.cache.generators.ByteArrayValueGenerator { }
12:22:12,077 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using cache selector Default { }
12:22:12,077 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Starting test stress-test
12:22:12,106 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Started 4 stressor threads.
12:32:12,114 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Finished test. Test duration is: 10 mins 0 secs
12:32:12,115 INFO  [org.radargun.Slave] (sc-main) Finished stage BasicOperationsTest
12:32:12,252 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
12:32:12,492 INFO  [org.radargun.Slave] (sc-main) Starting stage MonitorStop
12:32:12,493 INFO  [org.radargun.Slave] (sc-main) Finished stage MonitorStop
12:32:12,493 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
12:32:12,500 INFO  [org.radargun.Slave] (sc-main) Starting stage ScenarioDestroy
12:32:12,500 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Scenario finished, destroying...
12:32:12,500 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Memory before cleanup: 
Runtime free: 919,607 kb
Runtime max:1,332,224 kb
Runtime total:1,332,224 kb
MX Code Cache(Non-heap memory): used: 15,071 kb, init: 2,496 kb, committed: 15,232 kb, max: 245,760 kb
MX Metaspace(Non-heap memory): used: 37,866 kb, init: 0 kb, committed: 39,936 kb, max: 0 kb
MX Compressed Class Space(Non-heap memory): used: 4,441 kb, init: 0 kb, committed: 4,864 kb, max: 1,048,576 kb
MX PS Eden Space(Heap memory): used: 312,371 kb, init: 350,208 kb, committed: 332,800 kb, max: 332,800 kb
MX PS Survivor Space(Heap memory): used: 65,888 kb, init: 57,856 kb, committed: 66,560 kb, max: 66,560 kb
MX PS Old Gen(Heap memory): used: 34,356 kb, init: 932,864 kb, committed: 932,864 kb, max: 932,864 kb
12:32:12,500 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) Stopping service.
12:32:12,516 INFO  [org.infinispan.CLUSTER] (StopThread) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-64492: 247+86, fedora-6960: 265+100]}, pendingCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-64492: 256+256, fedora-6960: 256+256]}, unionCH=null, actualMembers=[fedora-64492, fedora-6960], persistentUUIDs=[8b597f18-fa66-4b80-a268-b3e80da1cbc1, 5522d009-7670-40e7-8e12-6a42dc692803]}
12:32:12,517 INFO  [org.infinispan.CLUSTER] (StopThread) [Context=testCache][Scope=fedora-20962]ISPN100002: Started rebalance with topology id 11
12:32:12,566 WARN  [org.infinispan.CLUSTER] (remote-thread--p2-t10) [Context=testCache]ISPN000312: Lost data because of graceful leaver fedora-6960
12:32:12,570 INFO  [org.infinispan.CLUSTER] (StopThread) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-64492: 123, fedora-6960: 133]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-64492: 122, fedora-6960: 134]}, unionCH=null, actualMembers=[fedora-64492, fedora-6960], persistentUUIDs=[8b597f18-fa66-4b80-a268-b3e80da1cbc1, 5522d009-7670-40e7-8e12-6a42dc692803]}
12:32:12,596 INFO  [org.infinispan.CLUSTER] (StopThread) [Context=___protobuf_metadata][Scope=fedora-20962]ISPN100002: Started rebalance with topology id 11
12:32:12,598 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t22) [Context=___protobuf_metadata][Scope=fedora-64492]ISPN100003: Node fedora-64492 finished rebalance phase with topology id 11
12:32:12,612 INFO  [org.infinispan.CLUSTER] (StopThread) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-64492: 128+55, fedora-6960: 128+42]}, pendingCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-64492: 122+134, fedora-6960: 134+122]}, unionCH=null, actualMembers=[fedora-64492, fedora-6960], persistentUUIDs=[8b597f18-fa66-4b80-a268-b3e80da1cbc1, 5522d009-7670-40e7-8e12-6a42dc692803]}
12:32:12,612 INFO  [org.infinispan.CLUSTER] (StopThread) [Context=___counters][Scope=fedora-20962]ISPN100002: Started rebalance with topology id 11
12:32:12,622 WARN  [org.infinispan.CLUSTER] (remote-thread--p2-t22) [Context=___counters]ISPN000312: Lost data because of graceful leaver fedora-64492
12:32:12,623 INFO  [org.infinispan.CLUSTER] (StopThread) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-64492: 123, fedora-6960: 133]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-64492: 122, fedora-6960: 134]}, unionCH=null, actualMembers=[fedora-64492, fedora-6960], persistentUUIDs=[8b597f18-fa66-4b80-a268-b3e80da1cbc1, 5522d009-7670-40e7-8e12-6a42dc692803]}
12:32:12,624 INFO  [org.infinispan.CLUSTER] (StopThread) [Context=org.infinispan.CONFIG][Scope=fedora-20962]ISPN100002: Started rebalance with topology id 11
12:32:12,628 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t22) [Context=org.infinispan.CONFIG][Scope=fedora-64492]ISPN100003: Node fedora-64492 finished rebalance phase with topology id 11
12:32:12,661 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t10) [Context=org.infinispan.CONFIG][Scope=fedora-6960]ISPN100003: Node fedora-6960 finished rebalance phase with topology id 11
12:32:12,661 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t30) [Context=___protobuf_metadata][Scope=fedora-6960]ISPN100003: Node fedora-6960 finished rebalance phase with topology id 12
12:32:12,663 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (remote-thread--p2-t10) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=org.infinispan.CONFIG, type=REBALANCE_PHASE_CONFIRM, sender=fedora-6960, joinInfo=null, topologyId=11, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-6960 for cache org.infinispan.CONFIG, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.invokeReplicableCommand(GlobalInboundInvocationHandler.java:169) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.runReplicableCommand(GlobalInboundInvocationHandler.java:150) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.lambda$handleReplicableCommand$1(GlobalInboundInvocationHandler.java:144) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.util.concurrent.BlockingTaskAwareExecutorServiceImpl$RunnableWrapper.run(BlockingTaskAwareExecutorServiceImpl.java:212) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0-internal]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0-internal]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0-internal]
12:32:12,663 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (remote-thread--p2-t30) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___protobuf_metadata, type=REBALANCE_PHASE_CONFIRM, sender=fedora-6960, joinInfo=null, topologyId=12, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-6960 for cache ___protobuf_metadata, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.invokeReplicableCommand(GlobalInboundInvocationHandler.java:169) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.runReplicableCommand(GlobalInboundInvocationHandler.java:150) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.lambda$handleReplicableCommand$1(GlobalInboundInvocationHandler.java:144) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.util.concurrent.BlockingTaskAwareExecutorServiceImpl$RunnableWrapper.run(BlockingTaskAwareExecutorServiceImpl.java:212) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0-internal]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0-internal]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0-internal]
12:32:12,666 INFO  [org.infinispan.CLUSTER] (StopThread) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=12, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-64492: 123, fedora-6960: 133]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-64492: 122, fedora-6960: 134]}, unionCH=null, actualMembers=[fedora-64492, fedora-6960], persistentUUIDs=[8b597f18-fa66-4b80-a268-b3e80da1cbc1, 5522d009-7670-40e7-8e12-6a42dc692803]}
12:32:12,666 INFO  [org.infinispan.CLUSTER] (StopThread) [Context=___counter_configuration][Scope=fedora-20962]ISPN100002: Started rebalance with topology id 12
12:32:12,677 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t22) [Context=___counter_configuration][Scope=fedora-6960]ISPN100003: Node fedora-6960 finished rebalance phase with topology id 12
12:32:12,678 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (remote-thread--p2-t22) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___counter_configuration, type=REBALANCE_PHASE_CONFIRM, sender=fedora-6960, joinInfo=null, topologyId=12, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-6960 for cache ___counter_configuration, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.invokeReplicableCommand(GlobalInboundInvocationHandler.java:169) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.runReplicableCommand(GlobalInboundInvocationHandler.java:150) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.lambda$handleReplicableCommand$1(GlobalInboundInvocationHandler.java:144) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.util.concurrent.BlockingTaskAwareExecutorServiceImpl$RunnableWrapper.run(BlockingTaskAwareExecutorServiceImpl.java:212) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0-internal]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0-internal]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0-internal]
12:32:12,679 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t30) [Context=___counter_configuration][Scope=fedora-6960]ISPN100003: Node fedora-6960 finished rebalance phase with topology id 13
12:32:12,680 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (remote-thread--p2-t30) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___counter_configuration, type=REBALANCE_PHASE_CONFIRM, sender=fedora-6960, joinInfo=null, topologyId=13, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-6960 for cache ___counter_configuration, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.invokeReplicableCommand(GlobalInboundInvocationHandler.java:169) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.runReplicableCommand(GlobalInboundInvocationHandler.java:150) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.lambda$handleReplicableCommand$1(GlobalInboundInvocationHandler.java:144) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.util.concurrent.BlockingTaskAwareExecutorServiceImpl$RunnableWrapper.run(BlockingTaskAwareExecutorServiceImpl.java:212) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0-internal]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0-internal]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0-internal]
12:32:12,687 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (StopThread) ISPN000080: Disconnecting JGroups channel results
12:32:12,723 INFO  [org.infinispan.CLUSTER] (jgroups-28,fedora-20962) ISPN000094: Received new cluster view for channel results: [fedora-20962|3] (2) [fedora-20962, fedora-6960]
12:32:12,723 INFO  [org.infinispan.CLUSTER] (jgroups-28,fedora-20962) ISPN100001: Node fedora-64492 left the cluster
12:32:12,764 WARN  [org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler] (remote-thread--p2-t30) ISPN000219: Shutdown while handling command CacheTopologyControlCommand{cache=___protobuf_metadata, type=LEAVE, sender=fedora-6960, joinInfo=null, topologyId=0, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
12:32:12,774 INFO  [org.radargun.service.Infinispan90Lifecycle] (StopThread) Stopped, previous view is [fedora-20962, fedora-64492, fedora-6960]
12:32:12,779 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Service successfully stopped.
12:32:12,779 INFO  [org.radargun.Slave] (sc-main) Finished stage ScenarioDestroy
12:32:12,779 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
12:32:12,825 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.service.Infinispan80EmbeddedService.destroy() overrides public void org.radargun.service.Infinispan60EmbeddedService.destroy() but both are declared with @Destroy annotation: calling only once
12:32:12,826 INFO  [org.radargun.Slave] (main) Starting stage ScenarioCleanup
12:32:12,915 INFO  [org.radargun.stages.ScenarioCleanupStage] (main) Memory after cleanup: 
Runtime free: 1,312,287 kb
Runtime max:1,331,712 kb
Runtime total:1,331,712 kb
MX Code Cache(Non-heap memory): used: 15,261 kb, init: 2,496 kb, committed: 15,488 kb, max: 245,760 kb
MX Metaspace(Non-heap memory): used: 37,964 kb, init: 0 kb, committed: 39,936 kb, max: 0 kb
MX Compressed Class Space(Non-heap memory): used: 4,458 kb, init: 0 kb, committed: 4,864 kb, max: 1,048,576 kb
MX PS Eden Space(Heap memory): used: 7,100 kb, init: 350,208 kb, committed: 331,776 kb, max: 331,776 kb
MX PS Survivor Space(Heap memory): used: 0 kb, init: 57,856 kb, committed: 67,072 kb, max: 67,072 kb
MX PS Old Gen(Heap memory): used: 12,324 kb, init: 932,864 kb, committed: 932,864 kb, max: 932,864 kb
12:32:12,917 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
12:32:18,090 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
12:32:21,933 INFO  [org.radargun.Slave] (main) Master shutdown!
12:32:21,936 INFO  [org.radargun.ShutDownHook] (Thread-0) Slave process is being shutdown
