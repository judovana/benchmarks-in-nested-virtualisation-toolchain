21:17:17,273 INFO  [org.radargun.RemoteMasterConnection] (main) Attempting to connect to master results:2103
21:17:17,282 INFO  [org.radargun.RemoteMasterConnection] (main) Successfully established connection with master at: results:2103
21:17:17,295 INFO  [org.radargun.Slave] (main) Received slave index 0
21:17:17,303 INFO  [org.radargun.Slave] (main) Received slave count 3
21:17:17,575 INFO  [org.radargun.ServiceHelper] (sc-main) ServiceContext properties: {}
21:17:17,859 INFO  [org.radargun.Slave] (sc-main) Eager Service Infinispan92EmbeddedService {batching=false, cache=testCache, channelRetrievalTimeout=2 mins 0 secs, enableDiagnostics=null, explicitLocking=false, file=/mnt/workspace/results/dist-sync.xml, internalsExpositionEnabled=false, jgroupsDumperEnabled=false, jgroupsDumperInterval=10.000 secs, keysPerThread=-1, mapReduceDistributedReducePhase=false, mapReduceUseIntermediateSharedCache=false, removedCaches=[  ], threadsPerNode=-1 } loaded.
21:17:21,900 INFO  [org.radargun.Slave] (sc-main) Starting stage ScenarioInit
21:17:21,923 INFO  [org.radargun.Slave] (sc-main) Finished stage ScenarioInit
21:17:21,927 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
21:17:21,996 INFO  [org.radargun.Slave] (sc-main) Starting stage BeforeServiceStart
21:17:21,996 INFO  [org.radargun.Slave] (sc-main) Finished stage BeforeServiceStart
21:17:21,997 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
21:17:22,006 INFO  [org.radargun.Slave] (sc-main) Starting stage ServiceStart
21:17:22,007 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Startup staggering, this is the slave with index 0, not sleeping
21:17:22,007 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 0
21:17:22,011 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) Infinispan version: Infinispan 'Gaina' 9.2.0.Final
21:17:22,029 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) JGroups version: JGroups 4.0.10.Final (Schiener Berg)
21:17:22,822 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (sc-main) ISPN000078: Starting JGroups channel results
21:17:22,916 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the send buffer of socket MulticastSocket was set to 1.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
21:17:22,917 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the receive buffer of socket MulticastSocket was set to 20.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
21:17:22,917 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the send buffer of socket MulticastSocket was set to 1.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
21:17:22,918 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the receive buffer of socket MulticastSocket was set to 25.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
21:17:27,973 INFO  [org.infinispan.CLUSTER] (sc-main) ISPN000094: Received new cluster view for channel results: [fedora-22843|0] (1) [fedora-22843]
21:17:28,053 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (sc-main) ISPN000079: Channel results local address is fedora-22843, physical addresses are [192.168.124.146:56522]
21:17:28,074 INFO  [org.infinispan.factories.GlobalComponentRegistry] (sc-main) ISPN000128: Infinispan version: Infinispan 'Gaina' 9.2.0.Final
21:17:28,846 INFO  [org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup] (sc-main) ISPN000107: Retrieving transaction manager Transaction: unknown
21:17:28,951 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) No RELAY2 protocol in XS service
21:17:28,953 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) No RELAY2 protocol in XS service
21:17:28,955 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) ([fedora-22843(local=true, coord=true)]) Number of members=1 is not the one expected: 3
21:17:29,334 INFO  [org.infinispan.CLUSTER] (jgroups-6,fedora-22843) ISPN000094: Received new cluster view for channel results: [fedora-22843|1] (2) [fedora-22843, fedora-31502]
21:17:29,350 INFO  [org.infinispan.CLUSTER] (jgroups-6,fedora-22843) ISPN100000: Node fedora-31502 joined the cluster
21:17:29,435 INFO  [org.infinispan.CLUSTER] (jgroups-6,fedora-22843) ISPN000094: Received new cluster view for channel results: [fedora-22843|2] (3) [fedora-22843, fedora-31502, fedora-53442]
21:17:29,436 INFO  [org.infinispan.CLUSTER] (jgroups-6,fedora-22843) ISPN100000: Node fedora-53442 joined the cluster
21:17:29,960 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) Number of members is the one expected: 3
21:17:29,960 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Successfully started cache service infinispan92/embedded on slave 0
21:17:30,046 ERROR [org.radargun.service.ConfigDumpHelper] (sc-main) Error while dumping ___protobuf_metadata cache config as properties
javax.management.AttributeNotFoundException: Unknown attribute 'configurationAsProperties'. Known attributes names are: [rebalancingEnabled, cacheStatus, cacheAvailability, cacheName, version, configurationAsProperties]
	at org.infinispan.jmx.ResourceDMBean.getAttribute(ResourceDMBean.java:181) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:641) ~[?:?]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:678) ~[?:?]
	at org.radargun.service.ConfigDumpHelper60.dumpCache(ConfigDumpHelper60.java:44) [plugin-infinispan60-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.service.EmbeddedConfigurationProvider.getNormalizedConfigs(EmbeddedConfigurationProvider.java:33) [plugin-infinispan52-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.stages.lifecycle.ServiceStartStage.executeOnSlave(ServiceStartStage.java:92) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase.scenarioLoop(SlaveBase.java:102) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase$ScenarioRunner.run(SlaveBase.java:203) [radargun-core-3.0.0-SNAPSHOT.jar:?]
21:17:30,081 ERROR [org.radargun.service.ConfigDumpHelper] (sc-main) Error while dumping ___protobuf_metadata cache config as properties
javax.management.AttributeNotFoundException: Unknown attribute 'configurationAsProperties'. Known attributes names are: [rebalancingEnabled, cacheStatus, cacheAvailability, cacheName, version, configurationAsProperties]
	at org.infinispan.jmx.ResourceDMBean.getAttribute(ResourceDMBean.java:181) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:641) ~[?:?]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:678) ~[?:?]
	at org.radargun.service.ConfigDumpHelper60.dumpCache(ConfigDumpHelper60.java:44) [plugin-infinispan60-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.service.EmbeddedConfigurationProvider.getNormalizedConfigs(EmbeddedConfigurationProvider.java:33) [plugin-infinispan52-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.stages.lifecycle.ServiceStartStage.executeOnSlave(ServiceStartStage.java:92) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase.scenarioLoop(SlaveBase.java:102) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase$ScenarioRunner.run(SlaveBase.java:203) [radargun-core-3.0.0-SNAPSHOT.jar:?]
21:17:30,154 INFO  [org.radargun.Slave] (sc-main) Finished stage ServiceStart
21:17:30,162 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-22843: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-22843: 128, fedora-53442: 128]}, unionCH=null, actualMembers=[fedora-22843, fedora-53442], persistentUUIDs=[2de5be0f-0592-4598-a000-8aeb6782ee80, b2079c35-97bc-438f-93e7-c52b6f1bf11a]}
21:17:30,163 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-22843: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-22843: 130, fedora-31502: 126]}, unionCH=null, actualMembers=[fedora-22843, fedora-31502], persistentUUIDs=[2de5be0f-0592-4598-a000-8aeb6782ee80, e77956b9-7655-417e-be4d-b7bb664ba123]}
21:17:30,165 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-22843]ISPN100002: Started rebalance with topology id 2
21:17:30,165 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counter_configuration][Scope=fedora-22843]ISPN100002: Started rebalance with topology id 2
21:17:30,169 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
21:17:30,204 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t22) [Context=org.infinispan.CONFIG][Scope=fedora-22843]ISPN100003: Node fedora-22843 finished rebalance phase with topology id 2
21:17:30,207 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t23) [Context=___counter_configuration][Scope=fedora-22843]ISPN100003: Node fedora-22843 finished rebalance phase with topology id 2
21:17:30,337 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___counter_configuration][Scope=fedora-31502]ISPN100003: Node fedora-31502 finished rebalance phase with topology id 2
21:17:30,338 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 2
21:17:30,345 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t25) [Context=___counter_configuration][Scope=fedora-22843]ISPN100003: Node fedora-22843 finished rebalance phase with topology id 3
21:17:30,355 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___counter_configuration][Scope=fedora-31502]ISPN100003: Node fedora-31502 finished rebalance phase with topology id 3
21:17:30,360 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t4) [Context=___counter_configuration][Scope=fedora-22843]ISPN100003: Node fedora-22843 finished rebalance phase with topology id 4
21:17:30,368 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___counter_configuration][Scope=fedora-31502]ISPN100003: Node fedora-31502 finished rebalance phase with topology id 4
21:17:30,370 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-22843: 130, fedora-31502: 126]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-22843: 87, fedora-31502: 80, fedora-53442: 89]}, unionCH=null, actualMembers=[fedora-22843, fedora-31502, fedora-53442], persistentUUIDs=[2de5be0f-0592-4598-a000-8aeb6782ee80, e77956b9-7655-417e-be4d-b7bb664ba123, b2079c35-97bc-438f-93e7-c52b6f1bf11a]}
21:17:30,372 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___counter_configuration][Scope=fedora-22843]ISPN100002: Started rebalance with topology id 6
21:17:30,376 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t9) [Context=___counter_configuration][Scope=fedora-22843]ISPN100003: Node fedora-22843 finished rebalance phase with topology id 6
21:17:30,389 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=org.infinispan.CONFIG][Scope=fedora-53442]ISPN100003: Node fedora-53442 finished rebalance phase with topology id 2
21:17:30,390 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 2
21:17:30,392 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t12) [Context=org.infinispan.CONFIG][Scope=fedora-22843]ISPN100003: Node fedora-22843 finished rebalance phase with topology id 3
21:17:30,408 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=org.infinispan.CONFIG][Scope=fedora-53442]ISPN100003: Node fedora-53442 finished rebalance phase with topology id 3
21:17:30,409 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counter_configuration][Scope=fedora-53442]ISPN100003: Node fedora-53442 finished rebalance phase with topology id 3
21:17:30,411 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t15) [Context=org.infinispan.CONFIG][Scope=fedora-22843]ISPN100003: Node fedora-22843 finished rebalance phase with topology id 4
21:17:30,412 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (remote-thread--p2-t3) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___counter_configuration, type=REBALANCE_PHASE_CONFIRM, sender=fedora-53442, joinInfo=null, topologyId=3, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-53442 for cache ___counter_configuration, expecting topology id 6 but got 3
	at org.infinispan.topology.RebalanceConfirmationCollector.confirmPhase(RebalanceConfirmationCollector.java:41) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:337) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.invokeReplicableCommand(GlobalInboundInvocationHandler.java:169) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.runReplicableCommand(GlobalInboundInvocationHandler.java:150) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.lambda$handleReplicableCommand$1(GlobalInboundInvocationHandler.java:144) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.util.concurrent.BlockingTaskAwareExecutorServiceImpl$RunnableWrapper.run(BlockingTaskAwareExecutorServiceImpl.java:212) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
21:17:30,414 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=org.infinispan.CONFIG][Scope=fedora-53442]ISPN100003: Node fedora-53442 finished rebalance phase with topology id 4
21:17:30,428 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-22843: 128, fedora-53442: 128]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-22843: 87, fedora-53442: 89, fedora-31502: 80]}, unionCH=null, actualMembers=[fedora-22843, fedora-53442, fedora-31502], persistentUUIDs=[2de5be0f-0592-4598-a000-8aeb6782ee80, b2079c35-97bc-438f-93e7-c52b6f1bf11a, e77956b9-7655-417e-be4d-b7bb664ba123]}
21:17:30,429 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=org.infinispan.CONFIG][Scope=fedora-22843]ISPN100002: Started rebalance with topology id 6
21:17:30,433 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t22) [Context=org.infinispan.CONFIG][Scope=fedora-22843]ISPN100003: Node fedora-22843 finished rebalance phase with topology id 6
21:17:30,450 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=org.infinispan.CONFIG][Scope=fedora-31502]ISPN100003: Node fedora-31502 finished rebalance phase with topology id 3
21:17:30,451 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (remote-thread--p2-t4) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=org.infinispan.CONFIG, type=REBALANCE_PHASE_CONFIRM, sender=fedora-31502, joinInfo=null, topologyId=3, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-31502 for cache org.infinispan.CONFIG, expecting topology id 6 but got 3
	at org.infinispan.topology.RebalanceConfirmationCollector.confirmPhase(RebalanceConfirmationCollector.java:41) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:337) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.invokeReplicableCommand(GlobalInboundInvocationHandler.java:169) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.runReplicableCommand(GlobalInboundInvocationHandler.java:150) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.lambda$handleReplicableCommand$1(GlobalInboundInvocationHandler.java:144) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.util.concurrent.BlockingTaskAwareExecutorServiceImpl$RunnableWrapper.run(BlockingTaskAwareExecutorServiceImpl.java:212) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
21:17:30,461 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___counter_configuration][Scope=fedora-31502]ISPN100003: Node fedora-31502 finished rebalance phase with topology id 6
21:17:30,474 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=org.infinispan.CONFIG][Scope=fedora-53442]ISPN100003: Node fedora-53442 finished rebalance phase with topology id 6
21:17:30,499 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___counter_configuration][Scope=fedora-53442]ISPN100003: Node fedora-53442 finished rebalance phase with topology id 6
21:17:30,499 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 6
21:17:30,500 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t3) [Context=___counter_configuration][Scope=fedora-22843]ISPN100003: Node fedora-22843 finished rebalance phase with topology id 7
21:17:30,518 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___counter_configuration][Scope=fedora-53442]ISPN100003: Node fedora-53442 finished rebalance phase with topology id 7
21:17:30,521 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=DefaultConsistentHash{ns=256, owners = (1)[fedora-22843: 256+0]}, pendingCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-22843: 130+126, fedora-31502: 126+130]}, unionCH=null, actualMembers=[fedora-22843, fedora-31502], persistentUUIDs=[2de5be0f-0592-4598-a000-8aeb6782ee80, e77956b9-7655-417e-be4d-b7bb664ba123]}
21:17:30,522 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___counters][Scope=fedora-22843]ISPN100002: Started rebalance with topology id 2
21:17:30,527 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t5) [Context=___counters][Scope=fedora-22843]ISPN100003: Node fedora-22843 finished rebalance phase with topology id 2
21:17:30,531 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___counter_configuration][Scope=fedora-31502]ISPN100003: Node fedora-31502 finished rebalance phase with topology id 7
21:17:30,533 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=___counter_configuration][Scope=fedora-22843]ISPN100003: Node fedora-22843 finished rebalance phase with topology id 8
21:17:30,536 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___counter_configuration][Scope=fedora-53442]ISPN100003: Node fedora-53442 finished rebalance phase with topology id 8
21:17:30,565 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___counter_configuration][Scope=fedora-31502]ISPN100003: Node fedora-31502 finished rebalance phase with topology id 8
21:17:30,697 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-22843: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-22843: 128, fedora-53442: 128]}, unionCH=null, actualMembers=[fedora-22843, fedora-53442], persistentUUIDs=[2de5be0f-0592-4598-a000-8aeb6782ee80, b2079c35-97bc-438f-93e7-c52b6f1bf11a]}
21:17:30,698 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___protobuf_metadata][Scope=fedora-22843]ISPN100002: Started rebalance with topology id 2
21:17:30,705 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t12) [Context=___protobuf_metadata][Scope=fedora-22843]ISPN100003: Node fedora-22843 finished rebalance phase with topology id 2
21:17:30,743 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=org.infinispan.CONFIG][Scope=fedora-31502]ISPN100003: Node fedora-31502 finished rebalance phase with topology id 6
21:17:30,743 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 6
21:17:30,748 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t15) [Context=org.infinispan.CONFIG][Scope=fedora-22843]ISPN100003: Node fedora-22843 finished rebalance phase with topology id 7
21:17:30,755 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=org.infinispan.CONFIG][Scope=fedora-53442]ISPN100003: Node fedora-53442 finished rebalance phase with topology id 7
21:17:30,756 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___protobuf_metadata][Scope=fedora-53442]ISPN100003: Node fedora-53442 finished rebalance phase with topology id 2
21:17:30,757 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 2
21:17:30,759 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=___protobuf_metadata][Scope=fedora-22843]ISPN100003: Node fedora-22843 finished rebalance phase with topology id 3
21:17:30,764 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___protobuf_metadata][Scope=fedora-53442]ISPN100003: Node fedora-53442 finished rebalance phase with topology id 3
21:17:30,765 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___counters][Scope=fedora-31502]ISPN100003: Node fedora-31502 finished rebalance phase with topology id 2
21:17:30,766 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t18) [Context=___protobuf_metadata][Scope=fedora-22843]ISPN100003: Node fedora-22843 finished rebalance phase with topology id 4
21:17:30,766 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) ISPN000336: Finished cluster-wide rebalance for cache ___counters, topology id = 2
21:17:30,769 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t3) [Context=___counters][Scope=fedora-22843]ISPN100003: Node fedora-22843 finished rebalance phase with topology id 3
21:17:30,776 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=org.infinispan.CONFIG][Scope=fedora-31502]ISPN100003: Node fedora-31502 finished rebalance phase with topology id 7
21:17:30,777 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t5) [Context=org.infinispan.CONFIG][Scope=fedora-22843]ISPN100003: Node fedora-22843 finished rebalance phase with topology id 8
21:17:30,787 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___protobuf_metadata][Scope=fedora-53442]ISPN100003: Node fedora-53442 finished rebalance phase with topology id 4
21:17:30,795 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=org.infinispan.CONFIG][Scope=fedora-53442]ISPN100003: Node fedora-53442 finished rebalance phase with topology id 8
21:17:30,800 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=DefaultConsistentHash{ns=512, owners = (1)[fedora-22843: 512+0]}, pendingCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-22843: 263+249, fedora-53442: 249+263]}, unionCH=null, actualMembers=[fedora-22843, fedora-53442], persistentUUIDs=[2de5be0f-0592-4598-a000-8aeb6782ee80, b2079c35-97bc-438f-93e7-c52b6f1bf11a]}
21:17:30,802 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=testCache][Scope=fedora-22843]ISPN100002: Started rebalance with topology id 2
21:17:30,802 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-31502]ISPN100003: Node fedora-31502 finished rebalance phase with topology id 3
21:17:30,801 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-22843: 128, fedora-53442: 128]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-22843: 87, fedora-53442: 89, fedora-31502: 80]}, unionCH=null, actualMembers=[fedora-22843, fedora-53442, fedora-31502], persistentUUIDs=[2de5be0f-0592-4598-a000-8aeb6782ee80, b2079c35-97bc-438f-93e7-c52b6f1bf11a, e77956b9-7655-417e-be4d-b7bb664ba123]}
21:17:30,804 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=fedora-22843]ISPN100002: Started rebalance with topology id 6
21:17:30,805 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t14) [Context=___counters][Scope=fedora-22843]ISPN100003: Node fedora-22843 finished rebalance phase with topology id 4
21:17:30,814 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t16) [Context=testCache][Scope=fedora-22843]ISPN100003: Node fedora-22843 finished rebalance phase with topology id 2
21:17:30,815 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=org.infinispan.CONFIG][Scope=fedora-31502]ISPN100003: Node fedora-31502 finished rebalance phase with topology id 8
21:17:30,810 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t12) [Context=___protobuf_metadata][Scope=fedora-22843]ISPN100003: Node fedora-22843 finished rebalance phase with topology id 6
21:17:30,827 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___counters][Scope=fedora-31502]ISPN100003: Node fedora-31502 finished rebalance phase with topology id 4
21:17:30,829 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=fedora-53442]ISPN100003: Node fedora-53442 finished rebalance phase with topology id 3
21:17:30,829 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-53442]ISPN100003: Node fedora-53442 finished rebalance phase with topology id 4
21:17:30,830 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-53442]ISPN100003: Node fedora-53442 finished rebalance phase with topology id 6
21:17:30,833 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-22843: 130+126, fedora-31502: 126+130]}, pendingCH=DefaultConsistentHash{ns=256, owners = (3)[fedora-22843: 87+71, fedora-31502: 80+86, fedora-53442: 89+99]}, unionCH=null, actualMembers=[fedora-22843, fedora-31502, fedora-53442], persistentUUIDs=[2de5be0f-0592-4598-a000-8aeb6782ee80, e77956b9-7655-417e-be4d-b7bb664ba123, b2079c35-97bc-438f-93e7-c52b6f1bf11a]}
21:17:30,833 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___counters][Scope=fedora-22843]ISPN100002: Started rebalance with topology id 6
21:17:30,834 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (remote-thread--p2-t1) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___counters, type=REBALANCE_PHASE_CONFIRM, sender=fedora-53442, joinInfo=null, topologyId=4, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-53442 for cache ___counters, expecting topology id 6 but got 4
	at org.infinispan.topology.RebalanceConfirmationCollector.confirmPhase(RebalanceConfirmationCollector.java:41) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:337) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.invokeReplicableCommand(GlobalInboundInvocationHandler.java:169) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.runReplicableCommand(GlobalInboundInvocationHandler.java:150) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.lambda$handleReplicableCommand$1(GlobalInboundInvocationHandler.java:144) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.util.concurrent.BlockingTaskAwareExecutorServiceImpl$RunnableWrapper.run(BlockingTaskAwareExecutorServiceImpl.java:212) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
21:17:30,837 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t18) [Context=___counters][Scope=fedora-22843]ISPN100003: Node fedora-22843 finished rebalance phase with topology id 6
21:17:30,837 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (remote-thread--p2-t3) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___counters, type=REBALANCE_PHASE_CONFIRM, sender=fedora-53442, joinInfo=null, topologyId=3, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-53442 for cache ___counters, expecting topology id 6 but got 3
	at org.infinispan.topology.RebalanceConfirmationCollector.confirmPhase(RebalanceConfirmationCollector.java:41) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:337) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.invokeReplicableCommand(GlobalInboundInvocationHandler.java:169) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.runReplicableCommand(GlobalInboundInvocationHandler.java:150) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.lambda$handleReplicableCommand$1(GlobalInboundInvocationHandler.java:144) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.util.concurrent.BlockingTaskAwareExecutorServiceImpl$RunnableWrapper.run(BlockingTaskAwareExecutorServiceImpl.java:212) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
21:17:30,859 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-53442]ISPN100003: Node fedora-53442 finished rebalance phase with topology id 2
21:17:30,859 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000336: Finished cluster-wide rebalance for cache testCache, topology id = 2
21:17:30,863 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t8) [Context=testCache][Scope=fedora-22843]ISPN100003: Node fedora-22843 finished rebalance phase with topology id 3
21:17:30,868 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-53442]ISPN100003: Node fedora-53442 finished rebalance phase with topology id 3
21:17:30,868 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-31502]ISPN100003: Node fedora-31502 finished rebalance phase with topology id 6
21:17:30,873 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=testCache][Scope=fedora-22843]ISPN100003: Node fedora-22843 finished rebalance phase with topology id 4
21:17:30,878 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-53442]ISPN100003: Node fedora-53442 finished rebalance phase with topology id 6
21:17:30,878 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-53442]ISPN100003: Node fedora-53442 finished rebalance phase with topology id 4
21:17:30,879 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache ___counters, topology id = 6
21:17:30,884 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t13) [Context=___counters][Scope=fedora-22843]ISPN100003: Node fedora-22843 finished rebalance phase with topology id 7
21:17:30,885 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=fedora-31502]ISPN100003: Node fedora-31502 finished rebalance phase with topology id 6
21:17:30,888 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 6
21:17:30,888 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-53442]ISPN100003: Node fedora-53442 finished rebalance phase with topology id 7
21:17:30,890 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-53442]ISPN100003: Node fedora-53442 finished rebalance phase with topology id 7
21:17:30,890 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-31502]ISPN100003: Node fedora-31502 finished rebalance phase with topology id 7
21:17:30,891 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t22) [Context=___protobuf_metadata][Scope=fedora-22843]ISPN100003: Node fedora-22843 finished rebalance phase with topology id 7
21:17:30,893 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t16) [Context=___protobuf_metadata][Scope=fedora-22843]ISPN100003: Node fedora-22843 finished rebalance phase with topology id 8
21:17:30,895 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-53442]ISPN100003: Node fedora-53442 finished rebalance phase with topology id 8
21:17:30,902 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-31502]ISPN100003: Node fedora-31502 finished rebalance phase with topology id 8
21:17:30,902 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=fedora-31502]ISPN100003: Node fedora-31502 finished rebalance phase with topology id 7
21:17:30,904 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t25) [Context=___counters][Scope=fedora-22843]ISPN100003: Node fedora-22843 finished rebalance phase with topology id 8
21:17:30,905 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=fedora-53442]ISPN100003: Node fedora-53442 finished rebalance phase with topology id 8
21:17:30,907 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=fedora-31502]ISPN100003: Node fedora-31502 finished rebalance phase with topology id 8
21:17:30,930 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-22843: 263+249, fedora-53442: 249+263]}, pendingCH=DefaultConsistentHash{ns=512, owners = (3)[fedora-22843: 169+159, fedora-53442: 175+190, fedora-31502: 168+163]}, unionCH=null, actualMembers=[fedora-22843, fedora-53442, fedora-31502], persistentUUIDs=[2de5be0f-0592-4598-a000-8aeb6782ee80, b2079c35-97bc-438f-93e7-c52b6f1bf11a, e77956b9-7655-417e-be4d-b7bb664ba123]}
21:17:30,933 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-22843]ISPN100002: Started rebalance with topology id 6
21:17:30,937 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t9) [Context=testCache][Scope=fedora-22843]ISPN100003: Node fedora-22843 finished rebalance phase with topology id 6
21:17:30,953 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-53442]ISPN100003: Node fedora-53442 finished rebalance phase with topology id 6
21:17:30,968 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-31502]ISPN100003: Node fedora-31502 finished rebalance phase with topology id 6
21:17:30,969 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache testCache, topology id = 6
21:17:30,971 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=testCache][Scope=fedora-22843]ISPN100003: Node fedora-22843 finished rebalance phase with topology id 7
21:17:30,976 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-31502]ISPN100003: Node fedora-31502 finished rebalance phase with topology id 7
21:17:30,976 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-53442]ISPN100003: Node fedora-53442 finished rebalance phase with topology id 7
21:17:30,979 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t19) [Context=testCache][Scope=fedora-22843]ISPN100003: Node fedora-22843 finished rebalance phase with topology id 8
21:17:30,984 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-53442]ISPN100003: Node fedora-53442 finished rebalance phase with topology id 8
21:17:30,984 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-31502]ISPN100003: Node fedora-31502 finished rebalance phase with topology id 8
21:17:31,188 INFO  [org.radargun.Slave] (sc-main) Starting stage AfterServiceStart
21:17:31,188 INFO  [org.radargun.Slave] (sc-main) Finished stage AfterServiceStart
21:17:31,190 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
21:17:31,325 INFO  [org.radargun.Slave] (sc-main) Starting stage MonitorStart
21:17:31,331 INFO  [org.radargun.sysmonitor.AbstractMonitors] (sc-main) Gathering statistics every 1000 ms
21:17:31,338 INFO  [org.radargun.Slave] (sc-main) Finished stage MonitorStart
21:17:31,338 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
21:17:31,357 INFO  [org.radargun.Slave] (sc-main) Starting stage Load
21:17:40,964 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) This node loaded 10000 entries (~10000000 bytes)
21:17:47,546 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) This node loaded 20000 entries (~20000000 bytes)
21:17:51,976 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) This node loaded 30000 entries (~30000000 bytes)
21:17:53,012 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) Finished loading entries
21:17:53,024 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) Finished loading entries
21:17:53,042 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) Finished loading entries
21:17:53,049 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) Finished loading entries
21:17:53,056 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) Finished loading entries
21:17:53,057 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) Finished loading entries
21:17:53,060 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) Finished loading entries
21:17:53,080 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) Finished loading entries
21:17:53,087 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) Finished loading entries
21:17:53,088 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) Finished loading entries
21:17:53,088 INFO  [org.radargun.Slave] (sc-main) Finished stage Load
21:17:53,089 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
21:17:53,124 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.stages.cache.test.BasicOperationsTestStage.init() overrides public void org.radargun.stages.test.TestStage.init() but both are declared with @Init annotation: calling only once
21:17:53,130 INFO  [org.radargun.Slave] (sc-main) Starting stage BasicOperationsTest
21:17:53,130 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using key generator org.radargun.stages.cache.generators.StringKeyGenerator {format=null }
21:17:53,131 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using value generator org.radargun.stages.cache.generators.ByteArrayValueGenerator { }
21:17:53,131 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using cache selector Default { }
21:17:53,131 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Starting test warmup
21:17:53,150 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Started 4 stressor threads.
21:18:53,185 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Finished test. Test duration is: 1 mins 0 secs
21:18:53,186 INFO  [org.radargun.Slave] (sc-main) Finished stage BasicOperationsTest
21:18:53,192 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
21:18:53,204 INFO  [org.radargun.Slave] (sc-main) Starting stage Clear
21:18:53,223 INFO  [org.radargun.stages.cache.ClearStage] (sc-main) Before executing clear, memory looks like this: 
Runtime free: 994,872 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,341 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,696 kb
MX Metaspace(Non-heap memory): used: 44,005 kb, init: 0 kb, committed: 45,340 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 12,467 kb, init: 2,496 kb, committed: 12,480 kb, max: 120,032 kb
MX Compressed Class Space(Non-heap memory): used: 4,963 kb, init: 0 kb, committed: 5,484 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 233,472 kb, init: 73,728 kb, committed: 828,416 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 118,215 kb, init: 1,325,056 kb, committed: 519,168 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 51,200 kb, init: 0 kb, committed: 51,200 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 5,277 kb, init: 2,496 kb, committed: 5,312 kb, max: 120,032 kb
21:18:53,375 INFO  [org.radargun.stages.cache.ClearStage] (sc-main) After executing clear, memory looks like this: 
Runtime free: 1,381,533 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,327 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,696 kb
MX Metaspace(Non-heap memory): used: 43,958 kb, init: 0 kb, committed: 45,340 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 12,533 kb, init: 2,496 kb, committed: 12,544 kb, max: 120,032 kb
MX Compressed Class Space(Non-heap memory): used: 4,941 kb, init: 0 kb, committed: 5,484 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 0 kb, init: 73,728 kb, committed: 880,640 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 16,738 kb, init: 1,325,056 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 0 kb, init: 0 kb, committed: 0 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 5,289 kb, init: 2,496 kb, committed: 5,312 kb, max: 120,032 kb
21:18:53,376 INFO  [org.radargun.Slave] (sc-main) Finished stage Clear
21:18:53,378 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
21:18:53,411 INFO  [org.radargun.Slave] (sc-main) Starting stage Load
21:18:56,786 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) This node loaded 10000 entries (~10000000 bytes)
21:19:00,095 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) This node loaded 20000 entries (~20000000 bytes)
21:19:03,420 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) This node loaded 30000 entries (~30000000 bytes)
21:19:04,339 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) Finished loading entries
21:19:04,355 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) Finished loading entries
21:19:04,372 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) Finished loading entries
21:19:04,373 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) Finished loading entries
21:19:04,376 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) Finished loading entries
21:19:04,385 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) Finished loading entries
21:19:04,385 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) Finished loading entries
21:19:04,388 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) Finished loading entries
21:19:04,391 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) Finished loading entries
21:19:04,413 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) Finished loading entries
21:19:04,414 INFO  [org.radargun.Slave] (sc-main) Finished stage Load
21:19:04,415 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
21:19:04,631 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.stages.cache.test.BasicOperationsTestStage.init() overrides public void org.radargun.stages.test.TestStage.init() but both are declared with @Init annotation: calling only once
21:19:04,632 INFO  [org.radargun.Slave] (sc-main) Starting stage BasicOperationsTest
21:19:04,632 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using key generator org.radargun.stages.cache.generators.StringKeyGenerator {format=null }
21:19:04,633 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using value generator org.radargun.stages.cache.generators.ByteArrayValueGenerator { }
21:19:04,633 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using cache selector Default { }
21:19:04,634 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Starting test stress-test
21:19:04,653 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Started 4 stressor threads.
21:29:04,657 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Finished test. Test duration is: 10 mins 0 secs
21:29:04,662 INFO  [org.radargun.Slave] (sc-main) Finished stage BasicOperationsTest
21:29:04,790 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
21:29:05,154 INFO  [org.radargun.Slave] (sc-main) Starting stage MonitorStop
21:29:05,156 INFO  [org.radargun.Slave] (sc-main) Finished stage MonitorStop
21:29:05,156 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
21:29:05,164 INFO  [org.radargun.Slave] (sc-main) Starting stage ScenarioDestroy
21:29:05,165 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Scenario finished, destroying...
21:29:05,166 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Memory before cleanup: 
Runtime free: 299,209 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,329 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,696 kb
MX Metaspace(Non-heap memory): used: 44,702 kb, init: 0 kb, committed: 46,236 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 14,399 kb, init: 2,496 kb, committed: 14,400 kb, max: 120,032 kb
MX Compressed Class Space(Non-heap memory): used: 4,982 kb, init: 0 kb, committed: 5,612 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 760,832 kb, init: 73,728 kb, committed: 824,320 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 280,372 kb, init: 1,325,056 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 56,320 kb, init: 0 kb, committed: 56,320 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 6,363 kb, init: 2,496 kb, committed: 6,400 kb, max: 120,032 kb
21:29:05,167 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) Stopping service.
21:29:05,179 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t29) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-22843: 239+89, fedora-53442: 273+92]}, pendingCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-22843: 263+249, fedora-53442: 249+263]}, unionCH=null, actualMembers=[fedora-22843, fedora-53442], persistentUUIDs=[2de5be0f-0592-4598-a000-8aeb6782ee80, b2079c35-97bc-438f-93e7-c52b6f1bf11a]}
21:29:05,180 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t29) [Context=testCache][Scope=fedora-22843]ISPN100002: Started rebalance with topology id 11
21:29:05,187 WARN  [org.infinispan.CLUSTER] (remote-thread--p2-t29) [Context=testCache]ISPN000312: Lost data because of graceful leaver fedora-53442
21:29:05,265 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t26) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-22843: 115+43, fedora-53442: 141+47]}, pendingCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-22843: 128+128, fedora-53442: 128+128]}, unionCH=null, actualMembers=[fedora-22843, fedora-53442], persistentUUIDs=[2de5be0f-0592-4598-a000-8aeb6782ee80, b2079c35-97bc-438f-93e7-c52b6f1bf11a]}
21:29:05,266 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t26) [Context=___counters][Scope=fedora-22843]ISPN100002: Started rebalance with topology id 11
21:29:05,289 INFO  [org.infinispan.CLUSTER] (jgroups-23,fedora-22843) ISPN000094: Received new cluster view for channel results: [fedora-22843|3] (2) [fedora-22843, fedora-53442]
21:29:05,291 INFO  [org.infinispan.CLUSTER] (jgroups-23,fedora-22843) ISPN100001: Node fedora-31502 left the cluster
21:29:05,299 WARN  [org.infinispan.CLUSTER] (StopThread) [Context=___counters]ISPN000312: Lost data because of graceful leaver fedora-22843
21:29:05,307 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t22) [Context=___counters][Scope=fedora-53442]ISPN100003: Node fedora-53442 finished rebalance phase with topology id 12
21:29:05,314 WARN  [org.infinispan.statetransfer.InboundTransferTask] (stateTransferExecutor-thread--p6-t1) ISPN000210: Failed to request state of cache testCache from node fedora-53442, segments {0-1 7-14 18 22 27-28 43 57-60 66-67 71-75 78-79 84 89 96-97 100-103 114-118 124-129 132-136 150-151 155 163-171 174-175 184-186 198 204-206 222-224 237 249 254-261 270-273 277-282 287 290-292 295 302-306 316-327 334-335 338-339 344-349 352-354 359 364-365 377 380-381 388 391-392 396-398 401 407 410 425-428 434-435 439 450 457-460 467 472-481 490 493-495 501-511}
org.infinispan.remoting.transport.jgroups.SuspectException: ISPN000400: Node fedora-53442 was suspected
	at org.infinispan.remoting.transport.ResponseCollectors.remoteNodeSuspected(ResponseCollectors.java:33) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleResponseCollector.targetNotFound(SingleResponseCollector.java:31) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleResponseCollector.targetNotFound(SingleResponseCollector.java:17) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.ValidSingleResponseCollector.addResponse(ValidSingleResponseCollector.java:23) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleTargetRequest.receiveResponse(SingleTargetRequest.java:51) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleTargetRequest.onResponse(SingleTargetRequest.java:35) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.RequestRepository.addResponse(RequestRepository.java:53) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.processResponse(JGroupsTransport.java:1302) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.processMessage(JGroupsTransport.java:1205) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.access$200(JGroupsTransport.java:123) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport$ChannelCallbacks.receive(JGroupsTransport.java:1340) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.jgroups.JChannel.up(JChannel.java:819) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.stack.ProtocolStack.up(ProtocolStack.java:893) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FRAG3.up(FRAG3.java:171) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FlowControl.up(FlowControl.java:343) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FlowControl.up(FlowControl.java:343) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.GMS.up(GMS.java:864) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.STABLE.up(STABLE.java:240) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.deliverMessage(UNICAST3.java:1002) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.handleDataReceived(UNICAST3.java:728) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.up(UNICAST3.java:383) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.NAKACK2.up(NAKACK2.java:600) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.VERIFY_SUSPECT.up(VERIFY_SUSPECT.java:119) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FD_ALL.up(FD_ALL.java:199) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FD_SOCK.up(FD_SOCK.java:252) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.MERGE3.up(MERGE3.java:276) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.Discovery.up(Discovery.java:267) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.TP.passMessageUp(TP.java:1248) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.util.SubmitToThreadPool$SingleMessageHandler.run(SubmitToThreadPool.java:87) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
21:29:05,405 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t2) [Context=testCache][Scope=fedora-22843]ISPN100003: Node fedora-22843 finished rebalance phase with topology id 12
21:29:05,415 INFO  [org.infinispan.CLUSTER] (jgroups-29,fedora-22843) ISPN000094: Received new cluster view for channel results: [fedora-22843|4] (1) [fedora-22843]
21:29:05,416 INFO  [org.infinispan.CLUSTER] (jgroups-29,fedora-22843) ISPN100001: Node fedora-53442 left the cluster
21:29:05,418 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (StopThread) ISPN000080: Disconnecting JGroups channel results
21:29:05,478 INFO  [org.radargun.service.Infinispan90Lifecycle] (StopThread) Stopped, previous view is [fedora-22843, fedora-31502, fedora-53442]
21:29:05,478 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Service successfully stopped.
21:29:05,479 INFO  [org.radargun.Slave] (sc-main) Finished stage ScenarioDestroy
21:29:05,479 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
21:29:05,487 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.service.Infinispan80EmbeddedService.destroy() overrides public void org.radargun.service.Infinispan60EmbeddedService.destroy() but both are declared with @Destroy annotation: calling only once
21:29:05,491 INFO  [org.radargun.Slave] (main) Starting stage ScenarioCleanup
21:29:05,492 WARN  [org.radargun.stages.ScenarioCleanupStage] (main) Unfinished thread ForkJoinPool.commonPool-worker-3 (id=34, state=WAITING)
	at java.base@11.0.16-internal/jdk.internal.misc.Unsafe.park(Native Method)
	at java.base@11.0.16-internal/java.util.concurrent.locks.LockSupport.park(LockSupport.java:194)
	at java.base@11.0.16-internal/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1628)
	at java.base@11.0.16-internal/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
21:29:05,492 INFO  [org.radargun.stages.ScenarioCleanupStage] (main) Interrupting thread ForkJoinPool.commonPool-worker-3 (id=34, state=WAITING)
21:29:10,494 INFO  [org.radargun.stages.ScenarioCleanupStage] (main) Stopping thread ForkJoinPool.commonPool-worker-3 (id=34, state=WAITING)
21:29:10,503 INFO  [org.radargun.stages.ScenarioCleanupStage] (main) Is thread ForkJoinPool.commonPool-worker-3 (id=34, state=TERMINATED)) alive? false
21:29:10,674 INFO  [org.radargun.stages.ScenarioCleanupStage] (main) Memory after cleanup: 
Runtime free: 1,380,562 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,331 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,696 kb
MX Metaspace(Non-heap memory): used: 44,857 kb, init: 0 kb, committed: 46,236 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 14,640 kb, init: 2,496 kb, committed: 14,656 kb, max: 120,032 kb
MX Compressed Class Space(Non-heap memory): used: 5,006 kb, init: 0 kb, committed: 5,612 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 0 kb, init: 73,728 kb, committed: 880,640 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 17,709 kb, init: 1,325,056 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 0 kb, init: 0 kb, committed: 0 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 6,461 kb, init: 2,496 kb, committed: 6,464 kb, max: 120,032 kb
21:29:10,676 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
21:29:10,716 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
21:29:16,386 INFO  [org.radargun.Slave] (main) Master shutdown!
21:29:16,388 INFO  [org.radargun.ShutDownHook] (Thread-0) Slave process is being shutdown
