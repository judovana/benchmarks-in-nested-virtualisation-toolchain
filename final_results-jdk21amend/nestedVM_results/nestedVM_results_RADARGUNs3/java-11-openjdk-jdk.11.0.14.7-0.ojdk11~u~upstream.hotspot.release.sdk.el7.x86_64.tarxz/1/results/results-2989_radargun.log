17:54:12,365 INFO  [org.radargun.RemoteMasterConnection] (main) Attempting to connect to master results:2103
17:54:12,374 INFO  [org.radargun.RemoteMasterConnection] (main) Successfully established connection with master at: results:2103
17:54:12,389 INFO  [org.radargun.Slave] (main) Received slave index 0
17:54:12,390 INFO  [org.radargun.Slave] (main) Received slave count 3
17:54:12,639 INFO  [org.radargun.ServiceHelper] (sc-main) ServiceContext properties: {}
17:54:12,977 INFO  [org.radargun.Slave] (sc-main) Eager Service Infinispan92EmbeddedService {batching=false, cache=testCache, channelRetrievalTimeout=2 mins 0 secs, enableDiagnostics=null, explicitLocking=false, file=/mnt/workspace/results/dist-sync.xml, internalsExpositionEnabled=false, jgroupsDumperEnabled=false, jgroupsDumperInterval=10.000 secs, keysPerThread=-1, mapReduceDistributedReducePhase=false, mapReduceUseIntermediateSharedCache=false, removedCaches=[  ], threadsPerNode=-1 } loaded.
17:54:15,323 INFO  [org.radargun.Slave] (sc-main) Starting stage ScenarioInit
17:54:15,408 INFO  [org.radargun.Slave] (sc-main) Finished stage ScenarioInit
17:54:15,412 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
17:54:15,451 INFO  [org.radargun.Slave] (sc-main) Starting stage BeforeServiceStart
17:54:15,451 INFO  [org.radargun.Slave] (sc-main) Finished stage BeforeServiceStart
17:54:15,453 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
17:54:15,460 INFO  [org.radargun.Slave] (sc-main) Starting stage ServiceStart
17:54:15,461 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Startup staggering, this is the slave with index 0, not sleeping
17:54:15,461 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 0
17:54:15,468 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) Infinispan version: Infinispan 'Gaina' 9.2.0.Final
17:54:15,487 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) JGroups version: JGroups 4.0.10.Final (Schiener Berg)
17:54:16,210 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (sc-main) ISPN000078: Starting JGroups channel results
17:54:16,285 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the send buffer of socket MulticastSocket was set to 1.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
17:54:16,286 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the receive buffer of socket MulticastSocket was set to 20.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
17:54:16,286 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the send buffer of socket MulticastSocket was set to 1.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
17:54:16,286 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the receive buffer of socket MulticastSocket was set to 25.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
17:54:21,318 INFO  [org.infinispan.CLUSTER] (sc-main) ISPN000094: Received new cluster view for channel results: [fedora-23590|0] (1) [fedora-23590]
17:54:21,443 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (sc-main) ISPN000079: Channel results local address is fedora-23590, physical addresses are [192.168.124.110:47915]
17:54:21,446 INFO  [org.infinispan.factories.GlobalComponentRegistry] (sc-main) ISPN000128: Infinispan version: Infinispan 'Gaina' 9.2.0.Final
17:54:22,271 INFO  [org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup] (sc-main) ISPN000107: Retrieving transaction manager Transaction: unknown
17:54:22,479 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) No RELAY2 protocol in XS service
17:54:22,482 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) No RELAY2 protocol in XS service
17:54:22,489 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) ([fedora-23590(local=true, coord=true)]) Number of members=1 is not the one expected: 3
17:54:22,693 INFO  [org.infinispan.CLUSTER] (jgroups-6,fedora-23590) ISPN000094: Received new cluster view for channel results: [fedora-23590|1] (2) [fedora-23590, fedora-32293]
17:54:22,714 INFO  [org.infinispan.CLUSTER] (jgroups-6,fedora-23590) ISPN100000: Node fedora-32293 joined the cluster
17:54:22,853 INFO  [org.infinispan.CLUSTER] (jgroups-6,fedora-23590) ISPN000094: Received new cluster view for channel results: [fedora-23590|2] (3) [fedora-23590, fedora-32293, fedora-17930]
17:54:22,864 INFO  [org.infinispan.CLUSTER] (jgroups-6,fedora-23590) ISPN100000: Node fedora-17930 joined the cluster
17:54:23,424 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-23590: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-23590: 132, fedora-32293: 124]}, unionCH=null, actualMembers=[fedora-23590, fedora-32293], persistentUUIDs=[386d38b4-2976-4f97-8389-4cabd28b9f69, 4f867261-5f71-414b-941c-f1c57baecdcc]}
17:54:23,426 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-23590]ISPN100002: Started rebalance with topology id 2
17:54:23,459 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-23590: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-23590: 132, fedora-32293: 124]}, unionCH=null, actualMembers=[fedora-23590, fedora-32293], persistentUUIDs=[386d38b4-2976-4f97-8389-4cabd28b9f69, 4f867261-5f71-414b-941c-f1c57baecdcc]}
17:54:23,460 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-23590]ISPN100002: Started rebalance with topology id 2
17:54:23,475 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t22) [Context=org.infinispan.CONFIG][Scope=fedora-23590]ISPN100003: Node fedora-23590 finished rebalance phase with topology id 2
17:54:23,490 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) Number of members is the one expected: 3
17:54:23,490 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Successfully started cache service infinispan92/embedded on slave 0
17:54:23,530 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t24) [Context=___counter_configuration][Scope=fedora-23590]ISPN100003: Node fedora-23590 finished rebalance phase with topology id 2
17:54:23,590 ERROR [org.radargun.service.ConfigDumpHelper] (sc-main) Error while dumping ___protobuf_metadata cache config as properties
javax.management.AttributeNotFoundException: Unknown attribute 'configurationAsProperties'. Known attributes names are: [rebalancingEnabled, cacheStatus, cacheName, cacheAvailability, version, configurationAsProperties]
	at org.infinispan.jmx.ResourceDMBean.getAttribute(ResourceDMBean.java:181) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:641) ~[?:?]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:678) ~[?:?]
	at org.radargun.service.ConfigDumpHelper60.dumpCache(ConfigDumpHelper60.java:44) [plugin-infinispan60-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.service.EmbeddedConfigurationProvider.getNormalizedConfigs(EmbeddedConfigurationProvider.java:33) [plugin-infinispan52-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.stages.lifecycle.ServiceStartStage.executeOnSlave(ServiceStartStage.java:92) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase.scenarioLoop(SlaveBase.java:102) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase$ScenarioRunner.run(SlaveBase.java:203) [radargun-core-3.0.0-SNAPSHOT.jar:?]
17:54:23,600 ERROR [org.radargun.service.ConfigDumpHelper] (sc-main) Error while dumping ___protobuf_metadata cache config as properties
javax.management.AttributeNotFoundException: Unknown attribute 'configurationAsProperties'. Known attributes names are: [rebalancingEnabled, cacheStatus, cacheName, cacheAvailability, version, configurationAsProperties]
	at org.infinispan.jmx.ResourceDMBean.getAttribute(ResourceDMBean.java:181) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:641) ~[?:?]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:678) ~[?:?]
	at org.radargun.service.ConfigDumpHelper60.dumpCache(ConfigDumpHelper60.java:44) [plugin-infinispan60-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.service.EmbeddedConfigurationProvider.getNormalizedConfigs(EmbeddedConfigurationProvider.java:33) [plugin-infinispan52-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.stages.lifecycle.ServiceStartStage.executeOnSlave(ServiceStartStage.java:92) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase.scenarioLoop(SlaveBase.java:102) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase$ScenarioRunner.run(SlaveBase.java:203) [radargun-core-3.0.0-SNAPSHOT.jar:?]
17:54:23,643 INFO  [org.radargun.Slave] (sc-main) Finished stage ServiceStart
17:54:23,667 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
17:54:23,710 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-32293]ISPN100003: Node fedora-32293 finished rebalance phase with topology id 2
17:54:23,713 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 2
17:54:23,717 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t5) [Context=___counter_configuration][Scope=fedora-23590]ISPN100003: Node fedora-23590 finished rebalance phase with topology id 3
17:54:23,733 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-32293]ISPN100003: Node fedora-32293 finished rebalance phase with topology id 3
17:54:23,739 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t4) [Context=___counter_configuration][Scope=fedora-23590]ISPN100003: Node fedora-23590 finished rebalance phase with topology id 4
17:54:23,743 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-17930]ISPN100003: Node fedora-17930 finished rebalance phase with topology id 3
17:54:23,745 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (remote-thread--p2-t1) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___counter_configuration, type=REBALANCE_PHASE_CONFIRM, sender=fedora-17930, joinInfo=null, topologyId=3, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-17930 for cache ___counter_configuration, expecting topology id 4 but got 3
	at org.infinispan.topology.RebalanceConfirmationCollector.confirmPhase(RebalanceConfirmationCollector.java:41) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:337) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.invokeReplicableCommand(GlobalInboundInvocationHandler.java:169) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.runReplicableCommand(GlobalInboundInvocationHandler.java:150) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.lambda$handleReplicableCommand$1(GlobalInboundInvocationHandler.java:144) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.util.concurrent.BlockingTaskAwareExecutorServiceImpl$RunnableWrapper.run(BlockingTaskAwareExecutorServiceImpl.java:212) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
17:54:23,747 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-17930]ISPN100003: Node fedora-17930 finished rebalance phase with topology id 4
17:54:23,759 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-32293]ISPN100003: Node fedora-32293 finished rebalance phase with topology id 2
17:54:23,760 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-32293]ISPN100003: Node fedora-32293 finished rebalance phase with topology id 4
17:54:23,762 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-23590: 132, fedora-32293: 124]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-23590: 84, fedora-32293: 90, fedora-17930: 82]}, unionCH=null, actualMembers=[fedora-23590, fedora-32293, fedora-17930], persistentUUIDs=[386d38b4-2976-4f97-8389-4cabd28b9f69, 4f867261-5f71-414b-941c-f1c57baecdcc, a7a7ef47-7b75-4269-be81-bbe4bd016d43]}
17:54:23,765 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-23590]ISPN100002: Started rebalance with topology id 6
17:54:23,761 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 2
17:54:23,773 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t10) [Context=___counter_configuration][Scope=fedora-23590]ISPN100003: Node fedora-23590 finished rebalance phase with topology id 6
17:54:23,773 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t11) [Context=org.infinispan.CONFIG][Scope=fedora-23590]ISPN100003: Node fedora-23590 finished rebalance phase with topology id 3
17:54:23,792 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-17930]ISPN100003: Node fedora-17930 finished rebalance phase with topology id 3
17:54:23,805 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-32293]ISPN100003: Node fedora-32293 finished rebalance phase with topology id 3
17:54:23,807 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t17) [Context=org.infinispan.CONFIG][Scope=fedora-23590]ISPN100003: Node fedora-23590 finished rebalance phase with topology id 4
17:54:23,814 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-32293]ISPN100003: Node fedora-32293 finished rebalance phase with topology id 6
17:54:23,825 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-32293]ISPN100003: Node fedora-32293 finished rebalance phase with topology id 4
17:54:23,833 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=DefaultConsistentHash{ns=256, owners = (1)[fedora-23590: 256+0]}, pendingCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-23590: 132+124, fedora-32293: 124+132]}, unionCH=null, actualMembers=[fedora-23590, fedora-32293], persistentUUIDs=[386d38b4-2976-4f97-8389-4cabd28b9f69, 4f867261-5f71-414b-941c-f1c57baecdcc]}
17:54:23,834 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-23590]ISPN100002: Started rebalance with topology id 2
17:54:23,834 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-23590: 132, fedora-32293: 124]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-23590: 84, fedora-32293: 90, fedora-17930: 82]}, unionCH=null, actualMembers=[fedora-23590, fedora-32293, fedora-17930], persistentUUIDs=[386d38b4-2976-4f97-8389-4cabd28b9f69, 4f867261-5f71-414b-941c-f1c57baecdcc, a7a7ef47-7b75-4269-be81-bbe4bd016d43]}
17:54:23,838 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-23590]ISPN100002: Started rebalance with topology id 6
17:54:23,844 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t24) [Context=org.infinispan.CONFIG][Scope=fedora-23590]ISPN100003: Node fedora-23590 finished rebalance phase with topology id 6
17:54:23,847 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t22) [Context=___counters][Scope=fedora-23590]ISPN100003: Node fedora-23590 finished rebalance phase with topology id 2
17:54:23,847 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-17930]ISPN100003: Node fedora-17930 finished rebalance phase with topology id 4
17:54:23,848 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (remote-thread--p2-t2) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=org.infinispan.CONFIG, type=REBALANCE_PHASE_CONFIRM, sender=fedora-17930, joinInfo=null, topologyId=4, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-17930 for cache org.infinispan.CONFIG, expecting topology id 6 but got 4
	at org.infinispan.topology.RebalanceConfirmationCollector.confirmPhase(RebalanceConfirmationCollector.java:41) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:337) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.invokeReplicableCommand(GlobalInboundInvocationHandler.java:169) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.runReplicableCommand(GlobalInboundInvocationHandler.java:150) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.lambda$handleReplicableCommand$1(GlobalInboundInvocationHandler.java:144) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.util.concurrent.BlockingTaskAwareExecutorServiceImpl$RunnableWrapper.run(BlockingTaskAwareExecutorServiceImpl.java:212) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
17:54:23,854 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-32293]ISPN100003: Node fedora-32293 finished rebalance phase with topology id 6
17:54:24,017 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-32293]ISPN100003: Node fedora-32293 finished rebalance phase with topology id 2
17:54:24,018 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache ___counters, topology id = 2
17:54:24,023 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=___counters][Scope=fedora-23590]ISPN100003: Node fedora-23590 finished rebalance phase with topology id 3
17:54:24,041 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-17930]ISPN100003: Node fedora-17930 finished rebalance phase with topology id 6
17:54:24,042 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 6
17:54:24,043 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t12) [Context=___counter_configuration][Scope=fedora-23590]ISPN100003: Node fedora-23590 finished rebalance phase with topology id 7
17:54:24,048 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-32293]ISPN100003: Node fedora-32293 finished rebalance phase with topology id 3
17:54:24,050 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t13) [Context=___counters][Scope=fedora-23590]ISPN100003: Node fedora-23590 finished rebalance phase with topology id 4
17:54:24,058 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-32293]ISPN100003: Node fedora-32293 finished rebalance phase with topology id 7
17:54:24,066 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-23590: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-23590: 132, fedora-32293: 124]}, unionCH=null, actualMembers=[fedora-23590, fedora-32293], persistentUUIDs=[386d38b4-2976-4f97-8389-4cabd28b9f69, 4f867261-5f71-414b-941c-f1c57baecdcc]}
17:54:24,069 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-23590]ISPN100002: Started rebalance with topology id 2
17:54:24,068 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-32293]ISPN100003: Node fedora-32293 finished rebalance phase with topology id 4
17:54:24,082 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t10) [Context=___protobuf_metadata][Scope=fedora-23590]ISPN100003: Node fedora-23590 finished rebalance phase with topology id 2
17:54:24,083 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-17930]ISPN100003: Node fedora-17930 finished rebalance phase with topology id 7
17:54:24,084 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=___counter_configuration][Scope=fedora-23590]ISPN100003: Node fedora-23590 finished rebalance phase with topology id 8
17:54:24,091 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-17930]ISPN100003: Node fedora-17930 finished rebalance phase with topology id 6
17:54:24,092 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 6
17:54:24,093 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t2) [Context=org.infinispan.CONFIG][Scope=fedora-23590]ISPN100003: Node fedora-23590 finished rebalance phase with topology id 7
17:54:24,095 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-17930]ISPN100003: Node fedora-17930 finished rebalance phase with topology id 8
17:54:24,099 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-32293]ISPN100003: Node fedora-32293 finished rebalance phase with topology id 8
17:54:24,112 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-32293]ISPN100003: Node fedora-32293 finished rebalance phase with topology id 7
17:54:24,132 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-17930]ISPN100003: Node fedora-17930 finished rebalance phase with topology id 7
17:54:24,133 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t4) [Context=org.infinispan.CONFIG][Scope=fedora-23590]ISPN100003: Node fedora-23590 finished rebalance phase with topology id 8
17:54:24,135 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-32293]ISPN100003: Node fedora-32293 finished rebalance phase with topology id 8
17:54:24,150 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=DefaultConsistentHash{ns=512, owners = (1)[fedora-23590: 512+0]}, pendingCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-23590: 251+261, fedora-32293: 261+251]}, unionCH=null, actualMembers=[fedora-23590, fedora-32293], persistentUUIDs=[386d38b4-2976-4f97-8389-4cabd28b9f69, 4f867261-5f71-414b-941c-f1c57baecdcc]}
17:54:24,151 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-23590]ISPN100002: Started rebalance with topology id 2
17:54:24,156 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-17930]ISPN100003: Node fedora-17930 finished rebalance phase with topology id 8
17:54:24,157 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-23590: 132+124, fedora-32293: 124+132]}, pendingCH=DefaultConsistentHash{ns=256, owners = (3)[fedora-23590: 84+76, fedora-32293: 90+89, fedora-17930: 82+91]}, unionCH=null, actualMembers=[fedora-23590, fedora-32293, fedora-17930], persistentUUIDs=[386d38b4-2976-4f97-8389-4cabd28b9f69, 4f867261-5f71-414b-941c-f1c57baecdcc, a7a7ef47-7b75-4269-be81-bbe4bd016d43]}
17:54:24,157 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-23590]ISPN100002: Started rebalance with topology id 6
17:54:24,160 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t12) [Context=___counters][Scope=fedora-23590]ISPN100003: Node fedora-23590 finished rebalance phase with topology id 6
17:54:24,161 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t9) [Context=testCache][Scope=fedora-23590]ISPN100003: Node fedora-23590 finished rebalance phase with topology id 2
17:54:24,191 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-32293]ISPN100003: Node fedora-32293 finished rebalance phase with topology id 6
17:54:24,202 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-32293]ISPN100003: Node fedora-32293 finished rebalance phase with topology id 2
17:54:24,203 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 2
17:54:24,205 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=___protobuf_metadata][Scope=fedora-23590]ISPN100003: Node fedora-23590 finished rebalance phase with topology id 3
17:54:24,207 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-32293]ISPN100003: Node fedora-32293 finished rebalance phase with topology id 3
17:54:24,210 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t25) [Context=___protobuf_metadata][Scope=fedora-23590]ISPN100003: Node fedora-23590 finished rebalance phase with topology id 4
17:54:24,212 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-32293]ISPN100003: Node fedora-32293 finished rebalance phase with topology id 4
17:54:24,214 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-23590: 132, fedora-32293: 124]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-23590: 84, fedora-32293: 90, fedora-17930: 82]}, unionCH=null, actualMembers=[fedora-23590, fedora-32293, fedora-17930], persistentUUIDs=[386d38b4-2976-4f97-8389-4cabd28b9f69, 4f867261-5f71-414b-941c-f1c57baecdcc, a7a7ef47-7b75-4269-be81-bbe4bd016d43]}
17:54:24,214 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-23590]ISPN100002: Started rebalance with topology id 6
17:54:24,220 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t5) [Context=___protobuf_metadata][Scope=fedora-23590]ISPN100003: Node fedora-23590 finished rebalance phase with topology id 6
17:54:24,227 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-32293]ISPN100003: Node fedora-32293 finished rebalance phase with topology id 6
17:54:24,238 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-17930]ISPN100003: Node fedora-17930 finished rebalance phase with topology id 3
17:54:24,239 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (remote-thread--p2-t1) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___protobuf_metadata, type=REBALANCE_PHASE_CONFIRM, sender=fedora-17930, joinInfo=null, topologyId=3, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-17930 for cache ___protobuf_metadata, expecting topology id 6 but got 3
	at org.infinispan.topology.RebalanceConfirmationCollector.confirmPhase(RebalanceConfirmationCollector.java:41) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:337) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.invokeReplicableCommand(GlobalInboundInvocationHandler.java:169) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.runReplicableCommand(GlobalInboundInvocationHandler.java:150) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.lambda$handleReplicableCommand$1(GlobalInboundInvocationHandler.java:144) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.util.concurrent.BlockingTaskAwareExecutorServiceImpl$RunnableWrapper.run(BlockingTaskAwareExecutorServiceImpl.java:212) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
17:54:24,242 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-17930]ISPN100003: Node fedora-17930 finished rebalance phase with topology id 4
17:54:24,242 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (remote-thread--p2-t1) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___protobuf_metadata, type=REBALANCE_PHASE_CONFIRM, sender=fedora-17930, joinInfo=null, topologyId=4, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-17930 for cache ___protobuf_metadata, expecting topology id 6 but got 4
	at org.infinispan.topology.RebalanceConfirmationCollector.confirmPhase(RebalanceConfirmationCollector.java:41) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:337) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.invokeReplicableCommand(GlobalInboundInvocationHandler.java:169) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.runReplicableCommand(GlobalInboundInvocationHandler.java:150) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.lambda$handleReplicableCommand$1(GlobalInboundInvocationHandler.java:144) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.util.concurrent.BlockingTaskAwareExecutorServiceImpl$RunnableWrapper.run(BlockingTaskAwareExecutorServiceImpl.java:212) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
17:54:24,260 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-32293]ISPN100003: Node fedora-32293 finished rebalance phase with topology id 2
17:54:24,261 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache testCache, topology id = 2
17:54:24,263 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t4) [Context=testCache][Scope=fedora-23590]ISPN100003: Node fedora-23590 finished rebalance phase with topology id 3
17:54:24,266 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-32293]ISPN100003: Node fedora-32293 finished rebalance phase with topology id 3
17:54:24,267 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-17930]ISPN100003: Node fedora-17930 finished rebalance phase with topology id 6
17:54:24,271 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t12) [Context=testCache][Scope=fedora-23590]ISPN100003: Node fedora-23590 finished rebalance phase with topology id 4
17:54:24,274 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache ___counters, topology id = 6
17:54:24,276 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t11) [Context=___counters][Scope=fedora-23590]ISPN100003: Node fedora-23590 finished rebalance phase with topology id 7
17:54:24,277 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-32293]ISPN100003: Node fedora-32293 finished rebalance phase with topology id 4
17:54:24,281 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-32293]ISPN100003: Node fedora-32293 finished rebalance phase with topology id 7
17:54:24,287 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-23590: 251+261, fedora-32293: 261+251]}, pendingCH=DefaultConsistentHash{ns=512, owners = (3)[fedora-23590: 167+164, fedora-32293: 177+178, fedora-17930: 168+170]}, unionCH=null, actualMembers=[fedora-23590, fedora-32293, fedora-17930], persistentUUIDs=[386d38b4-2976-4f97-8389-4cabd28b9f69, 4f867261-5f71-414b-941c-f1c57baecdcc, a7a7ef47-7b75-4269-be81-bbe4bd016d43]}
17:54:24,289 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-23590]ISPN100002: Started rebalance with topology id 6
17:54:24,292 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t10) [Context=testCache][Scope=fedora-23590]ISPN100003: Node fedora-23590 finished rebalance phase with topology id 6
17:54:24,296 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-17930]ISPN100003: Node fedora-17930 finished rebalance phase with topology id 3
17:54:24,303 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (remote-thread--p2-t2) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=testCache, type=REBALANCE_PHASE_CONFIRM, sender=fedora-17930, joinInfo=null, topologyId=3, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-17930 for cache testCache, expecting topology id 6 but got 3
	at org.infinispan.topology.RebalanceConfirmationCollector.confirmPhase(RebalanceConfirmationCollector.java:41) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:337) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.invokeReplicableCommand(GlobalInboundInvocationHandler.java:169) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.runReplicableCommand(GlobalInboundInvocationHandler.java:150) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.lambda$handleReplicableCommand$1(GlobalInboundInvocationHandler.java:144) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.util.concurrent.BlockingTaskAwareExecutorServiceImpl$RunnableWrapper.run(BlockingTaskAwareExecutorServiceImpl.java:212) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
17:54:24,304 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-32293]ISPN100003: Node fedora-32293 finished rebalance phase with topology id 6
17:54:24,306 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=testCache][Scope=fedora-17930]ISPN100003: Node fedora-17930 finished rebalance phase with topology id 4
17:54:24,307 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (remote-thread--p2-t4) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=testCache, type=REBALANCE_PHASE_CONFIRM, sender=fedora-17930, joinInfo=null, topologyId=4, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-17930 for cache testCache, expecting topology id 6 but got 4
	at org.infinispan.topology.RebalanceConfirmationCollector.confirmPhase(RebalanceConfirmationCollector.java:41) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:337) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.invokeReplicableCommand(GlobalInboundInvocationHandler.java:169) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.runReplicableCommand(GlobalInboundInvocationHandler.java:150) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.lambda$handleReplicableCommand$1(GlobalInboundInvocationHandler.java:144) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.util.concurrent.BlockingTaskAwareExecutorServiceImpl$RunnableWrapper.run(BlockingTaskAwareExecutorServiceImpl.java:212) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
17:54:24,315 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___counters][Scope=fedora-17930]ISPN100003: Node fedora-17930 finished rebalance phase with topology id 7
17:54:24,318 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=___counters][Scope=fedora-23590]ISPN100003: Node fedora-23590 finished rebalance phase with topology id 8
17:54:24,324 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___protobuf_metadata][Scope=fedora-17930]ISPN100003: Node fedora-17930 finished rebalance phase with topology id 6
17:54:24,324 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=fedora-32293]ISPN100003: Node fedora-32293 finished rebalance phase with topology id 8
17:54:24,326 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 6
17:54:24,331 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t22) [Context=___protobuf_metadata][Scope=fedora-23590]ISPN100003: Node fedora-23590 finished rebalance phase with topology id 7
17:54:24,339 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___protobuf_metadata][Scope=fedora-32293]ISPN100003: Node fedora-32293 finished rebalance phase with topology id 7
17:54:24,351 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___protobuf_metadata][Scope=fedora-17930]ISPN100003: Node fedora-17930 finished rebalance phase with topology id 7
17:54:24,352 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___counters][Scope=fedora-17930]ISPN100003: Node fedora-17930 finished rebalance phase with topology id 8
17:54:24,355 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=fedora-17930]ISPN100003: Node fedora-17930 finished rebalance phase with topology id 8
17:54:24,354 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t17) [Context=___protobuf_metadata][Scope=fedora-23590]ISPN100003: Node fedora-23590 finished rebalance phase with topology id 8
17:54:24,356 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-17930]ISPN100003: Node fedora-17930 finished rebalance phase with topology id 6
17:54:24,361 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000336: Finished cluster-wide rebalance for cache testCache, topology id = 6
17:54:24,362 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___protobuf_metadata][Scope=fedora-32293]ISPN100003: Node fedora-32293 finished rebalance phase with topology id 8
17:54:24,368 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t15) [Context=testCache][Scope=fedora-23590]ISPN100003: Node fedora-23590 finished rebalance phase with topology id 7
17:54:24,374 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-17930]ISPN100003: Node fedora-17930 finished rebalance phase with topology id 7
17:54:24,378 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-32293]ISPN100003: Node fedora-32293 finished rebalance phase with topology id 7
17:54:24,381 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t23) [Context=testCache][Scope=fedora-23590]ISPN100003: Node fedora-23590 finished rebalance phase with topology id 8
17:54:24,385 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-32293]ISPN100003: Node fedora-32293 finished rebalance phase with topology id 8
17:54:24,385 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=testCache][Scope=fedora-17930]ISPN100003: Node fedora-17930 finished rebalance phase with topology id 8
17:54:24,520 INFO  [org.radargun.Slave] (sc-main) Starting stage AfterServiceStart
17:54:24,521 INFO  [org.radargun.Slave] (sc-main) Finished stage AfterServiceStart
17:54:24,523 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
17:54:24,630 INFO  [org.radargun.Slave] (sc-main) Starting stage MonitorStart
17:54:24,644 INFO  [org.radargun.sysmonitor.AbstractMonitors] (sc-main) Gathering statistics every 1000 ms
17:54:24,645 INFO  [org.radargun.Slave] (sc-main) Finished stage MonitorStart
17:54:24,648 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
17:54:24,692 INFO  [org.radargun.Slave] (sc-main) Starting stage Load
17:54:33,477 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) This node loaded 10000 entries (~10000000 bytes)
17:54:39,683 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) This node loaded 20000 entries (~20000000 bytes)
17:54:44,259 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) This node loaded 30000 entries (~30000000 bytes)
17:54:45,377 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) Finished loading entries
17:54:45,433 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) Finished loading entries
17:54:45,446 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) Finished loading entries
17:54:45,469 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) Finished loading entries
17:54:45,474 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) Finished loading entries
17:54:45,514 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) Finished loading entries
17:54:45,525 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) Finished loading entries
17:54:45,538 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) Finished loading entries
17:54:45,591 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) Finished loading entries
17:54:45,611 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) Finished loading entries
17:54:45,611 INFO  [org.radargun.Slave] (sc-main) Finished stage Load
17:54:45,612 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
17:54:45,942 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.stages.cache.test.BasicOperationsTestStage.init() overrides public void org.radargun.stages.test.TestStage.init() but both are declared with @Init annotation: calling only once
17:54:45,945 INFO  [org.radargun.Slave] (sc-main) Starting stage BasicOperationsTest
17:54:45,945 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using key generator org.radargun.stages.cache.generators.StringKeyGenerator {format=null }
17:54:45,945 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using value generator org.radargun.stages.cache.generators.ByteArrayValueGenerator { }
17:54:45,946 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using cache selector Default { }
17:54:45,946 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Starting test warmup
17:54:45,957 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Started 4 stressor threads.
17:55:45,967 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Finished test. Test duration is: 1 mins 0 secs
17:55:45,969 INFO  [org.radargun.Slave] (sc-main) Finished stage BasicOperationsTest
17:55:45,974 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
17:55:46,025 INFO  [org.radargun.Slave] (sc-main) Starting stage Clear
17:55:46,028 INFO  [org.radargun.stages.cache.ClearStage] (sc-main) Before executing clear, memory looks like this: 
Runtime free: 1,068,541 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,328 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,696 kb
MX Metaspace(Non-heap memory): used: 43,870 kb, init: 0 kb, committed: 45,360 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 12,256 kb, init: 2,496 kb, committed: 12,288 kb, max: 120,032 kb
MX Compressed Class Space(Non-heap memory): used: 4,944 kb, init: 0 kb, committed: 5,504 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 155,648 kb, init: 73,728 kb, committed: 836,608 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 130,560 kb, init: 1,325,056 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 44,032 kb, init: 0 kb, committed: 44,032 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 5,446 kb, init: 2,496 kb, committed: 5,504 kb, max: 120,032 kb
17:55:46,150 INFO  [org.radargun.stages.cache.ClearStage] (sc-main) After executing clear, memory looks like this: 
Runtime free: 1,381,594 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,328 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,696 kb
MX Metaspace(Non-heap memory): used: 43,872 kb, init: 0 kb, committed: 45,360 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 12,379 kb, init: 2,496 kb, committed: 12,416 kb, max: 120,032 kb
MX Compressed Class Space(Non-heap memory): used: 4,934 kb, init: 0 kb, committed: 5,504 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 0 kb, init: 73,728 kb, committed: 880,640 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 16,677 kb, init: 1,325,056 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 0 kb, init: 0 kb, committed: 0 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 5,451 kb, init: 2,496 kb, committed: 5,504 kb, max: 120,032 kb
17:55:46,151 INFO  [org.radargun.Slave] (sc-main) Finished stage Clear
17:55:46,151 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
17:55:46,214 INFO  [org.radargun.Slave] (sc-main) Starting stage Load
17:55:49,502 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) This node loaded 10000 entries (~10000000 bytes)
17:55:52,684 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) This node loaded 20000 entries (~20000000 bytes)
17:55:56,017 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) This node loaded 30000 entries (~30000000 bytes)
17:55:56,918 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) Finished loading entries
17:55:56,935 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) Finished loading entries
17:55:56,952 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) Finished loading entries
17:55:56,959 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) Finished loading entries
17:55:57,002 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) Finished loading entries
17:55:57,010 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) Finished loading entries
17:55:57,013 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) Finished loading entries
17:55:57,042 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) Finished loading entries
17:55:57,045 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) Finished loading entries
17:55:57,048 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) Finished loading entries
17:55:57,048 INFO  [org.radargun.Slave] (sc-main) Finished stage Load
17:55:57,049 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
17:55:57,293 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.stages.cache.test.BasicOperationsTestStage.init() overrides public void org.radargun.stages.test.TestStage.init() but both are declared with @Init annotation: calling only once
17:55:57,294 INFO  [org.radargun.Slave] (sc-main) Starting stage BasicOperationsTest
17:55:57,294 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using key generator org.radargun.stages.cache.generators.StringKeyGenerator {format=null }
17:55:57,294 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using value generator org.radargun.stages.cache.generators.ByteArrayValueGenerator { }
17:55:57,295 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using cache selector Default { }
17:55:57,296 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Starting test stress-test
17:55:57,369 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Started 4 stressor threads.
18:05:57,377 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Finished test. Test duration is: 10 mins 0 secs
18:05:57,381 INFO  [org.radargun.Slave] (sc-main) Finished stage BasicOperationsTest
18:05:57,453 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
18:05:57,629 INFO  [org.radargun.Slave] (sc-main) Starting stage MonitorStop
18:05:57,631 INFO  [org.radargun.Slave] (sc-main) Finished stage MonitorStop
18:05:57,631 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
18:05:57,640 INFO  [org.radargun.Slave] (sc-main) Starting stage ScenarioDestroy
18:05:57,641 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Scenario finished, destroying...
18:05:57,642 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Memory before cleanup: 
Runtime free: 806,128 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,330 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,696 kb
MX Metaspace(Non-heap memory): used: 44,597 kb, init: 0 kb, committed: 45,872 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 14,345 kb, init: 2,496 kb, committed: 14,400 kb, max: 120,032 kb
MX Compressed Class Space(Non-heap memory): used: 4,975 kb, init: 0 kb, committed: 5,504 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 245,760 kb, init: 73,728 kb, committed: 825,344 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 290,061 kb, init: 1,325,056 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 55,296 kb, init: 0 kb, committed: 55,296 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 6,510 kb, init: 2,496 kb, committed: 6,528 kb, max: 120,032 kb
18:05:57,642 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) Stopping service.
18:05:57,655 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-23590: 260+71, fedora-17930: 252+86]}, pendingCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-23590: 257+255, fedora-17930: 255+257]}, unionCH=null, actualMembers=[fedora-23590, fedora-17930], persistentUUIDs=[386d38b4-2976-4f97-8389-4cabd28b9f69, a7a7ef47-7b75-4269-be81-bbe4bd016d43]}
18:05:57,655 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-23590]ISPN100002: Started rebalance with topology id 11
18:05:57,658 WARN  [org.infinispan.CLUSTER] (remote-thread--p2-t21) [Context=testCache]ISPN000312: Lost data because of graceful leaver fedora-17930
18:05:57,702 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-23590: 123+37, fedora-17930: 133+40]}, pendingCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-23590: 128+128, fedora-17930: 128+128]}, unionCH=null, actualMembers=[fedora-23590, fedora-17930], persistentUUIDs=[386d38b4-2976-4f97-8389-4cabd28b9f69, a7a7ef47-7b75-4269-be81-bbe4bd016d43]}
18:05:57,703 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-23590]ISPN100002: Started rebalance with topology id 11
18:05:57,712 WARN  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters]ISPN000312: Lost data because of graceful leaver fedora-17930
18:05:57,724 INFO  [org.infinispan.CLUSTER] (jgroups-30,fedora-23590) ISPN000094: Received new cluster view for channel results: [fedora-23590|3] (2) [fedora-23590, fedora-17930]
18:05:57,725 INFO  [org.infinispan.CLUSTER] (jgroups-30,fedora-23590) ISPN100001: Node fedora-32293 left the cluster
18:05:57,725 ERROR [org.infinispan.statetransfer.StateConsumerImpl] (transport-thread--p4-t17) ISPN000208: No live owners found for segments {0-4 10-20 24-28 33 40-45 53-56 67-71 81-83 86 95-103 121-122 137 142 146-147 152 155-156 159-162 166-179 183-186 194 206-210 213 222-223 233-237 255} of cache ___counters. Excluded owners: []
18:05:57,733 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t10) [Context=___counters][Scope=fedora-23590]ISPN100003: Node fedora-23590 finished rebalance phase with topology id 12
18:05:57,735 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (transport-thread--p4-t10) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___counters, type=REBALANCE_PHASE_CONFIRM, sender=fedora-23590, joinInfo=null, topologyId=12, rebalanceId=4, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=3}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-23590 for cache ___counters, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.commands.ReplicableCommand.invoke(ReplicableCommand.java:44) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.LocalTopologyManagerImpl.lambda$executeOnCoordinatorAsync$4(LocalTopologyManagerImpl.java:717) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
18:05:57,748 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=testCache][Scope=fedora-23590]ISPN100003: Node fedora-23590 finished rebalance phase with topology id 12
18:05:57,762 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (StopThread) ISPN000080: Disconnecting JGroups channel results
18:05:57,808 WARN  [org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler] (remote-thread--p2-t1) ISPN000219: Shutdown while handling command CacheTopologyControlCommand{cache=org.infinispan.CONFIG, type=LEAVE, sender=fedora-17930, joinInfo=null, topologyId=0, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=3}
18:05:57,817 INFO  [org.radargun.service.Infinispan90Lifecycle] (StopThread) Stopped, previous view is [fedora-23590, fedora-32293, fedora-17930]
18:05:57,817 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Service successfully stopped.
18:05:57,818 INFO  [org.radargun.Slave] (sc-main) Finished stage ScenarioDestroy
18:05:57,818 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
18:05:57,867 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.service.Infinispan80EmbeddedService.destroy() overrides public void org.radargun.service.Infinispan60EmbeddedService.destroy() but both are declared with @Destroy annotation: calling only once
18:05:57,869 INFO  [org.radargun.Slave] (main) Starting stage ScenarioCleanup
18:05:57,872 WARN  [org.radargun.stages.ScenarioCleanupStage] (main) Unfinished thread ForkJoinPool.commonPool-worker-3 (id=34, state=WAITING)
	at java.base@11.0.14-internal/jdk.internal.misc.Unsafe.park(Native Method)
	at java.base@11.0.14-internal/java.util.concurrent.locks.LockSupport.park(LockSupport.java:194)
	at java.base@11.0.14-internal/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1628)
	at java.base@11.0.14-internal/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
18:05:57,873 INFO  [org.radargun.stages.ScenarioCleanupStage] (main) Interrupting thread ForkJoinPool.commonPool-worker-3 (id=34, state=WAITING)
18:06:02,879 INFO  [org.radargun.stages.ScenarioCleanupStage] (main) Stopping thread ForkJoinPool.commonPool-worker-3 (id=34, state=WAITING)
18:06:02,894 INFO  [org.radargun.stages.ScenarioCleanupStage] (main) Is thread ForkJoinPool.commonPool-worker-3 (id=34, state=TERMINATED)) alive? false
18:06:03,055 INFO  [org.radargun.stages.ScenarioCleanupStage] (main) Memory after cleanup: 
Runtime free: 1,380,626 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,331 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,696 kb
MX Metaspace(Non-heap memory): used: 44,738 kb, init: 0 kb, committed: 46,128 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 14,533 kb, init: 2,496 kb, committed: 14,592 kb, max: 120,032 kb
MX Compressed Class Space(Non-heap memory): used: 4,996 kb, init: 0 kb, committed: 5,504 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 0 kb, init: 73,728 kb, committed: 880,640 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 17,645 kb, init: 1,325,056 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 0 kb, init: 0 kb, committed: 0 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 6,567 kb, init: 2,496 kb, committed: 6,592 kb, max: 120,032 kb
18:06:03,057 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
18:06:03,086 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
18:06:07,602 INFO  [org.radargun.Slave] (main) Master shutdown!
18:06:07,605 INFO  [org.radargun.ShutDownHook] (Thread-0) Slave process is being shutdown
