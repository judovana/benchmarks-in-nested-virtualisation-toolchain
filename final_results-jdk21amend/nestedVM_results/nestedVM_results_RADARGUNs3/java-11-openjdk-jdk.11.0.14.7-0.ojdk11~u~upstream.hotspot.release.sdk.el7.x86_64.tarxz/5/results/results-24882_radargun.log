20:37:16,801 INFO  [org.radargun.RemoteMasterConnection] (main) Attempting to connect to master results:2103
20:37:16,807 INFO  [org.radargun.RemoteMasterConnection] (main) Successfully established connection with master at: results:2103
20:37:16,810 INFO  [org.radargun.Slave] (main) Received slave index 0
20:37:16,810 INFO  [org.radargun.Slave] (main) Received slave count 3
20:37:17,018 INFO  [org.radargun.ServiceHelper] (sc-main) ServiceContext properties: {}
20:37:17,468 INFO  [org.radargun.Slave] (sc-main) Eager Service Infinispan92EmbeddedService {batching=false, cache=testCache, channelRetrievalTimeout=2 mins 0 secs, enableDiagnostics=null, explicitLocking=false, file=/mnt/workspace/results/dist-sync.xml, internalsExpositionEnabled=false, jgroupsDumperEnabled=false, jgroupsDumperInterval=10.000 secs, keysPerThread=-1, mapReduceDistributedReducePhase=false, mapReduceUseIntermediateSharedCache=false, removedCaches=[  ], threadsPerNode=-1 } loaded.
20:37:19,620 INFO  [org.radargun.Slave] (sc-main) Starting stage ScenarioInit
20:37:19,687 INFO  [org.radargun.Slave] (sc-main) Finished stage ScenarioInit
20:37:19,690 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
20:37:19,715 INFO  [org.radargun.Slave] (sc-main) Starting stage BeforeServiceStart
20:37:19,716 INFO  [org.radargun.Slave] (sc-main) Finished stage BeforeServiceStart
20:37:19,716 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
20:37:19,738 INFO  [org.radargun.Slave] (sc-main) Starting stage ServiceStart
20:37:19,740 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Startup staggering, this is the slave with index 0, not sleeping
20:37:19,744 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 0
20:37:19,747 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) Infinispan version: Infinispan 'Gaina' 9.2.0.Final
20:37:19,778 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) JGroups version: JGroups 4.0.10.Final (Schiener Berg)
20:37:20,379 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (sc-main) ISPN000078: Starting JGroups channel results
20:37:20,465 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the send buffer of socket MulticastSocket was set to 1.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
20:37:20,466 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the receive buffer of socket MulticastSocket was set to 20.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
20:37:20,466 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the send buffer of socket MulticastSocket was set to 1.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
20:37:20,467 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the receive buffer of socket MulticastSocket was set to 25.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
20:37:25,500 INFO  [org.infinispan.CLUSTER] (sc-main) ISPN000094: Received new cluster view for channel results: [fedora-37420|0] (1) [fedora-37420]
20:37:25,692 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (sc-main) ISPN000079: Channel results local address is fedora-37420, physical addresses are [192.168.124.39:50655]
20:37:25,699 INFO  [org.infinispan.factories.GlobalComponentRegistry] (sc-main) ISPN000128: Infinispan version: Infinispan 'Gaina' 9.2.0.Final
20:37:26,359 INFO  [org.infinispan.CLUSTER] (jgroups-7,fedora-37420) ISPN000094: Received new cluster view for channel results: [fedora-37420|1] (2) [fedora-37420, fedora-54873]
20:37:26,377 INFO  [org.infinispan.CLUSTER] (jgroups-7,fedora-37420) ISPN100000: Node fedora-54873 joined the cluster
20:37:26,487 INFO  [org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup] (sc-main) ISPN000107: Retrieving transaction manager Transaction: unknown
20:37:26,631 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) No RELAY2 protocol in XS service
20:37:26,633 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) No RELAY2 protocol in XS service
20:37:26,635 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) ([fedora-37420(local=true, coord=true), fedora-54873(local=false, coord=false)]) Number of members=2 is not the one expected: 3
20:37:27,066 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-37420: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-37420: 133, fedora-54873: 123]}, unionCH=null, actualMembers=[fedora-37420, fedora-54873], persistentUUIDs=[4f16bac2-c57d-428c-8e54-8fbf6c8c3266, 17972215-9f5b-4af4-b21e-fa7279ee2de4]}
20:37:27,067 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-37420: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-37420: 133, fedora-54873: 123]}, unionCH=null, actualMembers=[fedora-37420, fedora-54873], persistentUUIDs=[4f16bac2-c57d-428c-8e54-8fbf6c8c3266, 17972215-9f5b-4af4-b21e-fa7279ee2de4]}
20:37:27,070 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-37420]ISPN100002: Started rebalance with topology id 2
20:37:27,071 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-37420]ISPN100002: Started rebalance with topology id 2
20:37:27,136 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=org.infinispan.CONFIG][Scope=fedora-37420]ISPN100003: Node fedora-37420 finished rebalance phase with topology id 2
20:37:27,154 INFO  [org.infinispan.CLUSTER] (jgroups-7,fedora-37420) ISPN000094: Received new cluster view for channel results: [fedora-37420|2] (3) [fedora-37420, fedora-54873, fedora-52821]
20:37:27,138 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t22) [Context=___counter_configuration][Scope=fedora-37420]ISPN100003: Node fedora-37420 finished rebalance phase with topology id 2
20:37:27,184 INFO  [org.infinispan.CLUSTER] (jgroups-7,fedora-37420) ISPN100000: Node fedora-52821 joined the cluster
20:37:27,466 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-54873]ISPN100003: Node fedora-54873 finished rebalance phase with topology id 2
20:37:27,468 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 2
20:37:27,474 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t1) [Context=org.infinispan.CONFIG][Scope=fedora-37420]ISPN100003: Node fedora-37420 finished rebalance phase with topology id 3
20:37:27,593 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-54873]ISPN100003: Node fedora-54873 finished rebalance phase with topology id 3
20:37:27,601 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t4) [Context=org.infinispan.CONFIG][Scope=fedora-37420]ISPN100003: Node fedora-37420 finished rebalance phase with topology id 4
20:37:27,616 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-54873]ISPN100003: Node fedora-54873 finished rebalance phase with topology id 4
20:37:27,619 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-54873]ISPN100003: Node fedora-54873 finished rebalance phase with topology id 2
20:37:27,620 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 2
20:37:27,622 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t8) [Context=___counter_configuration][Scope=fedora-37420]ISPN100003: Node fedora-37420 finished rebalance phase with topology id 3
20:37:27,636 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) Number of members is the one expected: 3
20:37:27,638 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Successfully started cache service infinispan92/embedded on slave 0
20:37:27,677 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-54873]ISPN100003: Node fedora-54873 finished rebalance phase with topology id 3
20:37:27,686 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t13) [Context=___counter_configuration][Scope=fedora-37420]ISPN100003: Node fedora-37420 finished rebalance phase with topology id 4
20:37:27,734 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-54873]ISPN100003: Node fedora-54873 finished rebalance phase with topology id 4
20:37:27,780 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=DefaultConsistentHash{ns=256, owners = (1)[fedora-37420: 256+0]}, pendingCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-37420: 133+123, fedora-54873: 123+133]}, unionCH=null, actualMembers=[fedora-37420, fedora-54873], persistentUUIDs=[4f16bac2-c57d-428c-8e54-8fbf6c8c3266, 17972215-9f5b-4af4-b21e-fa7279ee2de4]}
20:37:27,781 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-37420]ISPN100002: Started rebalance with topology id 2
20:37:27,794 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t22) [Context=___counters][Scope=fedora-37420]ISPN100003: Node fedora-37420 finished rebalance phase with topology id 2
20:37:27,797 ERROR [org.radargun.service.ConfigDumpHelper] (sc-main) Error while dumping ___protobuf_metadata cache config as properties
javax.management.AttributeNotFoundException: Unknown attribute 'configurationAsProperties'. Known attributes names are: [rebalancingEnabled, cacheStatus, cacheName, cacheAvailability, version, configurationAsProperties]
	at org.infinispan.jmx.ResourceDMBean.getAttribute(ResourceDMBean.java:181) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:641) ~[?:?]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:678) ~[?:?]
	at org.radargun.service.ConfigDumpHelper60.dumpCache(ConfigDumpHelper60.java:44) [plugin-infinispan60-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.service.EmbeddedConfigurationProvider.getNormalizedConfigs(EmbeddedConfigurationProvider.java:33) [plugin-infinispan52-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.stages.lifecycle.ServiceStartStage.executeOnSlave(ServiceStartStage.java:92) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase.scenarioLoop(SlaveBase.java:102) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase$ScenarioRunner.run(SlaveBase.java:203) [radargun-core-3.0.0-SNAPSHOT.jar:?]
20:37:27,844 ERROR [org.radargun.service.ConfigDumpHelper] (sc-main) Error while dumping ___protobuf_metadata cache config as properties
javax.management.AttributeNotFoundException: Unknown attribute 'configurationAsProperties'. Known attributes names are: [rebalancingEnabled, cacheStatus, cacheName, cacheAvailability, version, configurationAsProperties]
	at org.infinispan.jmx.ResourceDMBean.getAttribute(ResourceDMBean.java:181) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:641) ~[?:?]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:678) ~[?:?]
	at org.radargun.service.ConfigDumpHelper60.dumpCache(ConfigDumpHelper60.java:44) [plugin-infinispan60-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.service.EmbeddedConfigurationProvider.getNormalizedConfigs(EmbeddedConfigurationProvider.java:33) [plugin-infinispan52-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.stages.lifecycle.ServiceStartStage.executeOnSlave(ServiceStartStage.java:92) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase.scenarioLoop(SlaveBase.java:102) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase$ScenarioRunner.run(SlaveBase.java:203) [radargun-core-3.0.0-SNAPSHOT.jar:?]
20:37:27,863 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-54873]ISPN100003: Node fedora-54873 finished rebalance phase with topology id 2
20:37:27,867 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___counters, topology id = 2
20:37:27,869 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t23) [Context=___counters][Scope=fedora-37420]ISPN100003: Node fedora-37420 finished rebalance phase with topology id 3
20:37:27,894 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-54873]ISPN100003: Node fedora-54873 finished rebalance phase with topology id 3
20:37:27,901 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t1) [Context=___counters][Scope=fedora-37420]ISPN100003: Node fedora-37420 finished rebalance phase with topology id 4
20:37:27,925 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-54873]ISPN100003: Node fedora-54873 finished rebalance phase with topology id 4
20:37:27,942 INFO  [org.radargun.Slave] (sc-main) Finished stage ServiceStart
20:37:27,962 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
20:37:28,023 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-37420: 133, fedora-54873: 123]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-37420: 80, fedora-54873: 86, fedora-52821: 90]}, unionCH=null, actualMembers=[fedora-37420, fedora-54873, fedora-52821], persistentUUIDs=[4f16bac2-c57d-428c-8e54-8fbf6c8c3266, 17972215-9f5b-4af4-b21e-fa7279ee2de4, 4174f50d-2d6b-4088-891b-3eb9657643d6]}
20:37:28,025 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-37420]ISPN100002: Started rebalance with topology id 6
20:37:28,029 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t6) [Context=org.infinispan.CONFIG][Scope=fedora-37420]ISPN100003: Node fedora-37420 finished rebalance phase with topology id 6
20:37:28,044 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-37420: 133, fedora-54873: 123]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-37420: 80, fedora-54873: 86, fedora-52821: 90]}, unionCH=null, actualMembers=[fedora-37420, fedora-54873, fedora-52821], persistentUUIDs=[4f16bac2-c57d-428c-8e54-8fbf6c8c3266, 17972215-9f5b-4af4-b21e-fa7279ee2de4, 4174f50d-2d6b-4088-891b-3eb9657643d6]}
20:37:28,045 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-37420]ISPN100002: Started rebalance with topology id 6
20:37:28,048 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t12) [Context=___counter_configuration][Scope=fedora-37420]ISPN100003: Node fedora-37420 finished rebalance phase with topology id 6
20:37:28,049 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-37420: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-37420: 133, fedora-54873: 123]}, unionCH=null, actualMembers=[fedora-37420, fedora-54873], persistentUUIDs=[4f16bac2-c57d-428c-8e54-8fbf6c8c3266, 17972215-9f5b-4af4-b21e-fa7279ee2de4]}
20:37:28,054 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-37420]ISPN100002: Started rebalance with topology id 2
20:37:28,063 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t15) [Context=___protobuf_metadata][Scope=fedora-37420]ISPN100003: Node fedora-37420 finished rebalance phase with topology id 2
20:37:28,066 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-54873]ISPN100003: Node fedora-54873 finished rebalance phase with topology id 6
20:37:28,083 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-54873]ISPN100003: Node fedora-54873 finished rebalance phase with topology id 6
20:37:28,142 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-54873]ISPN100003: Node fedora-54873 finished rebalance phase with topology id 2
20:37:28,143 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 2
20:37:28,146 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=___protobuf_metadata][Scope=fedora-37420]ISPN100003: Node fedora-37420 finished rebalance phase with topology id 3
20:37:28,169 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=DefaultConsistentHash{ns=512, owners = (1)[fedora-37420: 512+0]}, pendingCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-37420: 258+254, fedora-54873: 254+258]}, unionCH=null, actualMembers=[fedora-37420, fedora-54873], persistentUUIDs=[4f16bac2-c57d-428c-8e54-8fbf6c8c3266, 17972215-9f5b-4af4-b21e-fa7279ee2de4]}
20:37:28,175 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-54873]ISPN100003: Node fedora-54873 finished rebalance phase with topology id 3
20:37:28,176 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-37420]ISPN100002: Started rebalance with topology id 2
20:37:28,185 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=testCache][Scope=fedora-37420]ISPN100003: Node fedora-37420 finished rebalance phase with topology id 2
20:37:28,185 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t22) [Context=___protobuf_metadata][Scope=fedora-37420]ISPN100003: Node fedora-37420 finished rebalance phase with topology id 4
20:37:28,209 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-54873]ISPN100003: Node fedora-54873 finished rebalance phase with topology id 4
20:37:28,242 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-54873]ISPN100003: Node fedora-54873 finished rebalance phase with topology id 2
20:37:28,243 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache testCache, topology id = 2
20:37:28,246 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t4) [Context=testCache][Scope=fedora-37420]ISPN100003: Node fedora-37420 finished rebalance phase with topology id 3
20:37:28,250 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-54873]ISPN100003: Node fedora-54873 finished rebalance phase with topology id 3
20:37:28,252 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t8) [Context=testCache][Scope=fedora-37420]ISPN100003: Node fedora-37420 finished rebalance phase with topology id 4
20:37:28,254 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-54873]ISPN100003: Node fedora-54873 finished rebalance phase with topology id 4
20:37:28,327 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-52821]ISPN100003: Node fedora-52821 finished rebalance phase with topology id 6
20:37:28,328 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 6
20:37:28,330 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t16) [Context=___counter_configuration][Scope=fedora-37420]ISPN100003: Node fedora-37420 finished rebalance phase with topology id 7
20:37:28,334 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-54873]ISPN100003: Node fedora-54873 finished rebalance phase with topology id 7
20:37:28,337 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-52821]ISPN100003: Node fedora-52821 finished rebalance phase with topology id 7
20:37:28,338 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t17) [Context=___counter_configuration][Scope=fedora-37420]ISPN100003: Node fedora-37420 finished rebalance phase with topology id 8
20:37:28,340 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-54873]ISPN100003: Node fedora-54873 finished rebalance phase with topology id 8
20:37:28,364 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-52821]ISPN100003: Node fedora-52821 finished rebalance phase with topology id 8
20:37:28,443 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-37420: 133+123, fedora-54873: 123+133]}, pendingCH=DefaultConsistentHash{ns=256, owners = (3)[fedora-37420: 80+87, fedora-54873: 86+89, fedora-52821: 90+80]}, unionCH=null, actualMembers=[fedora-37420, fedora-54873, fedora-52821], persistentUUIDs=[4f16bac2-c57d-428c-8e54-8fbf6c8c3266, 17972215-9f5b-4af4-b21e-fa7279ee2de4, 4174f50d-2d6b-4088-891b-3eb9657643d6]}
20:37:28,447 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-37420]ISPN100002: Started rebalance with topology id 6
20:37:28,448 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=___counters][Scope=fedora-37420]ISPN100003: Node fedora-37420 finished rebalance phase with topology id 6
20:37:28,454 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-54873]ISPN100003: Node fedora-54873 finished rebalance phase with topology id 6
20:37:28,523 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-52821]ISPN100003: Node fedora-52821 finished rebalance phase with topology id 6
20:37:28,524 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 6
20:37:28,525 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t24) [Context=org.infinispan.CONFIG][Scope=fedora-37420]ISPN100003: Node fedora-37420 finished rebalance phase with topology id 7
20:37:28,527 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-54873]ISPN100003: Node fedora-54873 finished rebalance phase with topology id 7
20:37:28,530 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-37420: 133, fedora-54873: 123]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-37420: 80, fedora-54873: 86, fedora-52821: 90]}, unionCH=null, actualMembers=[fedora-37420, fedora-54873, fedora-52821], persistentUUIDs=[4f16bac2-c57d-428c-8e54-8fbf6c8c3266, 17972215-9f5b-4af4-b21e-fa7279ee2de4, 4174f50d-2d6b-4088-891b-3eb9657643d6]}
20:37:28,531 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-37420]ISPN100002: Started rebalance with topology id 6
20:37:28,533 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t11) [Context=___protobuf_metadata][Scope=fedora-37420]ISPN100003: Node fedora-37420 finished rebalance phase with topology id 6
20:37:28,542 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-54873]ISPN100003: Node fedora-54873 finished rebalance phase with topology id 6
20:37:28,545 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-52821]ISPN100003: Node fedora-52821 finished rebalance phase with topology id 6
20:37:28,549 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache ___counters, topology id = 6
20:37:28,550 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t8) [Context=___counters][Scope=fedora-37420]ISPN100003: Node fedora-37420 finished rebalance phase with topology id 7
20:37:28,553 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-54873]ISPN100003: Node fedora-54873 finished rebalance phase with topology id 7
20:37:28,556 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-52821]ISPN100003: Node fedora-52821 finished rebalance phase with topology id 7
20:37:28,559 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t14) [Context=org.infinispan.CONFIG][Scope=fedora-37420]ISPN100003: Node fedora-37420 finished rebalance phase with topology id 8
20:37:28,561 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-54873]ISPN100003: Node fedora-54873 finished rebalance phase with topology id 8
20:37:28,565 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-52821]ISPN100003: Node fedora-52821 finished rebalance phase with topology id 7
20:37:28,568 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t19) [Context=___counters][Scope=fedora-37420]ISPN100003: Node fedora-37420 finished rebalance phase with topology id 8
20:37:28,581 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-54873]ISPN100003: Node fedora-54873 finished rebalance phase with topology id 8
20:37:28,589 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-52821]ISPN100003: Node fedora-52821 finished rebalance phase with topology id 8
20:37:28,598 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-52821]ISPN100003: Node fedora-52821 finished rebalance phase with topology id 8
20:37:28,605 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-37420: 258+254, fedora-54873: 254+258]}, pendingCH=DefaultConsistentHash{ns=512, owners = (3)[fedora-37420: 174+181, fedora-54873: 162+166, fedora-52821: 176+165]}, unionCH=null, actualMembers=[fedora-37420, fedora-54873, fedora-52821], persistentUUIDs=[4f16bac2-c57d-428c-8e54-8fbf6c8c3266, 17972215-9f5b-4af4-b21e-fa7279ee2de4, 4174f50d-2d6b-4088-891b-3eb9657643d6]}
20:37:28,607 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-37420]ISPN100002: Started rebalance with topology id 6
20:37:28,612 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t1) [Context=testCache][Scope=fedora-37420]ISPN100003: Node fedora-37420 finished rebalance phase with topology id 6
20:37:28,621 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-54873]ISPN100003: Node fedora-54873 finished rebalance phase with topology id 6
20:37:28,659 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-52821]ISPN100003: Node fedora-52821 finished rebalance phase with topology id 6
20:37:28,660 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 6
20:37:28,662 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t24) [Context=___protobuf_metadata][Scope=fedora-37420]ISPN100003: Node fedora-37420 finished rebalance phase with topology id 7
20:37:28,665 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-54873]ISPN100003: Node fedora-54873 finished rebalance phase with topology id 7
20:37:28,670 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-52821]ISPN100003: Node fedora-52821 finished rebalance phase with topology id 7
20:37:28,672 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t11) [Context=___protobuf_metadata][Scope=fedora-37420]ISPN100003: Node fedora-37420 finished rebalance phase with topology id 8
20:37:28,676 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-52821]ISPN100003: Node fedora-52821 finished rebalance phase with topology id 8
20:37:28,675 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-54873]ISPN100003: Node fedora-54873 finished rebalance phase with topology id 8
20:37:28,687 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-52821]ISPN100003: Node fedora-52821 finished rebalance phase with topology id 6
20:37:28,688 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache testCache, topology id = 6
20:37:28,692 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t14) [Context=testCache][Scope=fedora-37420]ISPN100003: Node fedora-37420 finished rebalance phase with topology id 7
20:37:28,695 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-54873]ISPN100003: Node fedora-54873 finished rebalance phase with topology id 7
20:37:28,697 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-52821]ISPN100003: Node fedora-52821 finished rebalance phase with topology id 7
20:37:28,699 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t3) [Context=testCache][Scope=fedora-37420]ISPN100003: Node fedora-37420 finished rebalance phase with topology id 8
20:37:28,704 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-54873]ISPN100003: Node fedora-54873 finished rebalance phase with topology id 8
20:37:28,706 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-52821]ISPN100003: Node fedora-52821 finished rebalance phase with topology id 8
20:37:28,829 INFO  [org.radargun.Slave] (sc-main) Starting stage AfterServiceStart
20:37:28,831 INFO  [org.radargun.Slave] (sc-main) Finished stage AfterServiceStart
20:37:28,838 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
20:37:28,936 INFO  [org.radargun.Slave] (sc-main) Starting stage MonitorStart
20:37:28,942 INFO  [org.radargun.sysmonitor.AbstractMonitors] (sc-main) Gathering statistics every 1000 ms
20:37:28,942 INFO  [org.radargun.Slave] (sc-main) Finished stage MonitorStart
20:37:28,942 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
20:37:28,973 INFO  [org.radargun.Slave] (sc-main) Starting stage Load
20:37:37,449 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) This node loaded 10000 entries (~10000000 bytes)
20:37:43,977 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) This node loaded 20000 entries (~20000000 bytes)
20:37:47,681 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) This node loaded 30000 entries (~30000000 bytes)
20:37:49,008 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) Finished loading entries
20:37:49,035 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) Finished loading entries
20:37:49,056 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) Finished loading entries
20:37:49,061 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) Finished loading entries
20:37:49,069 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) Finished loading entries
20:37:49,142 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) Finished loading entries
20:37:49,158 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) Finished loading entries
20:37:49,237 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) Finished loading entries
20:37:49,248 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) Finished loading entries
20:37:49,297 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) Finished loading entries
20:37:49,298 INFO  [org.radargun.Slave] (sc-main) Finished stage Load
20:37:49,299 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
20:37:49,624 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.stages.cache.test.BasicOperationsTestStage.init() overrides public void org.radargun.stages.test.TestStage.init() but both are declared with @Init annotation: calling only once
20:37:49,627 INFO  [org.radargun.Slave] (sc-main) Starting stage BasicOperationsTest
20:37:49,627 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using key generator org.radargun.stages.cache.generators.StringKeyGenerator {format=null }
20:37:49,627 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using value generator org.radargun.stages.cache.generators.ByteArrayValueGenerator { }
20:37:49,628 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using cache selector Default { }
20:37:49,628 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Starting test warmup
20:37:49,650 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Started 4 stressor threads.
20:38:49,662 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Finished test. Test duration is: 1 mins 0 secs
20:38:49,665 INFO  [org.radargun.Slave] (sc-main) Finished stage BasicOperationsTest
20:38:49,696 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
20:38:49,713 INFO  [org.radargun.Slave] (sc-main) Starting stage Clear
20:38:49,724 INFO  [org.radargun.stages.cache.ClearStage] (sc-main) Before executing clear, memory looks like this: 
Runtime free: 805,720 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,326 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,696 kb
MX Metaspace(Non-heap memory): used: 43,909 kb, init: 0 kb, committed: 45,360 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 12,511 kb, init: 2,496 kb, committed: 12,544 kb, max: 120,032 kb
MX Compressed Class Space(Non-heap memory): used: 4,950 kb, init: 0 kb, committed: 5,504 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 407,552 kb, init: 73,728 kb, committed: 734,208 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 143,013 kb, init: 1,325,056 kb, committed: 622,592 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 41,984 kb, init: 0 kb, committed: 41,984 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 4,871 kb, init: 2,496 kb, committed: 4,928 kb, max: 120,032 kb
20:38:49,840 INFO  [org.radargun.stages.cache.ClearStage] (sc-main) After executing clear, memory looks like this: 
Runtime free: 1,381,650 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,326 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,696 kb
MX Metaspace(Non-heap memory): used: 43,885 kb, init: 0 kb, committed: 45,360 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 12,586 kb, init: 2,496 kb, committed: 12,608 kb, max: 120,032 kb
MX Compressed Class Space(Non-heap memory): used: 4,936 kb, init: 0 kb, committed: 5,504 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 0 kb, init: 73,728 kb, committed: 880,640 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 16,621 kb, init: 1,325,056 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 0 kb, init: 0 kb, committed: 0 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 4,878 kb, init: 2,496 kb, committed: 4,928 kb, max: 120,032 kb
20:38:49,841 INFO  [org.radargun.Slave] (sc-main) Finished stage Clear
20:38:49,841 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
20:38:49,921 INFO  [org.radargun.Slave] (sc-main) Starting stage Load
20:38:53,249 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) This node loaded 10000 entries (~10000000 bytes)
20:38:56,485 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) This node loaded 20000 entries (~20000000 bytes)
20:38:59,838 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) This node loaded 30000 entries (~30000000 bytes)
20:39:00,750 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) Finished loading entries
20:39:00,856 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) Finished loading entries
20:39:00,897 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) Finished loading entries
20:39:00,932 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) Finished loading entries
20:39:00,962 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) Finished loading entries
20:39:00,991 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) Finished loading entries
20:39:00,999 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) Finished loading entries
20:39:01,001 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) Finished loading entries
20:39:01,018 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) Finished loading entries
20:39:01,022 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) Finished loading entries
20:39:01,023 INFO  [org.radargun.Slave] (sc-main) Finished stage Load
20:39:01,024 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
20:39:01,239 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.stages.cache.test.BasicOperationsTestStage.init() overrides public void org.radargun.stages.test.TestStage.init() but both are declared with @Init annotation: calling only once
20:39:01,240 INFO  [org.radargun.Slave] (sc-main) Starting stage BasicOperationsTest
20:39:01,241 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using key generator org.radargun.stages.cache.generators.StringKeyGenerator {format=null }
20:39:01,241 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using value generator org.radargun.stages.cache.generators.ByteArrayValueGenerator { }
20:39:01,242 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using cache selector Default { }
20:39:01,243 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Starting test stress-test
20:39:01,287 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Started 4 stressor threads.
20:49:01,291 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Finished test. Test duration is: 10 mins 0 secs
20:49:01,293 INFO  [org.radargun.Slave] (sc-main) Finished stage BasicOperationsTest
20:49:01,375 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
20:49:01,560 INFO  [org.radargun.Slave] (sc-main) Starting stage MonitorStop
20:49:01,563 INFO  [org.radargun.Slave] (sc-main) Finished stage MonitorStop
20:49:01,564 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
20:49:01,568 INFO  [org.radargun.Slave] (sc-main) Starting stage ScenarioDestroy
20:49:01,569 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Scenario finished, destroying...
20:49:01,570 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Memory before cleanup: 
Runtime free: 622,137 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,328 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,696 kb
MX Metaspace(Non-heap memory): used: 44,625 kb, init: 0 kb, committed: 46,128 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 14,636 kb, init: 2,496 kb, committed: 14,656 kb, max: 120,032 kb
MX Compressed Class Space(Non-heap memory): used: 4,977 kb, init: 0 kb, committed: 5,504 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 385,024 kb, init: 73,728 kb, committed: 800,768 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 330,180 kb, init: 1,325,056 kb, committed: 538,624 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 59,392 kb, init: 0 kb, committed: 59,392 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 5,876 kb, init: 2,496 kb, committed: 5,888 kb, max: 120,032 kb
20:49:01,571 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) Stopping service.
20:49:01,583 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t32) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-37420: 274+81, fedora-54873: 238+90]}, pendingCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-37420: 258+254, fedora-54873: 254+258]}, unionCH=null, actualMembers=[fedora-37420, fedora-54873], persistentUUIDs=[4f16bac2-c57d-428c-8e54-8fbf6c8c3266, 17972215-9f5b-4af4-b21e-fa7279ee2de4]}
20:49:01,585 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t32) [Context=testCache][Scope=fedora-37420]ISPN100002: Started rebalance with topology id 11
20:49:01,588 WARN  [org.infinispan.CLUSTER] (remote-thread--p2-t33) [Context=testCache]ISPN000312: Lost data because of graceful leaver fedora-54873
20:49:01,638 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t33) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-37420: 127+40, fedora-54873: 129+46]}, pendingCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-37420: 133+123, fedora-54873: 123+133]}, unionCH=null, actualMembers=[fedora-37420, fedora-54873], persistentUUIDs=[4f16bac2-c57d-428c-8e54-8fbf6c8c3266, 17972215-9f5b-4af4-b21e-fa7279ee2de4]}
20:49:01,639 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t33) [Context=___counters][Scope=fedora-37420]ISPN100002: Started rebalance with topology id 11
20:49:01,654 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t8) [Context=testCache][Scope=fedora-37420]ISPN100003: Node fedora-37420 finished rebalance phase with topology id 12
20:49:01,651 WARN  [org.infinispan.statetransfer.InboundTransferTask] (stateTransferExecutor-thread--p6-t1) ISPN000210: Failed to request state of cache testCache from node fedora-54873, segments {3 23 31-41 44-46 49 60-61 68-69 72 81 87-92 95-102 105 121-122 129-133 137-140 143-146 151 167-168 172-178 188-189 192 195 203-205 215-219 223-224 228 236 256-257 261 269 273-276 279 285-286 290 293-298 309-312 317-320 325-326 329-333 339-341 356 363-365 368-369 373-377 382 390 393-395 399 419 423-427 430-433 444 465-472 504 507-511}
org.infinispan.remoting.transport.jgroups.SuspectException: ISPN000400: Node fedora-54873 was suspected
	at org.infinispan.remoting.transport.ResponseCollectors.remoteNodeSuspected(ResponseCollectors.java:33) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleResponseCollector.targetNotFound(SingleResponseCollector.java:31) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleResponseCollector.targetNotFound(SingleResponseCollector.java:17) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.ValidSingleResponseCollector.addResponse(ValidSingleResponseCollector.java:23) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleTargetRequest.receiveResponse(SingleTargetRequest.java:51) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleTargetRequest.onResponse(SingleTargetRequest.java:35) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.RequestRepository.addResponse(RequestRepository.java:53) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.processResponse(JGroupsTransport.java:1302) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.processMessage(JGroupsTransport.java:1205) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.access$200(JGroupsTransport.java:123) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport$ChannelCallbacks.receive(JGroupsTransport.java:1340) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.jgroups.JChannel.up(JChannel.java:819) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.stack.ProtocolStack.up(ProtocolStack.java:893) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FRAG3.up(FRAG3.java:171) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FlowControl.up(FlowControl.java:343) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FlowControl.up(FlowControl.java:343) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.GMS.up(GMS.java:864) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.STABLE.up(STABLE.java:240) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.deliverMessage(UNICAST3.java:1002) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.handleDataReceived(UNICAST3.java:728) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.up(UNICAST3.java:383) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.NAKACK2.up(NAKACK2.java:600) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.VERIFY_SUSPECT.up(VERIFY_SUSPECT.java:119) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FD_ALL.up(FD_ALL.java:199) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FD_SOCK.up(FD_SOCK.java:252) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.MERGE3.up(MERGE3.java:276) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.Discovery.up(Discovery.java:267) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.TP.passMessageUp(TP.java:1248) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.util.SubmitToThreadPool$SingleMessageHandler.run(SubmitToThreadPool.java:87) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
20:49:01,663 WARN  [org.infinispan.CLUSTER] (StopThread) [Context=___counters]ISPN000312: Lost data because of graceful leaver fedora-37420
20:49:01,668 INFO  [org.infinispan.CLUSTER] (jgroups-29,fedora-37420) ISPN000094: Received new cluster view for channel results: [fedora-37420|3] (2) [fedora-37420, fedora-54873]
20:49:01,670 INFO  [org.infinispan.CLUSTER] (jgroups-29,fedora-37420) ISPN100001: Node fedora-52821 left the cluster
20:49:01,708 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (StopThread) ISPN000080: Disconnecting JGroups channel results
20:49:01,719 INFO  [org.infinispan.CLUSTER] (jgroups-29,fedora-37420) ISPN000094: Received new cluster view for channel results: [fedora-37420|4] (1) [fedora-37420]
20:49:01,720 INFO  [org.infinispan.CLUSTER] (jgroups-29,fedora-37420) ISPN100001: Node fedora-54873 left the cluster
20:49:01,747 WARN  [org.infinispan.remoting.inboundhandler.TrianglePerCacheInboundInvocationHandler] (remote-thread--p2-t32) ISPN000071: Caught exception when handling command StateResponseCommand{cache=___counters, pushTransfer=false, stateChunks=[StateChunk{segmentId=5, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=11, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=15, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=16, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=17, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=18, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=22, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=23, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=24, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=25, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=43, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=44, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=45, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=48, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=49, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=50, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=51, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=52, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=59, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=60, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=61, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=64, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=65, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=66, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=67, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=68, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=72, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=73, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=76, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=83, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=84, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=85, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=86, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=87, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=88, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=89, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=90, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=91, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=94, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=95, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=108, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=109, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=110, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=111, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=112, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=113, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=120, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=121, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=126, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=127, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=128, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=137, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=140, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=141, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=142, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=143, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=144, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=147, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=148, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=155, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=156, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=157, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=158, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=159, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=163, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=169, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=180, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=184, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=185, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=186, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=187, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=188, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=195, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=209, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=210, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=211, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=212, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=213, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=214, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=215, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=216, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=217, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=233, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=234, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=235, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=236, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=251, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=252, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=253, cacheEntries=0, isLastChunk=true}], origin=fedora-54873, topologyId=11, applyState=true}
org.infinispan.commons.CacheException: java.lang.InterruptedException
	at org.infinispan.statetransfer.StateConsumerImpl.applyState(StateConsumerImpl.java:572) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.statetransfer.StateResponseCommand.invokeAsync(StateResponseCommand.java:88) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.BasePerCacheInboundInvocationHandler.invokeCommand(BasePerCacheInboundInvocationHandler.java:94) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.BaseBlockingRunnable.invoke(BaseBlockingRunnable.java:99) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.BaseBlockingRunnable.runAsync(BaseBlockingRunnable.java:71) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.BaseBlockingRunnable.run(BaseBlockingRunnable.java:40) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
Caused by: java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.tryAcquireSharedNanos(AbstractQueuedSynchronizer.java:1367) ~[?:?]
	at java.util.concurrent.CountDownLatch.await(CountDownLatch.java:278) ~[?:?]
	at org.infinispan.statetransfer.StateConsumerImpl.applyState(StateConsumerImpl.java:566) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	... 8 more
20:49:01,751 INFO  [org.radargun.service.Infinispan90Lifecycle] (StopThread) Stopped, previous view is [fedora-37420, fedora-54873, fedora-52821]
20:49:01,751 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Service successfully stopped.
20:49:01,752 INFO  [org.radargun.Slave] (sc-main) Finished stage ScenarioDestroy
20:49:01,752 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
20:49:01,771 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.service.Infinispan80EmbeddedService.destroy() overrides public void org.radargun.service.Infinispan60EmbeddedService.destroy() but both are declared with @Destroy annotation: calling only once
20:49:01,773 INFO  [org.radargun.Slave] (main) Starting stage ScenarioCleanup
20:49:01,775 WARN  [org.radargun.stages.ScenarioCleanupStage] (main) Unfinished thread ForkJoinPool.commonPool-worker-3 (id=35, state=WAITING)
	at java.base@11.0.14-internal/jdk.internal.misc.Unsafe.park(Native Method)
	at java.base@11.0.14-internal/java.util.concurrent.locks.LockSupport.park(LockSupport.java:194)
	at java.base@11.0.14-internal/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1628)
	at java.base@11.0.14-internal/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
20:49:01,776 INFO  [org.radargun.stages.ScenarioCleanupStage] (main) Interrupting thread ForkJoinPool.commonPool-worker-3 (id=35, state=WAITING)
20:49:06,778 INFO  [org.radargun.stages.ScenarioCleanupStage] (main) Stopping thread ForkJoinPool.commonPool-worker-3 (id=35, state=WAITING)
20:49:06,783 INFO  [org.radargun.stages.ScenarioCleanupStage] (main) Is thread ForkJoinPool.commonPool-worker-3 (id=35, state=TERMINATED)) alive? false
20:49:06,920 INFO  [org.radargun.stages.ScenarioCleanupStage] (main) Memory after cleanup: 
Runtime free: 1,380,602 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,329 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,696 kb
MX Metaspace(Non-heap memory): used: 44,784 kb, init: 0 kb, committed: 46,128 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 14,779 kb, init: 2,496 kb, committed: 14,784 kb, max: 120,032 kb
MX Compressed Class Space(Non-heap memory): used: 5,000 kb, init: 0 kb, committed: 5,504 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 0 kb, init: 73,728 kb, committed: 880,640 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 17,669 kb, init: 1,325,056 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 0 kb, init: 0 kb, committed: 0 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 5,970 kb, init: 2,496 kb, committed: 6,016 kb, max: 120,032 kb
20:49:06,922 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
20:49:06,954 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
20:49:10,544 INFO  [org.radargun.Slave] (main) Master shutdown!
