18:35:10,917 INFO  [org.radargun.RemoteMasterConnection] (main) Attempting to connect to master results:2103
18:35:10,927 INFO  [org.radargun.RemoteMasterConnection] (main) Successfully established connection with master at: results:2103
18:35:10,929 INFO  [org.radargun.Slave] (main) Received slave index 0
18:35:10,929 INFO  [org.radargun.Slave] (main) Received slave count 3
18:35:11,314 INFO  [org.radargun.ServiceHelper] (sc-main) ServiceContext properties: {}
18:35:11,802 INFO  [org.radargun.Slave] (sc-main) Eager Service Infinispan92EmbeddedService {batching=false, cache=testCache, channelRetrievalTimeout=2 mins 0 secs, enableDiagnostics=null, explicitLocking=false, file=/mnt/workspace/results/dist-sync.xml, internalsExpositionEnabled=false, jgroupsDumperEnabled=false, jgroupsDumperInterval=10.000 secs, keysPerThread=-1, mapReduceDistributedReducePhase=false, mapReduceUseIntermediateSharedCache=false, removedCaches=[  ], threadsPerNode=-1 } loaded.
18:35:14,329 INFO  [org.radargun.Slave] (sc-main) Starting stage ScenarioInit
18:35:14,392 INFO  [org.radargun.Slave] (sc-main) Finished stage ScenarioInit
18:35:14,396 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
18:35:14,406 INFO  [org.radargun.Slave] (sc-main) Starting stage BeforeServiceStart
18:35:14,406 INFO  [org.radargun.Slave] (sc-main) Finished stage BeforeServiceStart
18:35:14,407 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
18:35:14,420 INFO  [org.radargun.Slave] (sc-main) Starting stage ServiceStart
18:35:14,421 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Startup staggering, this is the slave with index 0, not sleeping
18:35:14,421 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 0
18:35:14,431 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) Infinispan version: Infinispan 'Gaina' 9.2.0.Final
18:35:14,448 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) JGroups version: JGroups 4.0.10.Final (Schiener Berg)
18:35:15,119 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (sc-main) ISPN000078: Starting JGroups channel results
18:35:15,207 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the send buffer of socket MulticastSocket was set to 1.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
18:35:15,208 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the receive buffer of socket MulticastSocket was set to 20.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
18:35:15,208 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the send buffer of socket MulticastSocket was set to 1.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
18:35:15,209 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the receive buffer of socket MulticastSocket was set to 25.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
18:35:20,230 INFO  [org.infinispan.CLUSTER] (sc-main) ISPN000094: Received new cluster view for channel results: [fedora-47567|0] (1) [fedora-47567]
18:35:20,291 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (sc-main) ISPN000079: Channel results local address is fedora-47567, physical addresses are [192.168.124.13:55548]
18:35:20,297 INFO  [org.infinispan.factories.GlobalComponentRegistry] (sc-main) ISPN000128: Infinispan version: Infinispan 'Gaina' 9.2.0.Final
18:35:20,989 INFO  [org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup] (sc-main) ISPN000107: Retrieving transaction manager Transaction: unknown
18:35:21,226 INFO  [org.infinispan.CLUSTER] (jgroups-6,fedora-47567) ISPN000094: Received new cluster view for channel results: [fedora-47567|1] (2) [fedora-47567, fedora-61078]
18:35:21,237 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) No RELAY2 protocol in XS service
18:35:21,237 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) No RELAY2 protocol in XS service
18:35:21,235 INFO  [org.infinispan.CLUSTER] (jgroups-6,fedora-47567) ISPN100000: Node fedora-61078 joined the cluster
18:35:21,251 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) ([fedora-47567(local=true, coord=true), fedora-61078(local=false, coord=false)]) Number of members=2 is not the one expected: 3
18:35:21,911 INFO  [org.infinispan.CLUSTER] (jgroups-10,fedora-47567) ISPN000094: Received new cluster view for channel results: [fedora-47567|2] (3) [fedora-47567, fedora-61078, fedora-989]
18:35:21,913 INFO  [org.infinispan.CLUSTER] (jgroups-10,fedora-47567) ISPN100000: Node fedora-989 joined the cluster
18:35:22,012 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-47567: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-47567: 134, fedora-61078: 122]}, unionCH=null, actualMembers=[fedora-47567, fedora-61078], persistentUUIDs=[e5bd8f96-4087-460a-b587-d69334711d59, 0c4ff1df-dde9-40e9-b94e-a612dec334f2]}
18:35:22,014 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-47567]ISPN100002: Started rebalance with topology id 2
18:35:22,012 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-47567: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-47567: 134, fedora-61078: 122]}, unionCH=null, actualMembers=[fedora-47567, fedora-61078], persistentUUIDs=[e5bd8f96-4087-460a-b587-d69334711d59, 0c4ff1df-dde9-40e9-b94e-a612dec334f2]}
18:35:22,015 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-47567]ISPN100002: Started rebalance with topology id 2
18:35:22,080 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t23) [Context=org.infinispan.CONFIG][Scope=fedora-47567]ISPN100003: Node fedora-47567 finished rebalance phase with topology id 2
18:35:22,095 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t24) [Context=___counter_configuration][Scope=fedora-47567]ISPN100003: Node fedora-47567 finished rebalance phase with topology id 2
18:35:22,256 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) Number of members is the one expected: 3
18:35:22,257 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Successfully started cache service infinispan92/embedded on slave 0
18:35:22,269 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-61078]ISPN100003: Node fedora-61078 finished rebalance phase with topology id 2
18:35:22,272 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 2
18:35:22,279 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t3) [Context=___counter_configuration][Scope=fedora-47567]ISPN100003: Node fedora-47567 finished rebalance phase with topology id 3
18:35:22,314 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-61078]ISPN100003: Node fedora-61078 finished rebalance phase with topology id 3
18:35:22,316 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t5) [Context=___counter_configuration][Scope=fedora-47567]ISPN100003: Node fedora-47567 finished rebalance phase with topology id 4
18:35:22,334 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=org.infinispan.CONFIG][Scope=fedora-61078]ISPN100003: Node fedora-61078 finished rebalance phase with topology id 2
18:35:22,344 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 2
18:35:22,346 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t8) [Context=org.infinispan.CONFIG][Scope=fedora-47567]ISPN100003: Node fedora-47567 finished rebalance phase with topology id 3
18:35:22,351 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counter_configuration][Scope=fedora-61078]ISPN100003: Node fedora-61078 finished rebalance phase with topology id 4
18:35:22,355 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=org.infinispan.CONFIG][Scope=fedora-61078]ISPN100003: Node fedora-61078 finished rebalance phase with topology id 3
18:35:22,365 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t15) [Context=org.infinispan.CONFIG][Scope=fedora-47567]ISPN100003: Node fedora-47567 finished rebalance phase with topology id 4
18:35:22,414 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=org.infinispan.CONFIG][Scope=fedora-61078]ISPN100003: Node fedora-61078 finished rebalance phase with topology id 4
18:35:22,426 ERROR [org.radargun.service.ConfigDumpHelper] (sc-main) Error while dumping ___protobuf_metadata cache config as properties
javax.management.AttributeNotFoundException: Unknown attribute 'configurationAsProperties'. Known attributes names are: [rebalancingEnabled, cacheStatus, cacheAvailability, cacheName, version, configurationAsProperties]
	at org.infinispan.jmx.ResourceDMBean.getAttribute(ResourceDMBean.java:181) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:641) ~[?:?]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:678) ~[?:?]
	at org.radargun.service.ConfigDumpHelper60.dumpCache(ConfigDumpHelper60.java:44) [plugin-infinispan60-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.service.EmbeddedConfigurationProvider.getNormalizedConfigs(EmbeddedConfigurationProvider.java:33) [plugin-infinispan52-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.stages.lifecycle.ServiceStartStage.executeOnSlave(ServiceStartStage.java:92) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase.scenarioLoop(SlaveBase.java:102) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase$ScenarioRunner.run(SlaveBase.java:203) [radargun-core-3.0.0-SNAPSHOT.jar:?]
18:35:22,460 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=DefaultConsistentHash{ns=256, owners = (1)[fedora-47567: 256+0]}, pendingCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-47567: 134+122, fedora-61078: 122+134]}, unionCH=null, actualMembers=[fedora-47567, fedora-61078], persistentUUIDs=[e5bd8f96-4087-460a-b587-d69334711d59, 0c4ff1df-dde9-40e9-b94e-a612dec334f2]}
18:35:22,461 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=fedora-47567]ISPN100002: Started rebalance with topology id 2
18:35:22,475 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=___counters][Scope=fedora-47567]ISPN100003: Node fedora-47567 finished rebalance phase with topology id 2
18:35:22,510 ERROR [org.radargun.service.ConfigDumpHelper] (sc-main) Error while dumping ___protobuf_metadata cache config as properties
javax.management.AttributeNotFoundException: Unknown attribute 'configurationAsProperties'. Known attributes names are: [rebalancingEnabled, cacheStatus, cacheAvailability, cacheName, version, configurationAsProperties]
	at org.infinispan.jmx.ResourceDMBean.getAttribute(ResourceDMBean.java:181) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:641) ~[?:?]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:678) ~[?:?]
	at org.radargun.service.ConfigDumpHelper60.dumpCache(ConfigDumpHelper60.java:44) [plugin-infinispan60-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.service.EmbeddedConfigurationProvider.getNormalizedConfigs(EmbeddedConfigurationProvider.java:33) [plugin-infinispan52-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.stages.lifecycle.ServiceStartStage.executeOnSlave(ServiceStartStage.java:92) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase.scenarioLoop(SlaveBase.java:102) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase$ScenarioRunner.run(SlaveBase.java:203) [radargun-core-3.0.0-SNAPSHOT.jar:?]
18:35:22,580 INFO  [org.radargun.Slave] (sc-main) Finished stage ServiceStart
18:35:22,594 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-47567: 134, fedora-61078: 122]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-47567: 90, fedora-61078: 86, fedora-989: 80]}, unionCH=null, actualMembers=[fedora-47567, fedora-61078, fedora-989], persistentUUIDs=[e5bd8f96-4087-460a-b587-d69334711d59, 0c4ff1df-dde9-40e9-b94e-a612dec334f2, 4fdc9301-bc14-4501-90e2-ed802c8747a3]}
18:35:22,594 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-47567]ISPN100002: Started rebalance with topology id 6
18:35:22,594 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-47567: 134, fedora-61078: 122]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-47567: 90, fedora-61078: 86, fedora-989: 80]}, unionCH=null, actualMembers=[fedora-47567, fedora-61078, fedora-989], persistentUUIDs=[e5bd8f96-4087-460a-b587-d69334711d59, 0c4ff1df-dde9-40e9-b94e-a612dec334f2, 4fdc9301-bc14-4501-90e2-ed802c8747a3]}
18:35:22,613 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=org.infinispan.CONFIG][Scope=fedora-47567]ISPN100002: Started rebalance with topology id 6
18:35:22,608 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-61078]ISPN100003: Node fedora-61078 finished rebalance phase with topology id 2
18:35:22,607 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t25) [Context=___counter_configuration][Scope=fedora-47567]ISPN100003: Node fedora-47567 finished rebalance phase with topology id 6
18:35:22,616 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t3) [Context=org.infinispan.CONFIG][Scope=fedora-47567]ISPN100003: Node fedora-47567 finished rebalance phase with topology id 6
18:35:22,616 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___counters, topology id = 2
18:35:22,620 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counter_configuration][Scope=fedora-61078]ISPN100003: Node fedora-61078 finished rebalance phase with topology id 6
18:35:22,626 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t9) [Context=___counters][Scope=fedora-47567]ISPN100003: Node fedora-47567 finished rebalance phase with topology id 3
18:35:22,632 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=org.infinispan.CONFIG][Scope=fedora-61078]ISPN100003: Node fedora-61078 finished rebalance phase with topology id 6
18:35:22,640 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=fedora-61078]ISPN100003: Node fedora-61078 finished rebalance phase with topology id 3
18:35:22,647 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
18:35:22,651 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-47567: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-47567: 134, fedora-61078: 122]}, unionCH=null, actualMembers=[fedora-47567, fedora-61078], persistentUUIDs=[e5bd8f96-4087-460a-b587-d69334711d59, 0c4ff1df-dde9-40e9-b94e-a612dec334f2]}
18:35:22,653 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t10) [Context=___counters][Scope=fedora-47567]ISPN100003: Node fedora-47567 finished rebalance phase with topology id 4
18:35:22,655 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-47567]ISPN100002: Started rebalance with topology id 2
18:35:22,659 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=fedora-61078]ISPN100003: Node fedora-61078 finished rebalance phase with topology id 4
18:35:22,675 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t18) [Context=___protobuf_metadata][Scope=fedora-47567]ISPN100003: Node fedora-47567 finished rebalance phase with topology id 2
18:35:22,682 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=fedora-61078]ISPN100003: Node fedora-61078 finished rebalance phase with topology id 2
18:35:22,683 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 2
18:35:22,685 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t22) [Context=___protobuf_metadata][Scope=fedora-47567]ISPN100003: Node fedora-47567 finished rebalance phase with topology id 3
18:35:22,686 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=fedora-61078]ISPN100003: Node fedora-61078 finished rebalance phase with topology id 3
18:35:22,687 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t19) [Context=___protobuf_metadata][Scope=fedora-47567]ISPN100003: Node fedora-47567 finished rebalance phase with topology id 4
18:35:22,689 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=fedora-61078]ISPN100003: Node fedora-61078 finished rebalance phase with topology id 4
18:35:22,714 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=DefaultConsistentHash{ns=512, owners = (1)[fedora-47567: 512+0]}, pendingCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-47567: 265+247, fedora-61078: 247+265]}, unionCH=null, actualMembers=[fedora-47567, fedora-61078], persistentUUIDs=[e5bd8f96-4087-460a-b587-d69334711d59, 0c4ff1df-dde9-40e9-b94e-a612dec334f2]}
18:35:22,715 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-47567]ISPN100002: Started rebalance with topology id 2
18:35:22,719 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t25) [Context=testCache][Scope=fedora-47567]ISPN100003: Node fedora-47567 finished rebalance phase with topology id 2
18:35:22,761 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-61078]ISPN100003: Node fedora-61078 finished rebalance phase with topology id 2
18:35:22,762 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000336: Finished cluster-wide rebalance for cache testCache, topology id = 2
18:35:22,765 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t8) [Context=testCache][Scope=fedora-47567]ISPN100003: Node fedora-47567 finished rebalance phase with topology id 3
18:35:22,766 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-61078]ISPN100003: Node fedora-61078 finished rebalance phase with topology id 3
18:35:22,773 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t12) [Context=testCache][Scope=fedora-47567]ISPN100003: Node fedora-47567 finished rebalance phase with topology id 4
18:35:22,778 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-61078]ISPN100003: Node fedora-61078 finished rebalance phase with topology id 4
18:35:22,938 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=org.infinispan.CONFIG][Scope=fedora-989]ISPN100003: Node fedora-989 finished rebalance phase with topology id 6
18:35:22,939 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 6
18:35:22,942 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=org.infinispan.CONFIG][Scope=fedora-61078]ISPN100003: Node fedora-61078 finished rebalance phase with topology id 7
18:35:22,943 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t17) [Context=org.infinispan.CONFIG][Scope=fedora-47567]ISPN100003: Node fedora-47567 finished rebalance phase with topology id 7
18:35:22,961 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=org.infinispan.CONFIG][Scope=fedora-989]ISPN100003: Node fedora-989 finished rebalance phase with topology id 7
18:35:22,963 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t23) [Context=org.infinispan.CONFIG][Scope=fedora-47567]ISPN100003: Node fedora-47567 finished rebalance phase with topology id 8
18:35:22,964 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=org.infinispan.CONFIG][Scope=fedora-61078]ISPN100003: Node fedora-61078 finished rebalance phase with topology id 8
18:35:22,974 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counter_configuration][Scope=fedora-989]ISPN100003: Node fedora-989 finished rebalance phase with topology id 6
18:35:22,974 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 6
18:35:22,976 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t19) [Context=___counter_configuration][Scope=fedora-47567]ISPN100003: Node fedora-47567 finished rebalance phase with topology id 7
18:35:22,979 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counter_configuration][Scope=fedora-61078]ISPN100003: Node fedora-61078 finished rebalance phase with topology id 7
18:35:22,995 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=org.infinispan.CONFIG][Scope=fedora-989]ISPN100003: Node fedora-989 finished rebalance phase with topology id 8
18:35:23,007 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counter_configuration][Scope=fedora-989]ISPN100003: Node fedora-989 finished rebalance phase with topology id 7
18:35:23,009 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t5) [Context=___counter_configuration][Scope=fedora-47567]ISPN100003: Node fedora-47567 finished rebalance phase with topology id 8
18:35:23,013 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counter_configuration][Scope=fedora-61078]ISPN100003: Node fedora-61078 finished rebalance phase with topology id 8
18:35:23,019 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counter_configuration][Scope=fedora-989]ISPN100003: Node fedora-989 finished rebalance phase with topology id 8
18:35:23,058 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-47567: 134+122, fedora-61078: 122+134]}, pendingCH=DefaultConsistentHash{ns=256, owners = (3)[fedora-47567: 90+80, fedora-61078: 86+95, fedora-989: 80+81]}, unionCH=null, actualMembers=[fedora-47567, fedora-61078, fedora-989], persistentUUIDs=[e5bd8f96-4087-460a-b587-d69334711d59, 0c4ff1df-dde9-40e9-b94e-a612dec334f2, 4fdc9301-bc14-4501-90e2-ed802c8747a3]}
18:35:23,059 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=fedora-47567]ISPN100002: Started rebalance with topology id 6
18:35:23,063 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t16) [Context=___counters][Scope=fedora-47567]ISPN100003: Node fedora-47567 finished rebalance phase with topology id 6
18:35:23,064 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=fedora-61078]ISPN100003: Node fedora-61078 finished rebalance phase with topology id 6
18:35:23,092 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=fedora-989]ISPN100003: Node fedora-989 finished rebalance phase with topology id 6
18:35:23,092 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000336: Finished cluster-wide rebalance for cache ___counters, topology id = 6
18:35:23,094 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t14) [Context=___counters][Scope=fedora-47567]ISPN100003: Node fedora-47567 finished rebalance phase with topology id 7
18:35:23,097 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=fedora-61078]ISPN100003: Node fedora-61078 finished rebalance phase with topology id 7
18:35:23,100 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=fedora-989]ISPN100003: Node fedora-989 finished rebalance phase with topology id 7
18:35:23,104 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=___counters][Scope=fedora-47567]ISPN100003: Node fedora-47567 finished rebalance phase with topology id 8
18:35:23,108 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-61078]ISPN100003: Node fedora-61078 finished rebalance phase with topology id 8
18:35:23,108 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=fedora-989]ISPN100003: Node fedora-989 finished rebalance phase with topology id 8
18:35:23,187 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-47567: 134, fedora-61078: 122]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-47567: 90, fedora-61078: 86, fedora-989: 80]}, unionCH=null, actualMembers=[fedora-47567, fedora-61078, fedora-989], persistentUUIDs=[e5bd8f96-4087-460a-b587-d69334711d59, 0c4ff1df-dde9-40e9-b94e-a612dec334f2, 4fdc9301-bc14-4501-90e2-ed802c8747a3]}
18:35:23,187 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=fedora-47567]ISPN100002: Started rebalance with topology id 6
18:35:23,195 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t1) [Context=___protobuf_metadata][Scope=fedora-47567]ISPN100003: Node fedora-47567 finished rebalance phase with topology id 6
18:35:23,199 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=fedora-61078]ISPN100003: Node fedora-61078 finished rebalance phase with topology id 6
18:35:23,218 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=fedora-989]ISPN100003: Node fedora-989 finished rebalance phase with topology id 6
18:35:23,219 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 6
18:35:23,221 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t25) [Context=___protobuf_metadata][Scope=fedora-47567]ISPN100003: Node fedora-47567 finished rebalance phase with topology id 7
18:35:23,223 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=fedora-61078]ISPN100003: Node fedora-61078 finished rebalance phase with topology id 7
18:35:23,227 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-989]ISPN100003: Node fedora-989 finished rebalance phase with topology id 7
18:35:23,229 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t9) [Context=___protobuf_metadata][Scope=fedora-47567]ISPN100003: Node fedora-47567 finished rebalance phase with topology id 8
18:35:23,234 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-989]ISPN100003: Node fedora-989 finished rebalance phase with topology id 8
18:35:23,235 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=fedora-61078]ISPN100003: Node fedora-61078 finished rebalance phase with topology id 8
18:35:23,244 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-47567: 265+247, fedora-61078: 247+265]}, pendingCH=DefaultConsistentHash{ns=512, owners = (3)[fedora-47567: 180+171, fedora-61078: 170+164, fedora-989: 162+177]}, unionCH=null, actualMembers=[fedora-47567, fedora-61078, fedora-989], persistentUUIDs=[e5bd8f96-4087-460a-b587-d69334711d59, 0c4ff1df-dde9-40e9-b94e-a612dec334f2, 4fdc9301-bc14-4501-90e2-ed802c8747a3]}
18:35:23,245 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-47567]ISPN100002: Started rebalance with topology id 6
18:35:23,248 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t11) [Context=testCache][Scope=fedora-47567]ISPN100003: Node fedora-47567 finished rebalance phase with topology id 6
18:35:23,254 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-61078]ISPN100003: Node fedora-61078 finished rebalance phase with topology id 6
18:35:23,276 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-989]ISPN100003: Node fedora-989 finished rebalance phase with topology id 6
18:35:23,276 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000336: Finished cluster-wide rebalance for cache testCache, topology id = 6
18:35:23,279 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t22) [Context=testCache][Scope=fedora-47567]ISPN100003: Node fedora-47567 finished rebalance phase with topology id 7
18:35:23,282 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-989]ISPN100003: Node fedora-989 finished rebalance phase with topology id 7
18:35:23,282 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-61078]ISPN100003: Node fedora-61078 finished rebalance phase with topology id 7
18:35:23,286 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t23) [Context=testCache][Scope=fedora-47567]ISPN100003: Node fedora-47567 finished rebalance phase with topology id 8
18:35:23,289 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-61078]ISPN100003: Node fedora-61078 finished rebalance phase with topology id 8
18:35:23,292 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-989]ISPN100003: Node fedora-989 finished rebalance phase with topology id 8
18:35:23,399 INFO  [org.radargun.Slave] (sc-main) Starting stage AfterServiceStart
18:35:23,400 INFO  [org.radargun.Slave] (sc-main) Finished stage AfterServiceStart
18:35:23,404 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
18:35:23,506 INFO  [org.radargun.Slave] (sc-main) Starting stage MonitorStart
18:35:23,526 INFO  [org.radargun.sysmonitor.AbstractMonitors] (sc-main) Gathering statistics every 1000 ms
18:35:23,529 INFO  [org.radargun.Slave] (sc-main) Finished stage MonitorStart
18:35:23,531 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
18:35:23,560 INFO  [org.radargun.Slave] (sc-main) Starting stage Load
18:35:31,997 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) This node loaded 10000 entries (~10000000 bytes)
18:35:37,981 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) This node loaded 20000 entries (~20000000 bytes)
18:35:42,518 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) This node loaded 30000 entries (~30000000 bytes)
18:35:43,645 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) Finished loading entries
18:35:43,657 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) Finished loading entries
18:35:43,672 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) Finished loading entries
18:35:43,676 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) Finished loading entries
18:35:43,676 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) Finished loading entries
18:35:43,697 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) Finished loading entries
18:35:43,705 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) Finished loading entries
18:35:43,720 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) Finished loading entries
18:35:43,721 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) Finished loading entries
18:35:43,736 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) Finished loading entries
18:35:43,736 INFO  [org.radargun.Slave] (sc-main) Finished stage Load
18:35:43,737 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
18:35:43,771 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.stages.cache.test.BasicOperationsTestStage.init() overrides public void org.radargun.stages.test.TestStage.init() but both are declared with @Init annotation: calling only once
18:35:43,791 INFO  [org.radargun.Slave] (sc-main) Starting stage BasicOperationsTest
18:35:43,793 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using key generator org.radargun.stages.cache.generators.StringKeyGenerator {format=null }
18:35:43,794 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using value generator org.radargun.stages.cache.generators.ByteArrayValueGenerator { }
18:35:43,795 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using cache selector Default { }
18:35:43,797 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Starting test warmup
18:35:43,829 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Started 4 stressor threads.
18:36:43,832 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Finished test. Test duration is: 1 mins 0 secs
18:36:43,834 INFO  [org.radargun.Slave] (sc-main) Finished stage BasicOperationsTest
18:36:43,840 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
18:36:43,948 INFO  [org.radargun.Slave] (sc-main) Starting stage Clear
18:36:43,961 INFO  [org.radargun.stages.cache.ClearStage] (sc-main) Before executing clear, memory looks like this: 
Runtime free: 833,649 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,326 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,696 kb
MX Metaspace(Non-heap memory): used: 43,942 kb, init: 0 kb, committed: 45,512 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 12,429 kb, init: 2,496 kb, committed: 12,480 kb, max: 120,032 kb
MX Compressed Class Space(Non-heap memory): used: 4,965 kb, init: 0 kb, committed: 5,504 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 388,096 kb, init: 73,728 kb, committed: 547,840 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 133,041 kb, init: 1,325,056 kb, committed: 807,936 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 43,008 kb, init: 0 kb, committed: 43,008 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 5,129 kb, init: 2,496 kb, committed: 5,184 kb, max: 120,032 kb
18:36:44,168 INFO  [org.radargun.stages.cache.ClearStage] (sc-main) After executing clear, memory looks like this: 
Runtime free: 1,381,586 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,340 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,696 kb
MX Metaspace(Non-heap memory): used: 43,900 kb, init: 0 kb, committed: 45,512 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 12,535 kb, init: 2,496 kb, committed: 12,544 kb, max: 120,032 kb
MX Compressed Class Space(Non-heap memory): used: 4,940 kb, init: 0 kb, committed: 5,504 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 0 kb, init: 73,728 kb, committed: 614,400 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 16,677 kb, init: 1,325,056 kb, committed: 784,384 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 0 kb, init: 0 kb, committed: 0 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 5,161 kb, init: 2,496 kb, committed: 5,184 kb, max: 120,032 kb
18:36:44,169 INFO  [org.radargun.Slave] (sc-main) Finished stage Clear
18:36:44,169 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
18:36:44,181 INFO  [org.radargun.Slave] (sc-main) Starting stage Load
18:36:47,425 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) This node loaded 10000 entries (~10000000 bytes)
18:36:50,705 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) This node loaded 20000 entries (~20000000 bytes)
18:36:53,998 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) This node loaded 30000 entries (~30000000 bytes)
18:36:54,975 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) Finished loading entries
18:36:55,001 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) Finished loading entries
18:36:55,027 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) Finished loading entries
18:36:55,039 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) Finished loading entries
18:36:55,046 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) Finished loading entries
18:36:55,053 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) Finished loading entries
18:36:55,071 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) Finished loading entries
18:36:55,071 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) Finished loading entries
18:36:55,078 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) Finished loading entries
18:36:55,103 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) Finished loading entries
18:36:55,103 INFO  [org.radargun.Slave] (sc-main) Finished stage Load
18:36:55,104 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
18:36:55,417 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.stages.cache.test.BasicOperationsTestStage.init() overrides public void org.radargun.stages.test.TestStage.init() but both are declared with @Init annotation: calling only once
18:36:55,420 INFO  [org.radargun.Slave] (sc-main) Starting stage BasicOperationsTest
18:36:55,422 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using key generator org.radargun.stages.cache.generators.StringKeyGenerator {format=null }
18:36:55,423 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using value generator org.radargun.stages.cache.generators.ByteArrayValueGenerator { }
18:36:55,424 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using cache selector Default { }
18:36:55,424 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Starting test stress-test
18:36:55,504 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Started 4 stressor threads.
18:46:55,510 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Finished test. Test duration is: 10 mins 0 secs
18:46:55,514 INFO  [org.radargun.Slave] (sc-main) Finished stage BasicOperationsTest
18:46:55,615 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
18:46:55,832 INFO  [org.radargun.Slave] (sc-main) Starting stage MonitorStop
18:46:55,834 INFO  [org.radargun.Slave] (sc-main) Finished stage MonitorStop
18:46:55,835 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
18:46:55,841 INFO  [org.radargun.Slave] (sc-main) Starting stage ScenarioDestroy
18:46:55,842 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Scenario finished, destroying...
18:46:55,843 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Memory before cleanup: 
Runtime free: 840,556 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,328 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,696 kb
MX Metaspace(Non-heap memory): used: 44,657 kb, init: 0 kb, committed: 46,152 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 14,456 kb, init: 2,496 kb, committed: 14,464 kb, max: 120,032 kb
MX Compressed Class Space(Non-heap memory): used: 4,980 kb, init: 0 kb, committed: 5,632 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 172,032 kb, init: 73,728 kb, committed: 807,936 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 325,777 kb, init: 1,325,056 kb, committed: 531,456 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 59,392 kb, init: 0 kb, committed: 59,392 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 6,152 kb, init: 2,496 kb, committed: 6,208 kb, max: 120,032 kb
18:46:55,843 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) Stopping service.
18:46:55,861 INFO  [org.infinispan.CLUSTER] (StopThread) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-61078: 263+71, fedora-989: 249+90]}, pendingCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-61078: 261+251, fedora-989: 251+261]}, unionCH=null, actualMembers=[fedora-61078, fedora-989], persistentUUIDs=[0c4ff1df-dde9-40e9-b94e-a612dec334f2, 4fdc9301-bc14-4501-90e2-ed802c8747a3]}
18:46:55,872 INFO  [org.infinispan.CLUSTER] (StopThread) [Context=testCache][Scope=fedora-47567]ISPN100002: Started rebalance with topology id 11
18:46:55,875 WARN  [org.infinispan.CLUSTER] (remote-thread--p2-t10) [Context=testCache]ISPN000312: Lost data because of graceful leaver fedora-61078
18:46:55,906 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t36) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-47567: 133, fedora-989: 123]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-47567: 134, fedora-989: 122]}, unionCH=null, actualMembers=[fedora-47567, fedora-989], persistentUUIDs=[e5bd8f96-4087-460a-b587-d69334711d59, 4fdc9301-bc14-4501-90e2-ed802c8747a3]}
18:46:55,907 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t36) [Context=___protobuf_metadata][Scope=fedora-47567]ISPN100002: Started rebalance with topology id 11
18:46:55,913 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t10) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-47567: 143+27, fedora-989: 113+48]}, pendingCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-47567: 134+122, fedora-989: 122+134]}, unionCH=null, actualMembers=[fedora-47567, fedora-989], persistentUUIDs=[e5bd8f96-4087-460a-b587-d69334711d59, 4fdc9301-bc14-4501-90e2-ed802c8747a3]}
18:46:55,913 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t10) [Context=___counters][Scope=fedora-47567]ISPN100002: Started rebalance with topology id 11
18:46:55,919 WARN  [org.infinispan.CLUSTER] (remote-thread--p2-t10) [Context=___counters]ISPN000312: Lost data because of graceful leaver fedora-989
18:46:55,920 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t36) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-47567: 133, fedora-989: 123]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-47567: 134, fedora-989: 122]}, unionCH=null, actualMembers=[fedora-47567, fedora-989], persistentUUIDs=[e5bd8f96-4087-460a-b587-d69334711d59, 4fdc9301-bc14-4501-90e2-ed802c8747a3]}
18:46:55,922 ERROR [org.infinispan.statetransfer.StateConsumerImpl] (transport-thread--p4-t11) ISPN000208: No live owners found for segments {4-5 14-24 27-29 32-36 44-47 51-55 60 64-65 69 83 89 97 101-102 105 112-113 120-121 126-129 146 151-152 155-156 166 171-177 185 188-190 196 199-200 204-210 218 225-227 233 239 243-247} of cache ___counters. Excluded owners: []
18:46:55,925 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t36) [Context=org.infinispan.CONFIG][Scope=fedora-47567]ISPN100002: Started rebalance with topology id 11
18:46:55,926 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t17) [Context=___counters][Scope=fedora-47567]ISPN100003: Node fedora-47567 finished rebalance phase with topology id 12
18:46:55,927 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t11) [Context=org.infinispan.CONFIG][Scope=fedora-47567]ISPN100003: Node fedora-47567 finished rebalance phase with topology id 11
18:46:55,928 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (transport-thread--p4-t17) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___counters, type=REBALANCE_PHASE_CONFIRM, sender=fedora-47567, joinInfo=null, topologyId=12, rebalanceId=4, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-47567 for cache ___counters, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.commands.ReplicableCommand.invoke(ReplicableCommand.java:44) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.LocalTopologyManagerImpl.lambda$executeOnCoordinatorAsync$4(LocalTopologyManagerImpl.java:717) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
18:46:55,932 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t23) [Context=org.infinispan.CONFIG][Scope=fedora-47567]ISPN100003: Node fedora-47567 finished rebalance phase with topology id 12
18:46:55,932 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t10) [Context=org.infinispan.CONFIG][Scope=fedora-989]ISPN100003: Node fedora-989 finished rebalance phase with topology id 11
18:46:55,934 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (transport-thread--p4-t23) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=org.infinispan.CONFIG, type=REBALANCE_PHASE_CONFIRM, sender=fedora-47567, joinInfo=null, topologyId=12, rebalanceId=4, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-47567 for cache org.infinispan.CONFIG, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.commands.ReplicableCommand.invoke(ReplicableCommand.java:44) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.LocalTopologyManagerImpl.lambda$executeOnCoordinatorAsync$4(LocalTopologyManagerImpl.java:717) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
18:46:55,932 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t36) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=12, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-47567: 133, fedora-989: 123]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-47567: 134, fedora-989: 122]}, unionCH=null, actualMembers=[fedora-47567, fedora-989], persistentUUIDs=[e5bd8f96-4087-460a-b587-d69334711d59, 4fdc9301-bc14-4501-90e2-ed802c8747a3]}
18:46:55,934 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (remote-thread--p2-t10) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=org.infinispan.CONFIG, type=REBALANCE_PHASE_CONFIRM, sender=fedora-989, joinInfo=null, topologyId=11, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-989 for cache org.infinispan.CONFIG, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.invokeReplicableCommand(GlobalInboundInvocationHandler.java:169) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.runReplicableCommand(GlobalInboundInvocationHandler.java:150) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.lambda$handleReplicableCommand$1(GlobalInboundInvocationHandler.java:144) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.util.concurrent.BlockingTaskAwareExecutorServiceImpl$RunnableWrapper.run(BlockingTaskAwareExecutorServiceImpl.java:212) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
18:46:55,937 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t36) [Context=___counter_configuration][Scope=fedora-47567]ISPN100002: Started rebalance with topology id 12
18:46:55,938 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t25) [Context=___counter_configuration][Scope=fedora-47567]ISPN100003: Node fedora-47567 finished rebalance phase with topology id 12
18:46:55,944 INFO  [org.infinispan.CLUSTER] (jgroups-31,fedora-47567) ISPN000094: Received new cluster view for channel results: [fedora-47567|3] (2) [fedora-47567, fedora-989]
18:46:55,948 INFO  [org.infinispan.CLUSTER] (jgroups-31,fedora-47567) ISPN100001: Node fedora-61078 left the cluster
18:46:55,949 WARN  [org.infinispan.statetransfer.InboundTransferTask] (stateTransferExecutor-thread--p6-t1) ISPN000210: Failed to request state of cache ___counters from node fedora-989, segments {4-5 14-24 27-29 32-36 44-47 51-55 60 64-65 69 83 89 97 101-102 105 112-113 120-121 126-129 146 151-152 155-156 166 171-177 185 188-190 196 199-200 204-210 218 225-227 233 239 243-247}
org.infinispan.remoting.transport.jgroups.SuspectException: ISPN000400: Node fedora-989 was suspected
	at org.infinispan.remoting.transport.ResponseCollectors.remoteNodeSuspected(ResponseCollectors.java:33) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleResponseCollector.targetNotFound(SingleResponseCollector.java:31) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleResponseCollector.targetNotFound(SingleResponseCollector.java:17) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.ValidSingleResponseCollector.addResponse(ValidSingleResponseCollector.java:23) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleTargetRequest.receiveResponse(SingleTargetRequest.java:51) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleTargetRequest.onResponse(SingleTargetRequest.java:35) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.RequestRepository.addResponse(RequestRepository.java:53) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.processResponse(JGroupsTransport.java:1302) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.processMessage(JGroupsTransport.java:1205) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.access$200(JGroupsTransport.java:123) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport$ChannelCallbacks.receive(JGroupsTransport.java:1340) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.jgroups.JChannel.up(JChannel.java:819) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.stack.ProtocolStack.up(ProtocolStack.java:893) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FRAG3.up(FRAG3.java:171) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FlowControl.up(FlowControl.java:343) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FlowControl.up(FlowControl.java:343) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.GMS.up(GMS.java:864) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.STABLE.up(STABLE.java:240) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.deliverMessage(UNICAST3.java:1002) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.handleDataReceived(UNICAST3.java:728) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.up(UNICAST3.java:383) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.NAKACK2.up(NAKACK2.java:600) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.VERIFY_SUSPECT.up(VERIFY_SUSPECT.java:119) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FD_ALL.up(FD_ALL.java:199) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FD_SOCK.up(FD_SOCK.java:252) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.MERGE3.up(MERGE3.java:276) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.Discovery.up(Discovery.java:267) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.TP.passMessageUp(TP.java:1248) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.util.SubmitToThreadPool$SingleMessageHandler.run(SubmitToThreadPool.java:87) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
18:46:55,971 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (StopThread) ISPN000080: Disconnecting JGroups channel results
18:46:55,999 WARN  [org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler] (remote-thread--p2-t36) ISPN000219: Shutdown while handling command CacheTopologyControlCommand{cache=___counter_configuration, type=REBALANCE_PHASE_CONFIRM, sender=fedora-989, joinInfo=null, topologyId=12, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=3}
18:46:56,003 INFO  [org.radargun.service.Infinispan90Lifecycle] (StopThread) Stopped, previous view is [fedora-47567, fedora-61078, fedora-989]
18:46:56,003 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Service successfully stopped.
18:46:56,004 INFO  [org.radargun.Slave] (sc-main) Finished stage ScenarioDestroy
18:46:56,004 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
18:46:57,105 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.service.Infinispan80EmbeddedService.destroy() overrides public void org.radargun.service.Infinispan60EmbeddedService.destroy() but both are declared with @Destroy annotation: calling only once
18:46:57,108 INFO  [org.radargun.Slave] (main) Starting stage ScenarioCleanup
18:46:57,110 WARN  [org.radargun.stages.ScenarioCleanupStage] (main) Unfinished thread ForkJoinPool.commonPool-worker-3 (id=33, state=WAITING)
	at java.base@11.0.14-internal/jdk.internal.misc.Unsafe.park(Native Method)
	at java.base@11.0.14-internal/java.util.concurrent.locks.LockSupport.park(LockSupport.java:194)
	at java.base@11.0.14-internal/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1628)
	at java.base@11.0.14-internal/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
18:46:57,110 INFO  [org.radargun.stages.ScenarioCleanupStage] (main) Interrupting thread ForkJoinPool.commonPool-worker-3 (id=33, state=WAITING)
18:47:02,112 INFO  [org.radargun.stages.ScenarioCleanupStage] (main) Stopping thread ForkJoinPool.commonPool-worker-3 (id=33, state=WAITING)
18:47:02,117 INFO  [org.radargun.stages.ScenarioCleanupStage] (main) Is thread ForkJoinPool.commonPool-worker-3 (id=33, state=TERMINATED)) alive? false
18:47:02,274 INFO  [org.radargun.stages.ScenarioCleanupStage] (main) Memory after cleanup: 
Runtime free: 1,380,672 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,329 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,696 kb
MX Metaspace(Non-heap memory): used: 44,801 kb, init: 0 kb, committed: 46,408 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 14,574 kb, init: 2,496 kb, committed: 14,592 kb, max: 120,032 kb
MX Compressed Class Space(Non-heap memory): used: 5,001 kb, init: 0 kb, committed: 5,632 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 0 kb, init: 73,728 kb, committed: 880,640 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 17,599 kb, init: 1,325,056 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 0 kb, init: 0 kb, committed: 0 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 6,250 kb, init: 2,496 kb, committed: 6,272 kb, max: 120,032 kb
18:47:02,277 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
18:47:02,331 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
18:47:06,093 INFO  [org.radargun.Slave] (main) Master shutdown!
18:47:06,094 INFO  [org.radargun.ShutDownHook] (Thread-0) Slave process is being shutdown
