10:21:12,433 INFO  [org.radargun.RemoteMasterConnection] (main) Attempting to connect to master results:2103
10:21:12,443 INFO  [org.radargun.RemoteMasterConnection] (main) Successfully established connection with master at: results:2103
10:21:12,445 INFO  [org.radargun.Slave] (main) Received slave index 0
10:21:12,446 INFO  [org.radargun.Slave] (main) Received slave count 3
10:21:12,780 INFO  [org.radargun.ServiceHelper] (sc-main) ServiceContext properties: {}
10:21:12,942 INFO  [org.radargun.Slave] (sc-main) Eager Service Infinispan92EmbeddedService {batching=false, cache=testCache, channelRetrievalTimeout=2 mins 0 secs, enableDiagnostics=null, explicitLocking=false, file=/mnt/workspace/results/dist-sync.xml, internalsExpositionEnabled=false, jgroupsDumperEnabled=false, jgroupsDumperInterval=10.000 secs, keysPerThread=-1, mapReduceDistributedReducePhase=false, mapReduceUseIntermediateSharedCache=false, removedCaches=[  ], threadsPerNode=-1 } loaded.
10:21:15,047 INFO  [org.radargun.Slave] (sc-main) Starting stage ScenarioInit
10:21:15,177 INFO  [org.radargun.Slave] (sc-main) Finished stage ScenarioInit
10:21:15,180 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
10:21:15,248 INFO  [org.radargun.Slave] (sc-main) Starting stage BeforeServiceStart
10:21:15,249 INFO  [org.radargun.Slave] (sc-main) Finished stage BeforeServiceStart
10:21:15,250 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
10:21:15,276 INFO  [org.radargun.Slave] (sc-main) Starting stage ServiceStart
10:21:15,278 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Startup staggering, this is the slave with index 0, not sleeping
10:21:15,279 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 0
10:21:15,282 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) Infinispan version: Infinispan 'Gaina' 9.2.0.Final
10:21:15,302 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) JGroups version: JGroups 4.0.10.Final (Schiener Berg)
10:21:16,044 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (sc-main) ISPN000078: Starting JGroups channel results
10:21:16,128 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the send buffer of socket MulticastSocket was set to 1.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
10:21:16,128 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the receive buffer of socket MulticastSocket was set to 20.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
10:21:16,129 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the send buffer of socket MulticastSocket was set to 1.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
10:21:16,129 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the receive buffer of socket MulticastSocket was set to 25.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
10:21:21,162 INFO  [org.infinispan.CLUSTER] (sc-main) ISPN000094: Received new cluster view for channel results: [fedora-4124|0] (1) [fedora-4124]
10:21:21,216 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (sc-main) ISPN000079: Channel results local address is fedora-4124, physical addresses are [192.168.124.4:45018]
10:21:21,223 INFO  [org.infinispan.factories.GlobalComponentRegistry] (sc-main) ISPN000128: Infinispan version: Infinispan 'Gaina' 9.2.0.Final
10:21:22,026 INFO  [org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup] (sc-main) ISPN000107: Retrieving transaction manager Transaction: unknown
10:21:22,191 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) No RELAY2 protocol in XS service
10:21:22,202 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) No RELAY2 protocol in XS service
10:21:22,210 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) ([fedora-4124(local=true, coord=true)]) Number of members=1 is not the one expected: 3
10:21:22,228 INFO  [org.infinispan.CLUSTER] (jgroups-6,fedora-4124) ISPN000094: Received new cluster view for channel results: [fedora-4124|1] (2) [fedora-4124, fedora-31522]
10:21:22,244 INFO  [org.infinispan.CLUSTER] (jgroups-6,fedora-4124) ISPN100000: Node fedora-31522 joined the cluster
10:21:22,352 INFO  [org.infinispan.CLUSTER] (jgroups-6,fedora-4124) ISPN000094: Received new cluster view for channel results: [fedora-4124|2] (3) [fedora-4124, fedora-31522, fedora-29837]
10:21:22,354 INFO  [org.infinispan.CLUSTER] (jgroups-6,fedora-4124) ISPN100000: Node fedora-29837 joined the cluster
10:21:23,086 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-4124: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-4124: 134, fedora-31522: 122]}, unionCH=null, actualMembers=[fedora-4124, fedora-31522], persistentUUIDs=[6e2f366e-d9a3-4555-8bcd-ce01cf4eba13, 439b40d0-e789-45f7-a684-2a9348af8375]}
10:21:23,089 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-4124]ISPN100002: Started rebalance with topology id 2
10:21:23,090 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-4124: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-4124: 134, fedora-31522: 122]}, unionCH=null, actualMembers=[fedora-4124, fedora-31522], persistentUUIDs=[6e2f366e-d9a3-4555-8bcd-ce01cf4eba13, 439b40d0-e789-45f7-a684-2a9348af8375]}
10:21:23,091 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-4124]ISPN100002: Started rebalance with topology id 2
10:21:23,155 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t23) [Context=___counter_configuration][Scope=fedora-4124]ISPN100003: Node fedora-4124 finished rebalance phase with topology id 2
10:21:23,155 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t22) [Context=org.infinispan.CONFIG][Scope=fedora-4124]ISPN100003: Node fedora-4124 finished rebalance phase with topology id 2
10:21:23,211 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) Number of members is the one expected: 3
10:21:23,211 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Successfully started cache service infinispan92/embedded on slave 0
10:21:23,258 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-31522]ISPN100003: Node fedora-31522 finished rebalance phase with topology id 2
10:21:23,266 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 2
10:21:23,283 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t1) [Context=org.infinispan.CONFIG][Scope=fedora-4124]ISPN100003: Node fedora-4124 finished rebalance phase with topology id 3
10:21:23,296 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-31522]ISPN100003: Node fedora-31522 finished rebalance phase with topology id 2
10:21:23,302 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 2
10:21:23,304 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t4) [Context=___counter_configuration][Scope=fedora-4124]ISPN100003: Node fedora-4124 finished rebalance phase with topology id 3
10:21:23,310 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-31522]ISPN100003: Node fedora-31522 finished rebalance phase with topology id 3
10:21:23,312 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-31522]ISPN100003: Node fedora-31522 finished rebalance phase with topology id 3
10:21:23,315 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=org.infinispan.CONFIG][Scope=fedora-4124]ISPN100003: Node fedora-4124 finished rebalance phase with topology id 4
10:21:23,315 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t8) [Context=___counter_configuration][Scope=fedora-4124]ISPN100003: Node fedora-4124 finished rebalance phase with topology id 4
10:21:23,325 ERROR [org.radargun.service.ConfigDumpHelper] (sc-main) Error while dumping ___protobuf_metadata cache config as properties
javax.management.AttributeNotFoundException: Unknown attribute 'configurationAsProperties'. Known attributes names are: [rebalancingEnabled, cacheStatus, cacheName, cacheAvailability, version, configurationAsProperties]
	at org.infinispan.jmx.ResourceDMBean.getAttribute(ResourceDMBean.java:181) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:647) ~[?:1.8.0-internal]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:678) ~[?:1.8.0-internal]
	at org.radargun.service.ConfigDumpHelper60.dumpCache(ConfigDumpHelper60.java:44) [plugin-infinispan60-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.service.EmbeddedConfigurationProvider.getNormalizedConfigs(EmbeddedConfigurationProvider.java:33) [plugin-infinispan52-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.stages.lifecycle.ServiceStartStage.executeOnSlave(ServiceStartStage.java:92) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase.scenarioLoop(SlaveBase.java:102) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase$ScenarioRunner.run(SlaveBase.java:203) [radargun-core-3.0.0-SNAPSHOT.jar:?]
10:21:23,339 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-31522]ISPN100003: Node fedora-31522 finished rebalance phase with topology id 4
10:21:23,342 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-29837]ISPN100003: Node fedora-29837 finished rebalance phase with topology id 4
10:21:23,348 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=org.infinispan.CONFIG][Scope=fedora-29837]ISPN100003: Node fedora-29837 finished rebalance phase with topology id 3
10:21:23,352 ERROR [org.radargun.service.ConfigDumpHelper] (sc-main) Error while dumping ___protobuf_metadata cache config as properties
javax.management.AttributeNotFoundException: Unknown attribute 'configurationAsProperties'. Known attributes names are: [rebalancingEnabled, cacheStatus, cacheName, cacheAvailability, version, configurationAsProperties]
	at org.infinispan.jmx.ResourceDMBean.getAttribute(ResourceDMBean.java:181) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:647) ~[?:1.8.0-internal]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:678) ~[?:1.8.0-internal]
	at org.radargun.service.ConfigDumpHelper60.dumpCache(ConfigDumpHelper60.java:44) [plugin-infinispan60-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.service.EmbeddedConfigurationProvider.getNormalizedConfigs(EmbeddedConfigurationProvider.java:33) [plugin-infinispan52-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.stages.lifecycle.ServiceStartStage.executeOnSlave(ServiceStartStage.java:92) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase.scenarioLoop(SlaveBase.java:102) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase$ScenarioRunner.run(SlaveBase.java:203) [radargun-core-3.0.0-SNAPSHOT.jar:?]
10:21:23,357 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=org.infinispan.CONFIG][Scope=fedora-29837]ISPN100003: Node fedora-29837 finished rebalance phase with topology id 4
10:21:23,367 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-4124: 134, fedora-31522: 122]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-4124: 85, fedora-31522: 89, fedora-29837: 82]}, unionCH=null, actualMembers=[fedora-4124, fedora-31522, fedora-29837], persistentUUIDs=[6e2f366e-d9a3-4555-8bcd-ce01cf4eba13, 439b40d0-e789-45f7-a684-2a9348af8375, b18373b3-67fe-4279-bed4-d8cce52949e9]}
10:21:23,369 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-4124]ISPN100002: Started rebalance with topology id 6
10:21:23,368 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___counter_configuration][Scope=fedora-29837]ISPN100003: Node fedora-29837 finished rebalance phase with topology id 3
10:21:23,383 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (remote-thread--p2-t4) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___counter_configuration, type=REBALANCE_PHASE_CONFIRM, sender=fedora-29837, joinInfo=null, topologyId=3, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-29837 for cache ___counter_configuration, expecting topology id 4 but got 3
	at org.infinispan.topology.RebalanceConfirmationCollector.confirmPhase(RebalanceConfirmationCollector.java:41) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:337) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.invokeReplicableCommand(GlobalInboundInvocationHandler.java:169) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.runReplicableCommand(GlobalInboundInvocationHandler.java:150) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.lambda$handleReplicableCommand$1(GlobalInboundInvocationHandler.java:144) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.util.concurrent.BlockingTaskAwareExecutorServiceImpl$RunnableWrapper.run(BlockingTaskAwareExecutorServiceImpl.java:212) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0-internal]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0-internal]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0-internal]
10:21:23,382 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (remote-thread--p2-t5) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=org.infinispan.CONFIG, type=REBALANCE_PHASE_CONFIRM, sender=fedora-29837, joinInfo=null, topologyId=4, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-29837 for cache org.infinispan.CONFIG, expecting topology id 6 but got 4
	at org.infinispan.topology.RebalanceConfirmationCollector.confirmPhase(RebalanceConfirmationCollector.java:41) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:337) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.invokeReplicableCommand(GlobalInboundInvocationHandler.java:169) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.runReplicableCommand(GlobalInboundInvocationHandler.java:150) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.lambda$handleReplicableCommand$1(GlobalInboundInvocationHandler.java:144) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.util.concurrent.BlockingTaskAwareExecutorServiceImpl$RunnableWrapper.run(BlockingTaskAwareExecutorServiceImpl.java:212) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0-internal]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0-internal]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0-internal]
10:21:23,379 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (remote-thread--p2-t3) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=org.infinispan.CONFIG, type=REBALANCE_PHASE_CONFIRM, sender=fedora-29837, joinInfo=null, topologyId=3, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-29837 for cache org.infinispan.CONFIG, expecting topology id 6 but got 3
	at org.infinispan.topology.RebalanceConfirmationCollector.confirmPhase(RebalanceConfirmationCollector.java:41) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:337) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.invokeReplicableCommand(GlobalInboundInvocationHandler.java:169) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.runReplicableCommand(GlobalInboundInvocationHandler.java:150) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.lambda$handleReplicableCommand$1(GlobalInboundInvocationHandler.java:144) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.util.concurrent.BlockingTaskAwareExecutorServiceImpl$RunnableWrapper.run(BlockingTaskAwareExecutorServiceImpl.java:212) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0-internal]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0-internal]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0-internal]
10:21:23,383 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t15) [Context=org.infinispan.CONFIG][Scope=fedora-4124]ISPN100003: Node fedora-4124 finished rebalance phase with topology id 6
10:21:23,388 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counter_configuration][Scope=fedora-31522]ISPN100003: Node fedora-31522 finished rebalance phase with topology id 4
10:21:23,389 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-4124: 134, fedora-31522: 122]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-4124: 85, fedora-31522: 89, fedora-29837: 82]}, unionCH=null, actualMembers=[fedora-4124, fedora-31522, fedora-29837], persistentUUIDs=[6e2f366e-d9a3-4555-8bcd-ce01cf4eba13, 439b40d0-e789-45f7-a684-2a9348af8375, b18373b3-67fe-4279-bed4-d8cce52949e9]}
10:21:23,390 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counter_configuration][Scope=fedora-4124]ISPN100002: Started rebalance with topology id 6
10:21:23,392 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t23) [Context=___counter_configuration][Scope=fedora-4124]ISPN100003: Node fedora-4124 finished rebalance phase with topology id 6
10:21:23,393 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=org.infinispan.CONFIG][Scope=fedora-31522]ISPN100003: Node fedora-31522 finished rebalance phase with topology id 6
10:21:23,415 INFO  [org.radargun.Slave] (sc-main) Finished stage ServiceStart
10:21:23,466 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counter_configuration][Scope=fedora-31522]ISPN100003: Node fedora-31522 finished rebalance phase with topology id 6
10:21:23,469 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
10:21:23,498 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=DefaultConsistentHash{ns=256, owners = (1)[fedora-4124: 256+0]}, pendingCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-4124: 134+122, fedora-31522: 122+134]}, unionCH=null, actualMembers=[fedora-4124, fedora-31522], persistentUUIDs=[6e2f366e-d9a3-4555-8bcd-ce01cf4eba13, 439b40d0-e789-45f7-a684-2a9348af8375]}
10:21:23,499 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=fedora-4124]ISPN100002: Started rebalance with topology id 2
10:21:23,505 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t22) [Context=___counters][Scope=fedora-4124]ISPN100003: Node fedora-4124 finished rebalance phase with topology id 2
10:21:23,555 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=fedora-31522]ISPN100003: Node fedora-31522 finished rebalance phase with topology id 2
10:21:23,556 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000336: Finished cluster-wide rebalance for cache ___counters, topology id = 2
10:21:23,558 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t1) [Context=___counters][Scope=fedora-4124]ISPN100003: Node fedora-4124 finished rebalance phase with topology id 3
10:21:23,565 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=fedora-31522]ISPN100003: Node fedora-31522 finished rebalance phase with topology id 3
10:21:23,567 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t6) [Context=___counters][Scope=fedora-4124]ISPN100003: Node fedora-4124 finished rebalance phase with topology id 4
10:21:23,571 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=fedora-31522]ISPN100003: Node fedora-31522 finished rebalance phase with topology id 4
10:21:23,589 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-4124: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-4124: 134, fedora-31522: 122]}, unionCH=null, actualMembers=[fedora-4124, fedora-31522], persistentUUIDs=[6e2f366e-d9a3-4555-8bcd-ce01cf4eba13, 439b40d0-e789-45f7-a684-2a9348af8375]}
10:21:23,590 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=fedora-4124]ISPN100002: Started rebalance with topology id 2
10:21:23,599 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t14) [Context=___protobuf_metadata][Scope=fedora-4124]ISPN100003: Node fedora-4124 finished rebalance phase with topology id 2
10:21:23,649 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=DefaultConsistentHash{ns=512, owners = (1)[fedora-4124: 512+0]}, pendingCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-4124: 255+257, fedora-31522: 257+255]}, unionCH=null, actualMembers=[fedora-4124, fedora-31522], persistentUUIDs=[6e2f366e-d9a3-4555-8bcd-ce01cf4eba13, 439b40d0-e789-45f7-a684-2a9348af8375]}
10:21:23,650 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-4124]ISPN100002: Started rebalance with topology id 2
10:21:23,655 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t19) [Context=testCache][Scope=fedora-4124]ISPN100003: Node fedora-4124 finished rebalance phase with topology id 2
10:21:23,667 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=fedora-31522]ISPN100003: Node fedora-31522 finished rebalance phase with topology id 2
10:21:23,669 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 2
10:21:23,672 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=___protobuf_metadata][Scope=fedora-4124]ISPN100003: Node fedora-4124 finished rebalance phase with topology id 3
10:21:23,677 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=org.infinispan.CONFIG][Scope=fedora-29837]ISPN100003: Node fedora-29837 finished rebalance phase with topology id 6
10:21:23,678 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 6
10:21:23,679 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=fedora-31522]ISPN100003: Node fedora-31522 finished rebalance phase with topology id 3
10:21:23,680 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t2) [Context=org.infinispan.CONFIG][Scope=fedora-4124]ISPN100003: Node fedora-4124 finished rebalance phase with topology id 7
10:21:23,683 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=___counter_configuration][Scope=fedora-29837]ISPN100003: Node fedora-29837 finished rebalance phase with topology id 6
10:21:23,687 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=org.infinispan.CONFIG][Scope=fedora-29837]ISPN100003: Node fedora-29837 finished rebalance phase with topology id 7
10:21:23,688 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t5) [Context=___protobuf_metadata][Scope=fedora-4124]ISPN100003: Node fedora-4124 finished rebalance phase with topology id 4
10:21:23,688 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 6
10:21:23,691 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t1) [Context=___counter_configuration][Scope=fedora-4124]ISPN100003: Node fedora-4124 finished rebalance phase with topology id 7
10:21:23,694 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=___counter_configuration][Scope=fedora-29837]ISPN100003: Node fedora-29837 finished rebalance phase with topology id 7
10:21:23,697 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=org.infinispan.CONFIG][Scope=fedora-31522]ISPN100003: Node fedora-31522 finished rebalance phase with topology id 7
10:21:23,698 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t10) [Context=org.infinispan.CONFIG][Scope=fedora-4124]ISPN100003: Node fedora-4124 finished rebalance phase with topology id 8
10:21:23,702 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=org.infinispan.CONFIG][Scope=fedora-29837]ISPN100003: Node fedora-29837 finished rebalance phase with topology id 8
10:21:23,711 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=org.infinispan.CONFIG][Scope=fedora-31522]ISPN100003: Node fedora-31522 finished rebalance phase with topology id 8
10:21:23,711 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counter_configuration][Scope=fedora-31522]ISPN100003: Node fedora-31522 finished rebalance phase with topology id 7
10:21:23,711 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___protobuf_metadata][Scope=fedora-31522]ISPN100003: Node fedora-31522 finished rebalance phase with topology id 4
10:21:23,715 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counter_configuration][Scope=fedora-29837]ISPN100003: Node fedora-29837 finished rebalance phase with topology id 8
10:21:23,717 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t8) [Context=___counter_configuration][Scope=fedora-4124]ISPN100003: Node fedora-4124 finished rebalance phase with topology id 8
10:21:23,734 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counter_configuration][Scope=fedora-31522]ISPN100003: Node fedora-31522 finished rebalance phase with topology id 8
10:21:23,747 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-31522]ISPN100003: Node fedora-31522 finished rebalance phase with topology id 2
10:21:23,748 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000336: Finished cluster-wide rebalance for cache testCache, topology id = 2
10:21:23,750 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t3) [Context=testCache][Scope=fedora-4124]ISPN100003: Node fedora-4124 finished rebalance phase with topology id 3
10:21:23,752 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-31522]ISPN100003: Node fedora-31522 finished rebalance phase with topology id 3
10:21:23,761 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t4) [Context=testCache][Scope=fedora-4124]ISPN100003: Node fedora-4124 finished rebalance phase with topology id 4
10:21:23,764 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-31522]ISPN100003: Node fedora-31522 finished rebalance phase with topology id 4
10:21:23,815 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-4124: 134+122, fedora-31522: 122+134]}, pendingCH=DefaultConsistentHash{ns=256, owners = (3)[fedora-4124: 85+98, fedora-31522: 89+83, fedora-29837: 82+75]}, unionCH=null, actualMembers=[fedora-4124, fedora-31522, fedora-29837], persistentUUIDs=[6e2f366e-d9a3-4555-8bcd-ce01cf4eba13, 439b40d0-e789-45f7-a684-2a9348af8375, b18373b3-67fe-4279-bed4-d8cce52949e9]}
10:21:23,817 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=fedora-4124]ISPN100002: Started rebalance with topology id 6
10:21:23,819 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t11) [Context=___counters][Scope=fedora-4124]ISPN100003: Node fedora-4124 finished rebalance phase with topology id 6
10:21:23,827 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=fedora-31522]ISPN100003: Node fedora-31522 finished rebalance phase with topology id 6
10:21:23,875 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=fedora-29837]ISPN100003: Node fedora-29837 finished rebalance phase with topology id 6
10:21:23,875 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000336: Finished cluster-wide rebalance for cache ___counters, topology id = 6
10:21:23,877 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t13) [Context=___counters][Scope=fedora-4124]ISPN100003: Node fedora-4124 finished rebalance phase with topology id 7
10:21:23,881 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=fedora-31522]ISPN100003: Node fedora-31522 finished rebalance phase with topology id 7
10:21:23,885 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=fedora-29837]ISPN100003: Node fedora-29837 finished rebalance phase with topology id 7
10:21:23,887 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t19) [Context=___counters][Scope=fedora-4124]ISPN100003: Node fedora-4124 finished rebalance phase with topology id 8
10:21:23,890 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-4124: 134, fedora-31522: 122]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-4124: 85, fedora-31522: 89, fedora-29837: 82]}, unionCH=null, actualMembers=[fedora-4124, fedora-31522, fedora-29837], persistentUUIDs=[6e2f366e-d9a3-4555-8bcd-ce01cf4eba13, 439b40d0-e789-45f7-a684-2a9348af8375, b18373b3-67fe-4279-bed4-d8cce52949e9]}
10:21:23,890 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=fedora-4124]ISPN100002: Started rebalance with topology id 6
10:21:23,894 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t25) [Context=___protobuf_metadata][Scope=fedora-4124]ISPN100003: Node fedora-4124 finished rebalance phase with topology id 6
10:21:23,896 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___counters][Scope=fedora-31522]ISPN100003: Node fedora-31522 finished rebalance phase with topology id 8
10:21:23,898 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=fedora-29837]ISPN100003: Node fedora-29837 finished rebalance phase with topology id 8
10:21:23,903 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=fedora-31522]ISPN100003: Node fedora-31522 finished rebalance phase with topology id 6
10:21:23,962 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___protobuf_metadata][Scope=fedora-29837]ISPN100003: Node fedora-29837 finished rebalance phase with topology id 6
10:21:23,963 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-4124: 255+257, fedora-31522: 257+255]}, pendingCH=DefaultConsistentHash{ns=512, owners = (3)[fedora-4124: 172+186, fedora-31522: 178+167, fedora-29837: 162+159]}, unionCH=null, actualMembers=[fedora-4124, fedora-31522, fedora-29837], persistentUUIDs=[6e2f366e-d9a3-4555-8bcd-ce01cf4eba13, 439b40d0-e789-45f7-a684-2a9348af8375, b18373b3-67fe-4279-bed4-d8cce52949e9]}
10:21:23,963 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-4124]ISPN100002: Started rebalance with topology id 6
10:21:23,963 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 6
10:21:23,967 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___protobuf_metadata][Scope=fedora-31522]ISPN100003: Node fedora-31522 finished rebalance phase with topology id 7
10:21:23,970 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t3) [Context=___protobuf_metadata][Scope=fedora-4124]ISPN100003: Node fedora-4124 finished rebalance phase with topology id 7
10:21:23,973 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t15) [Context=testCache][Scope=fedora-4124]ISPN100003: Node fedora-4124 finished rebalance phase with topology id 6
10:21:23,979 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-31522]ISPN100003: Node fedora-31522 finished rebalance phase with topology id 6
10:21:23,984 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=fedora-29837]ISPN100003: Node fedora-29837 finished rebalance phase with topology id 7
10:21:23,986 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t9) [Context=___protobuf_metadata][Scope=fedora-4124]ISPN100003: Node fedora-4124 finished rebalance phase with topology id 8
10:21:23,987 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=fedora-29837]ISPN100003: Node fedora-29837 finished rebalance phase with topology id 8
10:21:23,989 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=fedora-31522]ISPN100003: Node fedora-31522 finished rebalance phase with topology id 8
10:21:24,003 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-29837]ISPN100003: Node fedora-29837 finished rebalance phase with topology id 6
10:21:24,003 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000336: Finished cluster-wide rebalance for cache testCache, topology id = 6
10:21:24,006 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t16) [Context=testCache][Scope=fedora-4124]ISPN100003: Node fedora-4124 finished rebalance phase with topology id 7
10:21:24,008 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-29837]ISPN100003: Node fedora-29837 finished rebalance phase with topology id 7
10:21:24,010 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=testCache][Scope=fedora-31522]ISPN100003: Node fedora-31522 finished rebalance phase with topology id 7
10:21:24,012 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t23) [Context=testCache][Scope=fedora-4124]ISPN100003: Node fedora-4124 finished rebalance phase with topology id 8
10:21:24,014 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=testCache][Scope=fedora-29837]ISPN100003: Node fedora-29837 finished rebalance phase with topology id 8
10:21:24,016 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=testCache][Scope=fedora-31522]ISPN100003: Node fedora-31522 finished rebalance phase with topology id 8
10:21:24,123 INFO  [org.radargun.Slave] (sc-main) Starting stage AfterServiceStart
10:21:24,123 INFO  [org.radargun.Slave] (sc-main) Finished stage AfterServiceStart
10:21:24,125 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
10:21:24,176 INFO  [org.radargun.Slave] (sc-main) Starting stage MonitorStart
10:21:24,188 INFO  [org.radargun.sysmonitor.AbstractMonitors] (sc-main) Gathering statistics every 1000 ms
10:21:24,189 INFO  [org.radargun.Slave] (sc-main) Finished stage MonitorStart
10:21:24,189 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
10:21:24,222 INFO  [org.radargun.Slave] (sc-main) Starting stage Load
10:21:31,860 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) This node loaded 10000 entries (~10000000 bytes)
10:21:36,537 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) This node loaded 20000 entries (~20000000 bytes)
10:21:40,359 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) This node loaded 30000 entries (~30000000 bytes)
10:21:41,296 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) Finished loading entries
10:21:41,327 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) Finished loading entries
10:21:41,334 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) Finished loading entries
10:21:41,350 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) Finished loading entries
10:21:41,362 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) Finished loading entries
10:21:41,371 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) Finished loading entries
10:21:41,374 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) Finished loading entries
10:21:41,382 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) Finished loading entries
10:21:41,404 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) Finished loading entries
10:21:41,406 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) Finished loading entries
10:21:41,407 INFO  [org.radargun.Slave] (sc-main) Finished stage Load
10:21:41,407 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
10:21:41,440 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.stages.cache.test.BasicOperationsTestStage.init() overrides public void org.radargun.stages.test.TestStage.init() but both are declared with @Init annotation: calling only once
10:21:41,445 INFO  [org.radargun.Slave] (sc-main) Starting stage BasicOperationsTest
10:21:41,449 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using key generator org.radargun.stages.cache.generators.StringKeyGenerator {format=null }
10:21:41,452 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using value generator org.radargun.stages.cache.generators.ByteArrayValueGenerator { }
10:21:41,453 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using cache selector Default { }
10:21:41,453 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Starting test warmup
10:21:41,461 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Started 4 stressor threads.
10:22:41,465 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Finished test. Test duration is: 1 mins 0 secs
10:22:41,467 INFO  [org.radargun.Slave] (sc-main) Finished stage BasicOperationsTest
10:22:41,478 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
10:22:41,500 INFO  [org.radargun.Slave] (sc-main) Starting stage Clear
10:22:41,507 INFO  [org.radargun.stages.cache.ClearStage] (sc-main) Before executing clear, memory looks like this: 
Runtime free: 1,119,134 kb
Runtime max:1,301,504 kb
Runtime total:1,301,504 kb
MX Code Cache(Non-heap memory): used: 13,141 kb, init: 2,496 kb, committed: 13,824 kb, max: 245,760 kb
MX Metaspace(Non-heap memory): used: 37,229 kb, init: 0 kb, committed: 39,168 kb, max: 0 kb
MX Compressed Class Space(Non-heap memory): used: 4,415 kb, init: 0 kb, committed: 4,864 kb, max: 1,048,576 kb
MX PS Eden Space(Heap memory): used: 6,721 kb, init: 350,208 kb, committed: 269,312 kb, max: 269,312 kb
MX PS Survivor Space(Heap memory): used: 57,984 kb, init: 57,856 kb, committed: 99,328 kb, max: 99,328 kb
MX PS Old Gen(Heap memory): used: 117,663 kb, init: 932,864 kb, committed: 932,864 kb, max: 932,864 kb
10:22:41,752 INFO  [org.radargun.stages.cache.ClearStage] (sc-main) After executing clear, memory looks like this: 
Runtime free: 1,285,271 kb
Runtime max:1,299,456 kb
Runtime total:1,299,456 kb
MX Code Cache(Non-heap memory): used: 13,245 kb, init: 2,496 kb, committed: 13,824 kb, max: 245,760 kb
MX Metaspace(Non-heap memory): used: 37,202 kb, init: 0 kb, committed: 39,168 kb, max: 0 kb
MX Compressed Class Space(Non-heap memory): used: 4,400 kb, init: 0 kb, committed: 4,864 kb, max: 1,048,576 kb
MX PS Eden Space(Heap memory): used: 1,668 kb, init: 350,208 kb, committed: 269,312 kb, max: 273,408 kb
MX PS Survivor Space(Heap memory): used: 0 kb, init: 57,856 kb, committed: 97,280 kb, max: 97,280 kb
MX PS Old Gen(Heap memory): used: 12,525 kb, init: 932,864 kb, committed: 932,864 kb, max: 932,864 kb
10:22:41,754 INFO  [org.radargun.Slave] (sc-main) Finished stage Clear
10:22:41,761 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
10:22:41,787 INFO  [org.radargun.Slave] (sc-main) Starting stage Load
10:22:45,059 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) This node loaded 10000 entries (~10000000 bytes)
10:22:48,294 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) This node loaded 20000 entries (~20000000 bytes)
10:22:51,572 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) This node loaded 30000 entries (~30000000 bytes)
10:22:52,553 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) Finished loading entries
10:22:52,608 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) Finished loading entries
10:22:52,614 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) Finished loading entries
10:22:52,659 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) Finished loading entries
10:22:52,669 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) Finished loading entries
10:22:52,675 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) Finished loading entries
10:22:52,691 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) Finished loading entries
10:22:52,696 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) Finished loading entries
10:22:52,714 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) Finished loading entries
10:22:52,747 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) Finished loading entries
10:22:52,747 INFO  [org.radargun.Slave] (sc-main) Finished stage Load
10:22:52,748 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
10:22:53,240 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.stages.cache.test.BasicOperationsTestStage.init() overrides public void org.radargun.stages.test.TestStage.init() but both are declared with @Init annotation: calling only once
10:22:53,243 INFO  [org.radargun.Slave] (sc-main) Starting stage BasicOperationsTest
10:22:53,243 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using key generator org.radargun.stages.cache.generators.StringKeyGenerator {format=null }
10:22:53,244 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using value generator org.radargun.stages.cache.generators.ByteArrayValueGenerator { }
10:22:53,244 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using cache selector Default { }
10:22:53,244 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Starting test stress-test
10:22:53,277 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Started 4 stressor threads.
10:32:53,283 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Finished test. Test duration is: 10 mins 0 secs
10:32:53,284 INFO  [org.radargun.Slave] (sc-main) Finished stage BasicOperationsTest
10:32:53,372 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
10:32:53,620 INFO  [org.radargun.Slave] (sc-main) Starting stage MonitorStop
10:32:53,621 INFO  [org.radargun.Slave] (sc-main) Finished stage MonitorStop
10:32:53,622 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
10:32:53,628 INFO  [org.radargun.Slave] (sc-main) Starting stage ScenarioDestroy
10:32:53,628 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Scenario finished, destroying...
10:32:53,628 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Memory before cleanup: 
Runtime free: 945,242 kb
Runtime max:1,325,568 kb
Runtime total:1,325,568 kb
MX Code Cache(Non-heap memory): used: 14,853 kb, init: 2,496 kb, committed: 15,040 kb, max: 245,760 kb
MX Metaspace(Non-heap memory): used: 37,760 kb, init: 0 kb, committed: 39,680 kb, max: 0 kb
MX Compressed Class Space(Non-heap memory): used: 4,434 kb, init: 0 kb, committed: 4,864 kb, max: 1,048,576 kb
MX PS Eden Space(Heap memory): used: 265,657 kb, init: 350,208 kb, committed: 319,488 kb, max: 319,488 kb
MX PS Survivor Space(Heap memory): used: 72,928 kb, init: 57,856 kb, committed: 73,216 kb, max: 73,216 kb
MX PS Old Gen(Heap memory): used: 41,739 kb, init: 932,864 kb, committed: 932,864 kb, max: 932,864 kb
10:32:53,629 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) Stopping service.
10:32:53,640 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t27) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-4124: 254+104, fedora-31522: 258+87]}, pendingCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-4124: 255+257, fedora-31522: 257+255]}, unionCH=null, actualMembers=[fedora-4124, fedora-31522], persistentUUIDs=[6e2f366e-d9a3-4555-8bcd-ce01cf4eba13, 439b40d0-e789-45f7-a684-2a9348af8375]}
10:32:53,645 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t27) [Context=testCache][Scope=fedora-4124]ISPN100002: Started rebalance with topology id 11
10:32:53,682 WARN  [org.infinispan.CLUSTER] (remote-thread--p2-t28) [Context=testCache]ISPN000312: Lost data because of graceful leaver fedora-31522
10:32:53,714 ERROR [org.infinispan.statetransfer.StateConsumerImpl] (transport-thread--p4-t21) ISPN000208: No live owners found for segments {1-2 6-7 10-11 23 26-34 44-47 53 57 62 67-69 81 87 95 99 125-135 142-146 153-163 169-172 175 183-184 189 194-197 207 210-212 221-222 230-231 234 252-253 269 273 276-281 286-287 306-312 334 339 348-350 359-361 371-380 386-388 395-397 402-403 406 414 422-424 431-433 436 455-458 461-465 474-476 485-487 490-491 494-495 499-501} of cache testCache. Excluded owners: []
10:32:53,715 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t15) [Context=testCache][Scope=fedora-4124]ISPN100003: Node fedora-4124 finished rebalance phase with topology id 12
10:32:53,715 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (transport-thread--p4-t15) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=testCache, type=REBALANCE_PHASE_CONFIRM, sender=fedora-4124, joinInfo=null, topologyId=12, rebalanceId=4, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-4124 for cache testCache, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.commands.ReplicableCommand.invoke(ReplicableCommand.java:44) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.LocalTopologyManagerImpl.lambda$executeOnCoordinatorAsync$4(LocalTopologyManagerImpl.java:717) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0-internal]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0-internal]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0-internal]
10:32:53,716 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t28) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-4124: 130+53, fedora-31522: 126+46]}, pendingCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-4124: 134+122, fedora-31522: 122+134]}, unionCH=null, actualMembers=[fedora-4124, fedora-31522], persistentUUIDs=[6e2f366e-d9a3-4555-8bcd-ce01cf4eba13, 439b40d0-e789-45f7-a684-2a9348af8375]}
10:32:53,722 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t28) [Context=___counters][Scope=fedora-4124]ISPN100002: Started rebalance with topology id 11
10:32:53,761 WARN  [org.infinispan.CLUSTER] (remote-thread--p2-t27) [Context=___counters]ISPN000312: Lost data because of graceful leaver fedora-31522
10:32:53,755 WARN  [org.infinispan.statetransfer.InboundTransferTask] (stateTransferExecutor-thread--p6-t2) ISPN000210: Failed to request state of cache ___counters from node fedora-31522, segments {1-2 5 13-17 31-33 43-44 59-60 63-67 71 76-84 97-101 105 113-114 117 138-139 150-155 159 169 183 186-190 196-201 207 211 215-217 224 243-247 250}
org.infinispan.remoting.transport.jgroups.SuspectException: ISPN000400: Node fedora-31522 was suspected
	at org.infinispan.remoting.transport.ResponseCollectors.remoteNodeSuspected(ResponseCollectors.java:33) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleResponseCollector.targetNotFound(SingleResponseCollector.java:31) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleResponseCollector.targetNotFound(SingleResponseCollector.java:17) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.ValidSingleResponseCollector.addResponse(ValidSingleResponseCollector.java:23) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleTargetRequest.receiveResponse(SingleTargetRequest.java:51) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleTargetRequest.onResponse(SingleTargetRequest.java:35) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.RequestRepository.addResponse(RequestRepository.java:53) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.processResponse(JGroupsTransport.java:1302) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.processMessage(JGroupsTransport.java:1205) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.access$200(JGroupsTransport.java:123) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport$ChannelCallbacks.receive(JGroupsTransport.java:1340) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.jgroups.JChannel.up(JChannel.java:819) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.stack.ProtocolStack.up(ProtocolStack.java:893) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FRAG3.up(FRAG3.java:171) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FlowControl.up(FlowControl.java:343) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FlowControl.up(FlowControl.java:343) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.GMS.up(GMS.java:864) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.STABLE.up(STABLE.java:240) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.deliverMessage(UNICAST3.java:1002) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.handleDataReceived(UNICAST3.java:728) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.up(UNICAST3.java:383) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.NAKACK2.up(NAKACK2.java:600) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.VERIFY_SUSPECT.up(VERIFY_SUSPECT.java:119) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FD_ALL.up(FD_ALL.java:199) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FD_SOCK.up(FD_SOCK.java:252) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.MERGE3.up(MERGE3.java:276) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.Discovery.up(Discovery.java:267) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.TP.passMessageUp(TP.java:1248) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.util.SubmitToThreadPool$SingleMessageHandler.run(SubmitToThreadPool.java:87) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0-internal]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0-internal]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0-internal]
10:32:53,769 ERROR [org.infinispan.statetransfer.StateConsumerImpl] (transport-thread--p4-t17) ISPN000208: No live owners found for segments {1-2 5 13-17 31-33 43-44 59-60 63-67 71 76-84 97-101 105 113-114 117 138-139 150-155 159 169 183 186-190 196-201 207 211 215-217 224 243-247 250} of cache ___counters. Excluded owners: []
10:32:53,772 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t17) [Context=___counters][Scope=fedora-4124]ISPN100003: Node fedora-4124 finished rebalance phase with topology id 12
10:32:53,773 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (transport-thread--p4-t17) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___counters, type=REBALANCE_PHASE_CONFIRM, sender=fedora-4124, joinInfo=null, topologyId=12, rebalanceId=4, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-4124 for cache ___counters, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.commands.ReplicableCommand.invoke(ReplicableCommand.java:44) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.LocalTopologyManagerImpl.lambda$executeOnCoordinatorAsync$4(LocalTopologyManagerImpl.java:717) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0-internal]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0-internal]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0-internal]
10:32:53,775 INFO  [org.infinispan.CLUSTER] (jgroups-9,fedora-4124) ISPN000094: Received new cluster view for channel results: [fedora-4124|3] (2) [fedora-4124, fedora-31522]
10:32:53,776 INFO  [org.infinispan.CLUSTER] (jgroups-9,fedora-4124) ISPN100001: Node fedora-29837 left the cluster
10:32:53,805 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (StopThread) ISPN000080: Disconnecting JGroups channel results
10:32:53,856 INFO  [org.radargun.service.Infinispan90Lifecycle] (StopThread) Stopped, previous view is [fedora-4124, fedora-31522, fedora-29837]
10:32:53,857 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Service successfully stopped.
10:32:53,857 INFO  [org.radargun.Slave] (sc-main) Finished stage ScenarioDestroy
10:32:53,857 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
10:32:54,986 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.service.Infinispan80EmbeddedService.destroy() overrides public void org.radargun.service.Infinispan60EmbeddedService.destroy() but both are declared with @Destroy annotation: calling only once
10:32:54,989 INFO  [org.radargun.Slave] (main) Starting stage ScenarioCleanup
10:32:55,128 INFO  [org.radargun.stages.ScenarioCleanupStage] (main) Memory after cleanup: 
Runtime free: 1,306,660 kb
Runtime max:1,324,544 kb
Runtime total:1,324,544 kb
MX Code Cache(Non-heap memory): used: 14,970 kb, init: 2,496 kb, committed: 15,168 kb, max: 245,760 kb
MX Metaspace(Non-heap memory): used: 37,871 kb, init: 0 kb, committed: 39,680 kb, max: 0 kb
MX Compressed Class Space(Non-heap memory): used: 4,455 kb, init: 0 kb, committed: 4,864 kb, max: 1,048,576 kb
MX PS Eden Space(Heap memory): used: 5,544 kb, init: 350,208 kb, committed: 318,464 kb, max: 318,976 kb
MX PS Survivor Space(Heap memory): used: 0 kb, init: 57,856 kb, committed: 73,216 kb, max: 73,216 kb
MX PS Old Gen(Heap memory): used: 12,339 kb, init: 932,864 kb, committed: 932,864 kb, max: 932,864 kb
10:32:55,130 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
10:33:00,264 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
10:33:04,550 INFO  [org.radargun.Slave] (main) Master shutdown!
