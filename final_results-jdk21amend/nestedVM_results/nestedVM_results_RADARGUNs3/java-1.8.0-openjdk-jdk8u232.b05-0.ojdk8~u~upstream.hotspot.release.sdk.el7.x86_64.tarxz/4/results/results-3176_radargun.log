16:20:57,457 INFO  [org.radargun.RemoteMasterConnection] (main) Attempting to connect to master results:2103
16:20:57,464 INFO  [org.radargun.RemoteMasterConnection] (main) Successfully established connection with master at: results:2103
16:20:57,468 INFO  [org.radargun.Slave] (main) Received slave index 0
16:20:57,468 INFO  [org.radargun.Slave] (main) Received slave count 3
16:20:57,677 INFO  [org.radargun.ServiceHelper] (sc-main) ServiceContext properties: {}
16:20:57,867 INFO  [org.radargun.Slave] (sc-main) Eager Service Infinispan92EmbeddedService {batching=false, cache=testCache, channelRetrievalTimeout=2 mins 0 secs, enableDiagnostics=null, explicitLocking=false, file=/mnt/workspace/results/dist-sync.xml, internalsExpositionEnabled=false, jgroupsDumperEnabled=false, jgroupsDumperInterval=10.000 secs, keysPerThread=-1, mapReduceDistributedReducePhase=false, mapReduceUseIntermediateSharedCache=false, removedCaches=[  ], threadsPerNode=-1 } loaded.
16:20:59,811 INFO  [org.radargun.Slave] (sc-main) Starting stage ScenarioInit
16:20:59,858 INFO  [org.radargun.Slave] (sc-main) Finished stage ScenarioInit
16:20:59,861 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
16:20:59,966 INFO  [org.radargun.Slave] (sc-main) Starting stage BeforeServiceStart
16:20:59,967 INFO  [org.radargun.Slave] (sc-main) Finished stage BeforeServiceStart
16:20:59,968 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
16:20:59,976 INFO  [org.radargun.Slave] (sc-main) Starting stage ServiceStart
16:20:59,977 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Startup staggering, this is the slave with index 0, not sleeping
16:20:59,977 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 0
16:20:59,980 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) Infinispan version: Infinispan 'Gaina' 9.2.0.Final
16:20:59,992 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) JGroups version: JGroups 4.0.10.Final (Schiener Berg)
16:21:00,599 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (sc-main) ISPN000078: Starting JGroups channel results
16:21:00,694 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the send buffer of socket MulticastSocket was set to 1.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
16:21:00,694 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the receive buffer of socket MulticastSocket was set to 20.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
16:21:00,694 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the send buffer of socket MulticastSocket was set to 1.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
16:21:00,695 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the receive buffer of socket MulticastSocket was set to 25.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
16:21:05,723 INFO  [org.infinispan.CLUSTER] (sc-main) ISPN000094: Received new cluster view for channel results: [fedora-41317|0] (1) [fedora-41317]
16:21:05,791 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (sc-main) ISPN000079: Channel results local address is fedora-41317, physical addresses are [192.168.124.113:48049]
16:21:05,797 INFO  [org.infinispan.factories.GlobalComponentRegistry] (sc-main) ISPN000128: Infinispan version: Infinispan 'Gaina' 9.2.0.Final
16:21:06,583 INFO  [org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup] (sc-main) ISPN000107: Retrieving transaction manager Transaction: unknown
16:21:06,745 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) No RELAY2 protocol in XS service
16:21:06,746 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) No RELAY2 protocol in XS service
16:21:06,748 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) ([fedora-41317(local=true, coord=true)]) Number of members=1 is not the one expected: 3
16:21:06,853 INFO  [org.infinispan.CLUSTER] (jgroups-6,fedora-41317) ISPN000094: Received new cluster view for channel results: [fedora-41317|1] (2) [fedora-41317, fedora-4755]
16:21:06,862 INFO  [org.infinispan.CLUSTER] (jgroups-6,fedora-41317) ISPN100000: Node fedora-4755 joined the cluster
16:21:07,111 INFO  [org.infinispan.CLUSTER] (jgroups-12,fedora-41317) ISPN000094: Received new cluster view for channel results: [fedora-41317|2] (3) [fedora-41317, fedora-4755, fedora-53082]
16:21:07,112 INFO  [org.infinispan.CLUSTER] (jgroups-12,fedora-41317) ISPN100000: Node fedora-53082 joined the cluster
16:21:07,748 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) Number of members is the one expected: 3
16:21:07,748 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Successfully started cache service infinispan92/embedded on slave 0
16:21:07,770 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-41317: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-41317: 126, fedora-4755: 130]}, unionCH=null, actualMembers=[fedora-41317, fedora-4755], persistentUUIDs=[059e33e3-162e-408c-b22e-1b71d1225de7, c0e70399-af80-4502-9642-d5db025079e1]}
16:21:07,772 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-41317]ISPN100002: Started rebalance with topology id 2
16:21:07,788 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-41317: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-41317: 126, fedora-4755: 130]}, unionCH=null, actualMembers=[fedora-41317, fedora-4755], persistentUUIDs=[059e33e3-162e-408c-b22e-1b71d1225de7, c0e70399-af80-4502-9642-d5db025079e1]}
16:21:07,790 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-41317]ISPN100002: Started rebalance with topology id 2
16:21:07,810 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t23) [Context=org.infinispan.CONFIG][Scope=fedora-41317]ISPN100003: Node fedora-41317 finished rebalance phase with topology id 2
16:21:07,811 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t24) [Context=___counter_configuration][Scope=fedora-41317]ISPN100003: Node fedora-41317 finished rebalance phase with topology id 2
16:21:07,845 ERROR [org.radargun.service.ConfigDumpHelper] (sc-main) Error while dumping ___protobuf_metadata cache config as properties
javax.management.AttributeNotFoundException: Unknown attribute 'configurationAsProperties'. Known attributes names are: [rebalancingEnabled, cacheStatus, cacheName, cacheAvailability, version, configurationAsProperties]
	at org.infinispan.jmx.ResourceDMBean.getAttribute(ResourceDMBean.java:181) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:647) ~[?:1.8.0-internal]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:678) ~[?:1.8.0-internal]
	at org.radargun.service.ConfigDumpHelper60.dumpCache(ConfigDumpHelper60.java:44) [plugin-infinispan60-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.service.EmbeddedConfigurationProvider.getNormalizedConfigs(EmbeddedConfigurationProvider.java:33) [plugin-infinispan52-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.stages.lifecycle.ServiceStartStage.executeOnSlave(ServiceStartStage.java:92) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase.scenarioLoop(SlaveBase.java:102) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase$ScenarioRunner.run(SlaveBase.java:203) [radargun-core-3.0.0-SNAPSHOT.jar:?]
16:21:07,862 ERROR [org.radargun.service.ConfigDumpHelper] (sc-main) Error while dumping ___protobuf_metadata cache config as properties
javax.management.AttributeNotFoundException: Unknown attribute 'configurationAsProperties'. Known attributes names are: [rebalancingEnabled, cacheStatus, cacheName, cacheAvailability, version, configurationAsProperties]
	at org.infinispan.jmx.ResourceDMBean.getAttribute(ResourceDMBean.java:181) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:647) ~[?:1.8.0-internal]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:678) ~[?:1.8.0-internal]
	at org.radargun.service.ConfigDumpHelper60.dumpCache(ConfigDumpHelper60.java:44) [plugin-infinispan60-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.service.EmbeddedConfigurationProvider.getNormalizedConfigs(EmbeddedConfigurationProvider.java:33) [plugin-infinispan52-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.stages.lifecycle.ServiceStartStage.executeOnSlave(ServiceStartStage.java:92) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase.scenarioLoop(SlaveBase.java:102) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase$ScenarioRunner.run(SlaveBase.java:203) [radargun-core-3.0.0-SNAPSHOT.jar:?]
16:21:07,937 INFO  [org.radargun.Slave] (sc-main) Finished stage ServiceStart
16:21:07,957 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
16:21:08,001 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-4755]ISPN100003: Node fedora-4755 finished rebalance phase with topology id 2
16:21:08,003 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 2
16:21:08,007 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t2) [Context=org.infinispan.CONFIG][Scope=fedora-41317]ISPN100003: Node fedora-41317 finished rebalance phase with topology id 3
16:21:08,008 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-4755]ISPN100003: Node fedora-4755 finished rebalance phase with topology id 2
16:21:08,011 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 2
16:21:08,013 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t5) [Context=___counter_configuration][Scope=fedora-41317]ISPN100003: Node fedora-41317 finished rebalance phase with topology id 3
16:21:08,020 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-4755]ISPN100003: Node fedora-4755 finished rebalance phase with topology id 3
16:21:08,022 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t8) [Context=org.infinispan.CONFIG][Scope=fedora-41317]ISPN100003: Node fedora-41317 finished rebalance phase with topology id 4
16:21:08,028 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-4755]ISPN100003: Node fedora-4755 finished rebalance phase with topology id 3
16:21:08,029 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t11) [Context=___counter_configuration][Scope=fedora-41317]ISPN100003: Node fedora-41317 finished rebalance phase with topology id 4
16:21:08,032 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-53082]ISPN100003: Node fedora-53082 finished rebalance phase with topology id 3
16:21:08,033 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-53082]ISPN100003: Node fedora-53082 finished rebalance phase with topology id 3
16:21:08,034 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=org.infinispan.CONFIG][Scope=fedora-53082]ISPN100003: Node fedora-53082 finished rebalance phase with topology id 4
16:21:08,041 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (remote-thread--p2-t1) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=org.infinispan.CONFIG, type=REBALANCE_PHASE_CONFIRM, sender=fedora-53082, joinInfo=null, topologyId=3, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-53082 for cache org.infinispan.CONFIG, expecting topology id 4 but got 3
	at org.infinispan.topology.RebalanceConfirmationCollector.confirmPhase(RebalanceConfirmationCollector.java:41) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:337) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.invokeReplicableCommand(GlobalInboundInvocationHandler.java:169) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.runReplicableCommand(GlobalInboundInvocationHandler.java:150) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.lambda$handleReplicableCommand$1(GlobalInboundInvocationHandler.java:144) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.util.concurrent.BlockingTaskAwareExecutorServiceImpl$RunnableWrapper.run(BlockingTaskAwareExecutorServiceImpl.java:212) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0-internal]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0-internal]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0-internal]
16:21:08,041 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (remote-thread--p2-t2) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___counter_configuration, type=REBALANCE_PHASE_CONFIRM, sender=fedora-53082, joinInfo=null, topologyId=3, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-53082 for cache ___counter_configuration, expecting topology id 4 but got 3
	at org.infinispan.topology.RebalanceConfirmationCollector.confirmPhase(RebalanceConfirmationCollector.java:41) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:337) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.invokeReplicableCommand(GlobalInboundInvocationHandler.java:169) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.runReplicableCommand(GlobalInboundInvocationHandler.java:150) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.lambda$handleReplicableCommand$1(GlobalInboundInvocationHandler.java:144) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.util.concurrent.BlockingTaskAwareExecutorServiceImpl$RunnableWrapper.run(BlockingTaskAwareExecutorServiceImpl.java:212) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0-internal]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0-internal]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0-internal]
16:21:08,042 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___counter_configuration][Scope=fedora-53082]ISPN100003: Node fedora-53082 finished rebalance phase with topology id 4
16:21:08,044 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t6) [Context=___counter_configuration][Scope=fedora-4755]ISPN100003: Node fedora-4755 finished rebalance phase with topology id 4
16:21:08,051 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t6) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-41317: 126, fedora-4755: 130]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-41317: 76, fedora-4755: 90, fedora-53082: 90]}, unionCH=null, actualMembers=[fedora-41317, fedora-4755, fedora-53082], persistentUUIDs=[059e33e3-162e-408c-b22e-1b71d1225de7, c0e70399-af80-4502-9642-d5db025079e1, 4152fb2b-392b-4cd9-b136-27bd4a04827d]}
16:21:08,052 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t6) [Context=___counter_configuration][Scope=fedora-41317]ISPN100002: Started rebalance with topology id 6
16:21:08,056 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t18) [Context=___counter_configuration][Scope=fedora-41317]ISPN100003: Node fedora-41317 finished rebalance phase with topology id 6
16:21:08,051 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=org.infinispan.CONFIG][Scope=fedora-4755]ISPN100003: Node fedora-4755 finished rebalance phase with topology id 4
16:21:08,063 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-41317: 126, fedora-4755: 130]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-41317: 76, fedora-4755: 90, fedora-53082: 90]}, unionCH=null, actualMembers=[fedora-41317, fedora-4755, fedora-53082], persistentUUIDs=[059e33e3-162e-408c-b22e-1b71d1225de7, c0e70399-af80-4502-9642-d5db025079e1, 4152fb2b-392b-4cd9-b136-27bd4a04827d]}
16:21:08,063 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=org.infinispan.CONFIG][Scope=fedora-41317]ISPN100002: Started rebalance with topology id 6
16:21:08,064 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t22) [Context=org.infinispan.CONFIG][Scope=fedora-41317]ISPN100003: Node fedora-41317 finished rebalance phase with topology id 6
16:21:08,075 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=___counter_configuration][Scope=fedora-4755]ISPN100003: Node fedora-4755 finished rebalance phase with topology id 6
16:21:08,087 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=org.infinispan.CONFIG][Scope=fedora-4755]ISPN100003: Node fedora-4755 finished rebalance phase with topology id 6
16:21:08,120 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=DefaultConsistentHash{ns=256, owners = (1)[fedora-41317: 256+0]}, pendingCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-41317: 126+130, fedora-4755: 130+126]}, unionCH=null, actualMembers=[fedora-41317, fedora-4755], persistentUUIDs=[059e33e3-162e-408c-b22e-1b71d1225de7, c0e70399-af80-4502-9642-d5db025079e1]}
16:21:08,124 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=___counters][Scope=fedora-41317]ISPN100002: Started rebalance with topology id 2
16:21:08,128 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t24) [Context=___counters][Scope=fedora-41317]ISPN100003: Node fedora-41317 finished rebalance phase with topology id 2
16:21:08,216 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=org.infinispan.CONFIG][Scope=fedora-53082]ISPN100003: Node fedora-53082 finished rebalance phase with topology id 6
16:21:08,216 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 6
16:21:08,219 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=org.infinispan.CONFIG][Scope=fedora-41317]ISPN100003: Node fedora-41317 finished rebalance phase with topology id 7
16:21:08,228 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=org.infinispan.CONFIG][Scope=fedora-53082]ISPN100003: Node fedora-53082 finished rebalance phase with topology id 7
16:21:08,231 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=___counter_configuration][Scope=fedora-53082]ISPN100003: Node fedora-53082 finished rebalance phase with topology id 6
16:21:08,232 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 6
16:21:08,233 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t9) [Context=___counter_configuration][Scope=fedora-41317]ISPN100003: Node fedora-41317 finished rebalance phase with topology id 7
16:21:08,236 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=___counter_configuration][Scope=fedora-4755]ISPN100003: Node fedora-4755 finished rebalance phase with topology id 7
16:21:08,236 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t6) [Context=___counters][Scope=fedora-4755]ISPN100003: Node fedora-4755 finished rebalance phase with topology id 2
16:21:08,238 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t6) ISPN000336: Finished cluster-wide rebalance for cache ___counters, topology id = 2
16:21:08,240 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t12) [Context=___counters][Scope=fedora-41317]ISPN100003: Node fedora-41317 finished rebalance phase with topology id 3
16:21:08,245 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t6) [Context=___counter_configuration][Scope=fedora-53082]ISPN100003: Node fedora-53082 finished rebalance phase with topology id 7
16:21:08,245 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=org.infinispan.CONFIG][Scope=fedora-4755]ISPN100003: Node fedora-4755 finished rebalance phase with topology id 7
16:21:08,247 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t14) [Context=org.infinispan.CONFIG][Scope=fedora-41317]ISPN100003: Node fedora-41317 finished rebalance phase with topology id 8
16:21:08,248 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t17) [Context=___counter_configuration][Scope=fedora-41317]ISPN100003: Node fedora-41317 finished rebalance phase with topology id 8
16:21:08,251 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=___counter_configuration][Scope=fedora-53082]ISPN100003: Node fedora-53082 finished rebalance phase with topology id 8
16:21:08,252 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t6) [Context=org.infinispan.CONFIG][Scope=fedora-53082]ISPN100003: Node fedora-53082 finished rebalance phase with topology id 8
16:21:08,257 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t6) [Context=___counters][Scope=fedora-4755]ISPN100003: Node fedora-4755 finished rebalance phase with topology id 3
16:21:08,260 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t19) [Context=___counters][Scope=fedora-41317]ISPN100003: Node fedora-41317 finished rebalance phase with topology id 4
16:21:08,263 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t6) [Context=org.infinispan.CONFIG][Scope=fedora-4755]ISPN100003: Node fedora-4755 finished rebalance phase with topology id 8
16:21:08,269 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t6) [Context=___counter_configuration][Scope=fedora-4755]ISPN100003: Node fedora-4755 finished rebalance phase with topology id 8
16:21:08,284 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t6) [Context=___counters][Scope=fedora-4755]ISPN100003: Node fedora-4755 finished rebalance phase with topology id 4
16:21:08,308 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t6) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-41317: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-41317: 126, fedora-4755: 130]}, unionCH=null, actualMembers=[fedora-41317, fedora-4755], persistentUUIDs=[059e33e3-162e-408c-b22e-1b71d1225de7, c0e70399-af80-4502-9642-d5db025079e1]}
16:21:08,309 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t6) [Context=___protobuf_metadata][Scope=fedora-41317]ISPN100002: Started rebalance with topology id 2
16:21:08,316 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t9) [Context=___protobuf_metadata][Scope=fedora-41317]ISPN100003: Node fedora-41317 finished rebalance phase with topology id 2
16:21:08,348 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t6) [Context=___protobuf_metadata][Scope=fedora-4755]ISPN100003: Node fedora-4755 finished rebalance phase with topology id 2
16:21:08,349 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t6) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 2
16:21:08,351 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t12) [Context=___protobuf_metadata][Scope=fedora-41317]ISPN100003: Node fedora-41317 finished rebalance phase with topology id 3
16:21:08,356 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t6) [Context=___protobuf_metadata][Scope=fedora-4755]ISPN100003: Node fedora-4755 finished rebalance phase with topology id 3
16:21:08,359 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t18) [Context=___protobuf_metadata][Scope=fedora-41317]ISPN100003: Node fedora-41317 finished rebalance phase with topology id 4
16:21:08,362 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t6) [Context=___protobuf_metadata][Scope=fedora-4755]ISPN100003: Node fedora-4755 finished rebalance phase with topology id 4
16:21:08,396 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t6) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=DefaultConsistentHash{ns=512, owners = (1)[fedora-41317: 512+0]}, pendingCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-41317: 256+256, fedora-4755: 256+256]}, unionCH=null, actualMembers=[fedora-41317, fedora-4755], persistentUUIDs=[059e33e3-162e-408c-b22e-1b71d1225de7, c0e70399-af80-4502-9642-d5db025079e1]}
16:21:08,397 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t6) [Context=testCache][Scope=fedora-41317]ISPN100002: Started rebalance with topology id 2
16:21:08,403 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t22) [Context=testCache][Scope=fedora-41317]ISPN100003: Node fedora-41317 finished rebalance phase with topology id 2
16:21:08,416 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t6) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-41317: 126+130, fedora-4755: 130+126]}, pendingCH=DefaultConsistentHash{ns=256, owners = (3)[fedora-41317: 76+75, fedora-4755: 90+86, fedora-53082: 90+95]}, unionCH=null, actualMembers=[fedora-41317, fedora-4755, fedora-53082], persistentUUIDs=[059e33e3-162e-408c-b22e-1b71d1225de7, c0e70399-af80-4502-9642-d5db025079e1, 4152fb2b-392b-4cd9-b136-27bd4a04827d]}
16:21:08,416 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t6) [Context=___counters][Scope=fedora-41317]ISPN100002: Started rebalance with topology id 6
16:21:08,422 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t3) [Context=___counters][Scope=fedora-41317]ISPN100003: Node fedora-41317 finished rebalance phase with topology id 6
16:21:08,434 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=___counters][Scope=fedora-4755]ISPN100003: Node fedora-4755 finished rebalance phase with topology id 6
16:21:08,457 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=testCache][Scope=fedora-4755]ISPN100003: Node fedora-4755 finished rebalance phase with topology id 2
16:21:08,458 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) ISPN000336: Finished cluster-wide rebalance for cache testCache, topology id = 2
16:21:08,461 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=testCache][Scope=fedora-41317]ISPN100003: Node fedora-41317 finished rebalance phase with topology id 3
16:21:08,464 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=testCache][Scope=fedora-4755]ISPN100003: Node fedora-4755 finished rebalance phase with topology id 3
16:21:08,467 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t6) [Context=testCache][Scope=fedora-41317]ISPN100003: Node fedora-41317 finished rebalance phase with topology id 4
16:21:08,471 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=testCache][Scope=fedora-4755]ISPN100003: Node fedora-4755 finished rebalance phase with topology id 4
16:21:08,524 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-41317: 126, fedora-4755: 130]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-41317: 76, fedora-4755: 90, fedora-53082: 90]}, unionCH=null, actualMembers=[fedora-41317, fedora-4755, fedora-53082], persistentUUIDs=[059e33e3-162e-408c-b22e-1b71d1225de7, c0e70399-af80-4502-9642-d5db025079e1, 4152fb2b-392b-4cd9-b136-27bd4a04827d]}
16:21:08,525 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=___protobuf_metadata][Scope=fedora-41317]ISPN100002: Started rebalance with topology id 6
16:21:08,525 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t6) [Context=___counters][Scope=fedora-53082]ISPN100003: Node fedora-53082 finished rebalance phase with topology id 6
16:21:08,525 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t6) ISPN000336: Finished cluster-wide rebalance for cache ___counters, topology id = 6
16:21:08,527 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=___counters][Scope=fedora-41317]ISPN100003: Node fedora-41317 finished rebalance phase with topology id 7
16:21:08,528 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t16) [Context=___protobuf_metadata][Scope=fedora-41317]ISPN100003: Node fedora-41317 finished rebalance phase with topology id 6
16:21:08,535 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=___counters][Scope=fedora-4755]ISPN100003: Node fedora-4755 finished rebalance phase with topology id 7
16:21:08,539 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t6) [Context=___protobuf_metadata][Scope=fedora-4755]ISPN100003: Node fedora-4755 finished rebalance phase with topology id 6
16:21:08,539 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=___counters][Scope=fedora-53082]ISPN100003: Node fedora-53082 finished rebalance phase with topology id 7
16:21:08,541 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t17) [Context=___counters][Scope=fedora-41317]ISPN100003: Node fedora-41317 finished rebalance phase with topology id 8
16:21:08,543 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=___counters][Scope=fedora-4755]ISPN100003: Node fedora-4755 finished rebalance phase with topology id 8
16:21:08,562 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=___counters][Scope=fedora-53082]ISPN100003: Node fedora-53082 finished rebalance phase with topology id 8
16:21:08,601 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-41317: 256+256, fedora-4755: 256+256]}, pendingCH=DefaultConsistentHash{ns=512, owners = (3)[fedora-41317: 164+164, fedora-4755: 174+162, fedora-53082: 174+186]}, unionCH=null, actualMembers=[fedora-41317, fedora-4755, fedora-53082], persistentUUIDs=[059e33e3-162e-408c-b22e-1b71d1225de7, c0e70399-af80-4502-9642-d5db025079e1, 4152fb2b-392b-4cd9-b136-27bd4a04827d]}
16:21:08,607 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=testCache][Scope=fedora-41317]ISPN100002: Started rebalance with topology id 6
16:21:08,611 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t5) [Context=testCache][Scope=fedora-41317]ISPN100003: Node fedora-41317 finished rebalance phase with topology id 6
16:21:08,619 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t6) [Context=testCache][Scope=fedora-4755]ISPN100003: Node fedora-4755 finished rebalance phase with topology id 6
16:21:08,620 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___protobuf_metadata][Scope=fedora-53082]ISPN100003: Node fedora-53082 finished rebalance phase with topology id 6
16:21:08,620 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 6
16:21:08,622 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t8) [Context=___protobuf_metadata][Scope=fedora-41317]ISPN100003: Node fedora-41317 finished rebalance phase with topology id 7
16:21:08,624 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=___protobuf_metadata][Scope=fedora-4755]ISPN100003: Node fedora-4755 finished rebalance phase with topology id 7
16:21:08,629 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=___protobuf_metadata][Scope=fedora-53082]ISPN100003: Node fedora-53082 finished rebalance phase with topology id 7
16:21:08,631 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t9) [Context=___protobuf_metadata][Scope=fedora-41317]ISPN100003: Node fedora-41317 finished rebalance phase with topology id 8
16:21:08,636 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=___protobuf_metadata][Scope=fedora-4755]ISPN100003: Node fedora-4755 finished rebalance phase with topology id 8
16:21:08,638 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___protobuf_metadata][Scope=fedora-53082]ISPN100003: Node fedora-53082 finished rebalance phase with topology id 8
16:21:08,646 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=testCache][Scope=fedora-53082]ISPN100003: Node fedora-53082 finished rebalance phase with topology id 6
16:21:08,646 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) ISPN000336: Finished cluster-wide rebalance for cache testCache, topology id = 6
16:21:08,648 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=testCache][Scope=fedora-41317]ISPN100003: Node fedora-41317 finished rebalance phase with topology id 7
16:21:08,651 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=testCache][Scope=fedora-4755]ISPN100003: Node fedora-4755 finished rebalance phase with topology id 7
16:21:08,652 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=testCache][Scope=fedora-53082]ISPN100003: Node fedora-53082 finished rebalance phase with topology id 7
16:21:08,654 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t25) [Context=testCache][Scope=fedora-41317]ISPN100003: Node fedora-41317 finished rebalance phase with topology id 8
16:21:08,657 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=testCache][Scope=fedora-4755]ISPN100003: Node fedora-4755 finished rebalance phase with topology id 8
16:21:08,661 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=testCache][Scope=fedora-53082]ISPN100003: Node fedora-53082 finished rebalance phase with topology id 8
16:21:08,758 INFO  [org.radargun.Slave] (sc-main) Starting stage AfterServiceStart
16:21:08,759 INFO  [org.radargun.Slave] (sc-main) Finished stage AfterServiceStart
16:21:08,761 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
16:21:08,816 INFO  [org.radargun.Slave] (sc-main) Starting stage MonitorStart
16:21:08,821 INFO  [org.radargun.sysmonitor.AbstractMonitors] (sc-main) Gathering statistics every 1000 ms
16:21:08,821 INFO  [org.radargun.Slave] (sc-main) Finished stage MonitorStart
16:21:08,823 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
16:21:08,858 INFO  [org.radargun.Slave] (sc-main) Starting stage Load
16:21:16,071 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) This node loaded 10000 entries (~10000000 bytes)
16:21:20,364 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) This node loaded 20000 entries (~20000000 bytes)
16:21:24,230 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) This node loaded 30000 entries (~30000000 bytes)
16:21:25,117 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) Finished loading entries
16:21:25,179 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) Finished loading entries
16:21:25,188 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) Finished loading entries
16:21:25,200 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) Finished loading entries
16:21:25,202 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) Finished loading entries
16:21:25,209 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) Finished loading entries
16:21:25,218 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) Finished loading entries
16:21:25,220 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) Finished loading entries
16:21:25,225 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) Finished loading entries
16:21:25,247 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) Finished loading entries
16:21:25,247 INFO  [org.radargun.Slave] (sc-main) Finished stage Load
16:21:25,248 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
16:21:25,271 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.stages.cache.test.BasicOperationsTestStage.init() overrides public void org.radargun.stages.test.TestStage.init() but both are declared with @Init annotation: calling only once
16:21:25,277 INFO  [org.radargun.Slave] (sc-main) Starting stage BasicOperationsTest
16:21:25,277 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using key generator org.radargun.stages.cache.generators.StringKeyGenerator {format=null }
16:21:25,278 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using value generator org.radargun.stages.cache.generators.ByteArrayValueGenerator { }
16:21:25,278 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using cache selector Default { }
16:21:25,278 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Starting test warmup
16:21:25,292 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Started 4 stressor threads.
16:22:25,301 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Finished test. Test duration is: 1 mins 0 secs
16:22:25,303 INFO  [org.radargun.Slave] (sc-main) Finished stage BasicOperationsTest
16:22:25,314 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
16:22:25,348 INFO  [org.radargun.Slave] (sc-main) Starting stage Clear
16:22:25,351 INFO  [org.radargun.stages.cache.ClearStage] (sc-main) Before executing clear, memory looks like this: 
Runtime free: 1,016,612 kb
Runtime max:1,301,504 kb
Runtime total:1,301,504 kb
MX Code Cache(Non-heap memory): used: 13,181 kb, init: 2,496 kb, committed: 13,952 kb, max: 245,760 kb
MX Metaspace(Non-heap memory): used: 37,422 kb, init: 0 kb, committed: 39,468 kb, max: 0 kb
MX Compressed Class Space(Non-heap memory): used: 4,437 kb, init: 0 kb, committed: 4,908 kb, max: 1,048,576 kb
MX PS Eden Space(Heap memory): used: 149,314 kb, init: 350,208 kb, committed: 273,920 kb, max: 277,504 kb
MX PS Survivor Space(Heap memory): used: 60,480 kb, init: 57,856 kb, committed: 94,720 kb, max: 94,720 kb
MX PS Old Gen(Heap memory): used: 75,097 kb, init: 932,864 kb, committed: 932,864 kb, max: 932,864 kb
16:22:25,528 INFO  [org.radargun.stages.cache.ClearStage] (sc-main) After executing clear, memory looks like this: 
Runtime free: 1,292,836 kb
Runtime max:1,306,624 kb
Runtime total:1,306,624 kb
MX Code Cache(Non-heap memory): used: 13,284 kb, init: 2,496 kb, committed: 13,952 kb, max: 245,760 kb
MX Metaspace(Non-heap memory): used: 37,361 kb, init: 0 kb, committed: 39,468 kb, max: 0 kb
MX Compressed Class Space(Non-heap memory): used: 4,410 kb, init: 0 kb, committed: 4,908 kb, max: 1,048,576 kb
MX PS Eden Space(Heap memory): used: 1,157 kb, init: 350,208 kb, committed: 280,064 kb, max: 280,064 kb
MX PS Survivor Space(Heap memory): used: 0 kb, init: 57,856 kb, committed: 93,696 kb, max: 93,696 kb
MX PS Old Gen(Heap memory): used: 12,637 kb, init: 932,864 kb, committed: 932,864 kb, max: 932,864 kb
16:22:25,528 INFO  [org.radargun.Slave] (sc-main) Finished stage Clear
16:22:25,528 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
16:22:25,639 INFO  [org.radargun.Slave] (sc-main) Starting stage Load
16:22:28,973 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) This node loaded 10000 entries (~10000000 bytes)
16:22:32,191 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) This node loaded 20000 entries (~20000000 bytes)
16:22:35,353 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) This node loaded 30000 entries (~30000000 bytes)
16:22:36,198 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) Finished loading entries
16:22:36,252 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) Finished loading entries
16:22:36,266 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) Finished loading entries
16:22:36,274 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) Finished loading entries
16:22:36,277 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) Finished loading entries
16:22:36,288 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) Finished loading entries
16:22:36,289 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) Finished loading entries
16:22:36,297 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) Finished loading entries
16:22:36,306 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) Finished loading entries
16:22:36,318 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) Finished loading entries
16:22:36,318 INFO  [org.radargun.Slave] (sc-main) Finished stage Load
16:22:36,318 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
16:22:36,645 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.stages.cache.test.BasicOperationsTestStage.init() overrides public void org.radargun.stages.test.TestStage.init() but both are declared with @Init annotation: calling only once
16:22:36,645 INFO  [org.radargun.Slave] (sc-main) Starting stage BasicOperationsTest
16:22:36,646 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using key generator org.radargun.stages.cache.generators.StringKeyGenerator {format=null }
16:22:36,646 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using value generator org.radargun.stages.cache.generators.ByteArrayValueGenerator { }
16:22:36,646 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using cache selector Default { }
16:22:36,646 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Starting test stress-test
16:22:36,678 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Started 4 stressor threads.
16:32:36,690 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Finished test. Test duration is: 10 mins 0 secs
16:32:36,691 INFO  [org.radargun.Slave] (sc-main) Finished stage BasicOperationsTest
16:32:36,856 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
16:32:37,099 INFO  [org.radargun.Slave] (sc-main) Starting stage MonitorStop
16:32:37,100 INFO  [org.radargun.Slave] (sc-main) Finished stage MonitorStop
16:32:37,101 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
16:32:37,106 INFO  [org.radargun.Slave] (sc-main) Starting stage ScenarioDestroy
16:32:37,108 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Scenario finished, destroying...
16:32:37,108 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Memory before cleanup: 
Runtime free: 1,138,440 kb
Runtime max:1,331,200 kb
Runtime total:1,331,200 kb
MX Code Cache(Non-heap memory): used: 14,783 kb, init: 2,496 kb, committed: 14,976 kb, max: 245,760 kb
MX Metaspace(Non-heap memory): used: 37,898 kb, init: 0 kb, committed: 39,980 kb, max: 0 kb
MX Compressed Class Space(Non-heap memory): used: 4,445 kb, init: 0 kb, committed: 4,908 kb, max: 1,048,576 kb
MX PS Eden Space(Heap memory): used: 92,205 kb, init: 350,208 kb, committed: 330,752 kb, max: 330,752 kb
MX PS Survivor Space(Heap memory): used: 66,752 kb, init: 57,856 kb, committed: 67,584 kb, max: 67,584 kb
MX PS Old Gen(Heap memory): used: 33,801 kb, init: 932,864 kb, committed: 932,864 kb, max: 932,864 kb
16:32:37,109 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) Stopping service.
16:32:37,143 INFO  [org.infinispan.CLUSTER] (StopThread) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-4755: 244+92, fedora-53082: 268+92]}, pendingCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-4755: 262+250, fedora-53082: 250+262]}, unionCH=null, actualMembers=[fedora-4755, fedora-53082], persistentUUIDs=[c0e70399-af80-4502-9642-d5db025079e1, 4152fb2b-392b-4cd9-b136-27bd4a04827d]}
16:32:37,147 INFO  [org.infinispan.CLUSTER] (StopThread) [Context=testCache][Scope=fedora-41317]ISPN100002: Started rebalance with topology id 11
16:32:37,149 WARN  [org.infinispan.CLUSTER] (remote-thread--p2-t20) [Context=testCache]ISPN000312: Lost data because of graceful leaver fedora-4755
16:32:37,186 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t20) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-41317: 129, fedora-4755: 127]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-41317: 126, fedora-4755: 130]}, unionCH=null, actualMembers=[fedora-41317, fedora-4755], persistentUUIDs=[059e33e3-162e-408c-b22e-1b71d1225de7, c0e70399-af80-4502-9642-d5db025079e1]}
16:32:37,188 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t20) [Context=___protobuf_metadata][Scope=fedora-41317]ISPN100002: Started rebalance with topology id 11
16:32:37,190 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=___protobuf_metadata][Scope=fedora-41317]ISPN100003: Node fedora-41317 finished rebalance phase with topology id 11
16:32:37,199 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t22) [Context=___protobuf_metadata][Scope=fedora-4755]ISPN100003: Node fedora-4755 finished rebalance phase with topology id 11
16:32:37,205 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (remote-thread--p2-t22) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___protobuf_metadata, type=REBALANCE_PHASE_CONFIRM, sender=fedora-4755, joinInfo=null, topologyId=11, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-4755 for cache ___protobuf_metadata, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.invokeReplicableCommand(GlobalInboundInvocationHandler.java:169) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.runReplicableCommand(GlobalInboundInvocationHandler.java:150) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.lambda$handleReplicableCommand$1(GlobalInboundInvocationHandler.java:144) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.util.concurrent.BlockingTaskAwareExecutorServiceImpl$RunnableWrapper.run(BlockingTaskAwareExecutorServiceImpl.java:212) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0-internal]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0-internal]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0-internal]
16:32:37,210 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t22) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-41317: 119+32, fedora-53082: 137+48]}, pendingCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-41317: 122+134, fedora-53082: 134+122]}, unionCH=null, actualMembers=[fedora-41317, fedora-53082], persistentUUIDs=[059e33e3-162e-408c-b22e-1b71d1225de7, 4152fb2b-392b-4cd9-b136-27bd4a04827d]}
16:32:37,211 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t22) [Context=___counters][Scope=fedora-41317]ISPN100002: Started rebalance with topology id 11
16:32:37,215 WARN  [org.infinispan.CLUSTER] (remote-thread--p2-t20) [Context=___counters]ISPN000312: Lost data because of graceful leaver fedora-53082
16:32:37,225 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t20) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-41317: 123, fedora-53082: 133]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-41317: 122, fedora-53082: 134]}, unionCH=null, actualMembers=[fedora-41317, fedora-53082], persistentUUIDs=[059e33e3-162e-408c-b22e-1b71d1225de7, 4152fb2b-392b-4cd9-b136-27bd4a04827d]}
16:32:37,225 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t20) [Context=org.infinispan.CONFIG][Scope=fedora-41317]ISPN100002: Started rebalance with topology id 11
16:32:37,244 ERROR [org.infinispan.statetransfer.StateConsumerImpl] (transport-thread--p4-t15) ISPN000208: No live owners found for segments {3-6 11-13 17-19 22 25-26 37-43 47 61-65 71-72 76-80 86-88 97-98 102-104 109-110 114-116 121-123 135-138 155-156 161-167 170-171 174-176 179-180 183-185 191-199 204-206 209 213-224 234-237 240-241 244-245} of cache ___counters. Excluded owners: []
16:32:37,246 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=org.infinispan.CONFIG][Scope=fedora-41317]ISPN100003: Node fedora-41317 finished rebalance phase with topology id 12
16:32:37,247 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t22) [Context=___counters][Scope=fedora-41317]ISPN100003: Node fedora-41317 finished rebalance phase with topology id 12
16:32:37,245 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t24) [Context=org.infinispan.CONFIG][Scope=fedora-41317]ISPN100003: Node fedora-41317 finished rebalance phase with topology id 11
16:32:37,247 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (transport-thread--p4-t21) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=org.infinispan.CONFIG, type=REBALANCE_PHASE_CONFIRM, sender=fedora-41317, joinInfo=null, topologyId=12, rebalanceId=4, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-41317 for cache org.infinispan.CONFIG, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.commands.ReplicableCommand.invoke(ReplicableCommand.java:44) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.LocalTopologyManagerImpl.lambda$executeOnCoordinatorAsync$4(LocalTopologyManagerImpl.java:717) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0-internal]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0-internal]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0-internal]
16:32:37,248 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (transport-thread--p4-t24) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=org.infinispan.CONFIG, type=REBALANCE_PHASE_CONFIRM, sender=fedora-41317, joinInfo=null, topologyId=11, rebalanceId=4, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-41317 for cache org.infinispan.CONFIG, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.commands.ReplicableCommand.invoke(ReplicableCommand.java:44) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.LocalTopologyManagerImpl.lambda$executeOnCoordinatorAsync$4(LocalTopologyManagerImpl.java:717) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0-internal]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0-internal]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0-internal]
16:32:37,252 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t22) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=12, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-41317: 123, fedora-53082: 133]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-41317: 122, fedora-53082: 134]}, unionCH=null, actualMembers=[fedora-41317, fedora-53082], persistentUUIDs=[059e33e3-162e-408c-b22e-1b71d1225de7, 4152fb2b-392b-4cd9-b136-27bd4a04827d]}
16:32:37,253 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t22) [Context=___counter_configuration][Scope=fedora-41317]ISPN100002: Started rebalance with topology id 12
16:32:37,255 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t10) [Context=___counter_configuration][Scope=fedora-41317]ISPN100003: Node fedora-41317 finished rebalance phase with topology id 12
16:32:37,260 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t6) [Context=___counter_configuration][Scope=fedora-41317]ISPN100003: Node fedora-41317 finished rebalance phase with topology id 14
16:32:37,260 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t8) [Context=___counter_configuration][Scope=fedora-41317]ISPN100003: Node fedora-41317 finished rebalance phase with topology id 13
16:32:37,268 INFO  [org.infinispan.CLUSTER] (jgroups-14,fedora-41317) ISPN000094: Received new cluster view for channel results: [fedora-41317|3] (2) [fedora-41317, fedora-53082]
16:32:37,270 INFO  [org.infinispan.CLUSTER] (jgroups-14,fedora-41317) ISPN100001: Node fedora-4755 left the cluster
16:32:37,272 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (transport-thread--p4-t8) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___counter_configuration, type=REBALANCE_PHASE_CONFIRM, sender=fedora-41317, joinInfo=null, topologyId=13, rebalanceId=4, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-41317 for cache ___counter_configuration, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.commands.ReplicableCommand.invoke(ReplicableCommand.java:44) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.LocalTopologyManagerImpl.lambda$executeOnCoordinatorAsync$4(LocalTopologyManagerImpl.java:717) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0-internal]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0-internal]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0-internal]
16:32:37,275 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (transport-thread--p4-t6) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___counter_configuration, type=REBALANCE_PHASE_CONFIRM, sender=fedora-41317, joinInfo=null, topologyId=14, rebalanceId=4, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-41317 for cache ___counter_configuration, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.commands.ReplicableCommand.invoke(ReplicableCommand.java:44) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.LocalTopologyManagerImpl.lambda$executeOnCoordinatorAsync$4(LocalTopologyManagerImpl.java:717) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0-internal]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0-internal]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0-internal]
16:32:37,277 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (transport-thread--p4-t10) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___counter_configuration, type=REBALANCE_PHASE_CONFIRM, sender=fedora-41317, joinInfo=null, topologyId=12, rebalanceId=4, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-41317 for cache ___counter_configuration, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.commands.ReplicableCommand.invoke(ReplicableCommand.java:44) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.LocalTopologyManagerImpl.lambda$executeOnCoordinatorAsync$4(LocalTopologyManagerImpl.java:717) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0-internal]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0-internal]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0-internal]
16:32:37,285 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (StopThread) ISPN000080: Disconnecting JGroups channel results
16:32:37,349 INFO  [org.radargun.service.Infinispan90Lifecycle] (StopThread) Stopped, previous view is [fedora-41317, fedora-4755, fedora-53082]
16:32:37,349 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Service successfully stopped.
16:32:37,350 INFO  [org.radargun.Slave] (sc-main) Finished stage ScenarioDestroy
16:32:37,350 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
16:32:38,494 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.service.Infinispan80EmbeddedService.destroy() overrides public void org.radargun.service.Infinispan60EmbeddedService.destroy() but both are declared with @Destroy annotation: calling only once
16:32:38,507 INFO  [org.radargun.Slave] (main) Starting stage ScenarioCleanup
16:32:38,638 INFO  [org.radargun.stages.ScenarioCleanupStage] (main) Memory after cleanup: 
Runtime free: 1,315,033 kb
Runtime max:1,331,200 kb
Runtime total:1,331,200 kb
MX Code Cache(Non-heap memory): used: 14,664 kb, init: 2,496 kb, committed: 14,976 kb, max: 245,760 kb
MX Metaspace(Non-heap memory): used: 38,024 kb, init: 0 kb, committed: 39,980 kb, max: 0 kb
MX Compressed Class Space(Non-heap memory): used: 4,465 kb, init: 0 kb, committed: 4,908 kb, max: 1,048,576 kb
MX PS Eden Space(Heap memory): used: 3,770 kb, init: 350,208 kb, committed: 330,752 kb, max: 330,752 kb
MX PS Survivor Space(Heap memory): used: 0 kb, init: 57,856 kb, committed: 67,584 kb, max: 67,584 kb
MX PS Old Gen(Heap memory): used: 12,396 kb, init: 932,864 kb, committed: 932,864 kb, max: 932,864 kb
16:32:38,640 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
16:32:43,782 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
16:32:48,014 INFO  [org.radargun.Slave] (main) Master shutdown!
16:32:48,017 INFO  [org.radargun.ShutDownHook] (Thread-0) Slave process is being shutdown
