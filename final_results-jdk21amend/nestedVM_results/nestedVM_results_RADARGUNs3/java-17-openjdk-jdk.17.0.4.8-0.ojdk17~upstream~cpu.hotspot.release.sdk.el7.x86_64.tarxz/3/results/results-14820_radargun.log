17:07:20,162 INFO  [org.radargun.RemoteMasterConnection] (main) Attempting to connect to master results:2103
17:07:20,179 INFO  [org.radargun.RemoteMasterConnection] (main) Successfully established connection with master at: results:2103
17:07:20,183 INFO  [org.radargun.Slave] (main) Received slave index 0
17:07:20,184 INFO  [org.radargun.Slave] (main) Received slave count 3
17:07:20,550 INFO  [org.radargun.ServiceHelper] (sc-main) ServiceContext properties: {}
17:07:20,661 INFO  [org.radargun.Slave] (sc-main) Eager Service Infinispan92EmbeddedService {batching=false, cache=testCache, channelRetrievalTimeout=2 mins 0 secs, enableDiagnostics=null, explicitLocking=false, file=/mnt/workspace/results/dist-sync.xml, internalsExpositionEnabled=false, jgroupsDumperEnabled=false, jgroupsDumperInterval=10.000 secs, keysPerThread=-1, mapReduceDistributedReducePhase=false, mapReduceUseIntermediateSharedCache=false, removedCaches=[  ], threadsPerNode=-1 } loaded.
17:07:22,562 INFO  [org.radargun.Slave] (sc-main) Starting stage ScenarioInit
17:07:22,614 INFO  [org.radargun.Slave] (sc-main) Finished stage ScenarioInit
17:07:22,617 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
17:07:22,975 INFO  [org.radargun.Slave] (sc-main) Starting stage BeforeServiceStart
17:07:22,975 INFO  [org.radargun.Slave] (sc-main) Finished stage BeforeServiceStart
17:07:22,976 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
17:07:22,988 INFO  [org.radargun.Slave] (sc-main) Starting stage ServiceStart
17:07:22,989 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Startup staggering, this is the slave with index 0, not sleeping
17:07:22,989 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 0
17:07:22,993 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) Infinispan version: Infinispan 'Gaina' 9.2.0.Final
17:07:23,025 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) JGroups version: JGroups 4.0.10.Final (Schiener Berg)
17:07:23,566 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (sc-main) ISPN000078: Starting JGroups channel results
17:07:23,646 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the send buffer of socket MulticastSocket was set to 1.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
17:07:23,647 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the receive buffer of socket MulticastSocket was set to 20.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
17:07:23,647 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the send buffer of socket MulticastSocket was set to 1.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
17:07:23,648 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the receive buffer of socket MulticastSocket was set to 25.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
17:07:28,668 INFO  [org.infinispan.CLUSTER] (sc-main) ISPN000094: Received new cluster view for channel results: [fedora-19494|0] (1) [fedora-19494]
17:07:28,789 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (sc-main) ISPN000079: Channel results local address is fedora-19494, physical addresses are [192.168.124.236:54174]
17:07:28,793 INFO  [org.infinispan.factories.GlobalComponentRegistry] (sc-main) ISPN000128: Infinispan version: Infinispan 'Gaina' 9.2.0.Final
17:07:29,426 INFO  [org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup] (sc-main) ISPN000107: Retrieving transaction manager Transaction: unknown
17:07:29,497 INFO  [org.infinispan.CLUSTER] (jgroups-6,fedora-19494) ISPN000094: Received new cluster view for channel results: [fedora-19494|1] (2) [fedora-19494, fedora-15603]
17:07:29,503 INFO  [org.infinispan.CLUSTER] (jgroups-6,fedora-19494) ISPN100000: Node fedora-15603 joined the cluster
17:07:29,582 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) No RELAY2 protocol in XS service
17:07:29,582 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) No RELAY2 protocol in XS service
17:07:29,584 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) ([fedora-19494(local=true, coord=true), fedora-15603(local=false, coord=false)]) Number of members=2 is not the one expected: 3
17:07:29,949 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-19494: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-19494: 122, fedora-15603: 134]}, unionCH=null, actualMembers=[fedora-19494, fedora-15603], persistentUUIDs=[c9b5b668-adb0-4bcc-86ca-895147eef01f, 79959257-c75a-41f2-85f7-bd08bafd1c19]}
17:07:29,949 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-19494: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-19494: 122, fedora-15603: 134]}, unionCH=null, actualMembers=[fedora-19494, fedora-15603], persistentUUIDs=[c9b5b668-adb0-4bcc-86ca-895147eef01f, 79959257-c75a-41f2-85f7-bd08bafd1c19]}
17:07:29,959 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-19494]ISPN100002: Started rebalance with topology id 2
17:07:29,959 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-19494]ISPN100002: Started rebalance with topology id 2
17:07:29,989 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t22) [Context=___counter_configuration][Scope=fedora-19494]ISPN100003: Node fedora-19494 finished rebalance phase with topology id 2
17:07:29,991 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t23) [Context=org.infinispan.CONFIG][Scope=fedora-19494]ISPN100003: Node fedora-19494 finished rebalance phase with topology id 2
17:07:30,096 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-15603]ISPN100003: Node fedora-15603 finished rebalance phase with topology id 2
17:07:30,096 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 2
17:07:30,101 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t1) [Context=org.infinispan.CONFIG][Scope=fedora-19494]ISPN100003: Node fedora-19494 finished rebalance phase with topology id 3
17:07:30,118 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-15603]ISPN100003: Node fedora-15603 finished rebalance phase with topology id 2
17:07:30,118 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 2
17:07:30,121 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t4) [Context=___counter_configuration][Scope=fedora-19494]ISPN100003: Node fedora-19494 finished rebalance phase with topology id 3
17:07:30,123 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-15603]ISPN100003: Node fedora-15603 finished rebalance phase with topology id 3
17:07:30,125 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=org.infinispan.CONFIG][Scope=fedora-19494]ISPN100003: Node fedora-19494 finished rebalance phase with topology id 4
17:07:30,137 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-15603]ISPN100003: Node fedora-15603 finished rebalance phase with topology id 3
17:07:30,137 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-15603]ISPN100003: Node fedora-15603 finished rebalance phase with topology id 4
17:07:30,138 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t10) [Context=___counter_configuration][Scope=fedora-19494]ISPN100003: Node fedora-19494 finished rebalance phase with topology id 4
17:07:30,162 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-15603]ISPN100003: Node fedora-15603 finished rebalance phase with topology id 4
17:07:30,226 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=DefaultConsistentHash{ns=256, owners = (1)[fedora-19494: 256+0]}, pendingCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-19494: 122+134, fedora-15603: 134+122]}, unionCH=null, actualMembers=[fedora-19494, fedora-15603], persistentUUIDs=[c9b5b668-adb0-4bcc-86ca-895147eef01f, 79959257-c75a-41f2-85f7-bd08bafd1c19]}
17:07:30,227 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-19494]ISPN100002: Started rebalance with topology id 2
17:07:30,229 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=___counters][Scope=fedora-19494]ISPN100003: Node fedora-19494 finished rebalance phase with topology id 2
17:07:30,334 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-15603]ISPN100003: Node fedora-15603 finished rebalance phase with topology id 2
17:07:30,335 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___counters, topology id = 2
17:07:30,337 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t3) [Context=___counters][Scope=fedora-19494]ISPN100003: Node fedora-19494 finished rebalance phase with topology id 3
17:07:30,354 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-15603]ISPN100003: Node fedora-15603 finished rebalance phase with topology id 3
17:07:30,356 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t24) [Context=___counters][Scope=fedora-19494]ISPN100003: Node fedora-19494 finished rebalance phase with topology id 4
17:07:30,381 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-15603]ISPN100003: Node fedora-15603 finished rebalance phase with topology id 4
17:07:30,475 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-19494: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-19494: 122, fedora-15603: 134]}, unionCH=null, actualMembers=[fedora-19494, fedora-15603], persistentUUIDs=[c9b5b668-adb0-4bcc-86ca-895147eef01f, 79959257-c75a-41f2-85f7-bd08bafd1c19]}
17:07:30,476 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-19494]ISPN100002: Started rebalance with topology id 2
17:07:30,480 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t15) [Context=___protobuf_metadata][Scope=fedora-19494]ISPN100003: Node fedora-19494 finished rebalance phase with topology id 2
17:07:30,525 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-15603]ISPN100003: Node fedora-15603 finished rebalance phase with topology id 2
17:07:30,526 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 2
17:07:30,530 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t14) [Context=___protobuf_metadata][Scope=fedora-19494]ISPN100003: Node fedora-19494 finished rebalance phase with topology id 3
17:07:30,544 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=DefaultConsistentHash{ns=512, owners = (1)[fedora-19494: 512+0]}, pendingCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-19494: 250+262, fedora-15603: 262+250]}, unionCH=null, actualMembers=[fedora-19494, fedora-15603], persistentUUIDs=[c9b5b668-adb0-4bcc-86ca-895147eef01f, 79959257-c75a-41f2-85f7-bd08bafd1c19]}
17:07:30,545 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-19494]ISPN100002: Started rebalance with topology id 2
17:07:30,548 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t19) [Context=testCache][Scope=fedora-19494]ISPN100003: Node fedora-19494 finished rebalance phase with topology id 2
17:07:30,570 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-15603]ISPN100003: Node fedora-15603 finished rebalance phase with topology id 3
17:07:30,577 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t23) [Context=___protobuf_metadata][Scope=fedora-19494]ISPN100003: Node fedora-19494 finished rebalance phase with topology id 4
17:07:30,584 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) ([fedora-19494(local=true, coord=true), fedora-15603(local=false, coord=false)]) Number of members=2 is not the one expected: 3
17:07:30,590 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-15603]ISPN100003: Node fedora-15603 finished rebalance phase with topology id 4
17:07:30,618 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-15603]ISPN100003: Node fedora-15603 finished rebalance phase with topology id 2
17:07:30,619 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache testCache, topology id = 2
17:07:30,623 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t5) [Context=testCache][Scope=fedora-19494]ISPN100003: Node fedora-19494 finished rebalance phase with topology id 3
17:07:30,635 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-15603]ISPN100003: Node fedora-15603 finished rebalance phase with topology id 3
17:07:30,656 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-15603]ISPN100003: Node fedora-15603 finished rebalance phase with topology id 4
17:07:30,661 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t4) [Context=testCache][Scope=fedora-19494]ISPN100003: Node fedora-19494 finished rebalance phase with topology id 4
17:07:30,663 INFO  [org.infinispan.CLUSTER] (jgroups-8,fedora-19494) ISPN000094: Received new cluster view for channel results: [fedora-19494|2] (3) [fedora-19494, fedora-15603, fedora-39847]
17:07:30,668 INFO  [org.infinispan.CLUSTER] (jgroups-8,fedora-19494) ISPN100000: Node fedora-39847 joined the cluster
17:07:31,064 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-19494: 122, fedora-15603: 134]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-19494: 84, fedora-15603: 90, fedora-39847: 82]}, unionCH=null, actualMembers=[fedora-19494, fedora-15603, fedora-39847], persistentUUIDs=[c9b5b668-adb0-4bcc-86ca-895147eef01f, 79959257-c75a-41f2-85f7-bd08bafd1c19, 72d3d6e2-938d-4ac1-a4e6-bd59e10d79fe]}
17:07:31,065 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-19494]ISPN100002: Started rebalance with topology id 6
17:07:31,066 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t16) [Context=___counter_configuration][Scope=fedora-19494]ISPN100003: Node fedora-19494 finished rebalance phase with topology id 6
17:07:31,072 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-15603]ISPN100003: Node fedora-15603 finished rebalance phase with topology id 6
17:07:31,077 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-19494: 122, fedora-15603: 134]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-19494: 84, fedora-15603: 90, fedora-39847: 82]}, unionCH=null, actualMembers=[fedora-19494, fedora-15603, fedora-39847], persistentUUIDs=[c9b5b668-adb0-4bcc-86ca-895147eef01f, 79959257-c75a-41f2-85f7-bd08bafd1c19, 72d3d6e2-938d-4ac1-a4e6-bd59e10d79fe]}
17:07:31,078 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-19494]ISPN100002: Started rebalance with topology id 6
17:07:31,082 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-15603]ISPN100003: Node fedora-15603 finished rebalance phase with topology id 6
17:07:31,081 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t13) [Context=org.infinispan.CONFIG][Scope=fedora-19494]ISPN100003: Node fedora-19494 finished rebalance phase with topology id 6
17:07:31,164 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-39847]ISPN100003: Node fedora-39847 finished rebalance phase with topology id 6
17:07:31,166 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 6
17:07:31,167 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t23) [Context=___counter_configuration][Scope=fedora-19494]ISPN100003: Node fedora-19494 finished rebalance phase with topology id 7
17:07:31,171 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-15603]ISPN100003: Node fedora-15603 finished rebalance phase with topology id 7
17:07:31,187 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-39847]ISPN100003: Node fedora-39847 finished rebalance phase with topology id 7
17:07:31,188 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t3) [Context=___counter_configuration][Scope=fedora-19494]ISPN100003: Node fedora-19494 finished rebalance phase with topology id 8
17:07:31,191 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-39847]ISPN100003: Node fedora-39847 finished rebalance phase with topology id 6
17:07:31,192 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 6
17:07:31,193 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=org.infinispan.CONFIG][Scope=fedora-19494]ISPN100003: Node fedora-19494 finished rebalance phase with topology id 7
17:07:31,195 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-15603]ISPN100003: Node fedora-15603 finished rebalance phase with topology id 7
17:07:31,195 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-15603]ISPN100003: Node fedora-15603 finished rebalance phase with topology id 8
17:07:31,197 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-39847]ISPN100003: Node fedora-39847 finished rebalance phase with topology id 8
17:07:31,206 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-39847]ISPN100003: Node fedora-39847 finished rebalance phase with topology id 7
17:07:31,215 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t4) [Context=org.infinispan.CONFIG][Scope=fedora-19494]ISPN100003: Node fedora-19494 finished rebalance phase with topology id 8
17:07:31,217 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-39847]ISPN100003: Node fedora-39847 finished rebalance phase with topology id 8
17:07:31,219 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-15603]ISPN100003: Node fedora-15603 finished rebalance phase with topology id 8
17:07:31,256 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-19494: 122+134, fedora-15603: 134+122]}, pendingCH=DefaultConsistentHash{ns=256, owners = (3)[fedora-19494: 84+71, fedora-15603: 90+97, fedora-39847: 82+88]}, unionCH=null, actualMembers=[fedora-19494, fedora-15603, fedora-39847], persistentUUIDs=[c9b5b668-adb0-4bcc-86ca-895147eef01f, 79959257-c75a-41f2-85f7-bd08bafd1c19, 72d3d6e2-938d-4ac1-a4e6-bd59e10d79fe]}
17:07:31,256 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-19494]ISPN100002: Started rebalance with topology id 6
17:07:31,258 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t14) [Context=___counters][Scope=fedora-19494]ISPN100003: Node fedora-19494 finished rebalance phase with topology id 6
17:07:31,260 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-15603]ISPN100003: Node fedora-15603 finished rebalance phase with topology id 6
17:07:31,297 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-39847]ISPN100003: Node fedora-39847 finished rebalance phase with topology id 6
17:07:31,298 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___counters, topology id = 6
17:07:31,301 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t25) [Context=___counters][Scope=fedora-19494]ISPN100003: Node fedora-19494 finished rebalance phase with topology id 7
17:07:31,303 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-15603]ISPN100003: Node fedora-15603 finished rebalance phase with topology id 7
17:07:31,306 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-39847]ISPN100003: Node fedora-39847 finished rebalance phase with topology id 7
17:07:31,308 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t23) [Context=___counters][Scope=fedora-19494]ISPN100003: Node fedora-19494 finished rebalance phase with topology id 8
17:07:31,310 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-15603]ISPN100003: Node fedora-15603 finished rebalance phase with topology id 8
17:07:31,314 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-39847]ISPN100003: Node fedora-39847 finished rebalance phase with topology id 8
17:07:31,359 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-19494: 122, fedora-15603: 134]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-19494: 84, fedora-15603: 90, fedora-39847: 82]}, unionCH=null, actualMembers=[fedora-19494, fedora-15603, fedora-39847], persistentUUIDs=[c9b5b668-adb0-4bcc-86ca-895147eef01f, 79959257-c75a-41f2-85f7-bd08bafd1c19, 72d3d6e2-938d-4ac1-a4e6-bd59e10d79fe]}
17:07:31,360 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-19494]ISPN100002: Started rebalance with topology id 6
17:07:31,362 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=___protobuf_metadata][Scope=fedora-19494]ISPN100003: Node fedora-19494 finished rebalance phase with topology id 6
17:07:31,367 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-15603]ISPN100003: Node fedora-15603 finished rebalance phase with topology id 6
17:07:31,393 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-19494: 250+262, fedora-15603: 262+250]}, pendingCH=DefaultConsistentHash{ns=512, owners = (3)[fedora-19494: 165+159, fedora-15603: 177+176, fedora-39847: 170+177]}, unionCH=null, actualMembers=[fedora-19494, fedora-15603, fedora-39847], persistentUUIDs=[c9b5b668-adb0-4bcc-86ca-895147eef01f, 79959257-c75a-41f2-85f7-bd08bafd1c19, 72d3d6e2-938d-4ac1-a4e6-bd59e10d79fe]}
17:07:31,393 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-19494]ISPN100002: Started rebalance with topology id 6
17:07:31,396 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t4) [Context=testCache][Scope=fedora-19494]ISPN100003: Node fedora-19494 finished rebalance phase with topology id 6
17:07:31,406 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-15603]ISPN100003: Node fedora-15603 finished rebalance phase with topology id 6
17:07:31,409 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-39847]ISPN100003: Node fedora-39847 finished rebalance phase with topology id 6
17:07:31,410 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 6
17:07:31,413 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=___protobuf_metadata][Scope=fedora-19494]ISPN100003: Node fedora-19494 finished rebalance phase with topology id 7
17:07:31,415 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-39847]ISPN100003: Node fedora-39847 finished rebalance phase with topology id 7
17:07:31,417 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-15603]ISPN100003: Node fedora-15603 finished rebalance phase with topology id 7
17:07:31,420 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t18) [Context=___protobuf_metadata][Scope=fedora-19494]ISPN100003: Node fedora-19494 finished rebalance phase with topology id 8
17:07:31,423 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-15603]ISPN100003: Node fedora-15603 finished rebalance phase with topology id 8
17:07:31,431 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-39847]ISPN100003: Node fedora-39847 finished rebalance phase with topology id 6
17:07:31,432 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache testCache, topology id = 6
17:07:31,433 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-39847]ISPN100003: Node fedora-39847 finished rebalance phase with topology id 8
17:07:31,437 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t14) [Context=testCache][Scope=fedora-19494]ISPN100003: Node fedora-19494 finished rebalance phase with topology id 7
17:07:31,439 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-15603]ISPN100003: Node fedora-15603 finished rebalance phase with topology id 7
17:07:31,450 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-39847]ISPN100003: Node fedora-39847 finished rebalance phase with topology id 7
17:07:31,453 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t23) [Context=testCache][Scope=fedora-19494]ISPN100003: Node fedora-19494 finished rebalance phase with topology id 8
17:07:31,456 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-15603]ISPN100003: Node fedora-15603 finished rebalance phase with topology id 8
17:07:31,458 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-39847]ISPN100003: Node fedora-39847 finished rebalance phase with topology id 8
17:07:31,585 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) Number of members is the one expected: 3
17:07:31,586 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Successfully started cache service infinispan92/embedded on slave 0
17:07:31,656 ERROR [org.radargun.service.ConfigDumpHelper] (sc-main) Error while dumping ___protobuf_metadata cache config as properties
javax.management.AttributeNotFoundException: Unknown attribute 'configurationAsProperties'. Known attributes names are: [rebalancingEnabled, cacheStatus, cacheName, cacheAvailability, version, configurationAsProperties]
	at org.infinispan.jmx.ResourceDMBean.getAttribute(ResourceDMBean.java:181) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:644) ~[?:?]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:679) ~[?:?]
	at org.radargun.service.ConfigDumpHelper60.dumpCache(ConfigDumpHelper60.java:44) [plugin-infinispan60-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.service.EmbeddedConfigurationProvider.getNormalizedConfigs(EmbeddedConfigurationProvider.java:33) [plugin-infinispan52-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.stages.lifecycle.ServiceStartStage.executeOnSlave(ServiceStartStage.java:92) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase.scenarioLoop(SlaveBase.java:102) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase$ScenarioRunner.run(SlaveBase.java:203) [radargun-core-3.0.0-SNAPSHOT.jar:?]
17:07:31,665 ERROR [org.radargun.service.ConfigDumpHelper] (sc-main) Error while dumping ___protobuf_metadata cache config as properties
javax.management.AttributeNotFoundException: Unknown attribute 'configurationAsProperties'. Known attributes names are: [rebalancingEnabled, cacheStatus, cacheName, cacheAvailability, version, configurationAsProperties]
	at org.infinispan.jmx.ResourceDMBean.getAttribute(ResourceDMBean.java:181) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:644) ~[?:?]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:679) ~[?:?]
	at org.radargun.service.ConfigDumpHelper60.dumpCache(ConfigDumpHelper60.java:44) [plugin-infinispan60-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.service.EmbeddedConfigurationProvider.getNormalizedConfigs(EmbeddedConfigurationProvider.java:33) [plugin-infinispan52-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.stages.lifecycle.ServiceStartStage.executeOnSlave(ServiceStartStage.java:92) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase.scenarioLoop(SlaveBase.java:102) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase$ScenarioRunner.run(SlaveBase.java:203) [radargun-core-3.0.0-SNAPSHOT.jar:?]
17:07:31,685 INFO  [org.radargun.Slave] (sc-main) Finished stage ServiceStart
17:07:31,692 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
17:07:31,705 INFO  [org.radargun.Slave] (sc-main) Starting stage AfterServiceStart
17:07:31,709 INFO  [org.radargun.Slave] (sc-main) Finished stage AfterServiceStart
17:07:31,712 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
17:07:31,811 INFO  [org.radargun.Slave] (sc-main) Starting stage MonitorStart
17:07:31,818 INFO  [org.radargun.sysmonitor.AbstractMonitors] (sc-main) Gathering statistics every 1000 ms
17:07:31,820 INFO  [org.radargun.Slave] (sc-main) Finished stage MonitorStart
17:07:31,823 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
17:07:31,864 INFO  [org.radargun.Slave] (sc-main) Starting stage Load
17:07:41,917 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) This node loaded 10000 entries (~10000000 bytes)
17:07:46,426 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) This node loaded 20000 entries (~20000000 bytes)
17:07:49,254 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) This node loaded 30000 entries (~30000000 bytes)
17:07:49,548 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) Finished loading entries
17:07:49,554 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) Finished loading entries
17:07:49,555 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) Finished loading entries
17:07:49,567 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) Finished loading entries
17:07:49,577 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) Finished loading entries
17:07:49,586 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) Finished loading entries
17:07:49,588 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) Finished loading entries
17:07:49,596 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) Finished loading entries
17:07:49,598 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) Finished loading entries
17:07:49,600 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) Finished loading entries
17:07:49,601 INFO  [org.radargun.Slave] (sc-main) Finished stage Load
17:07:49,601 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
17:07:49,625 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.stages.cache.test.BasicOperationsTestStage.init() overrides public void org.radargun.stages.test.TestStage.init() but both are declared with @Init annotation: calling only once
17:07:49,637 INFO  [org.radargun.Slave] (sc-main) Starting stage BasicOperationsTest
17:07:49,637 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using key generator org.radargun.stages.cache.generators.StringKeyGenerator {format=null }
17:07:49,639 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using value generator org.radargun.stages.cache.generators.ByteArrayValueGenerator { }
17:07:49,639 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using cache selector Default { }
17:07:49,639 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Starting test warmup
17:07:49,683 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Started 4 stressor threads.
17:08:49,685 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Finished test. Test duration is: 1 mins 0 secs
17:08:49,687 INFO  [org.radargun.Slave] (sc-main) Finished stage BasicOperationsTest
17:08:49,697 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
17:08:49,722 INFO  [org.radargun.Slave] (sc-main) Starting stage Clear
17:08:49,735 INFO  [org.radargun.stages.cache.ClearStage] (sc-main) Before executing clear, memory looks like this: 
Runtime free: 926,569 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,311 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,700 kb
MX Metaspace(Non-heap memory): used: 34,816 kb, init: 0 kb, committed: 35,200 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 8,849 kb, init: 2,496 kb, committed: 10,304 kb, max: 120,028 kb
MX Compressed Class Space(Non-heap memory): used: 4,173 kb, init: 0 kb, committed: 4,352 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 283,648 kb, init: 73,728 kb, committed: 831,488 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 138,390 kb, init: 1,325,056 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 49,152 kb, init: 0 kb, committed: 49,152 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 4,290 kb, init: 2,496 kb, committed: 5,120 kb, max: 120,032 kb
17:08:49,900 INFO  [org.radargun.stages.cache.ClearStage] (sc-main) After executing clear, memory looks like this: 
Runtime free: 1,380,882 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,311 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,700 kb
MX Metaspace(Non-heap memory): used: 34,836 kb, init: 0 kb, committed: 35,200 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 8,916 kb, init: 2,496 kb, committed: 10,304 kb, max: 120,028 kb
MX Compressed Class Space(Non-heap memory): used: 4,171 kb, init: 0 kb, committed: 4,352 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 0 kb, init: 73,728 kb, committed: 880,640 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 17,350 kb, init: 1,325,056 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 0 kb, init: 0 kb, committed: 0 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 4,314 kb, init: 2,496 kb, committed: 5,120 kb, max: 120,032 kb
17:08:49,901 INFO  [org.radargun.Slave] (sc-main) Finished stage Clear
17:08:49,901 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
17:08:49,907 INFO  [org.radargun.Slave] (sc-main) Starting stage Load
17:08:52,358 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) This node loaded 10000 entries (~10000000 bytes)
17:08:54,768 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) This node loaded 20000 entries (~20000000 bytes)
17:08:57,207 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) This node loaded 30000 entries (~30000000 bytes)
17:08:57,832 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) Finished loading entries
17:08:57,844 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) Finished loading entries
17:08:57,854 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) Finished loading entries
17:08:57,864 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) Finished loading entries
17:08:57,886 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) Finished loading entries
17:08:57,915 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) Finished loading entries
17:08:57,919 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) Finished loading entries
17:08:57,931 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) Finished loading entries
17:08:57,939 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) Finished loading entries
17:08:57,945 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) Finished loading entries
17:08:57,946 INFO  [org.radargun.Slave] (sc-main) Finished stage Load
17:08:57,947 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
17:08:58,170 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.stages.cache.test.BasicOperationsTestStage.init() overrides public void org.radargun.stages.test.TestStage.init() but both are declared with @Init annotation: calling only once
17:08:58,172 INFO  [org.radargun.Slave] (sc-main) Starting stage BasicOperationsTest
17:08:58,173 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using key generator org.radargun.stages.cache.generators.StringKeyGenerator {format=null }
17:08:58,173 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using value generator org.radargun.stages.cache.generators.ByteArrayValueGenerator { }
17:08:58,173 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using cache selector Default { }
17:08:58,174 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Starting test stress-test
17:08:58,220 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Started 4 stressor threads.
17:18:58,229 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Finished test. Test duration is: 10 mins 0 secs
17:18:58,230 INFO  [org.radargun.Slave] (sc-main) Finished stage BasicOperationsTest
17:18:58,348 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
17:18:58,482 INFO  [org.radargun.Slave] (sc-main) Starting stage MonitorStop
17:18:58,483 INFO  [org.radargun.Slave] (sc-main) Finished stage MonitorStop
17:18:58,484 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
17:18:58,490 INFO  [org.radargun.Slave] (sc-main) Starting stage ScenarioDestroy
17:18:58,491 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Scenario finished, destroying...
17:18:58,491 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Memory before cleanup: 
Runtime free: 772,830 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,313 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,700 kb
MX Metaspace(Non-heap memory): used: 35,462 kb, init: 0 kb, committed: 35,840 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 9,720 kb, init: 2,496 kb, committed: 10,432 kb, max: 120,028 kb
MX Compressed Class Space(Non-heap memory): used: 4,204 kb, init: 0 kb, committed: 4,416 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 201,728 kb, init: 73,728 kb, committed: 775,168 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 370,975 kb, init: 1,325,056 kb, committed: 570,368 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 52,736 kb, init: 0 kb, committed: 53,248 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 5,230 kb, init: 2,496 kb, committed: 5,248 kb, max: 120,032 kb
17:18:58,492 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) Stopping service.
17:18:58,509 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t40) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-19494: 252+72, fedora-39847: 260+87]}, pendingCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-19494: 256+256, fedora-39847: 256+256]}, unionCH=null, actualMembers=[fedora-19494, fedora-39847], persistentUUIDs=[c9b5b668-adb0-4bcc-86ca-895147eef01f, 72d3d6e2-938d-4ac1-a4e6-bd59e10d79fe]}
17:18:58,512 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t40) [Context=testCache][Scope=fedora-19494]ISPN100002: Started rebalance with topology id 11
17:18:58,521 WARN  [org.infinispan.CLUSTER] (remote-thread--p2-t32) [Context=testCache]ISPN000312: Lost data because of graceful leaver fedora-39847
17:18:58,546 INFO  [org.infinispan.CLUSTER] (StopThread) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-15603: 127, fedora-39847: 129]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-15603: 128, fedora-39847: 128]}, unionCH=null, actualMembers=[fedora-15603, fedora-39847], persistentUUIDs=[79959257-c75a-41f2-85f7-bd08bafd1c19, 72d3d6e2-938d-4ac1-a4e6-bd59e10d79fe]}
17:18:58,547 INFO  [org.infinispan.CLUSTER] (StopThread) [Context=___protobuf_metadata][Scope=fedora-19494]ISPN100002: Started rebalance with topology id 11
17:18:58,552 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t40) [Context=___protobuf_metadata][Scope=fedora-39847]ISPN100003: Node fedora-39847 finished rebalance phase with topology id 11
17:18:58,553 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (remote-thread--p2-t40) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___protobuf_metadata, type=REBALANCE_PHASE_CONFIRM, sender=fedora-39847, joinInfo=null, topologyId=11, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-39847 for cache ___protobuf_metadata, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.invokeReplicableCommand(GlobalInboundInvocationHandler.java:169) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.runReplicableCommand(GlobalInboundInvocationHandler.java:150) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.lambda$handleReplicableCommand$1(GlobalInboundInvocationHandler.java:144) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.util.concurrent.BlockingTaskAwareExecutorServiceImpl$RunnableWrapper.run(BlockingTaskAwareExecutorServiceImpl.java:212) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
17:18:58,556 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t40) [Context=___protobuf_metadata][Scope=fedora-39847]ISPN100003: Node fedora-39847 finished rebalance phase with topology id 12
17:18:58,556 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (remote-thread--p2-t40) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___protobuf_metadata, type=REBALANCE_PHASE_CONFIRM, sender=fedora-39847, joinInfo=null, topologyId=12, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-39847 for cache ___protobuf_metadata, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.invokeReplicableCommand(GlobalInboundInvocationHandler.java:169) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.runReplicableCommand(GlobalInboundInvocationHandler.java:150) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.lambda$handleReplicableCommand$1(GlobalInboundInvocationHandler.java:144) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.util.concurrent.BlockingTaskAwareExecutorServiceImpl$RunnableWrapper.run(BlockingTaskAwareExecutorServiceImpl.java:212) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
17:18:58,558 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t32) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-19494: 125+30, fedora-39847: 131+39]}, pendingCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-19494: 128+128, fedora-39847: 128+128]}, unionCH=null, actualMembers=[fedora-19494, fedora-39847], persistentUUIDs=[c9b5b668-adb0-4bcc-86ca-895147eef01f, 72d3d6e2-938d-4ac1-a4e6-bd59e10d79fe]}
17:18:58,559 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t32) [Context=___counters][Scope=fedora-19494]ISPN100002: Started rebalance with topology id 11
17:18:58,555 WARN  [org.infinispan.statetransfer.InboundTransferTask] (stateTransferExecutor-thread--p6-t1) ISPN000210: Failed to request state of cache testCache from node fedora-39847, segments {0-1 26-28 44-51 55-56 65-66 80-82 89 93-97 106-111 124-126 131-135 139 143-147 152 171-172 175-178 186-190 203-205 208-212 216 227-228 231-234 238-249 253-256 259-263 268-269 277-278 298-300 303 309-310 316 321 327-331 339-340 345-355 358-360 363-369 372-373 382-383 388-391 403-409 423-424 430-447 457 466-468 471-474 480 487 491 495-498 505-507 511}
org.infinispan.remoting.transport.jgroups.SuspectException: ISPN000400: Node fedora-39847 was suspected
	at org.infinispan.remoting.transport.ResponseCollectors.remoteNodeSuspected(ResponseCollectors.java:33) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleResponseCollector.targetNotFound(SingleResponseCollector.java:31) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleResponseCollector.targetNotFound(SingleResponseCollector.java:17) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.ValidSingleResponseCollector.addResponse(ValidSingleResponseCollector.java:23) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleTargetRequest.receiveResponse(SingleTargetRequest.java:51) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleTargetRequest.onResponse(SingleTargetRequest.java:35) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.RequestRepository.addResponse(RequestRepository.java:53) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.processResponse(JGroupsTransport.java:1302) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.processMessage(JGroupsTransport.java:1205) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.access$200(JGroupsTransport.java:123) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport$ChannelCallbacks.receive(JGroupsTransport.java:1340) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.jgroups.JChannel.up(JChannel.java:819) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.stack.ProtocolStack.up(ProtocolStack.java:893) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FRAG3.up(FRAG3.java:171) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FlowControl.up(FlowControl.java:343) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FlowControl.up(FlowControl.java:343) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.GMS.up(GMS.java:864) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.STABLE.up(STABLE.java:240) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.deliverMessage(UNICAST3.java:1002) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.handleDataReceived(UNICAST3.java:728) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.up(UNICAST3.java:383) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.NAKACK2.up(NAKACK2.java:600) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.VERIFY_SUSPECT.up(VERIFY_SUSPECT.java:119) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FD_ALL.up(FD_ALL.java:199) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FD_SOCK.up(FD_SOCK.java:252) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.MERGE3.up(MERGE3.java:276) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.Discovery.up(Discovery.java:267) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.TP.passMessageUp(TP.java:1248) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.util.SubmitToThreadPool$SingleMessageHandler.run(SubmitToThreadPool.java:87) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
17:18:58,563 WARN  [org.infinispan.CLUSTER] (StopThread) [Context=___counters]ISPN000312: Lost data because of graceful leaver fedora-19494
17:18:58,574 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (StopThread) ISPN000080: Disconnecting JGroups channel results
17:18:58,607 INFO  [org.radargun.service.Infinispan90Lifecycle] (StopThread) Stopped, previous view is [fedora-19494, fedora-15603, fedora-39847]
17:18:58,608 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Service successfully stopped.
17:18:58,608 INFO  [org.radargun.Slave] (sc-main) Finished stage ScenarioDestroy
17:18:58,609 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
17:19:28,558 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.service.Infinispan80EmbeddedService.destroy() overrides public void org.radargun.service.Infinispan60EmbeddedService.destroy() but both are declared with @Destroy annotation: calling only once
17:19:28,567 INFO  [org.radargun.Slave] (main) Starting stage ScenarioCleanup
17:19:28,644 INFO  [org.radargun.stages.ScenarioCleanupStage] (main) Memory after cleanup: 
Runtime free: 1,379,893 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,315 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,700 kb
MX Metaspace(Non-heap memory): used: 35,583 kb, init: 0 kb, committed: 35,968 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 9,814 kb, init: 2,496 kb, committed: 10,432 kb, max: 120,028 kb
MX Compressed Class Space(Non-heap memory): used: 4,226 kb, init: 0 kb, committed: 4,416 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 0 kb, init: 73,728 kb, committed: 880,640 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 18,378 kb, init: 1,325,056 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 0 kb, init: 0 kb, committed: 0 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 5,327 kb, init: 2,496 kb, committed: 5,376 kb, max: 120,032 kb
17:19:28,647 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
17:19:38,871 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
17:19:43,523 INFO  [org.radargun.Slave] (main) Master shutdown!
17:19:43,525 INFO  [org.radargun.ShutDownHook] (Thread-0) Slave process is being shutdown
