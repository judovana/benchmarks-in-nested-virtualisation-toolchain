14:32:32,278 INFO  [org.radargun.RemoteMasterConnection] (main) Attempting to connect to master results:2103
14:32:32,285 INFO  [org.radargun.RemoteMasterConnection] (main) Successfully established connection with master at: results:2103
14:32:32,291 INFO  [org.radargun.Slave] (main) Received slave index 0
14:32:32,291 INFO  [org.radargun.Slave] (main) Received slave count 3
14:32:32,465 INFO  [org.radargun.ServiceHelper] (sc-main) ServiceContext properties: {}
14:32:32,622 INFO  [org.radargun.Slave] (sc-main) Eager Service Infinispan92EmbeddedService {batching=false, cache=testCache, channelRetrievalTimeout=2 mins 0 secs, enableDiagnostics=null, explicitLocking=false, file=/mnt/workspace/results/dist-sync.xml, internalsExpositionEnabled=false, jgroupsDumperEnabled=false, jgroupsDumperInterval=10.000 secs, keysPerThread=-1, mapReduceDistributedReducePhase=false, mapReduceUseIntermediateSharedCache=false, removedCaches=[  ], threadsPerNode=-1 } loaded.
14:32:34,782 INFO  [org.radargun.Slave] (sc-main) Starting stage ScenarioInit
14:32:34,821 INFO  [org.radargun.Slave] (sc-main) Finished stage ScenarioInit
14:32:34,830 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
14:32:34,834 INFO  [org.radargun.Slave] (sc-main) Starting stage BeforeServiceStart
14:32:34,834 INFO  [org.radargun.Slave] (sc-main) Finished stage BeforeServiceStart
14:32:34,837 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
14:32:34,846 INFO  [org.radargun.Slave] (sc-main) Starting stage ServiceStart
14:32:34,846 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Startup staggering, this is the slave with index 0, not sleeping
14:32:34,847 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 0
14:32:34,849 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) Infinispan version: Infinispan 'Gaina' 9.2.0.Final
14:32:34,861 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) JGroups version: JGroups 4.0.10.Final (Schiener Berg)
14:32:35,705 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (sc-main) ISPN000078: Starting JGroups channel results
14:32:35,790 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the send buffer of socket MulticastSocket was set to 1.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
14:32:35,791 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the receive buffer of socket MulticastSocket was set to 20.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
14:32:35,791 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the send buffer of socket MulticastSocket was set to 1.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
14:32:35,791 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the receive buffer of socket MulticastSocket was set to 25.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
14:32:40,814 INFO  [org.infinispan.CLUSTER] (sc-main) ISPN000094: Received new cluster view for channel results: [fedora-9136|0] (1) [fedora-9136]
14:32:40,917 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (sc-main) ISPN000079: Channel results local address is fedora-9136, physical addresses are [192.168.124.29:40799]
14:32:40,928 INFO  [org.infinispan.factories.GlobalComponentRegistry] (sc-main) ISPN000128: Infinispan version: Infinispan 'Gaina' 9.2.0.Final
14:32:41,364 INFO  [org.infinispan.CLUSTER] (jgroups-6,fedora-9136) ISPN000094: Received new cluster view for channel results: [fedora-9136|1] (2) [fedora-9136, fedora-43105]
14:32:41,382 INFO  [org.infinispan.CLUSTER] (jgroups-6,fedora-9136) ISPN100000: Node fedora-43105 joined the cluster
14:32:41,842 INFO  [org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup] (sc-main) ISPN000107: Retrieving transaction manager Transaction: unknown
14:32:42,010 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) No RELAY2 protocol in XS service
14:32:42,011 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) No RELAY2 protocol in XS service
14:32:42,014 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) ([fedora-9136(local=true, coord=true), fedora-43105(local=false, coord=false)]) Number of members=2 is not the one expected: 3
14:32:42,215 INFO  [org.infinispan.CLUSTER] (jgroups-10,fedora-9136) ISPN000094: Received new cluster view for channel results: [fedora-9136|2] (3) [fedora-9136, fedora-43105, fedora-61354]
14:32:42,225 INFO  [org.infinispan.CLUSTER] (jgroups-10,fedora-9136) ISPN100000: Node fedora-61354 joined the cluster
14:32:42,305 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-9136: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-9136: 125, fedora-43105: 131]}, unionCH=null, actualMembers=[fedora-9136, fedora-43105], persistentUUIDs=[67906b28-04c0-404d-aea1-1cfad193c23c, ab31ebb5-fd25-49ef-a933-25a035445cfd]}
14:32:42,308 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-9136]ISPN100002: Started rebalance with topology id 2
14:32:42,315 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-9136: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-9136: 125, fedora-43105: 131]}, unionCH=null, actualMembers=[fedora-9136, fedora-43105], persistentUUIDs=[67906b28-04c0-404d-aea1-1cfad193c23c, ab31ebb5-fd25-49ef-a933-25a035445cfd]}
14:32:42,315 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-9136]ISPN100002: Started rebalance with topology id 2
14:32:42,349 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t22) [Context=___counter_configuration][Scope=fedora-9136]ISPN100003: Node fedora-9136 finished rebalance phase with topology id 2
14:32:42,359 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t23) [Context=org.infinispan.CONFIG][Scope=fedora-9136]ISPN100003: Node fedora-9136 finished rebalance phase with topology id 2
14:32:42,515 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-43105]ISPN100003: Node fedora-43105 finished rebalance phase with topology id 2
14:32:42,520 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 2
14:32:42,525 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t1) [Context=___counter_configuration][Scope=fedora-9136]ISPN100003: Node fedora-9136 finished rebalance phase with topology id 3
14:32:42,573 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-43105]ISPN100003: Node fedora-43105 finished rebalance phase with topology id 3
14:32:42,575 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t2) [Context=___counter_configuration][Scope=fedora-9136]ISPN100003: Node fedora-9136 finished rebalance phase with topology id 4
14:32:42,598 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-43105]ISPN100003: Node fedora-43105 finished rebalance phase with topology id 4
14:32:42,647 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-43105]ISPN100003: Node fedora-43105 finished rebalance phase with topology id 2
14:32:42,648 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 2
14:32:42,650 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t9) [Context=org.infinispan.CONFIG][Scope=fedora-9136]ISPN100003: Node fedora-9136 finished rebalance phase with topology id 3
14:32:42,659 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-43105]ISPN100003: Node fedora-43105 finished rebalance phase with topology id 3
14:32:42,660 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t13) [Context=org.infinispan.CONFIG][Scope=fedora-9136]ISPN100003: Node fedora-9136 finished rebalance phase with topology id 4
14:32:42,667 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-43105]ISPN100003: Node fedora-43105 finished rebalance phase with topology id 4
14:32:42,769 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=DefaultConsistentHash{ns=256, owners = (1)[fedora-9136: 256+0]}, pendingCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-9136: 125+131, fedora-43105: 131+125]}, unionCH=null, actualMembers=[fedora-9136, fedora-43105], persistentUUIDs=[67906b28-04c0-404d-aea1-1cfad193c23c, ab31ebb5-fd25-49ef-a933-25a035445cfd]}
14:32:42,769 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-9136]ISPN100002: Started rebalance with topology id 2
14:32:42,780 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t17) [Context=___counters][Scope=fedora-9136]ISPN100003: Node fedora-9136 finished rebalance phase with topology id 2
14:32:42,806 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-9136: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-9136: 125, fedora-43105: 131]}, unionCH=null, actualMembers=[fedora-9136, fedora-43105], persistentUUIDs=[67906b28-04c0-404d-aea1-1cfad193c23c, ab31ebb5-fd25-49ef-a933-25a035445cfd]}
14:32:42,809 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-9136]ISPN100002: Started rebalance with topology id 2
14:32:42,824 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t3) [Context=___protobuf_metadata][Scope=fedora-9136]ISPN100003: Node fedora-9136 finished rebalance phase with topology id 2
14:32:42,897 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-43105]ISPN100003: Node fedora-43105 finished rebalance phase with topology id 2
14:32:42,898 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache ___counters, topology id = 2
14:32:42,901 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t4) [Context=___counters][Scope=fedora-9136]ISPN100003: Node fedora-9136 finished rebalance phase with topology id 3
14:32:42,914 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=DefaultConsistentHash{ns=512, owners = (1)[fedora-9136: 512+0]}, pendingCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-9136: 253+259, fedora-43105: 259+253]}, unionCH=null, actualMembers=[fedora-9136, fedora-43105], persistentUUIDs=[67906b28-04c0-404d-aea1-1cfad193c23c, ab31ebb5-fd25-49ef-a933-25a035445cfd]}
14:32:42,915 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-9136]ISPN100002: Started rebalance with topology id 2
14:32:42,922 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t8) [Context=testCache][Scope=fedora-9136]ISPN100003: Node fedora-9136 finished rebalance phase with topology id 2
14:32:42,938 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-43105]ISPN100003: Node fedora-43105 finished rebalance phase with topology id 3
14:32:42,941 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=___counters][Scope=fedora-9136]ISPN100003: Node fedora-9136 finished rebalance phase with topology id 4
14:32:42,981 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-43105]ISPN100003: Node fedora-43105 finished rebalance phase with topology id 2
14:32:42,982 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 2
14:32:42,984 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t12) [Context=___protobuf_metadata][Scope=fedora-9136]ISPN100003: Node fedora-9136 finished rebalance phase with topology id 3
14:32:42,988 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-43105]ISPN100003: Node fedora-43105 finished rebalance phase with topology id 4
14:32:43,005 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-9136: 125, fedora-43105: 131]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-9136: 77, fedora-43105: 89, fedora-61354: 90]}, unionCH=null, actualMembers=[fedora-9136, fedora-43105, fedora-61354], persistentUUIDs=[67906b28-04c0-404d-aea1-1cfad193c23c, ab31ebb5-fd25-49ef-a933-25a035445cfd, e469730a-ae16-439f-9c9b-341c1457a5b0]}
14:32:43,005 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-9136]ISPN100002: Started rebalance with topology id 6
14:32:43,009 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-43105]ISPN100003: Node fedora-43105 finished rebalance phase with topology id 3
14:32:43,012 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t22) [Context=___protobuf_metadata][Scope=fedora-9136]ISPN100003: Node fedora-9136 finished rebalance phase with topology id 4
14:32:43,016 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) Number of members is the one expected: 3
14:32:43,017 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Successfully started cache service infinispan92/embedded on slave 0
14:32:43,015 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t25) [Context=___counter_configuration][Scope=fedora-9136]ISPN100003: Node fedora-9136 finished rebalance phase with topology id 6
14:32:43,017 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-9136: 125, fedora-43105: 131]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-9136: 77, fedora-43105: 89, fedora-61354: 90]}, unionCH=null, actualMembers=[fedora-9136, fedora-43105, fedora-61354], persistentUUIDs=[67906b28-04c0-404d-aea1-1cfad193c23c, ab31ebb5-fd25-49ef-a933-25a035445cfd, e469730a-ae16-439f-9c9b-341c1457a5b0]}
14:32:43,018 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-9136]ISPN100002: Started rebalance with topology id 6
14:32:43,019 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=org.infinispan.CONFIG][Scope=fedora-9136]ISPN100003: Node fedora-9136 finished rebalance phase with topology id 6
14:32:43,027 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-43105]ISPN100003: Node fedora-43105 finished rebalance phase with topology id 6
14:32:43,038 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-43105]ISPN100003: Node fedora-43105 finished rebalance phase with topology id 6
14:32:43,042 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-43105]ISPN100003: Node fedora-43105 finished rebalance phase with topology id 2
14:32:43,043 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache testCache, topology id = 2
14:32:43,045 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t4) [Context=testCache][Scope=fedora-9136]ISPN100003: Node fedora-9136 finished rebalance phase with topology id 3
14:32:43,045 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-43105]ISPN100003: Node fedora-43105 finished rebalance phase with topology id 4
14:32:43,055 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-43105]ISPN100003: Node fedora-43105 finished rebalance phase with topology id 3
14:32:43,064 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=testCache][Scope=fedora-9136]ISPN100003: Node fedora-9136 finished rebalance phase with topology id 4
14:32:43,066 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-43105]ISPN100003: Node fedora-43105 finished rebalance phase with topology id 4
14:32:43,082 ERROR [org.radargun.service.ConfigDumpHelper] (sc-main) Error while dumping ___protobuf_metadata cache config as properties
javax.management.AttributeNotFoundException: Unknown attribute 'configurationAsProperties'. Known attributes names are: [rebalancingEnabled, cacheStatus, cacheAvailability, cacheName, version, configurationAsProperties]
	at org.infinispan.jmx.ResourceDMBean.getAttribute(ResourceDMBean.java:181) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:647) ~[?:1.8.0-internal]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:678) ~[?:1.8.0-internal]
	at org.radargun.service.ConfigDumpHelper60.dumpCache(ConfigDumpHelper60.java:44) [plugin-infinispan60-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.service.EmbeddedConfigurationProvider.getNormalizedConfigs(EmbeddedConfigurationProvider.java:33) [plugin-infinispan52-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.stages.lifecycle.ServiceStartStage.executeOnSlave(ServiceStartStage.java:92) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase.scenarioLoop(SlaveBase.java:102) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase$ScenarioRunner.run(SlaveBase.java:203) [radargun-core-3.0.0-SNAPSHOT.jar:?]
14:32:43,112 ERROR [org.radargun.service.ConfigDumpHelper] (sc-main) Error while dumping ___protobuf_metadata cache config as properties
javax.management.AttributeNotFoundException: Unknown attribute 'configurationAsProperties'. Known attributes names are: [rebalancingEnabled, cacheStatus, cacheAvailability, cacheName, version, configurationAsProperties]
	at org.infinispan.jmx.ResourceDMBean.getAttribute(ResourceDMBean.java:181) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:647) ~[?:1.8.0-internal]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:678) ~[?:1.8.0-internal]
	at org.radargun.service.ConfigDumpHelper60.dumpCache(ConfigDumpHelper60.java:44) [plugin-infinispan60-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.service.EmbeddedConfigurationProvider.getNormalizedConfigs(EmbeddedConfigurationProvider.java:33) [plugin-infinispan52-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.stages.lifecycle.ServiceStartStage.executeOnSlave(ServiceStartStage.java:92) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase.scenarioLoop(SlaveBase.java:102) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase$ScenarioRunner.run(SlaveBase.java:203) [radargun-core-3.0.0-SNAPSHOT.jar:?]
14:32:43,170 INFO  [org.radargun.Slave] (sc-main) Finished stage ServiceStart
14:32:43,184 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
14:32:43,262 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-61354]ISPN100003: Node fedora-61354 finished rebalance phase with topology id 6
14:32:43,263 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 6
14:32:43,264 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-61354]ISPN100003: Node fedora-61354 finished rebalance phase with topology id 6
14:32:43,265 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 6
14:32:43,266 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-43105]ISPN100003: Node fedora-43105 finished rebalance phase with topology id 7
14:32:43,264 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=org.infinispan.CONFIG][Scope=fedora-9136]ISPN100003: Node fedora-9136 finished rebalance phase with topology id 7
14:32:43,271 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t23) [Context=___counter_configuration][Scope=fedora-9136]ISPN100003: Node fedora-9136 finished rebalance phase with topology id 7
14:32:43,271 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-43105]ISPN100003: Node fedora-43105 finished rebalance phase with topology id 7
14:32:43,281 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-61354]ISPN100003: Node fedora-61354 finished rebalance phase with topology id 7
14:32:43,283 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t25) [Context=org.infinispan.CONFIG][Scope=fedora-9136]ISPN100003: Node fedora-9136 finished rebalance phase with topology id 8
14:32:43,286 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-43105]ISPN100003: Node fedora-43105 finished rebalance phase with topology id 8
14:32:43,288 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-61354]ISPN100003: Node fedora-61354 finished rebalance phase with topology id 7
14:32:43,289 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=___counter_configuration][Scope=fedora-9136]ISPN100003: Node fedora-9136 finished rebalance phase with topology id 8
14:32:43,290 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-43105]ISPN100003: Node fedora-43105 finished rebalance phase with topology id 8
14:32:43,296 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-61354]ISPN100003: Node fedora-61354 finished rebalance phase with topology id 8
14:32:43,296 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-61354]ISPN100003: Node fedora-61354 finished rebalance phase with topology id 8
14:32:43,333 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-9136: 125+131, fedora-43105: 131+125]}, pendingCH=DefaultConsistentHash{ns=256, owners = (3)[fedora-9136: 77+81, fedora-43105: 89+89, fedora-61354: 90+86]}, unionCH=null, actualMembers=[fedora-9136, fedora-43105, fedora-61354], persistentUUIDs=[67906b28-04c0-404d-aea1-1cfad193c23c, ab31ebb5-fd25-49ef-a933-25a035445cfd, e469730a-ae16-439f-9c9b-341c1457a5b0]}
14:32:43,334 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-9136]ISPN100002: Started rebalance with topology id 6
14:32:43,338 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t9) [Context=___counters][Scope=fedora-9136]ISPN100003: Node fedora-9136 finished rebalance phase with topology id 6
14:32:43,339 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-43105]ISPN100003: Node fedora-43105 finished rebalance phase with topology id 6
14:32:43,399 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-61354]ISPN100003: Node fedora-61354 finished rebalance phase with topology id 6
14:32:43,399 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___counters, topology id = 6
14:32:43,401 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t15) [Context=___counters][Scope=fedora-9136]ISPN100003: Node fedora-9136 finished rebalance phase with topology id 7
14:32:43,403 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-43105]ISPN100003: Node fedora-43105 finished rebalance phase with topology id 7
14:32:43,411 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-61354]ISPN100003: Node fedora-61354 finished rebalance phase with topology id 7
14:32:43,413 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t19) [Context=___counters][Scope=fedora-9136]ISPN100003: Node fedora-9136 finished rebalance phase with topology id 8
14:32:43,416 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-43105]ISPN100003: Node fedora-43105 finished rebalance phase with topology id 8
14:32:43,422 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-61354]ISPN100003: Node fedora-61354 finished rebalance phase with topology id 8
14:32:43,452 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-9136: 125, fedora-43105: 131]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-9136: 77, fedora-43105: 89, fedora-61354: 90]}, unionCH=null, actualMembers=[fedora-9136, fedora-43105, fedora-61354], persistentUUIDs=[67906b28-04c0-404d-aea1-1cfad193c23c, ab31ebb5-fd25-49ef-a933-25a035445cfd, e469730a-ae16-439f-9c9b-341c1457a5b0]}
14:32:43,453 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-9136]ISPN100002: Started rebalance with topology id 6
14:32:43,455 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t1) [Context=___protobuf_metadata][Scope=fedora-9136]ISPN100003: Node fedora-9136 finished rebalance phase with topology id 6
14:32:43,461 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-43105]ISPN100003: Node fedora-43105 finished rebalance phase with topology id 6
14:32:43,492 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-61354]ISPN100003: Node fedora-61354 finished rebalance phase with topology id 6
14:32:43,493 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 6
14:32:43,494 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t2) [Context=___protobuf_metadata][Scope=fedora-9136]ISPN100003: Node fedora-9136 finished rebalance phase with topology id 7
14:32:43,498 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-43105]ISPN100003: Node fedora-43105 finished rebalance phase with topology id 7
14:32:43,496 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-9136: 253+259, fedora-43105: 259+253]}, pendingCH=DefaultConsistentHash{ns=512, owners = (3)[fedora-9136: 167+174, fedora-43105: 165+160, fedora-61354: 180+178]}, unionCH=null, actualMembers=[fedora-9136, fedora-43105, fedora-61354], persistentUUIDs=[67906b28-04c0-404d-aea1-1cfad193c23c, ab31ebb5-fd25-49ef-a933-25a035445cfd, e469730a-ae16-439f-9c9b-341c1457a5b0]}
14:32:43,499 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-9136]ISPN100002: Started rebalance with topology id 6
14:32:43,502 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t11) [Context=testCache][Scope=fedora-9136]ISPN100003: Node fedora-9136 finished rebalance phase with topology id 6
14:32:43,508 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-61354]ISPN100003: Node fedora-61354 finished rebalance phase with topology id 7
14:32:43,506 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-43105]ISPN100003: Node fedora-43105 finished rebalance phase with topology id 6
14:32:43,510 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=___protobuf_metadata][Scope=fedora-9136]ISPN100003: Node fedora-9136 finished rebalance phase with topology id 8
14:32:43,513 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-43105]ISPN100003: Node fedora-43105 finished rebalance phase with topology id 8
14:32:43,523 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-61354]ISPN100003: Node fedora-61354 finished rebalance phase with topology id 8
14:32:43,544 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-61354]ISPN100003: Node fedora-61354 finished rebalance phase with topology id 6
14:32:43,545 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache testCache, topology id = 6
14:32:43,547 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t15) [Context=testCache][Scope=fedora-9136]ISPN100003: Node fedora-9136 finished rebalance phase with topology id 7
14:32:43,550 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-61354]ISPN100003: Node fedora-61354 finished rebalance phase with topology id 7
14:32:43,550 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-43105]ISPN100003: Node fedora-43105 finished rebalance phase with topology id 7
14:32:43,553 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t19) [Context=testCache][Scope=fedora-9136]ISPN100003: Node fedora-9136 finished rebalance phase with topology id 8
14:32:43,556 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-43105]ISPN100003: Node fedora-43105 finished rebalance phase with topology id 8
14:32:43,559 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-61354]ISPN100003: Node fedora-61354 finished rebalance phase with topology id 8
14:32:43,656 INFO  [org.radargun.Slave] (sc-main) Starting stage AfterServiceStart
14:32:43,656 INFO  [org.radargun.Slave] (sc-main) Finished stage AfterServiceStart
14:32:43,658 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
14:32:43,715 INFO  [org.radargun.Slave] (sc-main) Starting stage MonitorStart
14:32:43,723 INFO  [org.radargun.sysmonitor.AbstractMonitors] (sc-main) Gathering statistics every 1000 ms
14:32:43,723 INFO  [org.radargun.Slave] (sc-main) Finished stage MonitorStart
14:32:43,724 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
14:32:43,778 INFO  [org.radargun.Slave] (sc-main) Starting stage Load
14:32:51,681 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) This node loaded 10000 entries (~10000000 bytes)
14:32:55,894 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) This node loaded 20000 entries (~20000000 bytes)
14:32:59,266 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) This node loaded 30000 entries (~30000000 bytes)
14:33:00,297 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) Finished loading entries
14:33:00,303 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) Finished loading entries
14:33:00,310 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) Finished loading entries
14:33:00,325 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) Finished loading entries
14:33:00,332 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) Finished loading entries
14:33:00,357 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) Finished loading entries
14:33:00,371 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) Finished loading entries
14:33:00,381 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) Finished loading entries
14:33:00,381 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) Finished loading entries
14:33:00,423 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) Finished loading entries
14:33:00,424 INFO  [org.radargun.Slave] (sc-main) Finished stage Load
14:33:00,425 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
14:33:00,507 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.stages.cache.test.BasicOperationsTestStage.init() overrides public void org.radargun.stages.test.TestStage.init() but both are declared with @Init annotation: calling only once
14:33:00,511 INFO  [org.radargun.Slave] (sc-main) Starting stage BasicOperationsTest
14:33:00,511 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using key generator org.radargun.stages.cache.generators.StringKeyGenerator {format=null }
14:33:00,512 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using value generator org.radargun.stages.cache.generators.ByteArrayValueGenerator { }
14:33:00,512 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using cache selector Default { }
14:33:00,512 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Starting test warmup
14:33:00,525 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Started 4 stressor threads.
14:34:00,535 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Finished test. Test duration is: 1 mins 0 secs
14:34:00,537 INFO  [org.radargun.Slave] (sc-main) Finished stage BasicOperationsTest
14:34:00,553 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
14:34:00,603 INFO  [org.radargun.Slave] (sc-main) Starting stage Clear
14:34:00,608 INFO  [org.radargun.stages.cache.ClearStage] (sc-main) Before executing clear, memory looks like this: 
Runtime free: 1,074,028 kb
Runtime max:1,282,048 kb
Runtime total:1,282,048 kb
MX Code Cache(Non-heap memory): used: 13,343 kb, init: 2,496 kb, committed: 13,952 kb, max: 245,760 kb
MX Metaspace(Non-heap memory): used: 37,395 kb, init: 0 kb, committed: 39,424 kb, max: 0 kb
MX Compressed Class Space(Non-heap memory): used: 4,433 kb, init: 0 kb, committed: 4,864 kb, max: 1,048,576 kb
MX PS Eden Space(Heap memory): used: 83,903 kb, init: 350,208 kb, committed: 231,936 kb, max: 231,936 kb
MX PS Survivor Space(Heap memory): used: 78,304 kb, init: 57,856 kb, committed: 117,248 kb, max: 117,248 kb
MX PS Old Gen(Heap memory): used: 45,812 kb, init: 932,864 kb, committed: 932,864 kb, max: 932,864 kb
14:34:00,862 INFO  [org.radargun.stages.cache.ClearStage] (sc-main) After executing clear, memory looks like this: 
Runtime free: 1,180,138 kb
Runtime max:1,243,648 kb
Runtime total:1,193,984 kb
MX Code Cache(Non-heap memory): used: 13,446 kb, init: 2,496 kb, committed: 13,952 kb, max: 245,760 kb
MX Metaspace(Non-heap memory): used: 37,338 kb, init: 0 kb, committed: 39,424 kb, max: 0 kb
MX Compressed Class Space(Non-heap memory): used: 4,407 kb, init: 0 kb, committed: 4,864 kb, max: 1,048,576 kb
MX PS Eden Space(Heap memory): used: 1,408 kb, init: 350,208 kb, committed: 231,424 kb, max: 317,952 kb
MX PS Survivor Space(Heap memory): used: 0 kb, init: 57,856 kb, committed: 29,696 kb, max: 29,696 kb
MX PS Old Gen(Heap memory): used: 12,436 kb, init: 932,864 kb, committed: 932,864 kb, max: 932,864 kb
14:34:00,862 INFO  [org.radargun.Slave] (sc-main) Finished stage Clear
14:34:00,863 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
14:34:00,899 INFO  [org.radargun.Slave] (sc-main) Starting stage Load
14:34:04,144 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) This node loaded 10000 entries (~10000000 bytes)
14:34:07,438 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) This node loaded 20000 entries (~20000000 bytes)
14:34:10,604 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) This node loaded 30000 entries (~30000000 bytes)
14:34:11,611 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) Finished loading entries
14:34:11,643 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) Finished loading entries
14:34:11,662 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) Finished loading entries
14:34:11,669 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) Finished loading entries
14:34:11,680 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) Finished loading entries
14:34:11,707 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) Finished loading entries
14:34:11,710 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) Finished loading entries
14:34:11,714 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) Finished loading entries
14:34:11,721 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) Finished loading entries
14:34:11,744 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) Finished loading entries
14:34:11,744 INFO  [org.radargun.Slave] (sc-main) Finished stage Load
14:34:11,745 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
14:34:12,110 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.stages.cache.test.BasicOperationsTestStage.init() overrides public void org.radargun.stages.test.TestStage.init() but both are declared with @Init annotation: calling only once
14:34:12,111 INFO  [org.radargun.Slave] (sc-main) Starting stage BasicOperationsTest
14:34:12,111 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using key generator org.radargun.stages.cache.generators.StringKeyGenerator {format=null }
14:34:12,111 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using value generator org.radargun.stages.cache.generators.ByteArrayValueGenerator { }
14:34:12,111 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using cache selector Default { }
14:34:12,112 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Starting test stress-test
14:34:12,196 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Started 4 stressor threads.
14:44:12,205 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Finished test. Test duration is: 10 mins 0 secs
14:44:12,206 INFO  [org.radargun.Slave] (sc-main) Finished stage BasicOperationsTest
14:44:12,303 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
14:44:12,567 INFO  [org.radargun.Slave] (sc-main) Starting stage MonitorStop
14:44:12,567 INFO  [org.radargun.Slave] (sc-main) Finished stage MonitorStop
14:44:12,568 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
14:44:12,584 INFO  [org.radargun.Slave] (sc-main) Starting stage ScenarioDestroy
14:44:12,585 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Scenario finished, destroying...
14:44:12,585 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Memory before cleanup: 
Runtime free: 1,007,030 kb
Runtime max:1,328,640 kb
Runtime total:1,328,640 kb
MX Code Cache(Non-heap memory): used: 14,894 kb, init: 2,496 kb, committed: 15,040 kb, max: 245,760 kb
MX Metaspace(Non-heap memory): used: 37,894 kb, init: 0 kb, committed: 39,936 kb, max: 0 kb
MX Compressed Class Space(Non-heap memory): used: 4,442 kb, init: 0 kb, committed: 4,864 kb, max: 1,048,576 kb
MX PS Eden Space(Heap memory): used: 214,848 kb, init: 350,208 kb, committed: 325,632 kb, max: 325,632 kb
MX PS Survivor Space(Heap memory): used: 69,472 kb, init: 57,856 kb, committed: 70,144 kb, max: 70,144 kb
MX PS Old Gen(Heap memory): used: 37,288 kb, init: 932,864 kb, committed: 932,864 kb, max: 932,864 kb
14:44:12,585 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) Stopping service.
14:44:12,631 INFO  [org.infinispan.CLUSTER] (StopThread) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-43105: 244+81, fedora-61354: 268+90]}, pendingCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-43105: 243+269, fedora-61354: 269+243]}, unionCH=null, actualMembers=[fedora-43105, fedora-61354], persistentUUIDs=[ab31ebb5-fd25-49ef-a933-25a035445cfd, e469730a-ae16-439f-9c9b-341c1457a5b0]}
14:44:12,632 INFO  [org.infinispan.CLUSTER] (StopThread) [Context=testCache][Scope=fedora-9136]ISPN100002: Started rebalance with topology id 11
14:44:12,640 WARN  [org.infinispan.CLUSTER] (remote-thread--p2-t32) [Context=testCache]ISPN000312: Lost data because of graceful leaver fedora-43105
14:44:12,660 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t34) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-9136: 133, fedora-61354: 123]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-9136: 132, fedora-61354: 124]}, unionCH=null, actualMembers=[fedora-9136, fedora-61354], persistentUUIDs=[67906b28-04c0-404d-aea1-1cfad193c23c, e469730a-ae16-439f-9c9b-341c1457a5b0]}
14:44:12,661 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t34) [Context=___protobuf_metadata][Scope=fedora-9136]ISPN100002: Started rebalance with topology id 11
14:44:12,662 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t11) [Context=___protobuf_metadata][Scope=fedora-9136]ISPN100003: Node fedora-9136 finished rebalance phase with topology id 11
14:44:12,664 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (transport-thread--p4-t11) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___protobuf_metadata, type=REBALANCE_PHASE_CONFIRM, sender=fedora-9136, joinInfo=null, topologyId=11, rebalanceId=4, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-9136 for cache ___protobuf_metadata, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.commands.ReplicableCommand.invoke(ReplicableCommand.java:44) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.LocalTopologyManagerImpl.lambda$executeOnCoordinatorAsync$4(LocalTopologyManagerImpl.java:717) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0-internal]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0-internal]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0-internal]
14:44:12,665 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t14) [Context=___protobuf_metadata][Scope=fedora-9136]ISPN100003: Node fedora-9136 finished rebalance phase with topology id 12
14:44:12,666 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (transport-thread--p4-t14) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___protobuf_metadata, type=REBALANCE_PHASE_CONFIRM, sender=fedora-9136, joinInfo=null, topologyId=12, rebalanceId=4, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-9136 for cache ___protobuf_metadata, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.commands.ReplicableCommand.invoke(ReplicableCommand.java:44) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.LocalTopologyManagerImpl.lambda$executeOnCoordinatorAsync$4(LocalTopologyManagerImpl.java:717) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0-internal]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0-internal]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0-internal]
14:44:12,669 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t32) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-9136: 115+43, fedora-61354: 141+35]}, pendingCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-9136: 132+124, fedora-61354: 124+132]}, unionCH=null, actualMembers=[fedora-9136, fedora-61354], persistentUUIDs=[67906b28-04c0-404d-aea1-1cfad193c23c, e469730a-ae16-439f-9c9b-341c1457a5b0]}
14:44:12,669 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t32) [Context=___counters][Scope=fedora-9136]ISPN100002: Started rebalance with topology id 11
14:44:12,676 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t32) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-9136: 133, fedora-61354: 123]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-9136: 132, fedora-61354: 124]}, unionCH=null, actualMembers=[fedora-9136, fedora-61354], persistentUUIDs=[67906b28-04c0-404d-aea1-1cfad193c23c, e469730a-ae16-439f-9c9b-341c1457a5b0]}
14:44:12,677 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t32) [Context=org.infinispan.CONFIG][Scope=fedora-9136]ISPN100002: Started rebalance with topology id 11
14:44:12,678 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t23) [Context=org.infinispan.CONFIG][Scope=fedora-9136]ISPN100003: Node fedora-9136 finished rebalance phase with topology id 11
14:44:12,682 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t32) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=12, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-9136: 133, fedora-61354: 123]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-9136: 132, fedora-61354: 124]}, unionCH=null, actualMembers=[fedora-9136, fedora-61354], persistentUUIDs=[67906b28-04c0-404d-aea1-1cfad193c23c, e469730a-ae16-439f-9c9b-341c1457a5b0]}
14:44:12,683 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t33) [Context=org.infinispan.CONFIG][Scope=fedora-61354]ISPN100003: Node fedora-61354 finished rebalance phase with topology id 11
14:44:12,684 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t33) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 11
14:44:12,685 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t32) [Context=___counter_configuration][Scope=fedora-9136]ISPN100002: Started rebalance with topology id 12
14:44:12,685 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t6) [Context=org.infinispan.CONFIG][Scope=fedora-9136]ISPN100003: Node fedora-9136 finished rebalance phase with topology id 12
14:44:12,686 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t4) [Context=___counter_configuration][Scope=fedora-9136]ISPN100003: Node fedora-9136 finished rebalance phase with topology id 12
14:44:12,690 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t32) [Context=org.infinispan.CONFIG][Scope=fedora-61354]ISPN100003: Node fedora-61354 finished rebalance phase with topology id 12
14:44:12,697 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t9) [Context=org.infinispan.CONFIG][Scope=fedora-9136]ISPN100003: Node fedora-9136 finished rebalance phase with topology id 13
14:44:12,699 INFO  [org.infinispan.CLUSTER] (jgroups-35,fedora-9136) ISPN000094: Received new cluster view for channel results: [fedora-9136|3] (2) [fedora-9136, fedora-61354]
14:44:12,702 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t34) [Context=___counter_configuration][Scope=fedora-61354]ISPN100003: Node fedora-61354 finished rebalance phase with topology id 12
14:44:12,702 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t35) [Context=org.infinispan.CONFIG][Scope=fedora-61354]ISPN100003: Node fedora-61354 finished rebalance phase with topology id 13
14:44:12,704 WARN  [org.infinispan.CLUSTER] (remote-thread--p2-t32) [Context=___counters]ISPN000312: Lost data because of graceful leaver fedora-61354
14:44:12,703 INFO  [org.infinispan.CLUSTER] (jgroups-35,fedora-9136) ISPN100001: Node fedora-43105 left the cluster
14:44:12,704 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t34) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 12
14:44:12,708 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t3) [Context=___counter_configuration][Scope=fedora-9136]ISPN100003: Node fedora-9136 finished rebalance phase with topology id 13
14:44:12,716 ERROR [org.infinispan.statetransfer.StateConsumerImpl] (transport-thread--p4-t18) ISPN000208: No live owners found for segments {1-3 7 20-21 29-37 45-46 49-55 59-61 66-68 71-73 77-79 91-93 96-98 116-122 128-130 135-137 151-157 169-174 178-179 193-195 201-202 205-208 213-215 219-224 232-236 252-255} of cache ___counters. Excluded owners: []
14:44:12,732 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t25) [Context=___counter_configuration][Scope=fedora-9136]ISPN100003: Node fedora-9136 finished rebalance phase with topology id 14
14:44:12,733 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t2) [Context=___counter_configuration][Scope=fedora-9136]ISPN100003: Node fedora-9136 finished rebalance phase with topology id 15
14:44:12,733 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (transport-thread--p4-t25) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___counter_configuration, type=REBALANCE_PHASE_CONFIRM, sender=fedora-9136, joinInfo=null, topologyId=14, rebalanceId=4, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=3}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-9136 for cache ___counter_configuration, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.commands.ReplicableCommand.invoke(ReplicableCommand.java:44) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.LocalTopologyManagerImpl.lambda$executeOnCoordinatorAsync$4(LocalTopologyManagerImpl.java:717) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0-internal]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0-internal]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0-internal]
14:44:12,734 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (transport-thread--p4-t2) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___counter_configuration, type=REBALANCE_PHASE_CONFIRM, sender=fedora-9136, joinInfo=null, topologyId=15, rebalanceId=4, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=3}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-9136 for cache ___counter_configuration, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.commands.ReplicableCommand.invoke(ReplicableCommand.java:44) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.LocalTopologyManagerImpl.lambda$executeOnCoordinatorAsync$4(LocalTopologyManagerImpl.java:717) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0-internal]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0-internal]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0-internal]
14:44:12,739 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t35) [Context=___counter_configuration][Scope=fedora-61354]ISPN100003: Node fedora-61354 finished rebalance phase with topology id 13
14:44:12,739 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (remote-thread--p2-t35) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___counter_configuration, type=REBALANCE_PHASE_CONFIRM, sender=fedora-61354, joinInfo=null, topologyId=13, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=3}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-61354 for cache ___counter_configuration, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.invokeReplicableCommand(GlobalInboundInvocationHandler.java:169) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.runReplicableCommand(GlobalInboundInvocationHandler.java:150) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.lambda$handleReplicableCommand$1(GlobalInboundInvocationHandler.java:144) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.util.concurrent.BlockingTaskAwareExecutorServiceImpl$RunnableWrapper.run(BlockingTaskAwareExecutorServiceImpl.java:212) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0-internal]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0-internal]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0-internal]
14:44:12,755 INFO  [org.infinispan.CLUSTER] (jgroups-35,fedora-9136) ISPN000094: Received new cluster view for channel results: [fedora-9136|4] (1) [fedora-9136]
14:44:12,756 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (StopThread) ISPN000080: Disconnecting JGroups channel results
14:44:12,756 INFO  [org.infinispan.CLUSTER] (jgroups-35,fedora-9136) ISPN100001: Node fedora-61354 left the cluster
14:44:12,782 INFO  [org.radargun.service.Infinispan90Lifecycle] (StopThread) Stopped, previous view is [fedora-9136, fedora-43105, fedora-61354]
14:44:12,783 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Service successfully stopped.
14:44:12,783 INFO  [org.radargun.Slave] (sc-main) Finished stage ScenarioDestroy
14:44:12,784 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
14:44:12,790 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.service.Infinispan80EmbeddedService.destroy() overrides public void org.radargun.service.Infinispan60EmbeddedService.destroy() but both are declared with @Destroy annotation: calling only once
14:44:12,792 INFO  [org.radargun.Slave] (main) Starting stage ScenarioCleanup
14:44:12,893 INFO  [org.radargun.stages.ScenarioCleanupStage] (main) Memory after cleanup: 
Runtime free: 1,313,813 kb
Runtime max:1,328,640 kb
Runtime total:1,328,640 kb
MX Code Cache(Non-heap memory): used: 14,930 kb, init: 2,496 kb, committed: 15,168 kb, max: 245,760 kb
MX Metaspace(Non-heap memory): used: 38,028 kb, init: 0 kb, committed: 39,936 kb, max: 0 kb
MX Compressed Class Space(Non-heap memory): used: 4,464 kb, init: 0 kb, committed: 4,864 kb, max: 1,048,576 kb
MX PS Eden Space(Heap memory): used: 2,455 kb, init: 350,208 kb, committed: 325,632 kb, max: 325,632 kb
MX PS Survivor Space(Heap memory): used: 0 kb, init: 57,856 kb, committed: 70,144 kb, max: 70,144 kb
MX PS Old Gen(Heap memory): used: 12,371 kb, init: 932,864 kb, committed: 932,864 kb, max: 932,864 kb
14:44:12,895 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
14:44:18,056 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
14:44:22,333 INFO  [org.radargun.Slave] (main) Master shutdown!
