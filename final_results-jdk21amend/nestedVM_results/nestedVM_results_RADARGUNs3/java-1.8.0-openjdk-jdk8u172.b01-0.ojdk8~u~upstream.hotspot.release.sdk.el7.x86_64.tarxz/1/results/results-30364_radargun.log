12:45:22,514 INFO  [org.radargun.RemoteMasterConnection] (main) Attempting to connect to master results:2103
12:45:22,520 INFO  [org.radargun.RemoteMasterConnection] (main) Successfully established connection with master at: results:2103
12:45:22,523 INFO  [org.radargun.Slave] (main) Received slave index 0
12:45:22,523 INFO  [org.radargun.Slave] (main) Received slave count 3
12:45:22,763 INFO  [org.radargun.ServiceHelper] (sc-main) ServiceContext properties: {}
12:45:22,913 INFO  [org.radargun.Slave] (sc-main) Eager Service Infinispan92EmbeddedService {batching=false, cache=testCache, channelRetrievalTimeout=2 mins 0 secs, enableDiagnostics=null, explicitLocking=false, file=/mnt/workspace/results/dist-sync.xml, internalsExpositionEnabled=false, jgroupsDumperEnabled=false, jgroupsDumperInterval=10.000 secs, keysPerThread=-1, mapReduceDistributedReducePhase=false, mapReduceUseIntermediateSharedCache=false, removedCaches=[  ], threadsPerNode=-1 } loaded.
12:45:24,942 INFO  [org.radargun.Slave] (sc-main) Starting stage ScenarioInit
12:45:24,982 INFO  [org.radargun.Slave] (sc-main) Finished stage ScenarioInit
12:45:25,016 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
12:45:25,086 INFO  [org.radargun.Slave] (sc-main) Starting stage BeforeServiceStart
12:45:25,088 INFO  [org.radargun.Slave] (sc-main) Finished stage BeforeServiceStart
12:45:25,088 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
12:45:25,095 INFO  [org.radargun.Slave] (sc-main) Starting stage ServiceStart
12:45:25,099 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Startup staggering, this is the slave with index 0, not sleeping
12:45:25,099 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 0
12:45:25,102 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) Infinispan version: Infinispan 'Gaina' 9.2.0.Final
12:45:25,113 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) JGroups version: JGroups 4.0.10.Final (Schiener Berg)
12:45:25,926 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (sc-main) ISPN000078: Starting JGroups channel results
12:45:26,011 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the send buffer of socket MulticastSocket was set to 1.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
12:45:26,012 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the receive buffer of socket MulticastSocket was set to 20.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
12:45:26,012 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the send buffer of socket MulticastSocket was set to 1.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
12:45:26,012 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the receive buffer of socket MulticastSocket was set to 25.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
12:45:31,060 INFO  [org.infinispan.CLUSTER] (sc-main) ISPN000094: Received new cluster view for channel results: [fedora-15861|0] (1) [fedora-15861]
12:45:31,149 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (sc-main) ISPN000079: Channel results local address is fedora-15861, physical addresses are [192.168.124.111:33382]
12:45:31,155 INFO  [org.infinispan.factories.GlobalComponentRegistry] (sc-main) ISPN000128: Infinispan version: Infinispan 'Gaina' 9.2.0.Final
12:45:31,800 INFO  [org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup] (sc-main) ISPN000107: Retrieving transaction manager Transaction: unknown
12:45:31,887 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) No RELAY2 protocol in XS service
12:45:31,888 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) No RELAY2 protocol in XS service
12:45:31,890 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) ([fedora-15861(local=true, coord=true)]) Number of members=1 is not the one expected: 3
12:45:32,034 INFO  [org.infinispan.CLUSTER] (jgroups-6,fedora-15861) ISPN000094: Received new cluster view for channel results: [fedora-15861|1] (2) [fedora-15861, fedora-54088]
12:45:32,042 INFO  [org.infinispan.CLUSTER] (jgroups-6,fedora-15861) ISPN100000: Node fedora-54088 joined the cluster
12:45:32,505 INFO  [org.infinispan.CLUSTER] (jgroups-10,fedora-15861) ISPN000094: Received new cluster view for channel results: [fedora-15861|2] (3) [fedora-15861, fedora-54088, fedora-43405]
12:45:32,516 INFO  [org.infinispan.CLUSTER] (jgroups-10,fedora-15861) ISPN100000: Node fedora-43405 joined the cluster
12:45:32,795 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-15861: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-15861: 131, fedora-54088: 125]}, unionCH=null, actualMembers=[fedora-15861, fedora-54088], persistentUUIDs=[023e4cf9-c524-41c1-8395-9373ae964c8f, 0e32b4ba-f395-45b8-8130-a615c5d5e862]}
12:45:32,798 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-15861]ISPN100002: Started rebalance with topology id 2
12:45:32,816 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-15861: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-15861: 131, fedora-54088: 125]}, unionCH=null, actualMembers=[fedora-15861, fedora-54088], persistentUUIDs=[023e4cf9-c524-41c1-8395-9373ae964c8f, 0e32b4ba-f395-45b8-8130-a615c5d5e862]}
12:45:32,819 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-15861]ISPN100002: Started rebalance with topology id 2
12:45:32,843 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t23) [Context=___counter_configuration][Scope=fedora-15861]ISPN100003: Node fedora-15861 finished rebalance phase with topology id 2
12:45:32,846 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t24) [Context=org.infinispan.CONFIG][Scope=fedora-15861]ISPN100003: Node fedora-15861 finished rebalance phase with topology id 2
12:45:32,890 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) Number of members is the one expected: 3
12:45:32,891 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Successfully started cache service infinispan92/embedded on slave 0
12:45:32,951 ERROR [org.radargun.service.ConfigDumpHelper] (sc-main) Error while dumping ___protobuf_metadata cache config as properties
javax.management.AttributeNotFoundException: Unknown attribute 'configurationAsProperties'. Known attributes names are: [rebalancingEnabled, cacheStatus, cacheAvailability, cacheName, version, configurationAsProperties]
	at org.infinispan.jmx.ResourceDMBean.getAttribute(ResourceDMBean.java:181) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:647) ~[?:1.8.0-internal]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:678) ~[?:1.8.0-internal]
	at org.radargun.service.ConfigDumpHelper60.dumpCache(ConfigDumpHelper60.java:44) [plugin-infinispan60-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.service.EmbeddedConfigurationProvider.getNormalizedConfigs(EmbeddedConfigurationProvider.java:33) [plugin-infinispan52-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.stages.lifecycle.ServiceStartStage.executeOnSlave(ServiceStartStage.java:92) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase.scenarioLoop(SlaveBase.java:102) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase$ScenarioRunner.run(SlaveBase.java:203) [radargun-core-3.0.0-SNAPSHOT.jar:?]
12:45:32,971 ERROR [org.radargun.service.ConfigDumpHelper] (sc-main) Error while dumping ___protobuf_metadata cache config as properties
javax.management.AttributeNotFoundException: Unknown attribute 'configurationAsProperties'. Known attributes names are: [rebalancingEnabled, cacheStatus, cacheAvailability, cacheName, version, configurationAsProperties]
	at org.infinispan.jmx.ResourceDMBean.getAttribute(ResourceDMBean.java:181) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:647) ~[?:1.8.0-internal]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:678) ~[?:1.8.0-internal]
	at org.radargun.service.ConfigDumpHelper60.dumpCache(ConfigDumpHelper60.java:44) [plugin-infinispan60-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.service.EmbeddedConfigurationProvider.getNormalizedConfigs(EmbeddedConfigurationProvider.java:33) [plugin-infinispan52-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.stages.lifecycle.ServiceStartStage.executeOnSlave(ServiceStartStage.java:92) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase.scenarioLoop(SlaveBase.java:102) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase$ScenarioRunner.run(SlaveBase.java:203) [radargun-core-3.0.0-SNAPSHOT.jar:?]
12:45:33,026 INFO  [org.radargun.Slave] (sc-main) Finished stage ServiceStart
12:45:33,041 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
12:45:33,086 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-54088]ISPN100003: Node fedora-54088 finished rebalance phase with topology id 2
12:45:33,086 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-54088]ISPN100003: Node fedora-54088 finished rebalance phase with topology id 2
12:45:33,090 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 2
12:45:33,091 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 2
12:45:33,094 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t3) [Context=___counter_configuration][Scope=fedora-15861]ISPN100003: Node fedora-15861 finished rebalance phase with topology id 3
12:45:33,100 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t2) [Context=org.infinispan.CONFIG][Scope=fedora-15861]ISPN100003: Node fedora-15861 finished rebalance phase with topology id 3
12:45:33,106 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-54088]ISPN100003: Node fedora-54088 finished rebalance phase with topology id 3
12:45:33,109 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-54088]ISPN100003: Node fedora-54088 finished rebalance phase with topology id 3
12:45:33,108 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t8) [Context=org.infinispan.CONFIG][Scope=fedora-15861]ISPN100003: Node fedora-15861 finished rebalance phase with topology id 4
12:45:33,112 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t11) [Context=___counter_configuration][Scope=fedora-15861]ISPN100003: Node fedora-15861 finished rebalance phase with topology id 4
12:45:33,123 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-54088]ISPN100003: Node fedora-54088 finished rebalance phase with topology id 4
12:45:33,129 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-54088]ISPN100003: Node fedora-54088 finished rebalance phase with topology id 4
12:45:33,207 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=DefaultConsistentHash{ns=256, owners = (1)[fedora-15861: 256+0]}, pendingCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-15861: 131+125, fedora-54088: 125+131]}, unionCH=null, actualMembers=[fedora-15861, fedora-54088], persistentUUIDs=[023e4cf9-c524-41c1-8395-9373ae964c8f, 0e32b4ba-f395-45b8-8130-a615c5d5e862]}
12:45:33,208 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-15861]ISPN100002: Started rebalance with topology id 2
12:45:33,214 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t23) [Context=___counters][Scope=fedora-15861]ISPN100003: Node fedora-15861 finished rebalance phase with topology id 2
12:45:33,264 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-54088]ISPN100003: Node fedora-54088 finished rebalance phase with topology id 2
12:45:33,264 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___counters, topology id = 2
12:45:33,266 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t24) [Context=___counters][Scope=fedora-15861]ISPN100003: Node fedora-15861 finished rebalance phase with topology id 3
12:45:33,280 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-54088]ISPN100003: Node fedora-54088 finished rebalance phase with topology id 3
12:45:33,281 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t4) [Context=___counters][Scope=fedora-15861]ISPN100003: Node fedora-15861 finished rebalance phase with topology id 4
12:45:33,285 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-54088]ISPN100003: Node fedora-54088 finished rebalance phase with topology id 4
12:45:33,325 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-15861: 131, fedora-54088: 125]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-15861: 90, fedora-54088: 85, fedora-43405: 81]}, unionCH=null, actualMembers=[fedora-15861, fedora-54088, fedora-43405], persistentUUIDs=[023e4cf9-c524-41c1-8395-9373ae964c8f, 0e32b4ba-f395-45b8-8130-a615c5d5e862, f6d07186-ac04-4416-be99-a428eca56775]}
12:45:33,326 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-15861]ISPN100002: Started rebalance with topology id 6
12:45:33,327 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-15861: 131, fedora-54088: 125]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-15861: 90, fedora-54088: 85, fedora-43405: 81]}, unionCH=null, actualMembers=[fedora-15861, fedora-54088, fedora-43405], persistentUUIDs=[023e4cf9-c524-41c1-8395-9373ae964c8f, 0e32b4ba-f395-45b8-8130-a615c5d5e862, f6d07186-ac04-4416-be99-a428eca56775]}
12:45:33,331 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t13) [Context=___counter_configuration][Scope=fedora-15861]ISPN100003: Node fedora-15861 finished rebalance phase with topology id 6
12:45:33,331 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-15861]ISPN100002: Started rebalance with topology id 6
12:45:33,334 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t8) [Context=org.infinispan.CONFIG][Scope=fedora-15861]ISPN100003: Node fedora-15861 finished rebalance phase with topology id 6
12:45:33,344 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-54088]ISPN100003: Node fedora-54088 finished rebalance phase with topology id 6
12:45:33,353 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-54088]ISPN100003: Node fedora-54088 finished rebalance phase with topology id 6
12:45:33,358 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-15861: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-15861: 131, fedora-54088: 125]}, unionCH=null, actualMembers=[fedora-15861, fedora-54088], persistentUUIDs=[023e4cf9-c524-41c1-8395-9373ae964c8f, 0e32b4ba-f395-45b8-8130-a615c5d5e862]}
12:45:33,360 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-15861]ISPN100002: Started rebalance with topology id 2
12:45:33,368 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t18) [Context=___protobuf_metadata][Scope=fedora-15861]ISPN100003: Node fedora-15861 finished rebalance phase with topology id 2
12:45:33,404 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=DefaultConsistentHash{ns=512, owners = (1)[fedora-15861: 512+0]}, pendingCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-15861: 259+253, fedora-54088: 253+259]}, unionCH=null, actualMembers=[fedora-15861, fedora-54088], persistentUUIDs=[023e4cf9-c524-41c1-8395-9373ae964c8f, 0e32b4ba-f395-45b8-8130-a615c5d5e862]}
12:45:33,406 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-15861]ISPN100002: Started rebalance with topology id 2
12:45:33,414 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-54088]ISPN100003: Node fedora-54088 finished rebalance phase with topology id 2
12:45:33,416 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 2
12:45:33,416 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t19) [Context=testCache][Scope=fedora-15861]ISPN100003: Node fedora-15861 finished rebalance phase with topology id 2
12:45:33,417 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t1) [Context=___protobuf_metadata][Scope=fedora-15861]ISPN100003: Node fedora-15861 finished rebalance phase with topology id 3
12:45:33,427 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-54088]ISPN100003: Node fedora-54088 finished rebalance phase with topology id 3
12:45:33,431 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t25) [Context=___protobuf_metadata][Scope=fedora-15861]ISPN100003: Node fedora-15861 finished rebalance phase with topology id 4
12:45:33,435 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-54088]ISPN100003: Node fedora-54088 finished rebalance phase with topology id 4
12:45:33,446 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-54088]ISPN100003: Node fedora-54088 finished rebalance phase with topology id 2
12:45:33,448 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache testCache, topology id = 2
12:45:33,451 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t2) [Context=testCache][Scope=fedora-15861]ISPN100003: Node fedora-15861 finished rebalance phase with topology id 3
12:45:33,454 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-54088]ISPN100003: Node fedora-54088 finished rebalance phase with topology id 3
12:45:33,461 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-54088]ISPN100003: Node fedora-54088 finished rebalance phase with topology id 4
12:45:33,461 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t11) [Context=testCache][Scope=fedora-15861]ISPN100003: Node fedora-15861 finished rebalance phase with topology id 4
12:45:33,500 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-43405]ISPN100003: Node fedora-43405 finished rebalance phase with topology id 6
12:45:33,501 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 6
12:45:33,503 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t18) [Context=org.infinispan.CONFIG][Scope=fedora-15861]ISPN100003: Node fedora-15861 finished rebalance phase with topology id 7
12:45:33,507 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-54088]ISPN100003: Node fedora-54088 finished rebalance phase with topology id 7
12:45:33,510 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-43405]ISPN100003: Node fedora-43405 finished rebalance phase with topology id 7
12:45:33,513 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t23) [Context=org.infinispan.CONFIG][Scope=fedora-15861]ISPN100003: Node fedora-15861 finished rebalance phase with topology id 8
12:45:33,519 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-54088]ISPN100003: Node fedora-54088 finished rebalance phase with topology id 8
12:45:33,526 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-43405]ISPN100003: Node fedora-43405 finished rebalance phase with topology id 8
12:45:33,655 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-15861: 131, fedora-54088: 125]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-15861: 90, fedora-54088: 85, fedora-43405: 81]}, unionCH=null, actualMembers=[fedora-15861, fedora-54088, fedora-43405], persistentUUIDs=[023e4cf9-c524-41c1-8395-9373ae964c8f, 0e32b4ba-f395-45b8-8130-a615c5d5e862, f6d07186-ac04-4416-be99-a428eca56775]}
12:45:33,656 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-15861]ISPN100002: Started rebalance with topology id 6
12:45:33,658 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t3) [Context=___protobuf_metadata][Scope=fedora-15861]ISPN100003: Node fedora-15861 finished rebalance phase with topology id 6
12:45:33,666 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-54088]ISPN100003: Node fedora-54088 finished rebalance phase with topology id 6
12:45:33,707 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-43405]ISPN100003: Node fedora-43405 finished rebalance phase with topology id 6
12:45:33,707 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 6
12:45:33,708 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t6) [Context=___counter_configuration][Scope=fedora-15861]ISPN100003: Node fedora-15861 finished rebalance phase with topology id 7
12:45:33,712 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-54088]ISPN100003: Node fedora-54088 finished rebalance phase with topology id 7
12:45:33,716 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-43405]ISPN100003: Node fedora-43405 finished rebalance phase with topology id 6
12:45:33,716 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 6
12:45:33,718 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t13) [Context=___protobuf_metadata][Scope=fedora-15861]ISPN100003: Node fedora-15861 finished rebalance phase with topology id 7
12:45:33,718 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-15861: 259+253, fedora-54088: 253+259]}, pendingCH=DefaultConsistentHash{ns=512, owners = (3)[fedora-15861: 178+174, fedora-54088: 169+168, fedora-43405: 165+170]}, unionCH=null, actualMembers=[fedora-15861, fedora-54088, fedora-43405], persistentUUIDs=[023e4cf9-c524-41c1-8395-9373ae964c8f, 0e32b4ba-f395-45b8-8130-a615c5d5e862, f6d07186-ac04-4416-be99-a428eca56775]}
12:45:33,720 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-54088]ISPN100003: Node fedora-54088 finished rebalance phase with topology id 7
12:45:33,721 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-15861]ISPN100002: Started rebalance with topology id 6
12:45:33,717 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counter_configuration][Scope=fedora-43405]ISPN100003: Node fedora-43405 finished rebalance phase with topology id 7
12:45:33,731 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-54088]ISPN100003: Node fedora-54088 finished rebalance phase with topology id 6
12:45:33,732 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=fedora-43405]ISPN100003: Node fedora-43405 finished rebalance phase with topology id 7
12:45:33,731 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t8) [Context=___counter_configuration][Scope=fedora-15861]ISPN100003: Node fedora-15861 finished rebalance phase with topology id 8
12:45:33,733 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-54088]ISPN100003: Node fedora-54088 finished rebalance phase with topology id 8
12:45:33,734 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t22) [Context=___protobuf_metadata][Scope=fedora-15861]ISPN100003: Node fedora-15861 finished rebalance phase with topology id 8
12:45:33,737 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=fedora-54088]ISPN100003: Node fedora-54088 finished rebalance phase with topology id 8
12:45:33,739 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t15) [Context=testCache][Scope=fedora-15861]ISPN100003: Node fedora-15861 finished rebalance phase with topology id 6
12:45:33,742 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counter_configuration][Scope=fedora-43405]ISPN100003: Node fedora-43405 finished rebalance phase with topology id 8
12:45:33,742 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-43405]ISPN100003: Node fedora-43405 finished rebalance phase with topology id 8
12:45:33,760 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-15861: 131+125, fedora-54088: 125+131]}, pendingCH=DefaultConsistentHash{ns=256, owners = (3)[fedora-15861: 90+86, fedora-54088: 85+88, fedora-43405: 81+82]}, unionCH=null, actualMembers=[fedora-15861, fedora-54088, fedora-43405], persistentUUIDs=[023e4cf9-c524-41c1-8395-9373ae964c8f, 0e32b4ba-f395-45b8-8130-a615c5d5e862, f6d07186-ac04-4416-be99-a428eca56775]}
12:45:33,761 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=fedora-15861]ISPN100002: Started rebalance with topology id 6
12:45:33,764 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t4) [Context=___counters][Scope=fedora-15861]ISPN100003: Node fedora-15861 finished rebalance phase with topology id 6
12:45:33,766 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-43405]ISPN100003: Node fedora-43405 finished rebalance phase with topology id 6
12:45:33,767 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache testCache, topology id = 6
12:45:33,767 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-54088]ISPN100003: Node fedora-54088 finished rebalance phase with topology id 6
12:45:33,770 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t10) [Context=testCache][Scope=fedora-15861]ISPN100003: Node fedora-15861 finished rebalance phase with topology id 7
12:45:33,774 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-54088]ISPN100003: Node fedora-54088 finished rebalance phase with topology id 7
12:45:33,777 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-43405]ISPN100003: Node fedora-43405 finished rebalance phase with topology id 7
12:45:33,780 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t11) [Context=testCache][Scope=fedora-15861]ISPN100003: Node fedora-15861 finished rebalance phase with topology id 8
12:45:33,782 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-54088]ISPN100003: Node fedora-54088 finished rebalance phase with topology id 8
12:45:33,784 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-43405]ISPN100003: Node fedora-43405 finished rebalance phase with topology id 8
12:45:33,808 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-43405]ISPN100003: Node fedora-43405 finished rebalance phase with topology id 6
12:45:33,808 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache ___counters, topology id = 6
12:45:33,810 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t17) [Context=___counters][Scope=fedora-15861]ISPN100003: Node fedora-15861 finished rebalance phase with topology id 7
12:45:33,812 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-54088]ISPN100003: Node fedora-54088 finished rebalance phase with topology id 7
12:45:33,813 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-43405]ISPN100003: Node fedora-43405 finished rebalance phase with topology id 7
12:45:33,814 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t1) [Context=___counters][Scope=fedora-15861]ISPN100003: Node fedora-15861 finished rebalance phase with topology id 8
12:45:33,817 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-54088]ISPN100003: Node fedora-54088 finished rebalance phase with topology id 8
12:45:33,820 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-43405]ISPN100003: Node fedora-43405 finished rebalance phase with topology id 8
12:45:33,910 INFO  [org.radargun.Slave] (sc-main) Starting stage AfterServiceStart
12:45:33,910 INFO  [org.radargun.Slave] (sc-main) Finished stage AfterServiceStart
12:45:33,913 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
12:45:33,964 INFO  [org.radargun.Slave] (sc-main) Starting stage MonitorStart
12:45:33,978 INFO  [org.radargun.sysmonitor.AbstractMonitors] (sc-main) Gathering statistics every 1000 ms
12:45:33,978 INFO  [org.radargun.Slave] (sc-main) Finished stage MonitorStart
12:45:33,982 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
12:45:34,009 INFO  [org.radargun.Slave] (sc-main) Starting stage Load
12:45:41,891 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) This node loaded 10000 entries (~10000000 bytes)
12:45:46,250 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) This node loaded 20000 entries (~20000000 bytes)
12:45:50,067 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) This node loaded 30000 entries (~30000000 bytes)
12:45:50,767 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) Finished loading entries
12:45:50,781 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) Finished loading entries
12:45:50,783 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) Finished loading entries
12:45:50,784 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) Finished loading entries
12:45:50,791 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) Finished loading entries
12:45:50,795 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) Finished loading entries
12:45:50,798 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) Finished loading entries
12:45:50,800 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) Finished loading entries
12:45:50,805 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) Finished loading entries
12:45:50,816 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) Finished loading entries
12:45:50,817 INFO  [org.radargun.Slave] (sc-main) Finished stage Load
12:45:50,817 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
12:45:50,844 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.stages.cache.test.BasicOperationsTestStage.init() overrides public void org.radargun.stages.test.TestStage.init() but both are declared with @Init annotation: calling only once
12:45:50,848 INFO  [org.radargun.Slave] (sc-main) Starting stage BasicOperationsTest
12:45:50,849 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using key generator org.radargun.stages.cache.generators.StringKeyGenerator {format=null }
12:45:50,849 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using value generator org.radargun.stages.cache.generators.ByteArrayValueGenerator { }
12:45:50,849 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using cache selector Default { }
12:45:50,850 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Starting test warmup
12:45:50,867 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Started 4 stressor threads.
12:46:50,872 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Finished test. Test duration is: 1 mins 0 secs
12:46:50,874 INFO  [org.radargun.Slave] (sc-main) Finished stage BasicOperationsTest
12:46:50,884 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
12:46:50,905 INFO  [org.radargun.Slave] (sc-main) Starting stage Clear
12:46:50,924 INFO  [org.radargun.stages.cache.ClearStage] (sc-main) Before executing clear, memory looks like this: 
Runtime free: 1,020,118 kb
Runtime max:1,298,944 kb
Runtime total:1,298,944 kb
MX Code Cache(Non-heap memory): used: 13,209 kb, init: 2,496 kb, committed: 14,080 kb, max: 245,760 kb
MX Metaspace(Non-heap memory): used: 37,377 kb, init: 0 kb, committed: 39,468 kb, max: 0 kb
MX Compressed Class Space(Non-heap memory): used: 4,432 kb, init: 0 kb, committed: 4,908 kb, max: 1,048,576 kb
MX PS Eden Space(Heap memory): used: 133,393 kb, init: 350,208 kb, committed: 268,288 kb, max: 271,360 kb
MX PS Survivor Space(Heap memory): used: 64,032 kb, init: 57,856 kb, committed: 97,792 kb, max: 97,792 kb
MX PS Old Gen(Heap memory): used: 81,400 kb, init: 932,864 kb, committed: 932,864 kb, max: 932,864 kb
12:46:51,230 INFO  [org.radargun.stages.cache.ClearStage] (sc-main) After executing clear, memory looks like this: 
Runtime free: 1,287,919 kb
Runtime max:1,302,528 kb
Runtime total:1,302,528 kb
MX Code Cache(Non-heap memory): used: 13,385 kb, init: 2,496 kb, committed: 14,144 kb, max: 245,760 kb
MX Metaspace(Non-heap memory): used: 37,323 kb, init: 0 kb, committed: 39,468 kb, max: 0 kb
MX Compressed Class Space(Non-heap memory): used: 4,407 kb, init: 0 kb, committed: 4,908 kb, max: 1,048,576 kb
MX PS Eden Space(Heap memory): used: 2,150 kb, init: 350,208 kb, committed: 272,896 kb, max: 272,896 kb
MX PS Survivor Space(Heap memory): used: 0 kb, init: 57,856 kb, committed: 96,768 kb, max: 96,768 kb
MX PS Old Gen(Heap memory): used: 12,464 kb, init: 932,864 kb, committed: 932,864 kb, max: 932,864 kb
12:46:51,231 INFO  [org.radargun.Slave] (sc-main) Finished stage Clear
12:46:51,238 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
12:46:51,242 INFO  [org.radargun.Slave] (sc-main) Starting stage Load
12:46:54,543 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) This node loaded 10000 entries (~10000000 bytes)
12:46:57,763 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) This node loaded 20000 entries (~20000000 bytes)
12:47:00,909 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) This node loaded 30000 entries (~30000000 bytes)
12:47:01,880 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) Finished loading entries
12:47:01,912 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) Finished loading entries
12:47:01,931 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) Finished loading entries
12:47:01,998 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) Finished loading entries
12:47:02,008 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) Finished loading entries
12:47:02,024 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) Finished loading entries
12:47:02,028 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) Finished loading entries
12:47:02,031 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) Finished loading entries
12:47:02,052 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) Finished loading entries
12:47:02,056 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) Finished loading entries
12:47:02,057 INFO  [org.radargun.Slave] (sc-main) Finished stage Load
12:47:02,059 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
12:47:02,543 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.stages.cache.test.BasicOperationsTestStage.init() overrides public void org.radargun.stages.test.TestStage.init() but both are declared with @Init annotation: calling only once
12:47:02,544 INFO  [org.radargun.Slave] (sc-main) Starting stage BasicOperationsTest
12:47:02,545 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using key generator org.radargun.stages.cache.generators.StringKeyGenerator {format=null }
12:47:02,546 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using value generator org.radargun.stages.cache.generators.ByteArrayValueGenerator { }
12:47:02,548 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using cache selector Default { }
12:47:02,548 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Starting test stress-test
12:47:02,564 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Started 4 stressor threads.
12:54:12,594 WARN  [org.jgroups.protocols.UNICAST3] (jgroups-48,fedora-15861) JGRP000041: fedora-15861: message fedora-54088::2465966 not found in retransmission table
12:57:02,567 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Finished test. Test duration is: 10 mins 0 secs
12:57:02,569 INFO  [org.radargun.Slave] (sc-main) Finished stage BasicOperationsTest
12:57:02,677 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
12:57:02,877 INFO  [org.radargun.Slave] (sc-main) Starting stage MonitorStop
12:57:02,879 INFO  [org.radargun.Slave] (sc-main) Finished stage MonitorStop
12:57:02,879 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
12:57:02,884 INFO  [org.radargun.Slave] (sc-main) Starting stage ScenarioDestroy
12:57:02,885 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Scenario finished, destroying...
12:57:02,885 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Memory before cleanup: 
Runtime free: 1,087,612 kb
Runtime max:1,326,592 kb
Runtime total:1,326,592 kb
MX Code Cache(Non-heap memory): used: 15,048 kb, init: 2,496 kb, committed: 15,168 kb, max: 245,760 kb
MX Metaspace(Non-heap memory): used: 37,912 kb, init: 0 kb, committed: 39,980 kb, max: 0 kb
MX Compressed Class Space(Non-heap memory): used: 4,443 kb, init: 0 kb, committed: 4,908 kb, max: 1,048,576 kb
MX PS Eden Space(Heap memory): used: 128,082 kb, init: 350,208 kb, committed: 321,536 kb, max: 321,536 kb
MX PS Survivor Space(Heap memory): used: 71,136 kb, init: 57,856 kb, committed: 72,192 kb, max: 72,192 kb
MX PS Old Gen(Heap memory): used: 39,761 kb, init: 932,864 kb, committed: 932,864 kb, max: 932,864 kb
12:57:02,886 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) Stopping service.
12:57:02,897 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t14) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-15861: 267+85, fedora-54088: 245+92]}, pendingCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-15861: 259+253, fedora-54088: 253+259]}, unionCH=null, actualMembers=[fedora-15861, fedora-54088], persistentUUIDs=[023e4cf9-c524-41c1-8395-9373ae964c8f, 0e32b4ba-f395-45b8-8130-a615c5d5e862]}
12:57:02,905 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t14) [Context=testCache][Scope=fedora-15861]ISPN100002: Started rebalance with topology id 11
12:57:02,907 WARN  [org.infinispan.CLUSTER] (remote-thread--p2-t31) [Context=testCache]ISPN000312: Lost data because of graceful leaver fedora-54088
12:57:02,928 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t31) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-15861: 130, fedora-54088: 126]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-15861: 131, fedora-54088: 125]}, unionCH=null, actualMembers=[fedora-15861, fedora-54088], persistentUUIDs=[023e4cf9-c524-41c1-8395-9373ae964c8f, 0e32b4ba-f395-45b8-8130-a615c5d5e862]}
12:57:02,931 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t31) [Context=___protobuf_metadata][Scope=fedora-15861]ISPN100002: Started rebalance with topology id 11
12:57:02,933 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t13) [Context=___protobuf_metadata][Scope=fedora-15861]ISPN100003: Node fedora-15861 finished rebalance phase with topology id 11
12:57:02,936 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t31) [Context=___protobuf_metadata][Scope=fedora-54088]ISPN100003: Node fedora-54088 finished rebalance phase with topology id 11
12:57:02,936 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t31) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 11
12:57:02,940 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t11) [Context=___protobuf_metadata][Scope=fedora-15861]ISPN100003: Node fedora-15861 finished rebalance phase with topology id 12
12:57:02,943 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t31) [Context=___protobuf_metadata][Scope=fedora-54088]ISPN100003: Node fedora-54088 finished rebalance phase with topology id 12
12:57:02,940 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t14) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-15861: 140+36, fedora-54088: 116+57]}, pendingCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-15861: 131+125, fedora-54088: 125+131]}, unionCH=null, actualMembers=[fedora-15861, fedora-54088], persistentUUIDs=[023e4cf9-c524-41c1-8395-9373ae964c8f, 0e32b4ba-f395-45b8-8130-a615c5d5e862]}
12:57:02,946 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t14) [Context=___counters][Scope=fedora-15861]ISPN100002: Started rebalance with topology id 11
12:57:02,951 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t23) [Context=___protobuf_metadata][Scope=fedora-15861]ISPN100003: Node fedora-15861 finished rebalance phase with topology id 13
12:57:02,951 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t14) [Context=___protobuf_metadata][Scope=fedora-54088]ISPN100003: Node fedora-54088 finished rebalance phase with topology id 13
12:57:02,961 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (remote-thread--p2-t14) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___protobuf_metadata, type=REBALANCE_PHASE_CONFIRM, sender=fedora-54088, joinInfo=null, topologyId=13, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-54088 for cache ___protobuf_metadata, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.invokeReplicableCommand(GlobalInboundInvocationHandler.java:169) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.runReplicableCommand(GlobalInboundInvocationHandler.java:150) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.lambda$handleReplicableCommand$1(GlobalInboundInvocationHandler.java:144) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.util.concurrent.BlockingTaskAwareExecutorServiceImpl$RunnableWrapper.run(BlockingTaskAwareExecutorServiceImpl.java:212) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0-internal]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0-internal]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0-internal]
12:57:02,962 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t31) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-15861: 130, fedora-54088: 126]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-15861: 131, fedora-54088: 125]}, unionCH=null, actualMembers=[fedora-15861, fedora-54088], persistentUUIDs=[023e4cf9-c524-41c1-8395-9373ae964c8f, 0e32b4ba-f395-45b8-8130-a615c5d5e862]}
12:57:02,962 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t5) [Context=___protobuf_metadata][Scope=fedora-15861]ISPN100003: Node fedora-15861 finished rebalance phase with topology id 14
12:57:02,966 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (transport-thread--p4-t5) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___protobuf_metadata, type=REBALANCE_PHASE_CONFIRM, sender=fedora-15861, joinInfo=null, topologyId=14, rebalanceId=4, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-15861 for cache ___protobuf_metadata, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.commands.ReplicableCommand.invoke(ReplicableCommand.java:44) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.LocalTopologyManagerImpl.lambda$executeOnCoordinatorAsync$4(LocalTopologyManagerImpl.java:717) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0-internal]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0-internal]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0-internal]
12:57:02,966 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t31) [Context=org.infinispan.CONFIG][Scope=fedora-15861]ISPN100002: Started rebalance with topology id 11
12:57:02,971 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t22) [Context=org.infinispan.CONFIG][Scope=fedora-54088]ISPN100003: Node fedora-54088 finished rebalance phase with topology id 11
12:57:02,971 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t12) [Context=org.infinispan.CONFIG][Scope=fedora-15861]ISPN100003: Node fedora-15861 finished rebalance phase with topology id 11
12:57:02,969 ERROR [org.infinispan.statetransfer.StateConsumerImpl] (transport-thread--p4-t15) ISPN000208: No live owners found for segments {9-10 18-29 43 47 54 63-65 77-79 87-89 99 102-105 109-112 117 125-126 140 152-153 162 165-167 172 175-178 189-190 193 196-197 206-208 213 218-220 233-238 242 252-261 271-274 292 295-296 304-307 312-313 320 338-345 349 354-359 364-367 370-371 374-384 401 414 420-423 427 436-437 440-444 450-451 462 472-473 480-484 492-497 500-501 506-507 510} of cache testCache. Excluded owners: []
12:57:02,971 WARN  [org.infinispan.CLUSTER] (remote-thread--p2-t31) [Context=___counters]ISPN000312: Lost data because of graceful leaver fedora-54088
12:57:03,011 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t22) [Context=___counters][Scope=fedora-54088]ISPN100003: Node fedora-54088 finished rebalance phase with topology id 11
12:57:02,981 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t12) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 11
12:57:03,014 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t17) [Context=org.infinispan.CONFIG][Scope=fedora-15861]ISPN100003: Node fedora-15861 finished rebalance phase with topology id 12
12:57:03,012 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=testCache][Scope=fedora-15861]ISPN100003: Node fedora-15861 finished rebalance phase with topology id 12
12:57:03,014 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (remote-thread--p2-t22) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___counters, type=REBALANCE_PHASE_CONFIRM, sender=fedora-54088, joinInfo=null, topologyId=11, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-54088 for cache ___counters, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.invokeReplicableCommand(GlobalInboundInvocationHandler.java:169) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.runReplicableCommand(GlobalInboundInvocationHandler.java:150) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.lambda$handleReplicableCommand$1(GlobalInboundInvocationHandler.java:144) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.util.concurrent.BlockingTaskAwareExecutorServiceImpl$RunnableWrapper.run(BlockingTaskAwareExecutorServiceImpl.java:212) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0-internal]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0-internal]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0-internal]
12:57:03,014 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (transport-thread--p4-t20) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=testCache, type=REBALANCE_PHASE_CONFIRM, sender=fedora-15861, joinInfo=null, topologyId=12, rebalanceId=4, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-15861 for cache testCache, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.commands.ReplicableCommand.invoke(ReplicableCommand.java:44) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.LocalTopologyManagerImpl.lambda$executeOnCoordinatorAsync$4(LocalTopologyManagerImpl.java:717) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0-internal]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0-internal]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0-internal]
12:57:02,976 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t27) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=12, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-15861: 130, fedora-54088: 126]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-15861: 131, fedora-54088: 125]}, unionCH=null, actualMembers=[fedora-15861, fedora-54088], persistentUUIDs=[023e4cf9-c524-41c1-8395-9373ae964c8f, 0e32b4ba-f395-45b8-8130-a615c5d5e862]}
12:57:03,015 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t27) [Context=___counter_configuration][Scope=fedora-15861]ISPN100002: Started rebalance with topology id 12
12:57:03,018 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t22) [Context=org.infinispan.CONFIG][Scope=fedora-54088]ISPN100003: Node fedora-54088 finished rebalance phase with topology id 12
12:57:03,020 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t23) [Context=___counter_configuration][Scope=fedora-15861]ISPN100003: Node fedora-15861 finished rebalance phase with topology id 12
12:57:03,021 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t31) [Context=___counter_configuration][Scope=fedora-54088]ISPN100003: Node fedora-54088 finished rebalance phase with topology id 12
12:57:03,027 INFO  [org.infinispan.CLUSTER] (jgroups-49,fedora-15861) ISPN000094: Received new cluster view for channel results: [fedora-15861|3] (2) [fedora-15861, fedora-54088]
12:57:03,029 INFO  [org.infinispan.CLUSTER] (jgroups-49,fedora-15861) ISPN100001: Node fedora-43405 left the cluster
12:57:03,038 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t25) [Context=org.infinispan.CONFIG][Scope=fedora-15861]ISPN100003: Node fedora-15861 finished rebalance phase with topology id 13
12:57:03,039 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (transport-thread--p4-t25) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=org.infinispan.CONFIG, type=REBALANCE_PHASE_CONFIRM, sender=fedora-15861, joinInfo=null, topologyId=13, rebalanceId=4, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=3}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-15861 for cache org.infinispan.CONFIG, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.commands.ReplicableCommand.invoke(ReplicableCommand.java:44) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.LocalTopologyManagerImpl.lambda$executeOnCoordinatorAsync$4(LocalTopologyManagerImpl.java:717) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0-internal]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0-internal]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0-internal]
12:57:03,038 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t31) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 12
12:57:03,040 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t6) [Context=___counter_configuration][Scope=fedora-15861]ISPN100003: Node fedora-15861 finished rebalance phase with topology id 13
12:57:03,040 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=org.infinispan.CONFIG][Scope=fedora-15861]ISPN100003: Node fedora-15861 finished rebalance phase with topology id 14
12:57:03,042 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (transport-thread--p4-t7) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=org.infinispan.CONFIG, type=REBALANCE_PHASE_CONFIRM, sender=fedora-15861, joinInfo=null, topologyId=14, rebalanceId=4, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=3}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-15861 for cache org.infinispan.CONFIG, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.commands.ReplicableCommand.invoke(ReplicableCommand.java:44) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.LocalTopologyManagerImpl.lambda$executeOnCoordinatorAsync$4(LocalTopologyManagerImpl.java:717) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0-internal]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0-internal]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0-internal]
12:57:03,047 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t31) [Context=___counter_configuration][Scope=fedora-54088]ISPN100003: Node fedora-54088 finished rebalance phase with topology id 13
12:57:03,049 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (remote-thread--p2-t31) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___counter_configuration, type=REBALANCE_PHASE_CONFIRM, sender=fedora-54088, joinInfo=null, topologyId=13, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=3}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-54088 for cache ___counter_configuration, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.invokeReplicableCommand(GlobalInboundInvocationHandler.java:169) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.runReplicableCommand(GlobalInboundInvocationHandler.java:150) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.lambda$handleReplicableCommand$1(GlobalInboundInvocationHandler.java:144) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.util.concurrent.BlockingTaskAwareExecutorServiceImpl$RunnableWrapper.run(BlockingTaskAwareExecutorServiceImpl.java:212) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0-internal]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0-internal]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0-internal]
12:57:03,050 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t13) [Context=___counter_configuration][Scope=fedora-15861]ISPN100003: Node fedora-15861 finished rebalance phase with topology id 14
12:57:03,050 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (transport-thread--p4-t13) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___counter_configuration, type=REBALANCE_PHASE_CONFIRM, sender=fedora-15861, joinInfo=null, topologyId=14, rebalanceId=4, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=3}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-15861 for cache ___counter_configuration, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.commands.ReplicableCommand.invoke(ReplicableCommand.java:44) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.LocalTopologyManagerImpl.lambda$executeOnCoordinatorAsync$4(LocalTopologyManagerImpl.java:717) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0-internal]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0-internal]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0-internal]
12:57:03,050 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t1) [Context=___counter_configuration][Scope=fedora-15861]ISPN100003: Node fedora-15861 finished rebalance phase with topology id 15
12:57:03,051 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (transport-thread--p4-t1) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___counter_configuration, type=REBALANCE_PHASE_CONFIRM, sender=fedora-15861, joinInfo=null, topologyId=15, rebalanceId=4, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=3}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-15861 for cache ___counter_configuration, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.commands.ReplicableCommand.invoke(ReplicableCommand.java:44) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.LocalTopologyManagerImpl.lambda$executeOnCoordinatorAsync$4(LocalTopologyManagerImpl.java:717) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0-internal]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0-internal]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0-internal]
12:57:03,089 ERROR [org.infinispan.statetransfer.StateConsumerImpl] (transport-thread--p4-t18) ISPN000208: No live owners found for segments {26 39 44 55 59-66 75-76 81-83 86-87 94-96 103 106 117-118 121 133 156 162 169-171 177-190 199-200 209-210 213-214 218-222 240-241 245-249} of cache ___counters. Excluded owners: []
12:57:03,092 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=___counters][Scope=fedora-15861]ISPN100003: Node fedora-15861 finished rebalance phase with topology id 12
12:57:03,092 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (transport-thread--p4-t20) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___counters, type=REBALANCE_PHASE_CONFIRM, sender=fedora-15861, joinInfo=null, topologyId=12, rebalanceId=4, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=3}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-15861 for cache ___counters, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.commands.ReplicableCommand.invoke(ReplicableCommand.java:44) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.LocalTopologyManagerImpl.lambda$executeOnCoordinatorAsync$4(LocalTopologyManagerImpl.java:717) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0-internal]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0-internal]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0-internal]
12:57:03,098 INFO  [org.infinispan.CLUSTER] (jgroups-49,fedora-15861) ISPN000094: Received new cluster view for channel results: [fedora-15861|4] (1) [fedora-15861]
12:57:03,103 INFO  [org.infinispan.CLUSTER] (jgroups-49,fedora-15861) ISPN100001: Node fedora-54088 left the cluster
12:57:03,108 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (StopThread) ISPN000080: Disconnecting JGroups channel results
12:57:03,131 INFO  [org.radargun.service.Infinispan90Lifecycle] (StopThread) Stopped, previous view is [fedora-15861, fedora-54088, fedora-43405]
12:57:03,131 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Service successfully stopped.
12:57:03,132 INFO  [org.radargun.Slave] (sc-main) Finished stage ScenarioDestroy
12:57:03,132 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
12:57:03,141 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.service.Infinispan80EmbeddedService.destroy() overrides public void org.radargun.service.Infinispan60EmbeddedService.destroy() but both are declared with @Destroy annotation: calling only once
12:57:03,142 INFO  [org.radargun.Slave] (main) Starting stage ScenarioCleanup
12:57:03,240 INFO  [org.radargun.stages.ScenarioCleanupStage] (main) Memory after cleanup: 
Runtime free: 1,308,622 kb
Runtime max:1,326,592 kb
Runtime total:1,326,592 kb
MX Code Cache(Non-heap memory): used: 15,405 kb, init: 2,496 kb, committed: 15,552 kb, max: 245,760 kb
MX Metaspace(Non-heap memory): used: 38,051 kb, init: 0 kb, committed: 39,980 kb, max: 0 kb
MX Compressed Class Space(Non-heap memory): used: 4,464 kb, init: 0 kb, committed: 4,908 kb, max: 1,048,576 kb
MX PS Eden Space(Heap memory): used: 5,639 kb, init: 350,208 kb, committed: 321,536 kb, max: 321,536 kb
MX PS Survivor Space(Heap memory): used: 0 kb, init: 57,856 kb, committed: 72,192 kb, max: 72,192 kb
MX PS Old Gen(Heap memory): used: 12,330 kb, init: 932,864 kb, committed: 932,864 kb, max: 932,864 kb
12:57:03,241 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
12:57:08,431 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
12:57:12,546 INFO  [org.radargun.Slave] (main) Master shutdown!
