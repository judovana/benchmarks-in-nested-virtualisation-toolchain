14:01:13,589 INFO  [org.radargun.RemoteMasterConnection] (main) Attempting to connect to master results:2103
14:01:13,595 INFO  [org.radargun.RemoteMasterConnection] (main) Successfully established connection with master at: results:2103
14:01:13,597 INFO  [org.radargun.Slave] (main) Received slave index 0
14:01:13,598 INFO  [org.radargun.Slave] (main) Received slave count 3
14:01:13,888 INFO  [org.radargun.ServiceHelper] (sc-main) ServiceContext properties: {}
14:01:14,055 INFO  [org.radargun.Slave] (sc-main) Eager Service Infinispan92EmbeddedService {batching=false, cache=testCache, channelRetrievalTimeout=2 mins 0 secs, enableDiagnostics=null, explicitLocking=false, file=/mnt/workspace/results/dist-sync.xml, internalsExpositionEnabled=false, jgroupsDumperEnabled=false, jgroupsDumperInterval=10.000 secs, keysPerThread=-1, mapReduceDistributedReducePhase=false, mapReduceUseIntermediateSharedCache=false, removedCaches=[  ], threadsPerNode=-1 } loaded.
14:01:15,984 INFO  [org.radargun.Slave] (sc-main) Starting stage ScenarioInit
14:01:16,028 INFO  [org.radargun.Slave] (sc-main) Finished stage ScenarioInit
14:01:16,032 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
14:01:16,110 INFO  [org.radargun.Slave] (sc-main) Starting stage BeforeServiceStart
14:01:16,111 INFO  [org.radargun.Slave] (sc-main) Finished stage BeforeServiceStart
14:01:16,111 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
14:01:16,118 INFO  [org.radargun.Slave] (sc-main) Starting stage ServiceStart
14:01:16,120 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Startup staggering, this is the slave with index 0, not sleeping
14:01:16,120 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 0
14:01:16,123 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) Infinispan version: Infinispan 'Gaina' 9.2.0.Final
14:01:16,136 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) JGroups version: JGroups 4.0.10.Final (Schiener Berg)
14:01:16,883 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (sc-main) ISPN000078: Starting JGroups channel results
14:01:16,971 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the send buffer of socket MulticastSocket was set to 1.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
14:01:16,972 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the receive buffer of socket MulticastSocket was set to 20.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
14:01:16,972 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the send buffer of socket MulticastSocket was set to 1.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
14:01:16,972 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the receive buffer of socket MulticastSocket was set to 25.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
14:01:22,005 INFO  [org.infinispan.CLUSTER] (sc-main) ISPN000094: Received new cluster view for channel results: [fedora-57531|0] (1) [fedora-57531]
14:01:22,063 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (sc-main) ISPN000079: Channel results local address is fedora-57531, physical addresses are [192.168.124.29:59570]
14:01:22,067 INFO  [org.infinispan.factories.GlobalComponentRegistry] (sc-main) ISPN000128: Infinispan version: Infinispan 'Gaina' 9.2.0.Final
14:01:22,741 INFO  [org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup] (sc-main) ISPN000107: Retrieving transaction manager Transaction: unknown
14:01:22,876 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) No RELAY2 protocol in XS service
14:01:22,877 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) No RELAY2 protocol in XS service
14:01:22,879 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) ([fedora-57531(local=true, coord=true)]) Number of members=1 is not the one expected: 3
14:01:22,967 INFO  [org.infinispan.CLUSTER] (jgroups-6,fedora-57531) ISPN000094: Received new cluster view for channel results: [fedora-57531|1] (2) [fedora-57531, fedora-32129]
14:01:22,978 INFO  [org.infinispan.CLUSTER] (jgroups-6,fedora-57531) ISPN100000: Node fedora-32129 joined the cluster
14:01:23,527 INFO  [org.infinispan.CLUSTER] (jgroups-11,fedora-57531) ISPN000094: Received new cluster view for channel results: [fedora-57531|2] (3) [fedora-57531, fedora-32129, fedora-17062]
14:01:23,530 INFO  [org.infinispan.CLUSTER] (jgroups-11,fedora-57531) ISPN100000: Node fedora-17062 joined the cluster
14:01:23,697 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-57531: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-57531: 126, fedora-32129: 130]}, unionCH=null, actualMembers=[fedora-57531, fedora-32129], persistentUUIDs=[7f9f83ab-8f24-464c-8924-c7d87fa3cbe2, ba22fb57-23ce-49c3-aaf8-de7c6cad830d]}
14:01:23,700 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-57531]ISPN100002: Started rebalance with topology id 2
14:01:23,701 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-57531: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-57531: 126, fedora-32129: 130]}, unionCH=null, actualMembers=[fedora-57531, fedora-32129], persistentUUIDs=[7f9f83ab-8f24-464c-8924-c7d87fa3cbe2, ba22fb57-23ce-49c3-aaf8-de7c6cad830d]}
14:01:23,703 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-57531]ISPN100002: Started rebalance with topology id 2
14:01:23,778 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t25) [Context=___counter_configuration][Scope=fedora-57531]ISPN100003: Node fedora-57531 finished rebalance phase with topology id 2
14:01:23,783 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t24) [Context=org.infinispan.CONFIG][Scope=fedora-57531]ISPN100003: Node fedora-57531 finished rebalance phase with topology id 2
14:01:23,880 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) Number of members is the one expected: 3
14:01:23,880 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Successfully started cache service infinispan92/embedded on slave 0
14:01:23,957 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-32129]ISPN100003: Node fedora-32129 finished rebalance phase with topology id 2
14:01:23,959 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 2
14:01:23,952 ERROR [org.radargun.service.ConfigDumpHelper] (sc-main) Error while dumping ___protobuf_metadata cache config as properties
javax.management.AttributeNotFoundException: Unknown attribute 'configurationAsProperties'. Known attributes names are: [rebalancingEnabled, cacheStatus, cacheAvailability, cacheName, version, configurationAsProperties]
	at org.infinispan.jmx.ResourceDMBean.getAttribute(ResourceDMBean.java:181) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:647) ~[?:1.8.0-internal]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:678) ~[?:1.8.0-internal]
	at org.radargun.service.ConfigDumpHelper60.dumpCache(ConfigDumpHelper60.java:44) [plugin-infinispan60-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.service.EmbeddedConfigurationProvider.getNormalizedConfigs(EmbeddedConfigurationProvider.java:33) [plugin-infinispan52-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.stages.lifecycle.ServiceStartStage.executeOnSlave(ServiceStartStage.java:92) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase.scenarioLoop(SlaveBase.java:102) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase$ScenarioRunner.run(SlaveBase.java:203) [radargun-core-3.0.0-SNAPSHOT.jar:?]
14:01:23,972 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t2) [Context=org.infinispan.CONFIG][Scope=fedora-57531]ISPN100003: Node fedora-57531 finished rebalance phase with topology id 3
14:01:23,984 ERROR [org.radargun.service.ConfigDumpHelper] (sc-main) Error while dumping ___protobuf_metadata cache config as properties
javax.management.AttributeNotFoundException: Unknown attribute 'configurationAsProperties'. Known attributes names are: [rebalancingEnabled, cacheStatus, cacheAvailability, cacheName, version, configurationAsProperties]
	at org.infinispan.jmx.ResourceDMBean.getAttribute(ResourceDMBean.java:181) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:647) ~[?:1.8.0-internal]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:678) ~[?:1.8.0-internal]
	at org.radargun.service.ConfigDumpHelper60.dumpCache(ConfigDumpHelper60.java:44) [plugin-infinispan60-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.service.EmbeddedConfigurationProvider.getNormalizedConfigs(EmbeddedConfigurationProvider.java:33) [plugin-infinispan52-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.stages.lifecycle.ServiceStartStage.executeOnSlave(ServiceStartStage.java:92) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase.scenarioLoop(SlaveBase.java:102) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase$ScenarioRunner.run(SlaveBase.java:203) [radargun-core-3.0.0-SNAPSHOT.jar:?]
14:01:24,026 INFO  [org.radargun.Slave] (sc-main) Finished stage ServiceStart
14:01:24,040 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-32129]ISPN100003: Node fedora-32129 finished rebalance phase with topology id 3
14:01:24,044 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=org.infinispan.CONFIG][Scope=fedora-57531]ISPN100003: Node fedora-57531 finished rebalance phase with topology id 4
14:01:24,064 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
14:01:24,067 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-32129]ISPN100003: Node fedora-32129 finished rebalance phase with topology id 2
14:01:24,070 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 2
14:01:24,073 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t10) [Context=___counter_configuration][Scope=fedora-57531]ISPN100003: Node fedora-57531 finished rebalance phase with topology id 3
14:01:24,077 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-32129]ISPN100003: Node fedora-32129 finished rebalance phase with topology id 4
14:01:24,110 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-32129]ISPN100003: Node fedora-32129 finished rebalance phase with topology id 3
14:01:24,114 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t16) [Context=___counter_configuration][Scope=fedora-57531]ISPN100003: Node fedora-57531 finished rebalance phase with topology id 4
14:01:24,170 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-32129]ISPN100003: Node fedora-32129 finished rebalance phase with topology id 4
14:01:24,239 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=DefaultConsistentHash{ns=256, owners = (1)[fedora-57531: 256+0]}, pendingCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-57531: 126+130, fedora-32129: 130+126]}, unionCH=null, actualMembers=[fedora-57531, fedora-32129], persistentUUIDs=[7f9f83ab-8f24-464c-8924-c7d87fa3cbe2, ba22fb57-23ce-49c3-aaf8-de7c6cad830d]}
14:01:24,244 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-57531]ISPN100002: Started rebalance with topology id 2
14:01:24,254 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t1) [Context=___counters][Scope=fedora-57531]ISPN100003: Node fedora-57531 finished rebalance phase with topology id 2
14:01:24,295 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-57531: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-57531: 126, fedora-32129: 130]}, unionCH=null, actualMembers=[fedora-57531, fedora-32129], persistentUUIDs=[7f9f83ab-8f24-464c-8924-c7d87fa3cbe2, ba22fb57-23ce-49c3-aaf8-de7c6cad830d]}
14:01:24,297 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-57531]ISPN100002: Started rebalance with topology id 2
14:01:24,308 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t2) [Context=___protobuf_metadata][Scope=fedora-57531]ISPN100003: Node fedora-57531 finished rebalance phase with topology id 2
14:01:24,368 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=DefaultConsistentHash{ns=512, owners = (1)[fedora-57531: 512+0]}, pendingCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-57531: 254+258, fedora-32129: 258+254]}, unionCH=null, actualMembers=[fedora-57531, fedora-32129], persistentUUIDs=[7f9f83ab-8f24-464c-8924-c7d87fa3cbe2, ba22fb57-23ce-49c3-aaf8-de7c6cad830d]}
14:01:24,368 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-57531]ISPN100002: Started rebalance with topology id 2
14:01:24,374 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t3) [Context=testCache][Scope=fedora-57531]ISPN100003: Node fedora-57531 finished rebalance phase with topology id 2
14:01:24,377 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-32129]ISPN100003: Node fedora-32129 finished rebalance phase with topology id 2
14:01:24,378 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___counters, topology id = 2
14:01:24,379 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t9) [Context=___counters][Scope=fedora-57531]ISPN100003: Node fedora-57531 finished rebalance phase with topology id 3
14:01:24,402 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-32129]ISPN100003: Node fedora-32129 finished rebalance phase with topology id 3
14:01:24,404 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t12) [Context=___counters][Scope=fedora-57531]ISPN100003: Node fedora-57531 finished rebalance phase with topology id 4
14:01:24,408 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-32129]ISPN100003: Node fedora-32129 finished rebalance phase with topology id 2
14:01:24,409 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 2
14:01:24,411 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t15) [Context=___protobuf_metadata][Scope=fedora-57531]ISPN100003: Node fedora-57531 finished rebalance phase with topology id 3
14:01:24,416 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-32129]ISPN100003: Node fedora-32129 finished rebalance phase with topology id 3
14:01:24,419 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-32129]ISPN100003: Node fedora-32129 finished rebalance phase with topology id 4
14:01:24,419 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-32129]ISPN100003: Node fedora-32129 finished rebalance phase with topology id 4
14:01:24,419 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t19) [Context=___protobuf_metadata][Scope=fedora-57531]ISPN100003: Node fedora-57531 finished rebalance phase with topology id 4
14:01:24,447 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-57531: 126, fedora-32129: 130]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-57531: 88, fedora-32129: 84, fedora-17062: 84]}, unionCH=null, actualMembers=[fedora-57531, fedora-32129, fedora-17062], persistentUUIDs=[7f9f83ab-8f24-464c-8924-c7d87fa3cbe2, ba22fb57-23ce-49c3-aaf8-de7c6cad830d, fe55e33f-492f-41d5-8246-1b1569386b4e]}
14:01:24,450 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-57531]ISPN100002: Started rebalance with topology id 6
14:01:24,450 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-57531: 126, fedora-32129: 130]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-57531: 88, fedora-32129: 84, fedora-17062: 84]}, unionCH=null, actualMembers=[fedora-57531, fedora-32129, fedora-17062], persistentUUIDs=[7f9f83ab-8f24-464c-8924-c7d87fa3cbe2, ba22fb57-23ce-49c3-aaf8-de7c6cad830d, fe55e33f-492f-41d5-8246-1b1569386b4e]}
14:01:24,451 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-57531]ISPN100002: Started rebalance with topology id 6
14:01:24,454 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t2) [Context=org.infinispan.CONFIG][Scope=fedora-57531]ISPN100003: Node fedora-57531 finished rebalance phase with topology id 6
14:01:24,455 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=___counter_configuration][Scope=fedora-57531]ISPN100003: Node fedora-57531 finished rebalance phase with topology id 6
14:01:24,472 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-32129]ISPN100003: Node fedora-32129 finished rebalance phase with topology id 6
14:01:24,473 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-32129]ISPN100003: Node fedora-32129 finished rebalance phase with topology id 6
14:01:24,475 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-32129]ISPN100003: Node fedora-32129 finished rebalance phase with topology id 2
14:01:24,475 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache testCache, topology id = 2
14:01:24,478 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t13) [Context=testCache][Scope=fedora-57531]ISPN100003: Node fedora-57531 finished rebalance phase with topology id 3
14:01:24,482 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-32129]ISPN100003: Node fedora-32129 finished rebalance phase with topology id 3
14:01:24,485 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t6) [Context=testCache][Scope=fedora-57531]ISPN100003: Node fedora-57531 finished rebalance phase with topology id 4
14:01:24,489 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-32129]ISPN100003: Node fedora-32129 finished rebalance phase with topology id 4
14:01:24,692 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-17062]ISPN100003: Node fedora-17062 finished rebalance phase with topology id 6
14:01:24,693 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 6
14:01:24,694 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t24) [Context=org.infinispan.CONFIG][Scope=fedora-57531]ISPN100003: Node fedora-57531 finished rebalance phase with topology id 7
14:01:24,695 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-17062]ISPN100003: Node fedora-17062 finished rebalance phase with topology id 6
14:01:24,696 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 6
14:01:24,697 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t19) [Context=___counter_configuration][Scope=fedora-57531]ISPN100003: Node fedora-57531 finished rebalance phase with topology id 7
14:01:24,700 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-32129]ISPN100003: Node fedora-32129 finished rebalance phase with topology id 7
14:01:24,701 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-32129]ISPN100003: Node fedora-32129 finished rebalance phase with topology id 7
14:01:24,702 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=org.infinispan.CONFIG][Scope=fedora-17062]ISPN100003: Node fedora-17062 finished rebalance phase with topology id 7
14:01:24,702 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___counter_configuration][Scope=fedora-17062]ISPN100003: Node fedora-17062 finished rebalance phase with topology id 7
14:01:24,704 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t3) [Context=org.infinispan.CONFIG][Scope=fedora-57531]ISPN100003: Node fedora-57531 finished rebalance phase with topology id 8
14:01:24,704 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t8) [Context=___counter_configuration][Scope=fedora-57531]ISPN100003: Node fedora-57531 finished rebalance phase with topology id 8
14:01:24,706 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=org.infinispan.CONFIG][Scope=fedora-32129]ISPN100003: Node fedora-32129 finished rebalance phase with topology id 8
14:01:24,709 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=org.infinispan.CONFIG][Scope=fedora-17062]ISPN100003: Node fedora-17062 finished rebalance phase with topology id 8
14:01:24,711 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counter_configuration][Scope=fedora-32129]ISPN100003: Node fedora-32129 finished rebalance phase with topology id 8
14:01:24,727 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counter_configuration][Scope=fedora-17062]ISPN100003: Node fedora-17062 finished rebalance phase with topology id 8
14:01:24,745 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-57531: 126+130, fedora-32129: 130+126]}, pendingCH=DefaultConsistentHash{ns=256, owners = (3)[fedora-57531: 88+79, fedora-32129: 84+104, fedora-17062: 84+73]}, unionCH=null, actualMembers=[fedora-57531, fedora-32129, fedora-17062], persistentUUIDs=[7f9f83ab-8f24-464c-8924-c7d87fa3cbe2, ba22fb57-23ce-49c3-aaf8-de7c6cad830d, fe55e33f-492f-41d5-8246-1b1569386b4e]}
14:01:24,745 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=fedora-57531]ISPN100002: Started rebalance with topology id 6
14:01:24,747 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t17) [Context=___counters][Scope=fedora-57531]ISPN100003: Node fedora-57531 finished rebalance phase with topology id 6
14:01:24,750 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=fedora-32129]ISPN100003: Node fedora-32129 finished rebalance phase with topology id 6
14:01:24,772 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=fedora-17062]ISPN100003: Node fedora-17062 finished rebalance phase with topology id 6
14:01:24,772 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000336: Finished cluster-wide rebalance for cache ___counters, topology id = 6
14:01:24,774 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t1) [Context=___counters][Scope=fedora-57531]ISPN100003: Node fedora-57531 finished rebalance phase with topology id 7
14:01:24,777 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=fedora-32129]ISPN100003: Node fedora-32129 finished rebalance phase with topology id 7
14:01:24,781 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=fedora-17062]ISPN100003: Node fedora-17062 finished rebalance phase with topology id 7
14:01:24,783 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t5) [Context=___counters][Scope=fedora-57531]ISPN100003: Node fedora-57531 finished rebalance phase with topology id 8
14:01:24,788 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=fedora-32129]ISPN100003: Node fedora-32129 finished rebalance phase with topology id 8
14:01:24,789 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___counters][Scope=fedora-17062]ISPN100003: Node fedora-17062 finished rebalance phase with topology id 8
14:01:24,827 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-57531: 126, fedora-32129: 130]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-57531: 88, fedora-32129: 84, fedora-17062: 84]}, unionCH=null, actualMembers=[fedora-57531, fedora-32129, fedora-17062], persistentUUIDs=[7f9f83ab-8f24-464c-8924-c7d87fa3cbe2, ba22fb57-23ce-49c3-aaf8-de7c6cad830d, fe55e33f-492f-41d5-8246-1b1569386b4e]}
14:01:24,828 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___protobuf_metadata][Scope=fedora-57531]ISPN100002: Started rebalance with topology id 6
14:01:24,832 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t3) [Context=___protobuf_metadata][Scope=fedora-57531]ISPN100003: Node fedora-57531 finished rebalance phase with topology id 6
14:01:24,836 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___protobuf_metadata][Scope=fedora-32129]ISPN100003: Node fedora-32129 finished rebalance phase with topology id 6
14:01:24,862 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___protobuf_metadata][Scope=fedora-17062]ISPN100003: Node fedora-17062 finished rebalance phase with topology id 6
14:01:24,862 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 6
14:01:24,864 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t9) [Context=___protobuf_metadata][Scope=fedora-57531]ISPN100003: Node fedora-57531 finished rebalance phase with topology id 7
14:01:24,866 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=fedora-17062]ISPN100003: Node fedora-17062 finished rebalance phase with topology id 7
14:01:24,866 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___protobuf_metadata][Scope=fedora-32129]ISPN100003: Node fedora-32129 finished rebalance phase with topology id 7
14:01:24,868 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t14) [Context=___protobuf_metadata][Scope=fedora-57531]ISPN100003: Node fedora-57531 finished rebalance phase with topology id 8
14:01:24,870 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___protobuf_metadata][Scope=fedora-32129]ISPN100003: Node fedora-32129 finished rebalance phase with topology id 8
14:01:24,873 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___protobuf_metadata][Scope=fedora-17062]ISPN100003: Node fedora-17062 finished rebalance phase with topology id 8
14:01:24,888 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-57531: 254+258, fedora-32129: 258+254]}, pendingCH=DefaultConsistentHash{ns=512, owners = (3)[fedora-57531: 170+172, fedora-32129: 174+161, fedora-17062: 168+179]}, unionCH=null, actualMembers=[fedora-57531, fedora-32129, fedora-17062], persistentUUIDs=[7f9f83ab-8f24-464c-8924-c7d87fa3cbe2, ba22fb57-23ce-49c3-aaf8-de7c6cad830d, fe55e33f-492f-41d5-8246-1b1569386b4e]}
14:01:24,888 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=testCache][Scope=fedora-57531]ISPN100002: Started rebalance with topology id 6
14:01:24,892 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t15) [Context=testCache][Scope=fedora-57531]ISPN100003: Node fedora-57531 finished rebalance phase with topology id 6
14:01:24,893 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-32129]ISPN100003: Node fedora-32129 finished rebalance phase with topology id 6
14:01:24,918 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=testCache][Scope=fedora-17062]ISPN100003: Node fedora-17062 finished rebalance phase with topology id 6
14:01:24,918 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) ISPN000336: Finished cluster-wide rebalance for cache testCache, topology id = 6
14:01:24,920 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t22) [Context=testCache][Scope=fedora-57531]ISPN100003: Node fedora-57531 finished rebalance phase with topology id 7
14:01:24,923 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=testCache][Scope=fedora-32129]ISPN100003: Node fedora-32129 finished rebalance phase with topology id 7
14:01:24,925 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=testCache][Scope=fedora-17062]ISPN100003: Node fedora-17062 finished rebalance phase with topology id 7
14:01:24,928 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t16) [Context=testCache][Scope=fedora-57531]ISPN100003: Node fedora-57531 finished rebalance phase with topology id 8
14:01:24,929 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-32129]ISPN100003: Node fedora-32129 finished rebalance phase with topology id 8
14:01:24,929 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=testCache][Scope=fedora-17062]ISPN100003: Node fedora-17062 finished rebalance phase with topology id 8
14:01:25,024 INFO  [org.radargun.Slave] (sc-main) Starting stage AfterServiceStart
14:01:25,024 INFO  [org.radargun.Slave] (sc-main) Finished stage AfterServiceStart
14:01:25,027 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
14:01:25,075 INFO  [org.radargun.Slave] (sc-main) Starting stage MonitorStart
14:01:25,081 INFO  [org.radargun.sysmonitor.AbstractMonitors] (sc-main) Gathering statistics every 1000 ms
14:01:25,081 INFO  [org.radargun.Slave] (sc-main) Finished stage MonitorStart
14:01:25,083 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
14:01:25,137 INFO  [org.radargun.Slave] (sc-main) Starting stage Load
14:01:32,475 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) This node loaded 10000 entries (~10000000 bytes)
14:01:37,612 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) This node loaded 20000 entries (~20000000 bytes)
14:01:41,344 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) This node loaded 30000 entries (~30000000 bytes)
14:01:42,160 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) Finished loading entries
14:01:42,179 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) Finished loading entries
14:01:42,192 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) Finished loading entries
14:01:42,208 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) Finished loading entries
14:01:42,210 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) Finished loading entries
14:01:42,213 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) Finished loading entries
14:01:42,214 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) Finished loading entries
14:01:42,222 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) Finished loading entries
14:01:42,224 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) Finished loading entries
14:01:42,226 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) Finished loading entries
14:01:42,227 INFO  [org.radargun.Slave] (sc-main) Finished stage Load
14:01:42,227 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
14:01:42,255 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.stages.cache.test.BasicOperationsTestStage.init() overrides public void org.radargun.stages.test.TestStage.init() but both are declared with @Init annotation: calling only once
14:01:42,258 INFO  [org.radargun.Slave] (sc-main) Starting stage BasicOperationsTest
14:01:42,259 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using key generator org.radargun.stages.cache.generators.StringKeyGenerator {format=null }
14:01:42,259 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using value generator org.radargun.stages.cache.generators.ByteArrayValueGenerator { }
14:01:42,259 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using cache selector Default { }
14:01:42,260 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Starting test warmup
14:01:42,275 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Started 4 stressor threads.
14:02:42,280 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Finished test. Test duration is: 1 mins 0 secs
14:02:42,282 INFO  [org.radargun.Slave] (sc-main) Finished stage BasicOperationsTest
14:02:42,296 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
14:02:42,340 INFO  [org.radargun.Slave] (sc-main) Starting stage Clear
14:02:42,343 INFO  [org.radargun.stages.cache.ClearStage] (sc-main) Before executing clear, memory looks like this: 
Runtime free: 1,009,541 kb
Runtime max:1,281,536 kb
Runtime total:1,281,536 kb
MX Code Cache(Non-heap memory): used: 12,787 kb, init: 2,496 kb, committed: 13,888 kb, max: 245,760 kb
MX Metaspace(Non-heap memory): used: 37,351 kb, init: 0 kb, committed: 39,212 kb, max: 0 kb
MX Compressed Class Space(Non-heap memory): used: 4,432 kb, init: 0 kb, committed: 4,908 kb, max: 1,048,576 kb
MX PS Eden Space(Heap memory): used: 147,014 kb, init: 350,208 kb, committed: 230,912 kb, max: 230,912 kb
MX PS Survivor Space(Heap memory): used: 78,784 kb, init: 57,856 kb, committed: 117,760 kb, max: 117,760 kb
MX PS Old Gen(Heap memory): used: 46,196 kb, init: 932,864 kb, committed: 932,864 kb, max: 932,864 kb
14:02:42,618 INFO  [org.radargun.stages.cache.ClearStage] (sc-main) After executing clear, memory looks like this: 
Runtime free: 1,178,620 kb
Runtime max:1,243,648 kb
Runtime total:1,192,960 kb
MX Code Cache(Non-heap memory): used: 12,880 kb, init: 2,496 kb, committed: 13,888 kb, max: 245,760 kb
MX Metaspace(Non-heap memory): used: 37,301 kb, init: 0 kb, committed: 39,212 kb, max: 0 kb
MX Compressed Class Space(Non-heap memory): used: 4,409 kb, init: 0 kb, committed: 4,908 kb, max: 1,048,576 kb
MX PS Eden Space(Heap memory): used: 1,814 kb, init: 350,208 kb, committed: 229,888 kb, max: 316,928 kb
MX PS Survivor Space(Heap memory): used: 0 kb, init: 57,856 kb, committed: 30,208 kb, max: 30,208 kb
MX PS Old Gen(Heap memory): used: 12,525 kb, init: 932,864 kb, committed: 932,864 kb, max: 932,864 kb
14:02:42,618 INFO  [org.radargun.Slave] (sc-main) Finished stage Clear
14:02:42,620 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
14:02:42,625 INFO  [org.radargun.Slave] (sc-main) Starting stage Load
14:02:45,890 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) This node loaded 10000 entries (~10000000 bytes)
14:02:49,140 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) This node loaded 20000 entries (~20000000 bytes)
14:02:52,412 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) This node loaded 30000 entries (~30000000 bytes)
14:02:53,373 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) Finished loading entries
14:02:53,381 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) Finished loading entries
14:02:53,382 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) Finished loading entries
14:02:53,389 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) Finished loading entries
14:02:53,396 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) Finished loading entries
14:02:53,398 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) Finished loading entries
14:02:53,414 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) Finished loading entries
14:02:53,416 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) Finished loading entries
14:02:53,419 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) Finished loading entries
14:02:53,424 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) Finished loading entries
14:02:53,425 INFO  [org.radargun.Slave] (sc-main) Finished stage Load
14:02:53,425 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
14:02:53,762 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.stages.cache.test.BasicOperationsTestStage.init() overrides public void org.radargun.stages.test.TestStage.init() but both are declared with @Init annotation: calling only once
14:02:53,763 INFO  [org.radargun.Slave] (sc-main) Starting stage BasicOperationsTest
14:02:53,763 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using key generator org.radargun.stages.cache.generators.StringKeyGenerator {format=null }
14:02:53,765 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using value generator org.radargun.stages.cache.generators.ByteArrayValueGenerator { }
14:02:53,767 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using cache selector Default { }
14:02:53,768 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Starting test stress-test
14:02:53,786 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Started 4 stressor threads.
14:12:53,792 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Finished test. Test duration is: 10 mins 0 secs
14:12:53,793 INFO  [org.radargun.Slave] (sc-main) Finished stage BasicOperationsTest
14:12:53,938 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
14:12:54,209 INFO  [org.radargun.Slave] (sc-main) Starting stage MonitorStop
14:12:54,210 INFO  [org.radargun.Slave] (sc-main) Finished stage MonitorStop
14:12:54,212 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
14:12:54,218 INFO  [org.radargun.Slave] (sc-main) Starting stage ScenarioDestroy
14:12:54,219 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Scenario finished, destroying...
14:12:54,220 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Memory before cleanup: 
Runtime free: 1,165,037 kb
Runtime max:1,328,640 kb
Runtime total:1,328,640 kb
MX Code Cache(Non-heap memory): used: 14,542 kb, init: 2,496 kb, committed: 14,720 kb, max: 245,760 kb
MX Metaspace(Non-heap memory): used: 37,876 kb, init: 0 kb, committed: 39,724 kb, max: 0 kb
MX Compressed Class Space(Non-heap memory): used: 4,444 kb, init: 0 kb, committed: 4,908 kb, max: 1,048,576 kb
MX PS Eden Space(Heap memory): used: 56,416 kb, init: 350,208 kb, committed: 325,632 kb, max: 325,632 kb
MX PS Survivor Space(Heap memory): used: 69,376 kb, init: 57,856 kb, committed: 70,144 kb, max: 70,144 kb
MX PS Old Gen(Heap memory): used: 37,809 kb, init: 932,864 kb, committed: 932,864 kb, max: 932,864 kb
14:12:54,221 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) Stopping service.
14:12:54,230 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t32) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-57531: 250+92, fedora-17062: 262+85]}, pendingCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-57531: 256+256, fedora-17062: 256+256]}, unionCH=null, actualMembers=[fedora-57531, fedora-17062], persistentUUIDs=[7f9f83ab-8f24-464c-8924-c7d87fa3cbe2, fe55e33f-492f-41d5-8246-1b1569386b4e]}
14:12:54,231 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t32) [Context=testCache][Scope=fedora-57531]ISPN100002: Started rebalance with topology id 11
14:12:54,249 WARN  [org.infinispan.CLUSTER] (remote-thread--p2-t34) [Context=testCache]ISPN000312: Lost data because of graceful leaver fedora-17062
14:12:54,292 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t32) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-57531: 132+35, fedora-17062: 124+33]}, pendingCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-57531: 128+128, fedora-17062: 128+128]}, unionCH=null, actualMembers=[fedora-57531, fedora-17062], persistentUUIDs=[7f9f83ab-8f24-464c-8924-c7d87fa3cbe2, fe55e33f-492f-41d5-8246-1b1569386b4e]}
14:12:54,293 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t32) [Context=___counters][Scope=fedora-57531]ISPN100002: Started rebalance with topology id 11
14:12:54,312 ERROR [org.infinispan.statetransfer.StateConsumerImpl] (transport-thread--p4-t2) ISPN000208: No live owners found for segments {4-5 9-12 16-17 20-25 34-41 44-49 53 61-62 67-71 78-81 111-112 115-117 120-124 127-130 143 147-148 152 170 180-182 194-198 206-210 214-217 220-222 231-236 243-244 248-249 255-259 262-266 271-274 288-291 303 310 317-322 325 330 333 337-338 346 353-354 361-362 376-378 382-386 397-398 403 406-413 427-428 431-435 440 447 450-453 460-461 466-472 480-482 493} of cache testCache. Excluded owners: []
14:12:54,316 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t2) [Context=testCache][Scope=fedora-57531]ISPN100003: Node fedora-57531 finished rebalance phase with topology id 12
14:12:54,322 INFO  [org.infinispan.CLUSTER] (jgroups-23,fedora-57531) ISPN000094: Received new cluster view for channel results: [fedora-57531|3] (2) [fedora-57531, fedora-17062]
14:12:54,325 INFO  [org.infinispan.CLUSTER] (jgroups-23,fedora-57531) ISPN100001: Node fedora-32129 left the cluster
14:12:54,324 WARN  [org.infinispan.statetransfer.InboundTransferTask] (stateTransferExecutor-thread--p6-t2) ISPN000210: Failed to request state of cache testCache from node fedora-17062, segments {4-5 9-12 16-17 20-25 34-41 44-49 53 61-62 67-71 78-81 111-112 115-117 120-124 127-130 143 147-148 152 170 180-182 194-198 206-210 214-217 220-222 231-236 243-244 248-249 255-259 262-266 271-274 288-291 303 310 317-322 325 330 333 337-338 346 353-354 361-362 376-378 382-386 397-398 403 406-413 427-428 431-435 440 447 450-453 460-461 466-472 480-482 493}
org.infinispan.remoting.transport.jgroups.SuspectException: ISPN000400: Node fedora-17062 was suspected
	at org.infinispan.remoting.transport.ResponseCollectors.remoteNodeSuspected(ResponseCollectors.java:33) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleResponseCollector.targetNotFound(SingleResponseCollector.java:31) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleResponseCollector.targetNotFound(SingleResponseCollector.java:17) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.ValidSingleResponseCollector.addResponse(ValidSingleResponseCollector.java:23) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleTargetRequest.receiveResponse(SingleTargetRequest.java:51) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleTargetRequest.onResponse(SingleTargetRequest.java:35) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.RequestRepository.addResponse(RequestRepository.java:53) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.processResponse(JGroupsTransport.java:1302) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.processMessage(JGroupsTransport.java:1205) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.access$200(JGroupsTransport.java:123) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport$ChannelCallbacks.receive(JGroupsTransport.java:1340) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.jgroups.JChannel.up(JChannel.java:819) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.stack.ProtocolStack.up(ProtocolStack.java:893) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FRAG3.up(FRAG3.java:171) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FlowControl.up(FlowControl.java:343) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FlowControl.up(FlowControl.java:343) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.GMS.up(GMS.java:864) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.STABLE.up(STABLE.java:240) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.deliverMessage(UNICAST3.java:1002) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.handleDataReceived(UNICAST3.java:728) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.up(UNICAST3.java:383) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.NAKACK2.up(NAKACK2.java:600) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.VERIFY_SUSPECT.up(VERIFY_SUSPECT.java:119) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FD_ALL.up(FD_ALL.java:199) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FD_SOCK.up(FD_SOCK.java:252) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.MERGE3.up(MERGE3.java:276) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.Discovery.up(Discovery.java:267) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.TP.passMessageUp(TP.java:1248) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.util.SubmitToThreadPool$SingleMessageHandler.run(SubmitToThreadPool.java:87) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0-internal]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0-internal]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0-internal]
14:12:54,331 WARN  [org.infinispan.CLUSTER] (StopThread) [Context=___counters]ISPN000312: Lost data because of graceful leaver fedora-57531
14:12:54,358 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t32) [Context=___counters][Scope=fedora-17062]ISPN100003: Node fedora-17062 finished rebalance phase with topology id 11
14:12:54,359 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (remote-thread--p2-t32) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___counters, type=REBALANCE_PHASE_CONFIRM, sender=fedora-17062, joinInfo=null, topologyId=11, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-17062 for cache ___counters, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.invokeReplicableCommand(GlobalInboundInvocationHandler.java:169) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.runReplicableCommand(GlobalInboundInvocationHandler.java:150) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.lambda$handleReplicableCommand$1(GlobalInboundInvocationHandler.java:144) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.util.concurrent.BlockingTaskAwareExecutorServiceImpl$RunnableWrapper.run(BlockingTaskAwareExecutorServiceImpl.java:212) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0-internal]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0-internal]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0-internal]
14:12:54,370 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (StopThread) ISPN000080: Disconnecting JGroups channel results
14:12:54,423 WARN  [org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler] (remote-thread--p2-t32) ISPN000219: Shutdown while handling command CacheTopologyControlCommand{cache=___counters, type=LEAVE, sender=fedora-17062, joinInfo=null, topologyId=0, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
14:12:54,427 INFO  [org.radargun.service.Infinispan90Lifecycle] (StopThread) Stopped, previous view is [fedora-57531, fedora-32129, fedora-17062]
14:12:54,428 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Service successfully stopped.
14:12:54,428 INFO  [org.radargun.Slave] (sc-main) Finished stage ScenarioDestroy
14:12:54,428 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
14:12:54,456 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.service.Infinispan80EmbeddedService.destroy() overrides public void org.radargun.service.Infinispan60EmbeddedService.destroy() but both are declared with @Destroy annotation: calling only once
14:12:54,459 INFO  [org.radargun.Slave] (main) Starting stage ScenarioCleanup
14:12:54,542 INFO  [org.radargun.stages.ScenarioCleanupStage] (main) Memory after cleanup: 
Runtime free: 1,308,154 kb
Runtime max:1,327,616 kb
Runtime total:1,327,616 kb
MX Code Cache(Non-heap memory): used: 14,681 kb, init: 2,496 kb, committed: 14,848 kb, max: 245,760 kb
MX Metaspace(Non-heap memory): used: 37,985 kb, init: 0 kb, committed: 39,980 kb, max: 0 kb
MX Compressed Class Space(Non-heap memory): used: 4,465 kb, init: 0 kb, committed: 4,908 kb, max: 1,048,576 kb
MX PS Eden Space(Heap memory): used: 7,011 kb, init: 350,208 kb, committed: 324,608 kb, max: 325,120 kb
MX PS Survivor Space(Heap memory): used: 0 kb, init: 57,856 kb, committed: 70,144 kb, max: 70,144 kb
MX PS Old Gen(Heap memory): used: 12,449 kb, init: 932,864 kb, committed: 932,864 kb, max: 932,864 kb
14:12:54,544 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
14:12:59,748 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
14:13:04,151 INFO  [org.radargun.Slave] (main) Master shutdown!
14:13:04,157 INFO  [org.radargun.ShutDownHook] (Thread-0) Slave process is being shutdown
