19:13:49,039 INFO  [org.radargun.RemoteMasterConnection] (main) Attempting to connect to master results:2103
19:13:49,045 INFO  [org.radargun.RemoteMasterConnection] (main) Successfully established connection with master at: results:2103
19:13:49,047 INFO  [org.radargun.Slave] (main) Received slave index 0
19:13:49,047 INFO  [org.radargun.Slave] (main) Received slave count 3
19:13:49,352 INFO  [org.radargun.ServiceHelper] (sc-main) ServiceContext properties: {}
19:13:49,480 INFO  [org.radargun.Slave] (sc-main) Eager Service Infinispan92EmbeddedService {batching=false, cache=testCache, channelRetrievalTimeout=2 mins 0 secs, enableDiagnostics=null, explicitLocking=false, file=/mnt/workspace/results/dist-sync.xml, internalsExpositionEnabled=false, jgroupsDumperEnabled=false, jgroupsDumperInterval=10.000 secs, keysPerThread=-1, mapReduceDistributedReducePhase=false, mapReduceUseIntermediateSharedCache=false, removedCaches=[  ], threadsPerNode=-1 } loaded.
19:13:52,125 INFO  [org.radargun.Slave] (sc-main) Starting stage ScenarioInit
19:13:52,701 INFO  [org.radargun.Slave] (sc-main) Finished stage ScenarioInit
19:13:52,710 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
19:13:52,723 INFO  [org.radargun.Slave] (sc-main) Starting stage BeforeServiceStart
19:13:52,724 INFO  [org.radargun.Slave] (sc-main) Finished stage BeforeServiceStart
19:13:52,725 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
19:13:52,741 INFO  [org.radargun.Slave] (sc-main) Starting stage ServiceStart
19:13:52,741 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Startup staggering, this is the slave with index 0, not sleeping
19:13:52,743 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 0
19:13:52,746 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) Infinispan version: Infinispan 'Gaina' 9.2.0.Final
19:13:52,759 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) JGroups version: JGroups 4.0.10.Final (Schiener Berg)
19:13:53,340 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (sc-main) ISPN000078: Starting JGroups channel results
19:13:53,438 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the send buffer of socket MulticastSocket was set to 1.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
19:13:53,439 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the receive buffer of socket MulticastSocket was set to 20.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
19:13:53,439 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the send buffer of socket MulticastSocket was set to 1.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
19:13:53,440 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the receive buffer of socket MulticastSocket was set to 25.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
19:13:58,461 INFO  [org.infinispan.CLUSTER] (sc-main) ISPN000094: Received new cluster view for channel results: [fedora-11194|0] (1) [fedora-11194]
19:13:58,538 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (sc-main) ISPN000079: Channel results local address is fedora-11194, physical addresses are [192.168.124.236:59397]
19:13:58,553 INFO  [org.infinispan.factories.GlobalComponentRegistry] (sc-main) ISPN000128: Infinispan version: Infinispan 'Gaina' 9.2.0.Final
19:13:59,418 INFO  [org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup] (sc-main) ISPN000107: Retrieving transaction manager Transaction: unknown
19:13:59,422 INFO  [org.infinispan.CLUSTER] (jgroups-6,fedora-11194) ISPN000094: Received new cluster view for channel results: [fedora-11194|1] (2) [fedora-11194, fedora-36407]
19:13:59,437 INFO  [org.infinispan.CLUSTER] (jgroups-6,fedora-11194) ISPN100000: Node fedora-36407 joined the cluster
19:13:59,556 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) No RELAY2 protocol in XS service
19:13:59,557 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) No RELAY2 protocol in XS service
19:13:59,562 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) ([fedora-11194(local=true, coord=true), fedora-36407(local=false, coord=false)]) Number of members=2 is not the one expected: 3
19:14:00,071 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-11194: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-11194: 126, fedora-36407: 130]}, unionCH=null, actualMembers=[fedora-11194, fedora-36407], persistentUUIDs=[d20d1488-2d5b-49cb-b1e9-4462be8b1ccf, 20b99b3a-01ef-49bf-9b6c-abf523311c6f]}
19:14:00,074 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-11194]ISPN100002: Started rebalance with topology id 2
19:14:00,091 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=___counter_configuration][Scope=fedora-11194]ISPN100003: Node fedora-11194 finished rebalance phase with topology id 2
19:14:00,096 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-11194: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-11194: 126, fedora-36407: 130]}, unionCH=null, actualMembers=[fedora-11194, fedora-36407], persistentUUIDs=[d20d1488-2d5b-49cb-b1e9-4462be8b1ccf, 20b99b3a-01ef-49bf-9b6c-abf523311c6f]}
19:14:00,096 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-11194]ISPN100002: Started rebalance with topology id 2
19:14:00,100 INFO  [org.infinispan.CLUSTER] (jgroups-11,fedora-11194) ISPN000094: Received new cluster view for channel results: [fedora-11194|2] (3) [fedora-11194, fedora-36407, fedora-45103]
19:14:00,109 INFO  [org.infinispan.CLUSTER] (jgroups-11,fedora-11194) ISPN100000: Node fedora-45103 joined the cluster
19:14:00,124 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t25) [Context=org.infinispan.CONFIG][Scope=fedora-11194]ISPN100003: Node fedora-11194 finished rebalance phase with topology id 2
19:14:00,266 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-36407]ISPN100003: Node fedora-36407 finished rebalance phase with topology id 2
19:14:00,268 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 2
19:14:00,278 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t6) [Context=___counter_configuration][Scope=fedora-11194]ISPN100003: Node fedora-11194 finished rebalance phase with topology id 3
19:14:00,283 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-36407]ISPN100003: Node fedora-36407 finished rebalance phase with topology id 2
19:14:00,284 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 2
19:14:00,285 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t5) [Context=org.infinispan.CONFIG][Scope=fedora-11194]ISPN100003: Node fedora-11194 finished rebalance phase with topology id 3
19:14:00,288 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-36407]ISPN100003: Node fedora-36407 finished rebalance phase with topology id 3
19:14:00,288 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-36407]ISPN100003: Node fedora-36407 finished rebalance phase with topology id 3
19:14:00,291 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t10) [Context=org.infinispan.CONFIG][Scope=fedora-11194]ISPN100003: Node fedora-11194 finished rebalance phase with topology id 4
19:14:00,291 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t9) [Context=___counter_configuration][Scope=fedora-11194]ISPN100003: Node fedora-11194 finished rebalance phase with topology id 4
19:14:00,296 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-36407]ISPN100003: Node fedora-36407 finished rebalance phase with topology id 4
19:14:00,299 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-36407]ISPN100003: Node fedora-36407 finished rebalance phase with topology id 4
19:14:00,338 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=DefaultConsistentHash{ns=256, owners = (1)[fedora-11194: 256+0]}, pendingCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-11194: 126+130, fedora-36407: 130+126]}, unionCH=null, actualMembers=[fedora-11194, fedora-36407], persistentUUIDs=[d20d1488-2d5b-49cb-b1e9-4462be8b1ccf, 20b99b3a-01ef-49bf-9b6c-abf523311c6f]}
19:14:00,338 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-11194]ISPN100002: Started rebalance with topology id 2
19:14:00,343 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=___counters][Scope=fedora-11194]ISPN100003: Node fedora-11194 finished rebalance phase with topology id 2
19:14:00,378 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-36407]ISPN100003: Node fedora-36407 finished rebalance phase with topology id 2
19:14:00,392 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache ___counters, topology id = 2
19:14:00,395 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t24) [Context=___counters][Scope=fedora-11194]ISPN100003: Node fedora-11194 finished rebalance phase with topology id 3
19:14:00,404 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-36407]ISPN100003: Node fedora-36407 finished rebalance phase with topology id 3
19:14:00,415 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t3) [Context=___counters][Scope=fedora-11194]ISPN100003: Node fedora-11194 finished rebalance phase with topology id 4
19:14:00,427 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-36407]ISPN100003: Node fedora-36407 finished rebalance phase with topology id 4
19:14:00,524 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-11194: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-11194: 126, fedora-36407: 130]}, unionCH=null, actualMembers=[fedora-11194, fedora-36407], persistentUUIDs=[d20d1488-2d5b-49cb-b1e9-4462be8b1ccf, 20b99b3a-01ef-49bf-9b6c-abf523311c6f]}
19:14:00,525 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-11194]ISPN100002: Started rebalance with topology id 2
19:14:00,532 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t14) [Context=___protobuf_metadata][Scope=fedora-11194]ISPN100003: Node fedora-11194 finished rebalance phase with topology id 2
19:14:00,546 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-36407]ISPN100003: Node fedora-36407 finished rebalance phase with topology id 2
19:14:00,547 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 2
19:14:00,550 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t16) [Context=___protobuf_metadata][Scope=fedora-11194]ISPN100003: Node fedora-11194 finished rebalance phase with topology id 3
19:14:00,556 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-36407]ISPN100003: Node fedora-36407 finished rebalance phase with topology id 3
19:14:00,558 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=___protobuf_metadata][Scope=fedora-11194]ISPN100003: Node fedora-11194 finished rebalance phase with topology id 4
19:14:00,561 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-36407]ISPN100003: Node fedora-36407 finished rebalance phase with topology id 4
19:14:00,562 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) Number of members is the one expected: 3
19:14:00,563 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Successfully started cache service infinispan92/embedded on slave 0
19:14:00,584 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=DefaultConsistentHash{ns=512, owners = (1)[fedora-11194: 512+0]}, pendingCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-11194: 251+261, fedora-36407: 261+251]}, unionCH=null, actualMembers=[fedora-11194, fedora-36407], persistentUUIDs=[d20d1488-2d5b-49cb-b1e9-4462be8b1ccf, 20b99b3a-01ef-49bf-9b6c-abf523311c6f]}
19:14:00,585 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-11194]ISPN100002: Started rebalance with topology id 2
19:14:00,591 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t25) [Context=testCache][Scope=fedora-11194]ISPN100003: Node fedora-11194 finished rebalance phase with topology id 2
19:14:00,628 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-36407]ISPN100003: Node fedora-36407 finished rebalance phase with topology id 2
19:14:00,629 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache testCache, topology id = 2
19:14:00,631 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t4) [Context=testCache][Scope=fedora-11194]ISPN100003: Node fedora-11194 finished rebalance phase with topology id 3
19:14:00,625 ERROR [org.radargun.service.ConfigDumpHelper] (sc-main) Error while dumping ___protobuf_metadata cache config as properties
javax.management.AttributeNotFoundException: Unknown attribute 'configurationAsProperties'. Known attributes names are: [rebalancingEnabled, cacheStatus, cacheAvailability, cacheName, version, configurationAsProperties]
	at org.infinispan.jmx.ResourceDMBean.getAttribute(ResourceDMBean.java:181) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:647) ~[?:1.8.0_372-internal]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:678) ~[?:1.8.0_372-internal]
	at org.radargun.service.ConfigDumpHelper60.dumpCache(ConfigDumpHelper60.java:44) [plugin-infinispan60-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.service.EmbeddedConfigurationProvider.getNormalizedConfigs(EmbeddedConfigurationProvider.java:33) [plugin-infinispan52-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.stages.lifecycle.ServiceStartStage.executeOnSlave(ServiceStartStage.java:92) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase.scenarioLoop(SlaveBase.java:102) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase$ScenarioRunner.run(SlaveBase.java:203) [radargun-core-3.0.0-SNAPSHOT.jar:?]
19:14:00,637 ERROR [org.radargun.service.ConfigDumpHelper] (sc-main) Error while dumping ___protobuf_metadata cache config as properties
javax.management.AttributeNotFoundException: Unknown attribute 'configurationAsProperties'. Known attributes names are: [rebalancingEnabled, cacheStatus, cacheAvailability, cacheName, version, configurationAsProperties]
	at org.infinispan.jmx.ResourceDMBean.getAttribute(ResourceDMBean.java:181) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:647) ~[?:1.8.0_372-internal]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:678) ~[?:1.8.0_372-internal]
	at org.radargun.service.ConfigDumpHelper60.dumpCache(ConfigDumpHelper60.java:44) [plugin-infinispan60-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.service.EmbeddedConfigurationProvider.getNormalizedConfigs(EmbeddedConfigurationProvider.java:33) [plugin-infinispan52-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.stages.lifecycle.ServiceStartStage.executeOnSlave(ServiceStartStage.java:92) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase.scenarioLoop(SlaveBase.java:102) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase$ScenarioRunner.run(SlaveBase.java:203) [radargun-core-3.0.0-SNAPSHOT.jar:?]
19:14:00,645 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-36407]ISPN100003: Node fedora-36407 finished rebalance phase with topology id 3
19:14:00,656 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t3) [Context=testCache][Scope=fedora-11194]ISPN100003: Node fedora-11194 finished rebalance phase with topology id 4
19:14:00,658 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-36407]ISPN100003: Node fedora-36407 finished rebalance phase with topology id 4
19:14:00,721 INFO  [org.radargun.Slave] (sc-main) Finished stage ServiceStart
19:14:00,730 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
19:14:00,946 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-11194: 126, fedora-36407: 130]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-11194: 88, fedora-36407: 90, fedora-45103: 78]}, unionCH=null, actualMembers=[fedora-11194, fedora-36407, fedora-45103], persistentUUIDs=[d20d1488-2d5b-49cb-b1e9-4462be8b1ccf, 20b99b3a-01ef-49bf-9b6c-abf523311c6f, f17a4f8d-830c-452d-8012-0b460933f161]}
19:14:00,948 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-11194]ISPN100002: Started rebalance with topology id 6
19:14:00,947 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-11194: 126, fedora-36407: 130]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-11194: 88, fedora-36407: 90, fedora-45103: 78]}, unionCH=null, actualMembers=[fedora-11194, fedora-36407, fedora-45103], persistentUUIDs=[d20d1488-2d5b-49cb-b1e9-4462be8b1ccf, 20b99b3a-01ef-49bf-9b6c-abf523311c6f, f17a4f8d-830c-452d-8012-0b460933f161]}
19:14:00,953 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-11194]ISPN100002: Started rebalance with topology id 6
19:14:00,954 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t9) [Context=___counter_configuration][Scope=fedora-11194]ISPN100003: Node fedora-11194 finished rebalance phase with topology id 6
19:14:00,951 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=org.infinispan.CONFIG][Scope=fedora-36407]ISPN100003: Node fedora-36407 finished rebalance phase with topology id 6
19:14:00,959 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t14) [Context=org.infinispan.CONFIG][Scope=fedora-11194]ISPN100003: Node fedora-11194 finished rebalance phase with topology id 6
19:14:00,960 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counter_configuration][Scope=fedora-36407]ISPN100003: Node fedora-36407 finished rebalance phase with topology id 6
19:14:01,083 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counter_configuration][Scope=fedora-45103]ISPN100003: Node fedora-45103 finished rebalance phase with topology id 6
19:14:01,083 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 6
19:14:01,085 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=___counter_configuration][Scope=fedora-11194]ISPN100003: Node fedora-11194 finished rebalance phase with topology id 7
19:14:01,088 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counter_configuration][Scope=fedora-36407]ISPN100003: Node fedora-36407 finished rebalance phase with topology id 7
19:14:01,091 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counter_configuration][Scope=fedora-45103]ISPN100003: Node fedora-45103 finished rebalance phase with topology id 7
19:14:01,093 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=org.infinispan.CONFIG][Scope=fedora-45103]ISPN100003: Node fedora-45103 finished rebalance phase with topology id 6
19:14:01,093 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 6
19:14:01,092 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t19) [Context=___counter_configuration][Scope=fedora-11194]ISPN100003: Node fedora-11194 finished rebalance phase with topology id 8
19:14:01,095 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t25) [Context=org.infinispan.CONFIG][Scope=fedora-11194]ISPN100003: Node fedora-11194 finished rebalance phase with topology id 7
19:14:01,095 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counter_configuration][Scope=fedora-36407]ISPN100003: Node fedora-36407 finished rebalance phase with topology id 8
19:14:01,097 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-45103]ISPN100003: Node fedora-45103 finished rebalance phase with topology id 8
19:14:01,097 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=org.infinispan.CONFIG][Scope=fedora-36407]ISPN100003: Node fedora-36407 finished rebalance phase with topology id 7
19:14:01,101 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-45103]ISPN100003: Node fedora-45103 finished rebalance phase with topology id 7
19:14:01,103 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t8) [Context=org.infinispan.CONFIG][Scope=fedora-11194]ISPN100003: Node fedora-11194 finished rebalance phase with topology id 8
19:14:01,105 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-36407]ISPN100003: Node fedora-36407 finished rebalance phase with topology id 8
19:14:01,111 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-45103]ISPN100003: Node fedora-45103 finished rebalance phase with topology id 8
19:14:01,124 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-11194: 126+130, fedora-36407: 130+126]}, pendingCH=DefaultConsistentHash{ns=256, owners = (3)[fedora-11194: 88+100, fedora-36407: 90+82, fedora-45103: 78+74]}, unionCH=null, actualMembers=[fedora-11194, fedora-36407, fedora-45103], persistentUUIDs=[d20d1488-2d5b-49cb-b1e9-4462be8b1ccf, 20b99b3a-01ef-49bf-9b6c-abf523311c6f, f17a4f8d-830c-452d-8012-0b460933f161]}
19:14:01,124 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-11194]ISPN100002: Started rebalance with topology id 6
19:14:01,127 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t10) [Context=___counters][Scope=fedora-11194]ISPN100003: Node fedora-11194 finished rebalance phase with topology id 6
19:14:01,130 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=fedora-36407]ISPN100003: Node fedora-36407 finished rebalance phase with topology id 6
19:14:01,161 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=fedora-45103]ISPN100003: Node fedora-45103 finished rebalance phase with topology id 6
19:14:01,161 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000336: Finished cluster-wide rebalance for cache ___counters, topology id = 6
19:14:01,164 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t17) [Context=___counters][Scope=fedora-11194]ISPN100003: Node fedora-11194 finished rebalance phase with topology id 7
19:14:01,168 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=fedora-45103]ISPN100003: Node fedora-45103 finished rebalance phase with topology id 7
19:14:01,168 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-36407]ISPN100003: Node fedora-36407 finished rebalance phase with topology id 7
19:14:01,172 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t22) [Context=___counters][Scope=fedora-11194]ISPN100003: Node fedora-11194 finished rebalance phase with topology id 8
19:14:01,176 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-36407]ISPN100003: Node fedora-36407 finished rebalance phase with topology id 8
19:14:01,195 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-45103]ISPN100003: Node fedora-45103 finished rebalance phase with topology id 8
19:14:01,271 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-11194: 126, fedora-36407: 130]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-11194: 88, fedora-36407: 90, fedora-45103: 78]}, unionCH=null, actualMembers=[fedora-11194, fedora-36407, fedora-45103], persistentUUIDs=[d20d1488-2d5b-49cb-b1e9-4462be8b1ccf, 20b99b3a-01ef-49bf-9b6c-abf523311c6f, f17a4f8d-830c-452d-8012-0b460933f161]}
19:14:01,272 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-11194]ISPN100002: Started rebalance with topology id 6
19:14:01,275 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t24) [Context=___protobuf_metadata][Scope=fedora-11194]ISPN100003: Node fedora-11194 finished rebalance phase with topology id 6
19:14:01,278 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-36407]ISPN100003: Node fedora-36407 finished rebalance phase with topology id 6
19:14:01,314 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-11194: 251+261, fedora-36407: 261+251]}, pendingCH=DefaultConsistentHash{ns=512, owners = (3)[fedora-11194: 166+180, fedora-36407: 180+164, fedora-45103: 166+168]}, unionCH=null, actualMembers=[fedora-11194, fedora-36407, fedora-45103], persistentUUIDs=[d20d1488-2d5b-49cb-b1e9-4462be8b1ccf, 20b99b3a-01ef-49bf-9b6c-abf523311c6f, f17a4f8d-830c-452d-8012-0b460933f161]}
19:14:01,314 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-11194]ISPN100002: Started rebalance with topology id 6
19:14:01,318 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=testCache][Scope=fedora-11194]ISPN100003: Node fedora-11194 finished rebalance phase with topology id 6
19:14:01,320 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-36407]ISPN100003: Node fedora-36407 finished rebalance phase with topology id 6
19:14:01,318 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-45103]ISPN100003: Node fedora-45103 finished rebalance phase with topology id 6
19:14:01,326 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 6
19:14:01,329 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t8) [Context=___protobuf_metadata][Scope=fedora-11194]ISPN100003: Node fedora-11194 finished rebalance phase with topology id 7
19:14:01,331 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-36407]ISPN100003: Node fedora-36407 finished rebalance phase with topology id 7
19:14:01,334 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-45103]ISPN100003: Node fedora-45103 finished rebalance phase with topology id 7
19:14:01,336 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t15) [Context=___protobuf_metadata][Scope=fedora-11194]ISPN100003: Node fedora-11194 finished rebalance phase with topology id 8
19:14:01,340 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-36407]ISPN100003: Node fedora-36407 finished rebalance phase with topology id 8
19:14:01,343 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-45103]ISPN100003: Node fedora-45103 finished rebalance phase with topology id 8
19:14:01,356 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-45103]ISPN100003: Node fedora-45103 finished rebalance phase with topology id 6
19:14:01,356 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache testCache, topology id = 6
19:14:01,358 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t12) [Context=testCache][Scope=fedora-11194]ISPN100003: Node fedora-11194 finished rebalance phase with topology id 7
19:14:01,360 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-45103]ISPN100003: Node fedora-45103 finished rebalance phase with topology id 7
19:14:01,360 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-36407]ISPN100003: Node fedora-36407 finished rebalance phase with topology id 7
19:14:01,362 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=testCache][Scope=fedora-11194]ISPN100003: Node fedora-11194 finished rebalance phase with topology id 8
19:14:01,368 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-36407]ISPN100003: Node fedora-36407 finished rebalance phase with topology id 8
19:14:01,370 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-45103]ISPN100003: Node fedora-45103 finished rebalance phase with topology id 8
19:14:01,466 INFO  [org.radargun.Slave] (sc-main) Starting stage AfterServiceStart
19:14:01,467 INFO  [org.radargun.Slave] (sc-main) Finished stage AfterServiceStart
19:14:01,469 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
19:14:01,537 INFO  [org.radargun.Slave] (sc-main) Starting stage MonitorStart
19:14:01,548 INFO  [org.radargun.sysmonitor.AbstractMonitors] (sc-main) Gathering statistics every 1000 ms
19:14:01,548 INFO  [org.radargun.Slave] (sc-main) Finished stage MonitorStart
19:14:01,549 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
19:14:01,615 INFO  [org.radargun.Slave] (sc-main) Starting stage Load
19:14:10,290 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) This node loaded 10000 entries (~10000000 bytes)
19:14:14,095 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) This node loaded 20000 entries (~20000000 bytes)
19:14:17,845 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) This node loaded 30000 entries (~30000000 bytes)
19:14:18,877 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) Finished loading entries
19:14:18,913 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) Finished loading entries
19:14:18,924 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) Finished loading entries
19:14:18,939 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) Finished loading entries
19:14:18,941 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) Finished loading entries
19:14:18,944 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) Finished loading entries
19:14:18,952 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) Finished loading entries
19:14:18,966 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) Finished loading entries
19:14:18,968 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) Finished loading entries
19:14:18,973 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) Finished loading entries
19:14:18,974 INFO  [org.radargun.Slave] (sc-main) Finished stage Load
19:14:18,975 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
19:14:19,002 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.stages.cache.test.BasicOperationsTestStage.init() overrides public void org.radargun.stages.test.TestStage.init() but both are declared with @Init annotation: calling only once
19:14:19,006 INFO  [org.radargun.Slave] (sc-main) Starting stage BasicOperationsTest
19:14:19,010 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using key generator org.radargun.stages.cache.generators.StringKeyGenerator {format=null }
19:14:19,010 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using value generator org.radargun.stages.cache.generators.ByteArrayValueGenerator { }
19:14:19,010 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using cache selector Default { }
19:14:19,011 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Starting test warmup
19:14:19,023 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Started 4 stressor threads.
19:15:19,043 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Finished test. Test duration is: 1 mins 0 secs
19:15:19,045 INFO  [org.radargun.Slave] (sc-main) Finished stage BasicOperationsTest
19:15:19,054 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
19:15:19,066 INFO  [org.radargun.Slave] (sc-main) Starting stage Clear
19:15:19,069 INFO  [org.radargun.stages.cache.ClearStage] (sc-main) Before executing clear, memory looks like this: 
Runtime free: 1,054,576 kb
Runtime max:1,297,408 kb
Runtime total:1,297,408 kb
MX Code Cache(Non-heap memory): used: 13,430 kb, init: 2,496 kb, committed: 14,080 kb, max: 245,760 kb
MX Metaspace(Non-heap memory): used: 37,914 kb, init: 0 kb, committed: 39,756 kb, max: 0 kb
MX Compressed Class Space(Non-heap memory): used: 4,584 kb, init: 0 kb, committed: 4,940 kb, max: 1,048,576 kb
MX PS Eden Space(Heap memory): used: 83,709 kb, init: 350,208 kb, committed: 268,288 kb, max: 275,968 kb
MX PS Survivor Space(Heap memory): used: 53,472 kb, init: 57,856 kb, committed: 96,256 kb, max: 96,256 kb
MX PS Old Gen(Heap memory): used: 105,650 kb, init: 932,864 kb, committed: 932,864 kb, max: 932,864 kb
19:15:19,395 INFO  [org.radargun.stages.cache.ClearStage] (sc-main) After executing clear, memory looks like this: 
Runtime free: 1,292,964 kb
Runtime max:1,307,136 kb
Runtime total:1,307,136 kb
MX Code Cache(Non-heap memory): used: 13,529 kb, init: 2,496 kb, committed: 14,080 kb, max: 245,760 kb
MX Metaspace(Non-heap memory): used: 37,853 kb, init: 0 kb, committed: 39,756 kb, max: 0 kb
MX Compressed Class Space(Non-heap memory): used: 4,557 kb, init: 0 kb, committed: 4,940 kb, max: 1,048,576 kb
MX PS Eden Space(Heap memory): used: 1,588 kb, init: 350,208 kb, committed: 280,576 kb, max: 280,576 kb
MX PS Survivor Space(Heap memory): used: 0 kb, init: 57,856 kb, committed: 93,696 kb, max: 93,696 kb
MX PS Old Gen(Heap memory): used: 12,596 kb, init: 932,864 kb, committed: 932,864 kb, max: 932,864 kb
19:15:19,400 INFO  [org.radargun.Slave] (sc-main) Finished stage Clear
19:15:19,400 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
19:15:19,405 INFO  [org.radargun.Slave] (sc-main) Starting stage Load
19:15:22,832 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) This node loaded 10000 entries (~10000000 bytes)
19:15:25,978 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) This node loaded 20000 entries (~20000000 bytes)
19:15:29,031 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) This node loaded 30000 entries (~30000000 bytes)
19:15:29,871 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) Finished loading entries
19:15:30,059 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) Finished loading entries
19:15:30,096 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) Finished loading entries
19:15:30,110 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) Finished loading entries
19:15:30,115 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) Finished loading entries
19:15:30,125 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) Finished loading entries
19:15:30,140 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) Finished loading entries
19:15:30,144 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) Finished loading entries
19:15:30,153 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) Finished loading entries
19:15:30,165 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) Finished loading entries
19:15:30,165 INFO  [org.radargun.Slave] (sc-main) Finished stage Load
19:15:30,165 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
19:15:30,686 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.stages.cache.test.BasicOperationsTestStage.init() overrides public void org.radargun.stages.test.TestStage.init() but both are declared with @Init annotation: calling only once
19:15:30,687 INFO  [org.radargun.Slave] (sc-main) Starting stage BasicOperationsTest
19:15:30,687 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using key generator org.radargun.stages.cache.generators.StringKeyGenerator {format=null }
19:15:30,687 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using value generator org.radargun.stages.cache.generators.ByteArrayValueGenerator { }
19:15:30,688 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using cache selector Default { }
19:15:30,688 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Starting test stress-test
19:15:30,704 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Started 4 stressor threads.
19:25:30,714 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Finished test. Test duration is: 10 mins 0 secs
19:25:30,715 INFO  [org.radargun.Slave] (sc-main) Finished stage BasicOperationsTest
19:25:30,892 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
19:25:31,073 INFO  [org.radargun.Slave] (sc-main) Starting stage MonitorStop
19:25:31,074 INFO  [org.radargun.Slave] (sc-main) Finished stage MonitorStop
19:25:31,074 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
19:25:31,081 INFO  [org.radargun.Slave] (sc-main) Starting stage ScenarioDestroy
19:25:31,081 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Scenario finished, destroying...
19:25:31,086 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Memory before cleanup: 
Runtime free: 932,537 kb
Runtime max:1,328,128 kb
Runtime total:1,328,128 kb
MX Code Cache(Non-heap memory): used: 15,019 kb, init: 2,496 kb, committed: 15,232 kb, max: 245,760 kb
MX Metaspace(Non-heap memory): used: 38,436 kb, init: 0 kb, committed: 40,396 kb, max: 0 kb
MX Compressed Class Space(Non-heap memory): used: 4,593 kb, init: 0 kb, committed: 5,068 kb, max: 1,048,576 kb
MX PS Eden Space(Heap memory): used: 288,153 kb, init: 350,208 kb, committed: 324,608 kb, max: 324,608 kb
MX PS Survivor Space(Heap memory): used: 70,304 kb, init: 57,856 kb, committed: 70,656 kb, max: 70,656 kb
MX PS Old Gen(Heap memory): used: 37,132 kb, init: 932,864 kb, committed: 932,864 kb, max: 932,864 kb
19:25:31,086 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) Stopping service.
19:25:31,099 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t27) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-11194: 256+90, fedora-45103: 256+78]}, pendingCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-11194: 257+255, fedora-45103: 255+257]}, unionCH=null, actualMembers=[fedora-11194, fedora-45103], persistentUUIDs=[d20d1488-2d5b-49cb-b1e9-4462be8b1ccf, f17a4f8d-830c-452d-8012-0b460933f161]}
19:25:31,105 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t27) [Context=testCache][Scope=fedora-11194]ISPN100002: Started rebalance with topology id 11
19:25:31,137 WARN  [org.infinispan.CLUSTER] (StopThread) [Context=testCache]ISPN000312: Lost data because of graceful leaver fedora-11194
19:25:31,148 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t26) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-11194: 135, fedora-45103: 121]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-11194: 134, fedora-45103: 122]}, unionCH=null, actualMembers=[fedora-11194, fedora-45103], persistentUUIDs=[d20d1488-2d5b-49cb-b1e9-4462be8b1ccf, f17a4f8d-830c-452d-8012-0b460933f161]}
19:25:31,151 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t26) [Context=___protobuf_metadata][Scope=fedora-11194]ISPN100002: Started rebalance with topology id 11
19:25:31,154 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t10) [Context=___protobuf_metadata][Scope=fedora-11194]ISPN100003: Node fedora-11194 finished rebalance phase with topology id 11
19:25:31,155 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t27) [Context=___protobuf_metadata][Scope=fedora-45103]ISPN100003: Node fedora-45103 finished rebalance phase with topology id 11
19:25:31,175 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t27) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 11
19:25:31,179 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t27) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-11194: 143+45, fedora-45103: 113+39]}, pendingCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-11194: 134+122, fedora-45103: 122+134]}, unionCH=null, actualMembers=[fedora-11194, fedora-45103], persistentUUIDs=[d20d1488-2d5b-49cb-b1e9-4462be8b1ccf, f17a4f8d-830c-452d-8012-0b460933f161]}
19:25:31,183 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t27) [Context=___counters][Scope=fedora-11194]ISPN100002: Started rebalance with topology id 11
19:25:31,182 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t26) [Context=___protobuf_metadata][Scope=fedora-45103]ISPN100003: Node fedora-45103 finished rebalance phase with topology id 12
19:25:31,179 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t15) [Context=___protobuf_metadata][Scope=fedora-11194]ISPN100003: Node fedora-11194 finished rebalance phase with topology id 12
19:25:31,189 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (transport-thread--p4-t15) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___protobuf_metadata, type=REBALANCE_PHASE_CONFIRM, sender=fedora-11194, joinInfo=null, topologyId=12, rebalanceId=4, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-11194 for cache ___protobuf_metadata, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.commands.ReplicableCommand.invoke(ReplicableCommand.java:44) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.LocalTopologyManagerImpl.lambda$executeOnCoordinatorAsync$4(LocalTopologyManagerImpl.java:717) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_372-internal]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_372-internal]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_372-internal]
19:25:31,191 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t2) [Context=___protobuf_metadata][Scope=fedora-11194]ISPN100003: Node fedora-11194 finished rebalance phase with topology id 13
19:25:31,193 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (transport-thread--p4-t2) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___protobuf_metadata, type=REBALANCE_PHASE_CONFIRM, sender=fedora-11194, joinInfo=null, topologyId=13, rebalanceId=4, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-11194 for cache ___protobuf_metadata, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.commands.ReplicableCommand.invoke(ReplicableCommand.java:44) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.LocalTopologyManagerImpl.lambda$executeOnCoordinatorAsync$4(LocalTopologyManagerImpl.java:717) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_372-internal]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_372-internal]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_372-internal]
19:25:31,213 WARN  [org.infinispan.CLUSTER] (StopThread) [Context=___counters]ISPN000312: Lost data because of graceful leaver fedora-11194
19:25:31,195 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t14) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-11194: 135, fedora-45103: 121]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-11194: 134, fedora-45103: 122]}, unionCH=null, actualMembers=[fedora-11194, fedora-45103], persistentUUIDs=[d20d1488-2d5b-49cb-b1e9-4462be8b1ccf, f17a4f8d-830c-452d-8012-0b460933f161]}
19:25:31,189 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (remote-thread--p2-t26) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___protobuf_metadata, type=REBALANCE_PHASE_CONFIRM, sender=fedora-45103, joinInfo=null, topologyId=12, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-45103 for cache ___protobuf_metadata, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.invokeReplicableCommand(GlobalInboundInvocationHandler.java:169) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.runReplicableCommand(GlobalInboundInvocationHandler.java:150) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.lambda$handleReplicableCommand$1(GlobalInboundInvocationHandler.java:144) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.util.concurrent.BlockingTaskAwareExecutorServiceImpl$RunnableWrapper.run(BlockingTaskAwareExecutorServiceImpl.java:212) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_372-internal]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_372-internal]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_372-internal]
19:25:31,217 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t14) [Context=org.infinispan.CONFIG][Scope=fedora-11194]ISPN100002: Started rebalance with topology id 11
19:25:31,230 WARN  [org.infinispan.statetransfer.InboundTransferTask] (stateTransferExecutor-thread--p6-t1) ISPN000210: Failed to request state of cache testCache from node fedora-45103, segments {0-9 13-18 30-31 34-36 40 43-46 50-53 57-58 67 70 77 85-91 94-95 100-104 108 116-118 142-144 148-152 158-160 167 170-171 174-175 179 182-184 191-192 196-197 204-205 213-216 224 232 237 255 258-263 266 278-281 290 293 296 306-308 317 326 329-331 337 347-350 359-361 368-372 377-382 385 389-392 396-403 408 417-418 431-432 450-451 454-455 460-463 473 485-486 495 501-504 508-511}
org.infinispan.remoting.transport.jgroups.SuspectException: ISPN000400: Node fedora-45103 was suspected
	at org.infinispan.remoting.transport.ResponseCollectors.remoteNodeSuspected(ResponseCollectors.java:33) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleResponseCollector.targetNotFound(SingleResponseCollector.java:31) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleResponseCollector.targetNotFound(SingleResponseCollector.java:17) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.ValidSingleResponseCollector.addResponse(ValidSingleResponseCollector.java:23) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleTargetRequest.receiveResponse(SingleTargetRequest.java:51) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleTargetRequest.onResponse(SingleTargetRequest.java:35) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.RequestRepository.addResponse(RequestRepository.java:53) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.processResponse(JGroupsTransport.java:1302) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.processMessage(JGroupsTransport.java:1205) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.access$200(JGroupsTransport.java:123) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport$ChannelCallbacks.receive(JGroupsTransport.java:1340) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.jgroups.JChannel.up(JChannel.java:819) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.stack.ProtocolStack.up(ProtocolStack.java:893) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FRAG3.up(FRAG3.java:171) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FlowControl.up(FlowControl.java:343) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FlowControl.up(FlowControl.java:343) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.GMS.up(GMS.java:864) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.STABLE.up(STABLE.java:240) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.deliverMessage(UNICAST3.java:1002) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.handleDataReceived(UNICAST3.java:728) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.up(UNICAST3.java:383) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.NAKACK2.up(NAKACK2.java:600) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.VERIFY_SUSPECT.up(VERIFY_SUSPECT.java:119) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FD_ALL.up(FD_ALL.java:199) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FD_SOCK.up(FD_SOCK.java:252) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.MERGE3.up(MERGE3.java:276) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.Discovery.up(Discovery.java:267) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.TP.passMessageUp(TP.java:1248) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.util.SubmitToThreadPool$SingleMessageHandler.run(SubmitToThreadPool.java:87) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_372-internal]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_372-internal]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_372-internal]
19:25:31,239 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t14) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=12, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-11194: 135, fedora-45103: 121]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-11194: 134, fedora-45103: 122]}, unionCH=null, actualMembers=[fedora-11194, fedora-45103], persistentUUIDs=[d20d1488-2d5b-49cb-b1e9-4462be8b1ccf, f17a4f8d-830c-452d-8012-0b460933f161]}
19:25:31,243 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t14) [Context=___counter_configuration][Scope=fedora-11194]ISPN100002: Started rebalance with topology id 12
19:25:31,249 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (StopThread) ISPN000080: Disconnecting JGroups channel results
19:25:31,251 INFO  [org.infinispan.CLUSTER] (jgroups-18,fedora-11194) ISPN000094: Received new cluster view for channel results: [fedora-11194|3] (2) [fedora-11194, fedora-45103]
19:25:31,252 INFO  [org.infinispan.CLUSTER] (jgroups-18,fedora-11194) ISPN100001: Node fedora-36407 left the cluster
19:25:31,365 WARN  [org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler] (remote-thread--p2-t33) ISPN000219: Shutdown while handling command CacheTopologyControlCommand{cache=org.infinispan.CONFIG, type=REBALANCE_PHASE_CONFIRM, sender=fedora-45103, joinInfo=null, topologyId=12, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
19:25:31,365 WARN  [org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler] (remote-thread--p2-t27) ISPN000219: Shutdown while handling command CacheTopologyControlCommand{cache=org.infinispan.CONFIG, type=REBALANCE_PHASE_CONFIRM, sender=fedora-45103, joinInfo=null, topologyId=11, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
19:25:31,365 WARN  [org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler] (remote-thread--p2-t32) ISPN000219: Shutdown while handling command CacheTopologyControlCommand{cache=___counter_configuration, type=REBALANCE_PHASE_CONFIRM, sender=fedora-45103, joinInfo=null, topologyId=14, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
19:25:31,366 WARN  [org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler] (remote-thread--p2-t14) ISPN000219: Shutdown while handling command CacheTopologyControlCommand{cache=___counters, type=REBALANCE_PHASE_CONFIRM, sender=fedora-45103, joinInfo=null, topologyId=12, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
19:25:31,365 WARN  [org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler] (remote-thread--p2-t26) ISPN000219: Shutdown while handling command CacheTopologyControlCommand{cache=org.infinispan.CONFIG, type=LEAVE, sender=fedora-45103, joinInfo=null, topologyId=0, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
19:25:31,370 INFO  [org.radargun.service.Infinispan90Lifecycle] (StopThread) Stopped, previous view is [fedora-11194, fedora-36407, fedora-45103]
19:25:31,371 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Service successfully stopped.
19:25:31,371 INFO  [org.radargun.Slave] (sc-main) Finished stage ScenarioDestroy
19:25:31,371 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
19:25:31,435 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.service.Infinispan80EmbeddedService.destroy() overrides public void org.radargun.service.Infinispan60EmbeddedService.destroy() but both are declared with @Destroy annotation: calling only once
19:25:31,436 INFO  [org.radargun.Slave] (main) Starting stage ScenarioCleanup
19:25:31,541 INFO  [org.radargun.stages.ScenarioCleanupStage] (main) Memory after cleanup: 
Runtime free: 1,306,574 kb
Runtime max:1,326,080 kb
Runtime total:1,326,080 kb
MX Code Cache(Non-heap memory): used: 15,117 kb, init: 2,496 kb, committed: 15,296 kb, max: 245,760 kb
MX Metaspace(Non-heap memory): used: 38,546 kb, init: 0 kb, committed: 40,396 kb, max: 0 kb
MX Compressed Class Space(Non-heap memory): used: 4,615 kb, init: 0 kb, committed: 5,068 kb, max: 1,048,576 kb
MX PS Eden Space(Heap memory): used: 6,921 kb, init: 350,208 kb, committed: 322,560 kb, max: 323,584 kb
MX PS Survivor Space(Heap memory): used: 0 kb, init: 57,856 kb, committed: 70,656 kb, max: 70,656 kb
MX PS Old Gen(Heap memory): used: 12,583 kb, init: 932,864 kb, committed: 932,864 kb, max: 932,864 kb
19:25:31,543 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
19:25:36,707 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
19:25:41,700 INFO  [org.radargun.Slave] (main) Master shutdown!
19:25:41,703 INFO  [org.radargun.ShutDownHook] (Thread-0) Slave process is being shutdown
