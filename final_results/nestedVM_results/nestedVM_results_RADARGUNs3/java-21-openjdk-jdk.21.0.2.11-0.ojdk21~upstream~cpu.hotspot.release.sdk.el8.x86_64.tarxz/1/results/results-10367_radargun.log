14:16:26,425 INFO  [org.radargun.RemoteMasterConnection] (main) Attempting to connect to master results:2103
14:16:26,438 INFO  [org.radargun.RemoteMasterConnection] (main) Successfully established connection with master at: results:2103
14:16:26,446 INFO  [org.radargun.Slave] (main) Received slave index 0
14:16:26,449 INFO  [org.radargun.Slave] (main) Received slave count 3
14:16:27,173 INFO  [org.radargun.ServiceHelper] (sc-main) ServiceContext properties: {}
14:16:27,362 INFO  [org.radargun.Slave] (sc-main) Eager Service Infinispan92EmbeddedService {batching=false, cache=testCache, channelRetrievalTimeout=2 mins 0 secs, enableDiagnostics=null, explicitLocking=false, file=/mnt/workspace/results/dist-sync.xml, internalsExpositionEnabled=false, jgroupsDumperEnabled=false, jgroupsDumperInterval=10.000 secs, keysPerThread=-1, mapReduceDistributedReducePhase=false, mapReduceUseIntermediateSharedCache=false, removedCaches=[  ], threadsPerNode=-1 } loaded.
14:16:29,363 INFO  [org.radargun.Slave] (sc-main) Starting stage ScenarioInit
14:16:29,475 INFO  [org.radargun.Slave] (sc-main) Finished stage ScenarioInit
14:16:29,485 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
14:16:29,549 INFO  [org.radargun.Slave] (sc-main) Starting stage BeforeServiceStart
14:16:29,549 INFO  [org.radargun.Slave] (sc-main) Finished stage BeforeServiceStart
14:16:29,550 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
14:16:29,563 INFO  [org.radargun.Slave] (sc-main) Starting stage ServiceStart
14:16:29,567 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Startup staggering, this is the slave with index 0, not sleeping
14:16:29,568 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 0
14:16:29,573 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) Infinispan version: Infinispan 'Gaina' 9.2.0.Final
14:16:29,596 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) JGroups version: JGroups 4.0.10.Final (Schiener Berg)
14:16:30,276 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (sc-main) ISPN000078: Starting JGroups channel results
14:16:30,404 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the send buffer of socket MulticastSocket was set to 1.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
14:16:30,405 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the receive buffer of socket MulticastSocket was set to 20.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
14:16:30,405 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the send buffer of socket MulticastSocket was set to 1.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
14:16:30,406 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the receive buffer of socket MulticastSocket was set to 25.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
14:16:35,429 INFO  [org.infinispan.CLUSTER] (sc-main) ISPN000094: Received new cluster view for channel results: [fedora-30462|0] (1) [fedora-30462]
14:16:35,519 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (sc-main) ISPN000079: Channel results local address is fedora-30462, physical addresses are [192.168.124.249:52446]
14:16:35,523 INFO  [org.infinispan.factories.GlobalComponentRegistry] (sc-main) ISPN000128: Infinispan version: Infinispan 'Gaina' 9.2.0.Final
14:16:36,236 INFO  [org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup] (sc-main) ISPN000107: Retrieving transaction manager Transaction: unknown
14:16:36,369 INFO  [org.infinispan.CLUSTER] (jgroups-6,fedora-30462) ISPN000094: Received new cluster view for channel results: [fedora-30462|1] (2) [fedora-30462, fedora-56754]
14:16:36,385 INFO  [org.infinispan.CLUSTER] (jgroups-6,fedora-30462) ISPN100000: Node fedora-56754 joined the cluster
14:16:36,482 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) No RELAY2 protocol in XS service
14:16:36,506 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) No RELAY2 protocol in XS service
14:16:36,510 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) ([fedora-30462(local=true, coord=true), fedora-56754(local=false, coord=false)]) Number of members=2 is not the one expected: 3
14:16:36,912 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-30462: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-30462: 133, fedora-56754: 123]}, unionCH=null, actualMembers=[fedora-30462, fedora-56754], persistentUUIDs=[1101edb5-56bb-4db5-ab24-686b4186c5da, 21e70863-f618-408c-a6e7-cdd992461cd5]}
14:16:36,914 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-30462]ISPN100002: Started rebalance with topology id 2
14:16:36,947 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-30462: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-30462: 133, fedora-56754: 123]}, unionCH=null, actualMembers=[fedora-30462, fedora-56754], persistentUUIDs=[1101edb5-56bb-4db5-ab24-686b4186c5da, 21e70863-f618-408c-a6e7-cdd992461cd5]}
14:16:36,948 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-30462]ISPN100002: Started rebalance with topology id 2
14:16:36,965 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t22) [Context=org.infinispan.CONFIG][Scope=fedora-30462]ISPN100003: Node fedora-30462 finished rebalance phase with topology id 2
14:16:36,975 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t24) [Context=___counter_configuration][Scope=fedora-30462]ISPN100003: Node fedora-30462 finished rebalance phase with topology id 2
14:16:37,047 INFO  [org.infinispan.CLUSTER] (jgroups-10,fedora-30462) ISPN000094: Received new cluster view for channel results: [fedora-30462|2] (3) [fedora-30462, fedora-56754, fedora-40301]
14:16:37,052 INFO  [org.infinispan.CLUSTER] (jgroups-10,fedora-30462) ISPN100000: Node fedora-40301 joined the cluster
14:16:37,158 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-56754]ISPN100003: Node fedora-56754 finished rebalance phase with topology id 2
14:16:37,158 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 2
14:16:37,162 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t3) [Context=___counter_configuration][Scope=fedora-30462]ISPN100003: Node fedora-30462 finished rebalance phase with topology id 3
14:16:37,177 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-56754]ISPN100003: Node fedora-56754 finished rebalance phase with topology id 3
14:16:37,181 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=___counter_configuration][Scope=fedora-30462]ISPN100003: Node fedora-30462 finished rebalance phase with topology id 4
14:16:37,184 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-56754]ISPN100003: Node fedora-56754 finished rebalance phase with topology id 2
14:16:37,184 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 2
14:16:37,186 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t9) [Context=org.infinispan.CONFIG][Scope=fedora-30462]ISPN100003: Node fedora-30462 finished rebalance phase with topology id 3
14:16:37,188 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-56754]ISPN100003: Node fedora-56754 finished rebalance phase with topology id 4
14:16:37,201 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-56754]ISPN100003: Node fedora-56754 finished rebalance phase with topology id 3
14:16:37,202 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t17) [Context=org.infinispan.CONFIG][Scope=fedora-30462]ISPN100003: Node fedora-30462 finished rebalance phase with topology id 4
14:16:37,218 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-56754]ISPN100003: Node fedora-56754 finished rebalance phase with topology id 4
14:16:37,269 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=DefaultConsistentHash{ns=256, owners = (1)[fedora-30462: 256+0]}, pendingCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-30462: 133+123, fedora-56754: 123+133]}, unionCH=null, actualMembers=[fedora-30462, fedora-56754], persistentUUIDs=[1101edb5-56bb-4db5-ab24-686b4186c5da, 21e70863-f618-408c-a6e7-cdd992461cd5]}
14:16:37,270 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-30462]ISPN100002: Started rebalance with topology id 2
14:16:37,272 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t22) [Context=___counters][Scope=fedora-30462]ISPN100003: Node fedora-30462 finished rebalance phase with topology id 2
14:16:37,340 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-30462: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-30462: 133, fedora-56754: 123]}, unionCH=null, actualMembers=[fedora-30462, fedora-56754], persistentUUIDs=[1101edb5-56bb-4db5-ab24-686b4186c5da, 21e70863-f618-408c-a6e7-cdd992461cd5]}
14:16:37,341 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-56754]ISPN100003: Node fedora-56754 finished rebalance phase with topology id 2
14:16:37,342 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___counters, topology id = 2
14:16:37,342 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-30462]ISPN100002: Started rebalance with topology id 2
14:16:37,345 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t6) [Context=___counters][Scope=fedora-30462]ISPN100003: Node fedora-30462 finished rebalance phase with topology id 3
14:16:37,348 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t3) [Context=___protobuf_metadata][Scope=fedora-30462]ISPN100003: Node fedora-30462 finished rebalance phase with topology id 2
14:16:37,356 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-56754]ISPN100003: Node fedora-56754 finished rebalance phase with topology id 3
14:16:37,358 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=___counters][Scope=fedora-30462]ISPN100003: Node fedora-30462 finished rebalance phase with topology id 4
14:16:37,364 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-56754]ISPN100003: Node fedora-56754 finished rebalance phase with topology id 4
14:16:37,387 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=DefaultConsistentHash{ns=512, owners = (1)[fedora-30462: 512+0]}, pendingCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-30462: 258+254, fedora-56754: 254+258]}, unionCH=null, actualMembers=[fedora-30462, fedora-56754], persistentUUIDs=[1101edb5-56bb-4db5-ab24-686b4186c5da, 21e70863-f618-408c-a6e7-cdd992461cd5]}
14:16:37,388 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-30462]ISPN100002: Started rebalance with topology id 2
14:16:37,389 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-56754]ISPN100003: Node fedora-56754 finished rebalance phase with topology id 2
14:16:37,391 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 2
14:16:37,393 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t15) [Context=___protobuf_metadata][Scope=fedora-30462]ISPN100003: Node fedora-30462 finished rebalance phase with topology id 3
14:16:37,393 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t19) [Context=testCache][Scope=fedora-30462]ISPN100003: Node fedora-30462 finished rebalance phase with topology id 2
14:16:37,401 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-56754]ISPN100003: Node fedora-56754 finished rebalance phase with topology id 3
14:16:37,406 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=___protobuf_metadata][Scope=fedora-30462]ISPN100003: Node fedora-30462 finished rebalance phase with topology id 4
14:16:37,416 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-56754]ISPN100003: Node fedora-56754 finished rebalance phase with topology id 4
14:16:37,434 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-56754]ISPN100003: Node fedora-56754 finished rebalance phase with topology id 2
14:16:37,435 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache testCache, topology id = 2
14:16:37,438 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t8) [Context=testCache][Scope=fedora-30462]ISPN100003: Node fedora-30462 finished rebalance phase with topology id 3
14:16:37,452 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-56754]ISPN100003: Node fedora-56754 finished rebalance phase with topology id 3
14:16:37,456 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t3) [Context=testCache][Scope=fedora-30462]ISPN100003: Node fedora-30462 finished rebalance phase with topology id 4
14:16:37,466 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-56754]ISPN100003: Node fedora-56754 finished rebalance phase with topology id 4
14:16:37,511 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) Number of members is the one expected: 3
14:16:37,512 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Successfully started cache service infinispan92/embedded on slave 0
14:16:37,623 ERROR [org.radargun.service.ConfigDumpHelper] (sc-main) Error while dumping ___protobuf_metadata cache config as properties
javax.management.AttributeNotFoundException: Unknown attribute 'configurationAsProperties'. Known attributes names are: [rebalancingEnabled, cacheStatus, cacheName, cacheAvailability, version, configurationAsProperties]
	at org.infinispan.jmx.ResourceDMBean.getAttribute(ResourceDMBean.java:181) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:636) ~[?:?]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:679) ~[?:?]
	at org.radargun.service.ConfigDumpHelper60.dumpCache(ConfigDumpHelper60.java:44) [plugin-infinispan60-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.service.EmbeddedConfigurationProvider.getNormalizedConfigs(EmbeddedConfigurationProvider.java:33) [plugin-infinispan52-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.stages.lifecycle.ServiceStartStage.executeOnSlave(ServiceStartStage.java:92) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase.scenarioLoop(SlaveBase.java:102) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase$ScenarioRunner.run(SlaveBase.java:203) [radargun-core-3.0.0-SNAPSHOT.jar:?]
14:16:37,662 ERROR [org.radargun.service.ConfigDumpHelper] (sc-main) Error while dumping ___protobuf_metadata cache config as properties
javax.management.AttributeNotFoundException: Unknown attribute 'configurationAsProperties'. Known attributes names are: [rebalancingEnabled, cacheStatus, cacheName, cacheAvailability, version, configurationAsProperties]
	at org.infinispan.jmx.ResourceDMBean.getAttribute(ResourceDMBean.java:181) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:636) ~[?:?]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:679) ~[?:?]
	at org.radargun.service.ConfigDumpHelper60.dumpCache(ConfigDumpHelper60.java:44) [plugin-infinispan60-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.service.EmbeddedConfigurationProvider.getNormalizedConfigs(EmbeddedConfigurationProvider.java:33) [plugin-infinispan52-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.stages.lifecycle.ServiceStartStage.executeOnSlave(ServiceStartStage.java:92) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase.scenarioLoop(SlaveBase.java:102) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase$ScenarioRunner.run(SlaveBase.java:203) [radargun-core-3.0.0-SNAPSHOT.jar:?]
14:16:37,731 INFO  [org.radargun.Slave] (sc-main) Finished stage ServiceStart
14:16:37,750 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
14:16:37,802 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-30462: 133, fedora-56754: 123]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-30462: 87, fedora-56754: 84, fedora-40301: 85]}, unionCH=null, actualMembers=[fedora-30462, fedora-56754, fedora-40301], persistentUUIDs=[1101edb5-56bb-4db5-ab24-686b4186c5da, 21e70863-f618-408c-a6e7-cdd992461cd5, 09f92928-61c6-44ea-acf9-9071ff732e3a]}
14:16:37,803 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-30462]ISPN100002: Started rebalance with topology id 6
14:16:37,804 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-30462: 133, fedora-56754: 123]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-30462: 87, fedora-56754: 84, fedora-40301: 85]}, unionCH=null, actualMembers=[fedora-30462, fedora-56754, fedora-40301], persistentUUIDs=[1101edb5-56bb-4db5-ab24-686b4186c5da, 21e70863-f618-408c-a6e7-cdd992461cd5, 09f92928-61c6-44ea-acf9-9071ff732e3a]}
14:16:37,804 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-30462]ISPN100002: Started rebalance with topology id 6
14:16:37,805 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t12) [Context=org.infinispan.CONFIG][Scope=fedora-30462]ISPN100003: Node fedora-30462 finished rebalance phase with topology id 6
14:16:37,806 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=___counter_configuration][Scope=fedora-30462]ISPN100003: Node fedora-30462 finished rebalance phase with topology id 6
14:16:37,818 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=org.infinispan.CONFIG][Scope=fedora-56754]ISPN100003: Node fedora-56754 finished rebalance phase with topology id 6
14:16:37,819 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-56754]ISPN100003: Node fedora-56754 finished rebalance phase with topology id 6
14:16:37,920 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counter_configuration][Scope=fedora-40301]ISPN100003: Node fedora-40301 finished rebalance phase with topology id 6
14:16:37,921 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 6
14:16:37,923 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t19) [Context=___counter_configuration][Scope=fedora-30462]ISPN100003: Node fedora-30462 finished rebalance phase with topology id 7
14:16:37,926 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counter_configuration][Scope=fedora-56754]ISPN100003: Node fedora-56754 finished rebalance phase with topology id 7
14:16:37,930 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=org.infinispan.CONFIG][Scope=fedora-40301]ISPN100003: Node fedora-40301 finished rebalance phase with topology id 6
14:16:37,931 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 6
14:16:37,931 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-40301]ISPN100003: Node fedora-40301 finished rebalance phase with topology id 7
14:16:37,933 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=org.infinispan.CONFIG][Scope=fedora-30462]ISPN100003: Node fedora-30462 finished rebalance phase with topology id 7
14:16:37,933 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t2) [Context=___counter_configuration][Scope=fedora-30462]ISPN100003: Node fedora-30462 finished rebalance phase with topology id 8
14:16:37,937 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-56754]ISPN100003: Node fedora-56754 finished rebalance phase with topology id 7
14:16:37,937 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counter_configuration][Scope=fedora-56754]ISPN100003: Node fedora-56754 finished rebalance phase with topology id 8
14:16:37,941 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=org.infinispan.CONFIG][Scope=fedora-40301]ISPN100003: Node fedora-40301 finished rebalance phase with topology id 7
14:16:37,942 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t4) [Context=org.infinispan.CONFIG][Scope=fedora-30462]ISPN100003: Node fedora-30462 finished rebalance phase with topology id 8
14:16:37,944 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=org.infinispan.CONFIG][Scope=fedora-56754]ISPN100003: Node fedora-56754 finished rebalance phase with topology id 8
14:16:37,948 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counter_configuration][Scope=fedora-40301]ISPN100003: Node fedora-40301 finished rebalance phase with topology id 8
14:16:37,960 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=org.infinispan.CONFIG][Scope=fedora-40301]ISPN100003: Node fedora-40301 finished rebalance phase with topology id 8
14:16:38,029 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-30462: 133+123, fedora-56754: 123+133]}, pendingCH=DefaultConsistentHash{ns=256, owners = (3)[fedora-30462: 87+84, fedora-56754: 84+99, fedora-40301: 85+73]}, unionCH=null, actualMembers=[fedora-30462, fedora-56754, fedora-40301], persistentUUIDs=[1101edb5-56bb-4db5-ab24-686b4186c5da, 21e70863-f618-408c-a6e7-cdd992461cd5, 09f92928-61c6-44ea-acf9-9071ff732e3a]}
14:16:38,030 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=fedora-30462]ISPN100002: Started rebalance with topology id 6
14:16:38,031 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t18) [Context=___counters][Scope=fedora-30462]ISPN100003: Node fedora-30462 finished rebalance phase with topology id 6
14:16:38,034 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=fedora-56754]ISPN100003: Node fedora-56754 finished rebalance phase with topology id 6
14:16:38,062 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-40301]ISPN100003: Node fedora-40301 finished rebalance phase with topology id 6
14:16:38,062 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___counters, topology id = 6
14:16:38,064 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t25) [Context=___counters][Scope=fedora-30462]ISPN100003: Node fedora-30462 finished rebalance phase with topology id 7
14:16:38,068 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-56754]ISPN100003: Node fedora-56754 finished rebalance phase with topology id 7
14:16:38,072 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-40301]ISPN100003: Node fedora-40301 finished rebalance phase with topology id 7
14:16:38,073 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t24) [Context=___counters][Scope=fedora-30462]ISPN100003: Node fedora-30462 finished rebalance phase with topology id 8
14:16:38,075 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-56754]ISPN100003: Node fedora-56754 finished rebalance phase with topology id 8
14:16:38,078 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-40301]ISPN100003: Node fedora-40301 finished rebalance phase with topology id 8
14:16:38,144 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-30462: 133, fedora-56754: 123]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-30462: 87, fedora-56754: 84, fedora-40301: 85]}, unionCH=null, actualMembers=[fedora-30462, fedora-56754, fedora-40301], persistentUUIDs=[1101edb5-56bb-4db5-ab24-686b4186c5da, 21e70863-f618-408c-a6e7-cdd992461cd5, 09f92928-61c6-44ea-acf9-9071ff732e3a]}
14:16:38,145 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-30462]ISPN100002: Started rebalance with topology id 6
14:16:38,147 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t8) [Context=___protobuf_metadata][Scope=fedora-30462]ISPN100003: Node fedora-30462 finished rebalance phase with topology id 6
14:16:38,152 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-56754]ISPN100003: Node fedora-56754 finished rebalance phase with topology id 6
14:16:38,179 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-40301]ISPN100003: Node fedora-40301 finished rebalance phase with topology id 6
14:16:38,179 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 6
14:16:38,182 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t13) [Context=___protobuf_metadata][Scope=fedora-30462]ISPN100003: Node fedora-30462 finished rebalance phase with topology id 7
14:16:38,185 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=fedora-40301]ISPN100003: Node fedora-40301 finished rebalance phase with topology id 7
14:16:38,186 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-56754]ISPN100003: Node fedora-56754 finished rebalance phase with topology id 7
14:16:38,188 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t11) [Context=___protobuf_metadata][Scope=fedora-30462]ISPN100003: Node fedora-30462 finished rebalance phase with topology id 8
14:16:38,191 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-56754]ISPN100003: Node fedora-56754 finished rebalance phase with topology id 8
14:16:38,191 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=fedora-40301]ISPN100003: Node fedora-40301 finished rebalance phase with topology id 8
14:16:38,199 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-30462: 258+254, fedora-56754: 254+258]}, pendingCH=DefaultConsistentHash{ns=512, owners = (3)[fedora-30462: 167+183, fedora-56754: 165+146, fedora-40301: 180+183]}, unionCH=null, actualMembers=[fedora-30462, fedora-56754, fedora-40301], persistentUUIDs=[1101edb5-56bb-4db5-ab24-686b4186c5da, 21e70863-f618-408c-a6e7-cdd992461cd5, 09f92928-61c6-44ea-acf9-9071ff732e3a]}
14:16:38,200 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-30462]ISPN100002: Started rebalance with topology id 6
14:16:38,202 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t16) [Context=testCache][Scope=fedora-30462]ISPN100003: Node fedora-30462 finished rebalance phase with topology id 6
14:16:38,206 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-56754]ISPN100003: Node fedora-56754 finished rebalance phase with topology id 6
14:16:38,241 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-40301]ISPN100003: Node fedora-40301 finished rebalance phase with topology id 6
14:16:38,241 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000336: Finished cluster-wide rebalance for cache testCache, topology id = 6
14:16:38,245 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t23) [Context=testCache][Scope=fedora-30462]ISPN100003: Node fedora-30462 finished rebalance phase with topology id 7
14:16:38,247 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-56754]ISPN100003: Node fedora-56754 finished rebalance phase with topology id 7
14:16:38,252 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-40301]ISPN100003: Node fedora-40301 finished rebalance phase with topology id 7
14:16:38,254 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t22) [Context=testCache][Scope=fedora-30462]ISPN100003: Node fedora-30462 finished rebalance phase with topology id 8
14:16:38,259 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-56754]ISPN100003: Node fedora-56754 finished rebalance phase with topology id 8
14:16:38,263 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-40301]ISPN100003: Node fedora-40301 finished rebalance phase with topology id 8
14:16:38,431 INFO  [org.radargun.Slave] (sc-main) Starting stage AfterServiceStart
14:16:38,432 INFO  [org.radargun.Slave] (sc-main) Finished stage AfterServiceStart
14:16:38,436 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
14:16:38,594 INFO  [org.radargun.Slave] (sc-main) Starting stage MonitorStart
14:16:38,603 INFO  [org.radargun.sysmonitor.AbstractMonitors] (sc-main) Gathering statistics every 1000 ms
14:16:38,603 INFO  [org.radargun.Slave] (sc-main) Finished stage MonitorStart
14:16:38,604 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
14:16:38,687 INFO  [org.radargun.Slave] (sc-main) Starting stage Load
14:16:47,864 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) This node loaded 10000 entries (~10000000 bytes)
14:16:53,446 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) This node loaded 20000 entries (~20000000 bytes)
14:16:57,971 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) This node loaded 30000 entries (~30000000 bytes)
14:16:58,818 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) Finished loading entries
14:16:58,868 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) Finished loading entries
14:16:58,872 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) Finished loading entries
14:16:58,894 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) Finished loading entries
14:16:58,904 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) Finished loading entries
14:16:58,910 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) Finished loading entries
14:16:58,916 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) Finished loading entries
14:16:58,936 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) Finished loading entries
14:16:58,936 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) Finished loading entries
14:16:58,939 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) Finished loading entries
14:16:58,940 INFO  [org.radargun.Slave] (sc-main) Finished stage Load
14:16:58,943 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
14:16:58,968 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.stages.cache.test.BasicOperationsTestStage.init() overrides public void org.radargun.stages.test.TestStage.init() but both are declared with @Init annotation: calling only once
14:16:58,971 INFO  [org.radargun.Slave] (sc-main) Starting stage BasicOperationsTest
14:16:58,973 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using key generator org.radargun.stages.cache.generators.StringKeyGenerator {format=null }
14:16:58,974 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using value generator org.radargun.stages.cache.generators.ByteArrayValueGenerator { }
14:16:58,974 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using cache selector Default { }
14:16:58,974 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Starting test warmup
14:16:59,000 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Started 4 stressor threads.
14:17:59,002 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Finished test. Test duration is: 1 mins 0 secs
14:17:59,004 INFO  [org.radargun.Slave] (sc-main) Finished stage BasicOperationsTest
14:17:59,013 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
14:17:59,049 INFO  [org.radargun.Slave] (sc-main) Starting stage Clear
14:17:59,053 INFO  [org.radargun.stages.cache.ClearStage] (sc-main) Before executing clear, memory looks like this: 
Runtime free: 1,130,755 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,593 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,700 kb
MX Metaspace(Non-heap memory): used: 35,987 kb, init: 0 kb, committed: 36,544 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 11,600 kb, init: 2,496 kb, committed: 11,648 kb, max: 120,028 kb
MX Compressed Class Space(Non-heap memory): used: 4,207 kb, init: 0 kb, committed: 4,480 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 84,992 kb, init: 69,632 kb, committed: 817,152 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 119,036 kb, init: 1,329,152 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 62,976 kb, init: 0 kb, committed: 63,488 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 6,179 kb, init: 2,496 kb, committed: 6,208 kb, max: 120,032 kb
14:17:59,220 INFO  [org.radargun.stages.cache.ClearStage] (sc-main) After executing clear, memory looks like this: 
Runtime free: 1,380,120 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,593 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,700 kb
MX Metaspace(Non-heap memory): used: 36,007 kb, init: 0 kb, committed: 36,544 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 11,503 kb, init: 2,496 kb, committed: 11,712 kb, max: 120,028 kb
MX Compressed Class Space(Non-heap memory): used: 4,205 kb, init: 0 kb, committed: 4,480 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 0 kb, init: 69,632 kb, committed: 880,640 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 18,151 kb, init: 1,329,152 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 0 kb, init: 0 kb, committed: 0 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 6,172 kb, init: 2,496 kb, committed: 6,272 kb, max: 120,032 kb
14:17:59,221 INFO  [org.radargun.Slave] (sc-main) Finished stage Clear
14:17:59,224 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
14:17:59,248 INFO  [org.radargun.Slave] (sc-main) Starting stage Load
14:18:01,868 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) This node loaded 10000 entries (~10000000 bytes)
14:18:04,264 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) This node loaded 20000 entries (~20000000 bytes)
14:18:06,528 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) This node loaded 30000 entries (~30000000 bytes)
14:18:07,223 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) Finished loading entries
14:18:07,244 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) Finished loading entries
14:18:07,301 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) Finished loading entries
14:18:07,306 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) Finished loading entries
14:18:07,312 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) Finished loading entries
14:18:07,320 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) Finished loading entries
14:18:07,337 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) Finished loading entries
14:18:07,346 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) Finished loading entries
14:18:07,351 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) Finished loading entries
14:18:07,360 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) Finished loading entries
14:18:07,361 INFO  [org.radargun.Slave] (sc-main) Finished stage Load
14:18:07,362 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
14:18:07,630 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.stages.cache.test.BasicOperationsTestStage.init() overrides public void org.radargun.stages.test.TestStage.init() but both are declared with @Init annotation: calling only once
14:18:07,636 INFO  [org.radargun.Slave] (sc-main) Starting stage BasicOperationsTest
14:18:07,637 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using key generator org.radargun.stages.cache.generators.StringKeyGenerator {format=null }
14:18:07,638 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using value generator org.radargun.stages.cache.generators.ByteArrayValueGenerator { }
14:18:07,639 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using cache selector Default { }
14:18:07,640 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Starting test stress-test
14:18:07,687 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Started 4 stressor threads.
14:28:07,691 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Finished test. Test duration is: 10 mins 0 secs
14:28:07,694 INFO  [org.radargun.Slave] (sc-main) Finished stage BasicOperationsTest
14:28:07,848 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
14:28:08,021 INFO  [org.radargun.Slave] (sc-main) Starting stage MonitorStop
14:28:08,023 INFO  [org.radargun.Slave] (sc-main) Finished stage MonitorStop
14:28:08,023 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
14:28:08,029 INFO  [org.radargun.Slave] (sc-main) Starting stage ScenarioDestroy
14:28:08,029 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Scenario finished, destroying...
14:28:08,030 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Memory before cleanup: 
Runtime free: 895,884 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,597 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,700 kb
MX Metaspace(Non-heap memory): used: 36,661 kb, init: 0 kb, committed: 37,184 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 13,474 kb, init: 2,496 kb, committed: 13,504 kb, max: 120,028 kb
MX Compressed Class Space(Non-heap memory): used: 4,242 kb, init: 0 kb, committed: 4,480 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 23,552 kb, init: 69,632 kb, committed: 822,272 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 420,949 kb, init: 1,329,152 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 57,856 kb, init: 0 kb, committed: 58,368 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 7,383 kb, init: 2,496 kb, committed: 7,424 kb, max: 120,032 kb
14:28:08,031 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) Stopping service.
14:28:08,046 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t16) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-30462: 240+110, fedora-40301: 272+91]}, pendingCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-30462: 243+269, fedora-40301: 269+243]}, unionCH=null, actualMembers=[fedora-30462, fedora-40301], persistentUUIDs=[1101edb5-56bb-4db5-ab24-686b4186c5da, 09f92928-61c6-44ea-acf9-9071ff732e3a]}
14:28:08,055 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t16) [Context=testCache][Scope=fedora-30462]ISPN100002: Started rebalance with topology id 11
14:28:08,060 WARN  [org.infinispan.CLUSTER] (remote-thread--p2-t34) [Context=testCache]ISPN000312: Lost data because of graceful leaver fedora-40301
14:28:08,099 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t34) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-30462: 131+40, fedora-40301: 125+33]}, pendingCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-30462: 122+134, fedora-40301: 134+122]}, unionCH=null, actualMembers=[fedora-30462, fedora-40301], persistentUUIDs=[1101edb5-56bb-4db5-ab24-686b4186c5da, 09f92928-61c6-44ea-acf9-9071ff732e3a]}
14:28:08,100 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t34) [Context=___counters][Scope=fedora-30462]ISPN100002: Started rebalance with topology id 11
14:28:08,110 WARN  [org.infinispan.statetransfer.InboundTransferTask] (stateTransferExecutor-thread--p6-t1) ISPN000210: Failed to request state of cache testCache from node fedora-40301, segments {0 3 13-24 27-28 41 44-46 56 61-62 65-78 83-84 87-91 96-99 111-114 117-122 125-127 131-132 135-137 140 154-161 171-175 178 187 192-193 201 208-209 215 230 234 244-246 249 254-257 265-272 277-278 281 286-287 302-303 306 325-327 332-334 338-340 352-355 358-359 362-364 367 374 386-389 393 409-410 435-443 449-450 460-461 478-480 491 502 509-511}
org.infinispan.remoting.transport.jgroups.SuspectException: ISPN000400: Node fedora-40301 was suspected
	at org.infinispan.remoting.transport.ResponseCollectors.remoteNodeSuspected(ResponseCollectors.java:33) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleResponseCollector.targetNotFound(SingleResponseCollector.java:31) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleResponseCollector.targetNotFound(SingleResponseCollector.java:17) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.ValidSingleResponseCollector.addResponse(ValidSingleResponseCollector.java:23) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleTargetRequest.receiveResponse(SingleTargetRequest.java:51) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleTargetRequest.onResponse(SingleTargetRequest.java:35) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.RequestRepository.addResponse(RequestRepository.java:53) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.processResponse(JGroupsTransport.java:1302) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.processMessage(JGroupsTransport.java:1205) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.access$200(JGroupsTransport.java:123) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport$ChannelCallbacks.receive(JGroupsTransport.java:1340) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.jgroups.JChannel.up(JChannel.java:819) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.stack.ProtocolStack.up(ProtocolStack.java:893) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FRAG3.up(FRAG3.java:171) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FlowControl.up(FlowControl.java:343) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FlowControl.up(FlowControl.java:343) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.GMS.up(GMS.java:864) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.STABLE.up(STABLE.java:240) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.deliverMessage(UNICAST3.java:1002) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.handleDataReceived(UNICAST3.java:728) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.up(UNICAST3.java:383) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.NAKACK2.up(NAKACK2.java:600) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.VERIFY_SUSPECT.up(VERIFY_SUSPECT.java:119) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FD_ALL.up(FD_ALL.java:199) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FD_SOCK.up(FD_SOCK.java:252) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.MERGE3.up(MERGE3.java:276) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.Discovery.up(Discovery.java:267) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.TP.passMessageUp(TP.java:1248) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.util.SubmitToThreadPool$SingleMessageHandler.run(SubmitToThreadPool.java:87) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
14:28:08,113 WARN  [org.infinispan.CLUSTER] (StopThread) [Context=___counters]ISPN000312: Lost data because of graceful leaver fedora-30462
14:28:08,118 WARN  [org.infinispan.statetransfer.InboundTransferTask] (stateTransferExecutor-thread--p6-t2) ISPN000210: Failed to request state of cache ___counters from node fedora-40301, segments {4-16 22 33-41 44 48-49 54-65 68-69 84-85 96 104-107 117-118 127-128 131-135 141-142 151-152 163 166 169-171 181-188 193 204 218-221 230 237-239 254-255}
org.infinispan.remoting.transport.jgroups.SuspectException: ISPN000400: Node fedora-40301 was suspected
	at org.infinispan.remoting.transport.ResponseCollectors.remoteNodeSuspected(ResponseCollectors.java:33) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleResponseCollector.targetNotFound(SingleResponseCollector.java:31) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleResponseCollector.targetNotFound(SingleResponseCollector.java:17) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.ValidSingleResponseCollector.addResponse(ValidSingleResponseCollector.java:23) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleTargetRequest.receiveResponse(SingleTargetRequest.java:51) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleTargetRequest.onResponse(SingleTargetRequest.java:35) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.RequestRepository.addResponse(RequestRepository.java:53) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.processResponse(JGroupsTransport.java:1302) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.processMessage(JGroupsTransport.java:1205) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.access$200(JGroupsTransport.java:123) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport$ChannelCallbacks.receive(JGroupsTransport.java:1340) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.jgroups.JChannel.up(JChannel.java:819) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.stack.ProtocolStack.up(ProtocolStack.java:893) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FRAG3.up(FRAG3.java:171) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FlowControl.up(FlowControl.java:343) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FlowControl.up(FlowControl.java:343) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.GMS.up(GMS.java:864) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.STABLE.up(STABLE.java:240) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.deliverMessage(UNICAST3.java:1002) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.handleDataReceived(UNICAST3.java:728) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.up(UNICAST3.java:383) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.NAKACK2.up(NAKACK2.java:600) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.VERIFY_SUSPECT.up(VERIFY_SUSPECT.java:119) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FD_ALL.up(FD_ALL.java:199) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FD_SOCK.up(FD_SOCK.java:252) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.MERGE3.up(MERGE3.java:276) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.Discovery.up(Discovery.java:267) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.TP.passMessageUp(TP.java:1248) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.util.SubmitToThreadPool$SingleMessageHandler.run(SubmitToThreadPool.java:87) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
14:28:08,129 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (StopThread) ISPN000080: Disconnecting JGroups channel results
14:28:08,130 INFO  [org.infinispan.CLUSTER] (jgroups-37,fedora-30462) ISPN000094: Received new cluster view for channel results: [fedora-30462|3] (2) [fedora-30462, fedora-40301]
14:28:08,135 INFO  [org.infinispan.CLUSTER] (jgroups-37,fedora-30462) ISPN100001: Node fedora-56754 left the cluster
14:28:08,175 INFO  [org.radargun.service.Infinispan90Lifecycle] (StopThread) Stopped, previous view is [fedora-30462, fedora-56754, fedora-40301]
14:28:08,176 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Service successfully stopped.
14:28:08,177 INFO  [org.radargun.Slave] (sc-main) Finished stage ScenarioDestroy
14:28:08,177 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
14:28:09,189 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.service.Infinispan80EmbeddedService.destroy() overrides public void org.radargun.service.Infinispan60EmbeddedService.destroy() but both are declared with @Destroy annotation: calling only once
14:28:09,191 INFO  [org.radargun.Slave] (main) Starting stage ScenarioCleanup
14:28:09,248 INFO  [org.radargun.stages.ScenarioCleanupStage] (main) Memory after cleanup: 
Runtime free: 1,379,174 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,599 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,700 kb
MX Metaspace(Non-heap memory): used: 36,783 kb, init: 0 kb, committed: 37,312 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 9,692 kb, init: 2,496 kb, committed: 13,632 kb, max: 120,028 kb
MX Compressed Class Space(Non-heap memory): used: 4,268 kb, init: 0 kb, committed: 4,544 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 0 kb, init: 69,632 kb, committed: 880,640 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 19,097 kb, init: 1,329,152 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 0 kb, init: 0 kb, committed: 0 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 5,964 kb, init: 2,496 kb, committed: 7,552 kb, max: 120,032 kb
14:28:09,256 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
14:28:14,254 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
14:28:18,420 INFO  [org.radargun.Slave] (main) Master shutdown!
14:28:18,425 INFO  [org.radargun.ShutDownHook] (Thread-0) Slave process is being shutdown
