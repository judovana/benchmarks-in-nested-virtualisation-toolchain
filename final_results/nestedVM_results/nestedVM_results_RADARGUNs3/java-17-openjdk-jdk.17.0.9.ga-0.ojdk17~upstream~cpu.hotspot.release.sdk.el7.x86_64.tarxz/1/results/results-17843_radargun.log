19:05:31,520 INFO  [org.radargun.RemoteMasterConnection] (main) Attempting to connect to master results:2103
19:05:31,537 INFO  [org.radargun.RemoteMasterConnection] (main) Successfully established connection with master at: results:2103
19:05:31,544 INFO  [org.radargun.Slave] (main) Received slave index 0
19:05:31,545 INFO  [org.radargun.Slave] (main) Received slave count 3
19:05:31,971 INFO  [org.radargun.ServiceHelper] (sc-main) ServiceContext properties: {}
19:05:32,198 INFO  [org.radargun.Slave] (sc-main) Eager Service Infinispan92EmbeddedService {batching=false, cache=testCache, channelRetrievalTimeout=2 mins 0 secs, enableDiagnostics=null, explicitLocking=false, file=/mnt/workspace/results/dist-sync.xml, internalsExpositionEnabled=false, jgroupsDumperEnabled=false, jgroupsDumperInterval=10.000 secs, keysPerThread=-1, mapReduceDistributedReducePhase=false, mapReduceUseIntermediateSharedCache=false, removedCaches=[  ], threadsPerNode=-1 } loaded.
19:05:34,289 INFO  [org.radargun.Slave] (sc-main) Starting stage ScenarioInit
19:05:34,337 INFO  [org.radargun.Slave] (sc-main) Finished stage ScenarioInit
19:05:34,345 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
19:05:34,353 INFO  [org.radargun.Slave] (sc-main) Starting stage BeforeServiceStart
19:05:34,355 INFO  [org.radargun.Slave] (sc-main) Finished stage BeforeServiceStart
19:05:34,359 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
19:05:34,375 INFO  [org.radargun.Slave] (sc-main) Starting stage ServiceStart
19:05:34,376 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Startup staggering, this is the slave with index 0, not sleeping
19:05:34,376 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 0
19:05:34,379 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) Infinispan version: Infinispan 'Gaina' 9.2.0.Final
19:05:34,392 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) JGroups version: JGroups 4.0.10.Final (Schiener Berg)
19:05:35,042 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (sc-main) ISPN000078: Starting JGroups channel results
19:05:35,138 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the send buffer of socket MulticastSocket was set to 1.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
19:05:35,139 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the receive buffer of socket MulticastSocket was set to 20.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
19:05:35,140 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the send buffer of socket MulticastSocket was set to 1.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
19:05:35,141 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the receive buffer of socket MulticastSocket was set to 25.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
19:05:40,177 INFO  [org.infinispan.CLUSTER] (sc-main) ISPN000094: Received new cluster view for channel results: [fedora-23104|0] (1) [fedora-23104]
19:05:40,272 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (sc-main) ISPN000079: Channel results local address is fedora-23104, physical addresses are [192.168.124.194:58424]
19:05:40,276 INFO  [org.infinispan.factories.GlobalComponentRegistry] (sc-main) ISPN000128: Infinispan version: Infinispan 'Gaina' 9.2.0.Final
19:05:40,847 INFO  [org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup] (sc-main) ISPN000107: Retrieving transaction manager Transaction: unknown
19:05:40,908 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) No RELAY2 protocol in XS service
19:05:40,909 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) No RELAY2 protocol in XS service
19:05:40,912 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) ([fedora-23104(local=true, coord=true)]) Number of members=1 is not the one expected: 3
19:05:41,913 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) ([fedora-23104(local=true, coord=true)]) Number of members=1 is not the one expected: 3
19:05:42,483 INFO  [org.infinispan.CLUSTER] (jgroups-6,fedora-23104) ISPN000094: Received new cluster view for channel results: [fedora-23104|1] (2) [fedora-23104, fedora-21900]
19:05:42,497 INFO  [org.infinispan.CLUSTER] (jgroups-6,fedora-23104) ISPN100000: Node fedora-21900 joined the cluster
19:05:42,916 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) ([fedora-23104(local=true, coord=true), fedora-21900(local=false, coord=false)]) Number of members=2 is not the one expected: 3
19:05:43,032 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-23104: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-23104: 128, fedora-21900: 128]}, unionCH=null, actualMembers=[fedora-23104, fedora-21900], persistentUUIDs=[f1f4c444-acb7-43de-a68b-940de2ea1bf9, f4182d39-41ca-489b-ab79-3a6b351be2e1]}
19:05:43,034 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-23104]ISPN100002: Started rebalance with topology id 2
19:05:43,056 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-23104: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-23104: 128, fedora-21900: 128]}, unionCH=null, actualMembers=[fedora-23104, fedora-21900], persistentUUIDs=[f1f4c444-acb7-43de-a68b-940de2ea1bf9, f4182d39-41ca-489b-ab79-3a6b351be2e1]}
19:05:43,057 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-23104]ISPN100002: Started rebalance with topology id 2
19:05:43,079 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t23) [Context=org.infinispan.CONFIG][Scope=fedora-23104]ISPN100003: Node fedora-23104 finished rebalance phase with topology id 2
19:05:43,076 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=___counter_configuration][Scope=fedora-23104]ISPN100003: Node fedora-23104 finished rebalance phase with topology id 2
19:05:43,222 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-21900]ISPN100003: Node fedora-21900 finished rebalance phase with topology id 2
19:05:43,222 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 2
19:05:43,226 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t1) [Context=___counter_configuration][Scope=fedora-23104]ISPN100003: Node fedora-23104 finished rebalance phase with topology id 3
19:05:43,238 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-21900]ISPN100003: Node fedora-21900 finished rebalance phase with topology id 3
19:05:43,240 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t4) [Context=___counter_configuration][Scope=fedora-23104]ISPN100003: Node fedora-23104 finished rebalance phase with topology id 4
19:05:43,248 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-21900]ISPN100003: Node fedora-21900 finished rebalance phase with topology id 4
19:05:43,254 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-21900]ISPN100003: Node fedora-21900 finished rebalance phase with topology id 2
19:05:43,256 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 2
19:05:43,257 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t12) [Context=org.infinispan.CONFIG][Scope=fedora-23104]ISPN100003: Node fedora-23104 finished rebalance phase with topology id 3
19:05:43,270 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-21900]ISPN100003: Node fedora-21900 finished rebalance phase with topology id 3
19:05:43,272 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t13) [Context=org.infinispan.CONFIG][Scope=fedora-23104]ISPN100003: Node fedora-23104 finished rebalance phase with topology id 4
19:05:43,288 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-21900]ISPN100003: Node fedora-21900 finished rebalance phase with topology id 4
19:05:43,305 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=DefaultConsistentHash{ns=256, owners = (1)[fedora-23104: 256+0]}, pendingCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-23104: 128+128, fedora-21900: 128+128]}, unionCH=null, actualMembers=[fedora-23104, fedora-21900], persistentUUIDs=[f1f4c444-acb7-43de-a68b-940de2ea1bf9, f4182d39-41ca-489b-ab79-3a6b351be2e1]}
19:05:43,307 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-23104]ISPN100002: Started rebalance with topology id 2
19:05:43,311 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=___counters][Scope=fedora-23104]ISPN100003: Node fedora-23104 finished rebalance phase with topology id 2
19:05:43,370 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-21900]ISPN100003: Node fedora-21900 finished rebalance phase with topology id 2
19:05:43,371 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache ___counters, topology id = 2
19:05:43,374 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t2) [Context=___counters][Scope=fedora-23104]ISPN100003: Node fedora-23104 finished rebalance phase with topology id 3
19:05:43,384 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-21900]ISPN100003: Node fedora-21900 finished rebalance phase with topology id 3
19:05:43,386 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t1) [Context=___counters][Scope=fedora-23104]ISPN100003: Node fedora-23104 finished rebalance phase with topology id 4
19:05:43,392 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-21900]ISPN100003: Node fedora-21900 finished rebalance phase with topology id 4
19:05:43,440 INFO  [org.infinispan.CLUSTER] (jgroups-11,fedora-23104) ISPN000094: Received new cluster view for channel results: [fedora-23104|2] (3) [fedora-23104, fedora-21900, fedora-23901]
19:05:43,441 INFO  [org.infinispan.CLUSTER] (jgroups-11,fedora-23104) ISPN100000: Node fedora-23901 joined the cluster
19:05:43,456 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-23104: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-23104: 128, fedora-21900: 128]}, unionCH=null, actualMembers=[fedora-23104, fedora-21900], persistentUUIDs=[f1f4c444-acb7-43de-a68b-940de2ea1bf9, f4182d39-41ca-489b-ab79-3a6b351be2e1]}
19:05:43,457 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-23104]ISPN100002: Started rebalance with topology id 2
19:05:43,462 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t10) [Context=___protobuf_metadata][Scope=fedora-23104]ISPN100003: Node fedora-23104 finished rebalance phase with topology id 2
19:05:43,553 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=DefaultConsistentHash{ns=512, owners = (1)[fedora-23104: 512+0]}, pendingCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-23104: 260+252, fedora-21900: 252+260]}, unionCH=null, actualMembers=[fedora-23104, fedora-21900], persistentUUIDs=[f1f4c444-acb7-43de-a68b-940de2ea1bf9, f4182d39-41ca-489b-ab79-3a6b351be2e1]}
19:05:43,554 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-23104]ISPN100002: Started rebalance with topology id 2
19:05:43,557 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t14) [Context=testCache][Scope=fedora-23104]ISPN100003: Node fedora-23104 finished rebalance phase with topology id 2
19:05:43,577 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-21900]ISPN100003: Node fedora-21900 finished rebalance phase with topology id 2
19:05:43,577 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 2
19:05:43,579 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t18) [Context=___protobuf_metadata][Scope=fedora-23104]ISPN100003: Node fedora-23104 finished rebalance phase with topology id 3
19:05:43,588 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-21900]ISPN100003: Node fedora-21900 finished rebalance phase with topology id 3
19:05:43,590 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=___protobuf_metadata][Scope=fedora-23104]ISPN100003: Node fedora-23104 finished rebalance phase with topology id 4
19:05:43,605 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-21900]ISPN100003: Node fedora-21900 finished rebalance phase with topology id 4
19:05:43,631 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-21900]ISPN100003: Node fedora-21900 finished rebalance phase with topology id 2
19:05:43,631 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache testCache, topology id = 2
19:05:43,634 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t5) [Context=testCache][Scope=fedora-23104]ISPN100003: Node fedora-23104 finished rebalance phase with topology id 3
19:05:43,644 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-21900]ISPN100003: Node fedora-21900 finished rebalance phase with topology id 3
19:05:43,646 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t4) [Context=testCache][Scope=fedora-23104]ISPN100003: Node fedora-23104 finished rebalance phase with topology id 4
19:05:43,651 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-21900]ISPN100003: Node fedora-21900 finished rebalance phase with topology id 4
19:05:43,916 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) Number of members is the one expected: 3
19:05:43,917 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Successfully started cache service infinispan92/embedded on slave 0
19:05:43,972 ERROR [org.radargun.service.ConfigDumpHelper] (sc-main) Error while dumping ___protobuf_metadata cache config as properties
javax.management.AttributeNotFoundException: Unknown attribute 'configurationAsProperties'. Known attributes names are: [rebalancingEnabled, cacheStatus, cacheName, cacheAvailability, version, configurationAsProperties]
	at org.infinispan.jmx.ResourceDMBean.getAttribute(ResourceDMBean.java:181) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:644) ~[?:?]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:679) ~[?:?]
	at org.radargun.service.ConfigDumpHelper60.dumpCache(ConfigDumpHelper60.java:44) [plugin-infinispan60-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.service.EmbeddedConfigurationProvider.getNormalizedConfigs(EmbeddedConfigurationProvider.java:33) [plugin-infinispan52-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.stages.lifecycle.ServiceStartStage.executeOnSlave(ServiceStartStage.java:92) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase.scenarioLoop(SlaveBase.java:102) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase$ScenarioRunner.run(SlaveBase.java:203) [radargun-core-3.0.0-SNAPSHOT.jar:?]
19:05:43,981 ERROR [org.radargun.service.ConfigDumpHelper] (sc-main) Error while dumping ___protobuf_metadata cache config as properties
javax.management.AttributeNotFoundException: Unknown attribute 'configurationAsProperties'. Known attributes names are: [rebalancingEnabled, cacheStatus, cacheName, cacheAvailability, version, configurationAsProperties]
	at org.infinispan.jmx.ResourceDMBean.getAttribute(ResourceDMBean.java:181) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:644) ~[?:?]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:679) ~[?:?]
	at org.radargun.service.ConfigDumpHelper60.dumpCache(ConfigDumpHelper60.java:44) [plugin-infinispan60-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.service.EmbeddedConfigurationProvider.getNormalizedConfigs(EmbeddedConfigurationProvider.java:33) [plugin-infinispan52-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.stages.lifecycle.ServiceStartStage.executeOnSlave(ServiceStartStage.java:92) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase.scenarioLoop(SlaveBase.java:102) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase$ScenarioRunner.run(SlaveBase.java:203) [radargun-core-3.0.0-SNAPSHOT.jar:?]
19:05:44,008 INFO  [org.radargun.Slave] (sc-main) Finished stage ServiceStart
19:05:44,018 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
19:05:44,039 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-23104: 128, fedora-21900: 128]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-23104: 80, fedora-21900: 86, fedora-23901: 90]}, unionCH=null, actualMembers=[fedora-23104, fedora-21900, fedora-23901], persistentUUIDs=[f1f4c444-acb7-43de-a68b-940de2ea1bf9, f4182d39-41ca-489b-ab79-3a6b351be2e1, 7e0fe3a0-07a8-4adb-8e62-8f508654c2e9]}
19:05:44,040 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-23104]ISPN100002: Started rebalance with topology id 6
19:05:44,041 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t15) [Context=org.infinispan.CONFIG][Scope=fedora-23104]ISPN100003: Node fedora-23104 finished rebalance phase with topology id 6
19:05:44,044 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-21900]ISPN100003: Node fedora-21900 finished rebalance phase with topology id 6
19:05:44,050 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-23104: 128, fedora-21900: 128]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-23104: 80, fedora-21900: 86, fedora-23901: 90]}, unionCH=null, actualMembers=[fedora-23104, fedora-21900, fedora-23901], persistentUUIDs=[f1f4c444-acb7-43de-a68b-940de2ea1bf9, f4182d39-41ca-489b-ab79-3a6b351be2e1, 7e0fe3a0-07a8-4adb-8e62-8f508654c2e9]}
19:05:44,050 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-23104]ISPN100002: Started rebalance with topology id 6
19:05:44,052 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t12) [Context=___counter_configuration][Scope=fedora-23104]ISPN100003: Node fedora-23104 finished rebalance phase with topology id 6
19:05:44,055 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-21900]ISPN100003: Node fedora-21900 finished rebalance phase with topology id 6
19:05:44,295 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-23104: 128, fedora-21900: 128]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-23104: 80, fedora-21900: 86, fedora-23901: 90]}, unionCH=null, actualMembers=[fedora-23104, fedora-21900, fedora-23901], persistentUUIDs=[f1f4c444-acb7-43de-a68b-940de2ea1bf9, f4182d39-41ca-489b-ab79-3a6b351be2e1, 7e0fe3a0-07a8-4adb-8e62-8f508654c2e9]}
19:05:44,295 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-23104]ISPN100002: Started rebalance with topology id 6
19:05:44,297 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t22) [Context=___protobuf_metadata][Scope=fedora-23104]ISPN100003: Node fedora-23104 finished rebalance phase with topology id 6
19:05:44,303 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-21900]ISPN100003: Node fedora-21900 finished rebalance phase with topology id 6
19:05:44,343 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-23104: 260+252, fedora-21900: 252+260]}, pendingCH=DefaultConsistentHash{ns=512, owners = (3)[fedora-23104: 170+173, fedora-21900: 177+175, fedora-23901: 165+164]}, unionCH=null, actualMembers=[fedora-23104, fedora-21900, fedora-23901], persistentUUIDs=[f1f4c444-acb7-43de-a68b-940de2ea1bf9, f4182d39-41ca-489b-ab79-3a6b351be2e1, 7e0fe3a0-07a8-4adb-8e62-8f508654c2e9]}
19:05:44,344 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-23104]ISPN100002: Started rebalance with topology id 6
19:05:44,343 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-23901]ISPN100003: Node fedora-23901 finished rebalance phase with topology id 6
19:05:44,344 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 6
19:05:44,346 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t3) [Context=testCache][Scope=fedora-23104]ISPN100003: Node fedora-23104 finished rebalance phase with topology id 6
19:05:44,347 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t1) [Context=___protobuf_metadata][Scope=fedora-23104]ISPN100003: Node fedora-23104 finished rebalance phase with topology id 7
19:05:44,353 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-21900]ISPN100003: Node fedora-21900 finished rebalance phase with topology id 7
19:05:44,357 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-21900]ISPN100003: Node fedora-21900 finished rebalance phase with topology id 6
19:05:44,370 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-23901]ISPN100003: Node fedora-23901 finished rebalance phase with topology id 7
19:05:44,372 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t8) [Context=___protobuf_metadata][Scope=fedora-23104]ISPN100003: Node fedora-23104 finished rebalance phase with topology id 8
19:05:44,375 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-21900]ISPN100003: Node fedora-21900 finished rebalance phase with topology id 8
19:05:44,382 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-23901]ISPN100003: Node fedora-23901 finished rebalance phase with topology id 8
19:05:44,422 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-23901]ISPN100003: Node fedora-23901 finished rebalance phase with topology id 6
19:05:44,422 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache testCache, topology id = 6
19:05:44,425 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t13) [Context=testCache][Scope=fedora-23104]ISPN100003: Node fedora-23104 finished rebalance phase with topology id 7
19:05:44,429 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-21900]ISPN100003: Node fedora-21900 finished rebalance phase with topology id 7
19:05:44,435 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-23901]ISPN100003: Node fedora-23901 finished rebalance phase with topology id 7
19:05:44,437 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t16) [Context=testCache][Scope=fedora-23104]ISPN100003: Node fedora-23104 finished rebalance phase with topology id 8
19:05:44,445 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-21900]ISPN100003: Node fedora-21900 finished rebalance phase with topology id 8
19:05:44,450 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-23901]ISPN100003: Node fedora-23901 finished rebalance phase with topology id 6
19:05:44,450 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 6
19:05:44,451 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t18) [Context=org.infinispan.CONFIG][Scope=fedora-23104]ISPN100003: Node fedora-23104 finished rebalance phase with topology id 7
19:05:44,454 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-21900]ISPN100003: Node fedora-21900 finished rebalance phase with topology id 7
19:05:44,458 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-23901]ISPN100003: Node fedora-23901 finished rebalance phase with topology id 6
19:05:44,458 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 6
19:05:44,460 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t6) [Context=___counter_configuration][Scope=fedora-23104]ISPN100003: Node fedora-23104 finished rebalance phase with topology id 7
19:05:44,462 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-21900]ISPN100003: Node fedora-21900 finished rebalance phase with topology id 7
19:05:44,465 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-23901]ISPN100003: Node fedora-23901 finished rebalance phase with topology id 7
19:05:44,465 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-23901]ISPN100003: Node fedora-23901 finished rebalance phase with topology id 8
19:05:44,466 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t19) [Context=org.infinispan.CONFIG][Scope=fedora-23104]ISPN100003: Node fedora-23104 finished rebalance phase with topology id 8
19:05:44,470 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counter_configuration][Scope=fedora-23901]ISPN100003: Node fedora-23901 finished rebalance phase with topology id 7
19:05:44,471 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t9) [Context=___counter_configuration][Scope=fedora-23104]ISPN100003: Node fedora-23104 finished rebalance phase with topology id 8
19:05:44,476 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=org.infinispan.CONFIG][Scope=fedora-21900]ISPN100003: Node fedora-21900 finished rebalance phase with topology id 8
19:05:44,477 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counter_configuration][Scope=fedora-21900]ISPN100003: Node fedora-21900 finished rebalance phase with topology id 8
19:05:44,484 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=org.infinispan.CONFIG][Scope=fedora-23901]ISPN100003: Node fedora-23901 finished rebalance phase with topology id 8
19:05:44,487 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-23901]ISPN100003: Node fedora-23901 finished rebalance phase with topology id 8
19:05:44,506 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-23104: 128+128, fedora-21900: 128+128]}, pendingCH=DefaultConsistentHash{ns=256, owners = (3)[fedora-23104: 80+76, fedora-21900: 86+96, fedora-23901: 90+84]}, unionCH=null, actualMembers=[fedora-23104, fedora-21900, fedora-23901], persistentUUIDs=[f1f4c444-acb7-43de-a68b-940de2ea1bf9, f4182d39-41ca-489b-ab79-3a6b351be2e1, 7e0fe3a0-07a8-4adb-8e62-8f508654c2e9]}
19:05:44,507 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=fedora-23104]ISPN100002: Started rebalance with topology id 6
19:05:44,508 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t12) [Context=___counters][Scope=fedora-23104]ISPN100003: Node fedora-23104 finished rebalance phase with topology id 6
19:05:44,511 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=fedora-21900]ISPN100003: Node fedora-21900 finished rebalance phase with topology id 6
19:05:44,541 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=fedora-23901]ISPN100003: Node fedora-23901 finished rebalance phase with topology id 6
19:05:44,542 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000336: Finished cluster-wide rebalance for cache ___counters, topology id = 6
19:05:44,545 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=___counters][Scope=fedora-23104]ISPN100003: Node fedora-23104 finished rebalance phase with topology id 7
19:05:44,548 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=fedora-23901]ISPN100003: Node fedora-23901 finished rebalance phase with topology id 7
19:05:44,549 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=fedora-21900]ISPN100003: Node fedora-21900 finished rebalance phase with topology id 7
19:05:44,550 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t25) [Context=___counters][Scope=fedora-23104]ISPN100003: Node fedora-23104 finished rebalance phase with topology id 8
19:05:44,555 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=fedora-21900]ISPN100003: Node fedora-21900 finished rebalance phase with topology id 8
19:05:44,556 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=fedora-23901]ISPN100003: Node fedora-23901 finished rebalance phase with topology id 8
19:05:44,620 INFO  [org.radargun.Slave] (sc-main) Starting stage AfterServiceStart
19:05:44,621 INFO  [org.radargun.Slave] (sc-main) Finished stage AfterServiceStart
19:05:44,627 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
19:05:44,712 INFO  [org.radargun.Slave] (sc-main) Starting stage MonitorStart
19:05:44,719 INFO  [org.radargun.sysmonitor.AbstractMonitors] (sc-main) Gathering statistics every 1000 ms
19:05:44,722 INFO  [org.radargun.Slave] (sc-main) Finished stage MonitorStart
19:05:44,723 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
19:05:44,760 INFO  [org.radargun.Slave] (sc-main) Starting stage Load
19:05:54,033 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) This node loaded 10000 entries (~10000000 bytes)
19:05:58,917 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) This node loaded 20000 entries (~20000000 bytes)
19:06:03,510 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) This node loaded 30000 entries (~30000000 bytes)
19:06:04,464 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) Finished loading entries
19:06:04,638 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) Finished loading entries
19:06:04,642 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) Finished loading entries
19:06:04,657 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) Finished loading entries
19:06:04,661 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) Finished loading entries
19:06:04,677 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) Finished loading entries
19:06:04,779 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) Finished loading entries
19:06:04,791 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) Finished loading entries
19:06:04,826 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) Finished loading entries
19:06:04,899 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) Finished loading entries
19:06:04,901 INFO  [org.radargun.Slave] (sc-main) Finished stage Load
19:06:04,902 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
19:06:05,037 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.stages.cache.test.BasicOperationsTestStage.init() overrides public void org.radargun.stages.test.TestStage.init() but both are declared with @Init annotation: calling only once
19:06:05,040 INFO  [org.radargun.Slave] (sc-main) Starting stage BasicOperationsTest
19:06:05,040 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using key generator org.radargun.stages.cache.generators.StringKeyGenerator {format=null }
19:06:05,040 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using value generator org.radargun.stages.cache.generators.ByteArrayValueGenerator { }
19:06:05,041 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using cache selector Default { }
19:06:05,041 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Starting test warmup
19:06:05,084 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Started 4 stressor threads.
19:07:05,094 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Finished test. Test duration is: 1 mins 0 secs
19:07:05,098 INFO  [org.radargun.Slave] (sc-main) Finished stage BasicOperationsTest
19:07:05,114 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
19:07:05,147 INFO  [org.radargun.Slave] (sc-main) Starting stage Clear
19:07:05,150 INFO  [org.radargun.stages.cache.ClearStage] (sc-main) Before executing clear, memory looks like this: 
Runtime free: 579,370 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,310 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,700 kb
MX Metaspace(Non-heap memory): used: 34,814 kb, init: 0 kb, committed: 35,200 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 8,691 kb, init: 2,496 kb, committed: 10,240 kb, max: 120,028 kb
MX Compressed Class Space(Non-heap memory): used: 4,175 kb, init: 0 kb, committed: 4,352 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 637,952 kb, init: 73,728 kb, committed: 857,088 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 156,885 kb, init: 1,325,056 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 23,552 kb, init: 0 kb, committed: 23,552 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 4,888 kb, init: 2,496 kb, committed: 5,696 kb, max: 120,032 kb
19:07:05,277 INFO  [org.radargun.stages.cache.ClearStage] (sc-main) After executing clear, memory looks like this: 
Runtime free: 1,380,671 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,310 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,700 kb
MX Metaspace(Non-heap memory): used: 34,834 kb, init: 0 kb, committed: 35,200 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 8,762 kb, init: 2,496 kb, committed: 10,240 kb, max: 120,028 kb
MX Compressed Class Space(Non-heap memory): used: 4,175 kb, init: 0 kb, committed: 4,352 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 0 kb, init: 73,728 kb, committed: 880,640 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 17,559 kb, init: 1,325,056 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 0 kb, init: 0 kb, committed: 0 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 4,900 kb, init: 2,496 kb, committed: 5,696 kb, max: 120,032 kb
19:07:05,278 INFO  [org.radargun.Slave] (sc-main) Finished stage Clear
19:07:05,278 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
19:07:05,322 INFO  [org.radargun.Slave] (sc-main) Starting stage Load
19:07:07,884 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) This node loaded 10000 entries (~10000000 bytes)
19:07:10,281 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) This node loaded 20000 entries (~20000000 bytes)
19:07:12,801 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) This node loaded 30000 entries (~30000000 bytes)
19:07:13,503 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) Finished loading entries
19:07:13,545 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) Finished loading entries
19:07:13,548 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) Finished loading entries
19:07:13,556 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) Finished loading entries
19:07:13,557 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) Finished loading entries
19:07:13,570 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) Finished loading entries
19:07:13,572 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) Finished loading entries
19:07:13,598 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) Finished loading entries
19:07:13,609 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) Finished loading entries
19:07:13,625 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) Finished loading entries
19:07:13,626 INFO  [org.radargun.Slave] (sc-main) Finished stage Load
19:07:13,627 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
19:07:13,837 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.stages.cache.test.BasicOperationsTestStage.init() overrides public void org.radargun.stages.test.TestStage.init() but both are declared with @Init annotation: calling only once
19:07:13,845 INFO  [org.radargun.Slave] (sc-main) Starting stage BasicOperationsTest
19:07:13,847 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using key generator org.radargun.stages.cache.generators.StringKeyGenerator {format=null }
19:07:13,851 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using value generator org.radargun.stages.cache.generators.ByteArrayValueGenerator { }
19:07:13,851 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using cache selector Default { }
19:07:13,851 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Starting test stress-test
19:07:13,917 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Started 4 stressor threads.
19:17:13,919 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Finished test. Test duration is: 10 mins 0 secs
19:17:13,920 INFO  [org.radargun.Slave] (sc-main) Finished stage BasicOperationsTest
19:17:13,990 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
19:17:14,185 INFO  [org.radargun.Slave] (sc-main) Starting stage MonitorStop
19:17:14,187 INFO  [org.radargun.Slave] (sc-main) Finished stage MonitorStop
19:17:14,188 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
19:17:14,196 INFO  [org.radargun.Slave] (sc-main) Starting stage ScenarioDestroy
19:17:14,197 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Scenario finished, destroying...
19:17:14,199 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Memory before cleanup: 
Runtime free: 908,275 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,313 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,700 kb
MX Metaspace(Non-heap memory): used: 35,465 kb, init: 0 kb, committed: 35,840 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 9,634 kb, init: 2,496 kb, committed: 10,240 kb, max: 120,028 kb
MX Compressed Class Space(Non-heap memory): used: 4,208 kb, init: 0 kb, committed: 4,416 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 58,368 kb, init: 73,728 kb, committed: 759,808 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 375,306 kb, init: 1,325,056 kb, committed: 581,632 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 56,832 kb, init: 0 kb, committed: 57,344 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 5,693 kb, init: 2,496 kb, committed: 5,696 kb, max: 120,032 kb
19:17:14,199 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) Stopping service.
19:17:14,214 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t38) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-23104: 264+79, fedora-23901: 248+81]}, pendingCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-23104: 255+257, fedora-23901: 257+255]}, unionCH=null, actualMembers=[fedora-23104, fedora-23901], persistentUUIDs=[f1f4c444-acb7-43de-a68b-940de2ea1bf9, 7e0fe3a0-07a8-4adb-8e62-8f508654c2e9]}
19:17:14,216 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t38) [Context=testCache][Scope=fedora-23104]ISPN100002: Started rebalance with topology id 11
19:17:14,221 WARN  [org.infinispan.CLUSTER] (StopThread) [Context=testCache]ISPN000312: Lost data because of graceful leaver fedora-23104
19:17:14,241 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t38) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-23104: 124, fedora-23901: 132]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-23104: 122, fedora-23901: 134]}, unionCH=null, actualMembers=[fedora-23104, fedora-23901], persistentUUIDs=[f1f4c444-acb7-43de-a68b-940de2ea1bf9, 7e0fe3a0-07a8-4adb-8e62-8f508654c2e9]}
19:17:14,242 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t38) [Context=___protobuf_metadata][Scope=fedora-23104]ISPN100002: Started rebalance with topology id 11
19:17:14,244 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t14) [Context=___protobuf_metadata][Scope=fedora-23104]ISPN100003: Node fedora-23104 finished rebalance phase with topology id 11
19:17:14,245 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t38) [Context=___protobuf_metadata][Scope=fedora-23901]ISPN100003: Node fedora-23901 finished rebalance phase with topology id 11
19:17:14,249 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t38) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 11
19:17:14,251 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t16) [Context=___protobuf_metadata][Scope=fedora-23104]ISPN100003: Node fedora-23104 finished rebalance phase with topology id 12
19:17:14,252 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t35) [Context=___protobuf_metadata][Scope=fedora-23901]ISPN100003: Node fedora-23901 finished rebalance phase with topology id 12
19:17:14,253 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t18) [Context=___protobuf_metadata][Scope=fedora-23104]ISPN100003: Node fedora-23104 finished rebalance phase with topology id 13
19:17:14,255 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t38) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-23104: 122+34, fedora-23901: 134+40]}, pendingCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-23104: 122+134, fedora-23901: 134+122]}, unionCH=null, actualMembers=[fedora-23104, fedora-23901], persistentUUIDs=[f1f4c444-acb7-43de-a68b-940de2ea1bf9, 7e0fe3a0-07a8-4adb-8e62-8f508654c2e9]}
19:17:14,255 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t38) [Context=___counters][Scope=fedora-23104]ISPN100002: Started rebalance with topology id 11
19:17:14,258 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t35) [Context=___protobuf_metadata][Scope=fedora-23901]ISPN100003: Node fedora-23901 finished rebalance phase with topology id 13
19:17:14,267 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t38) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-23104: 124, fedora-23901: 132]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-23104: 122, fedora-23901: 134]}, unionCH=null, actualMembers=[fedora-23104, fedora-23901], persistentUUIDs=[f1f4c444-acb7-43de-a68b-940de2ea1bf9, 7e0fe3a0-07a8-4adb-8e62-8f508654c2e9]}
19:17:14,269 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t38) [Context=org.infinispan.CONFIG][Scope=fedora-23104]ISPN100002: Started rebalance with topology id 11
19:17:14,271 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t19) [Context=org.infinispan.CONFIG][Scope=fedora-23104]ISPN100003: Node fedora-23104 finished rebalance phase with topology id 11
19:17:14,272 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t38) [Context=org.infinispan.CONFIG][Scope=fedora-23901]ISPN100003: Node fedora-23901 finished rebalance phase with topology id 11
19:17:14,273 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t38) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 11
19:17:14,275 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t10) [Context=org.infinispan.CONFIG][Scope=fedora-23104]ISPN100003: Node fedora-23104 finished rebalance phase with topology id 12
19:17:14,276 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t35) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=12, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-23104: 124, fedora-23901: 132]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-23104: 122, fedora-23901: 134]}, unionCH=null, actualMembers=[fedora-23104, fedora-23901], persistentUUIDs=[f1f4c444-acb7-43de-a68b-940de2ea1bf9, 7e0fe3a0-07a8-4adb-8e62-8f508654c2e9]}
19:17:14,277 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t35) [Context=___counter_configuration][Scope=fedora-23104]ISPN100002: Started rebalance with topology id 12
19:17:14,276 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t38) [Context=org.infinispan.CONFIG][Scope=fedora-23901]ISPN100003: Node fedora-23901 finished rebalance phase with topology id 12
19:17:14,278 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t16) [Context=___counter_configuration][Scope=fedora-23104]ISPN100003: Node fedora-23104 finished rebalance phase with topology id 12
19:17:14,279 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t12) [Context=org.infinispan.CONFIG][Scope=fedora-23104]ISPN100003: Node fedora-23104 finished rebalance phase with topology id 13
19:17:14,280 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t38) [Context=___counter_configuration][Scope=fedora-23901]ISPN100003: Node fedora-23901 finished rebalance phase with topology id 12
19:17:14,283 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t38) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 12
19:17:14,284 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t2) [Context=___counter_configuration][Scope=fedora-23104]ISPN100003: Node fedora-23104 finished rebalance phase with topology id 13
19:17:14,285 INFO  [org.infinispan.CLUSTER] (jgroups-40,fedora-23104) ISPN000094: Received new cluster view for channel results: [fedora-23104|3] (2) [fedora-23104, fedora-23901]
19:17:14,286 INFO  [org.infinispan.CLUSTER] (jgroups-40,fedora-23104) ISPN100001: Node fedora-21900 left the cluster
19:17:14,280 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t35) [Context=org.infinispan.CONFIG][Scope=fedora-23901]ISPN100003: Node fedora-23901 finished rebalance phase with topology id 13
19:17:14,288 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t35) [Context=___counter_configuration][Scope=fedora-23901]ISPN100003: Node fedora-23901 finished rebalance phase with topology id 13
19:17:14,291 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=___counter_configuration][Scope=fedora-23104]ISPN100003: Node fedora-23104 finished rebalance phase with topology id 14
19:17:14,302 WARN  [org.infinispan.statetransfer.InboundTransferTask] (stateTransferExecutor-thread--p6-t2) ISPN000210: Failed to request state of cache testCache from node fedora-23901, segments {7-10 19-20 26-28 32-33 36 41-42 52-61 70 73 78-80 84-94 98 104-106 116-120 127 133-136 142-144 147-153 159-161 169 182 186 192-193 196-200 209-210 217-219 222-224 246-247 257-260 267 281-283 286-288 299 310-313 318 324-330 334-335 338-341 351-352 356-361 364 370-371 374 377 398 403-404 407-408 411 418-424 427-429 433-434 440-444 452-453 457-462 471 482 491-495 507}
org.infinispan.remoting.transport.jgroups.SuspectException: ISPN000400: Node fedora-23901 was suspected
	at org.infinispan.remoting.transport.ResponseCollectors.remoteNodeSuspected(ResponseCollectors.java:33) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleResponseCollector.targetNotFound(SingleResponseCollector.java:31) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleResponseCollector.targetNotFound(SingleResponseCollector.java:17) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.ValidSingleResponseCollector.addResponse(ValidSingleResponseCollector.java:23) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleTargetRequest.receiveResponse(SingleTargetRequest.java:51) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleTargetRequest.onResponse(SingleTargetRequest.java:35) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.RequestRepository.addResponse(RequestRepository.java:53) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.processResponse(JGroupsTransport.java:1302) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.processMessage(JGroupsTransport.java:1205) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.access$200(JGroupsTransport.java:123) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport$ChannelCallbacks.receive(JGroupsTransport.java:1340) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.jgroups.JChannel.up(JChannel.java:819) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.stack.ProtocolStack.up(ProtocolStack.java:893) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FRAG3.up(FRAG3.java:171) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FlowControl.up(FlowControl.java:343) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FlowControl.up(FlowControl.java:343) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.GMS.up(GMS.java:864) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.STABLE.up(STABLE.java:240) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.deliverMessage(UNICAST3.java:1002) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.handleDataReceived(UNICAST3.java:728) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.up(UNICAST3.java:383) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.NAKACK2.up(NAKACK2.java:600) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.VERIFY_SUSPECT.up(VERIFY_SUSPECT.java:119) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FD_ALL.up(FD_ALL.java:199) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FD_SOCK.up(FD_SOCK.java:252) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.MERGE3.up(MERGE3.java:276) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.Discovery.up(Discovery.java:267) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.TP.passMessageUp(TP.java:1248) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.util.SubmitToThreadPool$SingleMessageHandler.run(SubmitToThreadPool.java:87) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
19:17:14,308 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t38) [Context=___counter_configuration][Scope=fedora-23901]ISPN100003: Node fedora-23901 finished rebalance phase with topology id 14
19:17:14,325 WARN  [org.infinispan.CLUSTER] (StopThread) [Context=___counters]ISPN000312: Lost data because of graceful leaver fedora-23104
19:17:14,331 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t38) [Context=___counters][Scope=fedora-23901]ISPN100003: Node fedora-23901 finished rebalance phase with topology id 12
19:17:14,336 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (remote-thread--p2-t38) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___counters, type=REBALANCE_PHASE_CONFIRM, sender=fedora-23901, joinInfo=null, topologyId=12, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=3}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-23901 for cache ___counters, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.invokeReplicableCommand(GlobalInboundInvocationHandler.java:169) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.runReplicableCommand(GlobalInboundInvocationHandler.java:150) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.lambda$handleReplicableCommand$1(GlobalInboundInvocationHandler.java:144) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.util.concurrent.BlockingTaskAwareExecutorServiceImpl$RunnableWrapper.run(BlockingTaskAwareExecutorServiceImpl.java:212) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
19:17:14,364 INFO  [org.infinispan.CLUSTER] (jgroups-40,fedora-23104) ISPN000094: Received new cluster view for channel results: [fedora-23104|4] (1) [fedora-23104]
19:17:14,365 INFO  [org.infinispan.CLUSTER] (jgroups-40,fedora-23104) ISPN100001: Node fedora-23901 left the cluster
19:17:14,393 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (StopThread) ISPN000080: Disconnecting JGroups channel results
19:17:14,414 WARN  [org.infinispan.remoting.inboundhandler.TrianglePerCacheInboundInvocationHandler] (remote-thread--p2-t35) ISPN000071: Caught exception when handling command StateResponseCommand{cache=___counters, pushTransfer=false, stateChunks=[StateChunk{segmentId=3, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=4, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=5, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=6, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=10, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=11, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=12, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=13, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=14, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=15, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=16, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=17, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=18, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=21, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=22, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=23, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=24, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=25, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=26, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=27, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=28, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=29, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=39, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=40, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=41, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=42, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=43, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=44, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=45, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=46, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=52, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=58, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=59, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=62, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=63, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=70, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=71, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=72, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=73, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=74, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=75, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=80, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=90, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=96, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=97, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=98, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=99, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=100, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=101, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=102, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=111, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=122, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=129, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=130, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=136, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=137, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=138, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=143, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=159, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=160, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=161, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=162, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=163, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=164, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=165, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=166, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=173, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=178, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=179, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=180, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=181, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=197, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=198, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=199, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=200, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=201, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=202, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=203, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=204, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=205, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=208, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=209, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=210, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=211, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=212, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=213, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=214, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=215, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=216, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=217, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=220, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=221, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=222, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=226, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=227, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=228, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=229, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=246, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=247, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=253, cacheEntries=0, isLastChunk=true}], origin=fedora-23901, topologyId=11, applyState=true}
org.infinispan.commons.CacheException: java.lang.InterruptedException
	at org.infinispan.statetransfer.StateConsumerImpl.applyState(StateConsumerImpl.java:572) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.statetransfer.StateResponseCommand.invokeAsync(StateResponseCommand.java:88) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.BasePerCacheInboundInvocationHandler.invokeCommand(BasePerCacheInboundInvocationHandler.java:94) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.BaseBlockingRunnable.invoke(BaseBlockingRunnable.java:99) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.BaseBlockingRunnable.runAsync(BaseBlockingRunnable.java:71) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.BaseBlockingRunnable.run(BaseBlockingRunnable.java:40) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
Caused by: java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.tryAcquireSharedNanos(AbstractQueuedSynchronizer.java:1081) ~[?:?]
	at java.util.concurrent.CountDownLatch.await(CountDownLatch.java:276) ~[?:?]
	at org.infinispan.statetransfer.StateConsumerImpl.applyState(StateConsumerImpl.java:566) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	... 8 more
19:17:14,420 INFO  [org.radargun.service.Infinispan90Lifecycle] (StopThread) Stopped, previous view is [fedora-23104, fedora-21900, fedora-23901]
19:17:14,421 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Service successfully stopped.
19:17:14,422 INFO  [org.radargun.Slave] (sc-main) Finished stage ScenarioDestroy
19:17:14,423 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
19:17:14,430 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.service.Infinispan80EmbeddedService.destroy() overrides public void org.radargun.service.Infinispan60EmbeddedService.destroy() but both are declared with @Destroy annotation: calling only once
19:17:14,438 INFO  [org.radargun.Slave] (main) Starting stage ScenarioCleanup
19:17:14,474 INFO  [org.radargun.stages.ScenarioCleanupStage] (main) Memory after cleanup: 
Runtime free: 1,379,853 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,314 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,700 kb
MX Metaspace(Non-heap memory): used: 35,657 kb, init: 0 kb, committed: 36,032 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 9,846 kb, init: 2,496 kb, committed: 10,240 kb, max: 120,028 kb
MX Compressed Class Space(Non-heap memory): used: 4,235 kb, init: 0 kb, committed: 4,416 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 0 kb, init: 73,728 kb, committed: 880,640 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 18,418 kb, init: 1,325,056 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 0 kb, init: 0 kb, committed: 0 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 5,688 kb, init: 2,496 kb, committed: 5,696 kb, max: 120,032 kb
19:17:14,475 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
19:17:19,616 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
19:17:24,198 INFO  [org.radargun.Slave] (main) Master shutdown!
19:17:24,199 INFO  [org.radargun.ShutDownHook] (Thread-0) Slave process is being shutdown
