03:08:48,578 INFO  [org.radargun.RemoteMasterConnection] (main) Attempting to connect to master results:2103
03:08:48,585 INFO  [org.radargun.RemoteMasterConnection] (main) Successfully established connection with master at: results:2103
03:08:48,598 INFO  [org.radargun.Slave] (main) Received slave index 0
03:08:48,599 INFO  [org.radargun.Slave] (main) Received slave count 3
03:08:48,841 INFO  [org.radargun.ServiceHelper] (sc-main) ServiceContext properties: {}
03:08:49,032 INFO  [org.radargun.Slave] (sc-main) Eager Service Infinispan92EmbeddedService {batching=false, cache=testCache, channelRetrievalTimeout=2 mins 0 secs, enableDiagnostics=null, explicitLocking=false, file=/mnt/workspace/results/dist-sync.xml, internalsExpositionEnabled=false, jgroupsDumperEnabled=false, jgroupsDumperInterval=10.000 secs, keysPerThread=-1, mapReduceDistributedReducePhase=false, mapReduceUseIntermediateSharedCache=false, removedCaches=[  ], threadsPerNode=-1 } loaded.
03:08:50,681 INFO  [org.radargun.Slave] (sc-main) Starting stage ScenarioInit
03:08:50,748 INFO  [org.radargun.Slave] (sc-main) Finished stage ScenarioInit
03:08:50,758 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
03:08:50,958 INFO  [org.radargun.Slave] (sc-main) Starting stage BeforeServiceStart
03:08:50,958 INFO  [org.radargun.Slave] (sc-main) Finished stage BeforeServiceStart
03:08:50,959 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
03:08:50,972 INFO  [org.radargun.Slave] (sc-main) Starting stage ServiceStart
03:08:50,972 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Startup staggering, this is the slave with index 0, not sleeping
03:08:50,975 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 0
03:08:50,985 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) Infinispan version: Infinispan 'Gaina' 9.2.0.Final
03:08:51,006 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) JGroups version: JGroups 4.0.10.Final (Schiener Berg)
03:08:51,494 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (sc-main) ISPN000078: Starting JGroups channel results
03:08:51,607 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the send buffer of socket MulticastSocket was set to 1.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
03:08:51,608 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the receive buffer of socket MulticastSocket was set to 20.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
03:08:51,608 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the send buffer of socket MulticastSocket was set to 1.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
03:08:51,609 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the receive buffer of socket MulticastSocket was set to 25.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
03:08:56,637 INFO  [org.infinispan.CLUSTER] (sc-main) ISPN000094: Received new cluster view for channel results: [fedora-27553|0] (1) [fedora-27553]
03:08:56,747 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (sc-main) ISPN000079: Channel results local address is fedora-27553, physical addresses are [192.168.124.94:42334]
03:08:56,752 INFO  [org.infinispan.factories.GlobalComponentRegistry] (sc-main) ISPN000128: Infinispan version: Infinispan 'Gaina' 9.2.0.Final
03:08:57,239 INFO  [org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup] (sc-main) ISPN000107: Retrieving transaction manager Transaction: unknown
03:08:57,361 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) No RELAY2 protocol in XS service
03:08:57,361 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) No RELAY2 protocol in XS service
03:08:57,363 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) ([fedora-27553(local=true, coord=true)]) Number of members=1 is not the one expected: 3
03:08:57,689 INFO  [org.infinispan.CLUSTER] (jgroups-6,fedora-27553) ISPN000094: Received new cluster view for channel results: [fedora-27553|1] (2) [fedora-27553, fedora-21018]
03:08:57,703 INFO  [org.infinispan.CLUSTER] (jgroups-6,fedora-27553) ISPN100000: Node fedora-21018 joined the cluster
03:08:58,163 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-27553: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-27553: 128, fedora-21018: 128]}, unionCH=null, actualMembers=[fedora-27553, fedora-21018], persistentUUIDs=[cfafe099-bfe1-451c-a681-9789379c67ea, 6fe2e957-3ceb-4578-9281-d7bf15510ce3]}
03:08:58,165 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-27553]ISPN100002: Started rebalance with topology id 2
03:08:58,165 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-27553: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-27553: 128, fedora-21018: 128]}, unionCH=null, actualMembers=[fedora-27553, fedora-21018], persistentUUIDs=[cfafe099-bfe1-451c-a681-9789379c67ea, 6fe2e957-3ceb-4578-9281-d7bf15510ce3]}
03:08:58,166 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-27553]ISPN100002: Started rebalance with topology id 2
03:08:58,183 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t22) [Context=___counter_configuration][Scope=fedora-27553]ISPN100003: Node fedora-27553 finished rebalance phase with topology id 2
03:08:58,189 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t23) [Context=org.infinispan.CONFIG][Scope=fedora-27553]ISPN100003: Node fedora-27553 finished rebalance phase with topology id 2
03:08:58,231 INFO  [org.infinispan.CLUSTER] (jgroups-11,fedora-27553) ISPN000094: Received new cluster view for channel results: [fedora-27553|2] (3) [fedora-27553, fedora-21018, fedora-38777]
03:08:58,232 INFO  [org.infinispan.CLUSTER] (jgroups-11,fedora-27553) ISPN100000: Node fedora-38777 joined the cluster
03:08:58,365 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) Number of members is the one expected: 3
03:08:58,366 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Successfully started cache service infinispan92/embedded on slave 0
03:08:58,477 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-21018]ISPN100003: Node fedora-21018 finished rebalance phase with topology id 2
03:08:58,477 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 2
03:08:58,463 ERROR [org.radargun.service.ConfigDumpHelper] (sc-main) Error while dumping ___protobuf_metadata cache config as properties
javax.management.AttributeNotFoundException: Unknown attribute 'configurationAsProperties'. Known attributes names are: [rebalancingEnabled, cacheStatus, cacheAvailability, cacheName, version, configurationAsProperties]
	at org.infinispan.jmx.ResourceDMBean.getAttribute(ResourceDMBean.java:181) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:636) ~[?:?]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:679) ~[?:?]
	at org.radargun.service.ConfigDumpHelper60.dumpCache(ConfigDumpHelper60.java:44) [plugin-infinispan60-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.service.EmbeddedConfigurationProvider.getNormalizedConfigs(EmbeddedConfigurationProvider.java:33) [plugin-infinispan52-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.stages.lifecycle.ServiceStartStage.executeOnSlave(ServiceStartStage.java:92) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase.scenarioLoop(SlaveBase.java:102) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase$ScenarioRunner.run(SlaveBase.java:203) [radargun-core-3.0.0-SNAPSHOT.jar:?]
03:08:58,483 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t3) [Context=___counter_configuration][Scope=fedora-27553]ISPN100003: Node fedora-27553 finished rebalance phase with topology id 3
03:08:58,498 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-21018]ISPN100003: Node fedora-21018 finished rebalance phase with topology id 3
03:08:58,501 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t4) [Context=___counter_configuration][Scope=fedora-27553]ISPN100003: Node fedora-27553 finished rebalance phase with topology id 4
03:08:58,504 ERROR [org.radargun.service.ConfigDumpHelper] (sc-main) Error while dumping ___protobuf_metadata cache config as properties
javax.management.AttributeNotFoundException: Unknown attribute 'configurationAsProperties'. Known attributes names are: [rebalancingEnabled, cacheStatus, cacheAvailability, cacheName, version, configurationAsProperties]
	at org.infinispan.jmx.ResourceDMBean.getAttribute(ResourceDMBean.java:181) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:636) ~[?:?]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:679) ~[?:?]
	at org.radargun.service.ConfigDumpHelper60.dumpCache(ConfigDumpHelper60.java:44) [plugin-infinispan60-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.service.EmbeddedConfigurationProvider.getNormalizedConfigs(EmbeddedConfigurationProvider.java:33) [plugin-infinispan52-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.stages.lifecycle.ServiceStartStage.executeOnSlave(ServiceStartStage.java:92) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase.scenarioLoop(SlaveBase.java:102) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase$ScenarioRunner.run(SlaveBase.java:203) [radargun-core-3.0.0-SNAPSHOT.jar:?]
03:08:58,516 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-21018]ISPN100003: Node fedora-21018 finished rebalance phase with topology id 2
03:08:58,517 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 2
03:08:58,518 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t8) [Context=org.infinispan.CONFIG][Scope=fedora-27553]ISPN100003: Node fedora-27553 finished rebalance phase with topology id 3
03:08:58,519 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-27553: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-27553: 128, fedora-21018: 128]}, unionCH=null, actualMembers=[fedora-27553, fedora-21018], persistentUUIDs=[cfafe099-bfe1-451c-a681-9789379c67ea, 6fe2e957-3ceb-4578-9281-d7bf15510ce3]}
03:08:58,520 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-27553]ISPN100002: Started rebalance with topology id 2
03:08:58,524 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t11) [Context=___protobuf_metadata][Scope=fedora-27553]ISPN100003: Node fedora-27553 finished rebalance phase with topology id 2
03:08:58,536 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-21018]ISPN100003: Node fedora-21018 finished rebalance phase with topology id 4
03:08:58,548 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-21018]ISPN100003: Node fedora-21018 finished rebalance phase with topology id 3
03:08:58,565 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t17) [Context=org.infinispan.CONFIG][Scope=fedora-27553]ISPN100003: Node fedora-27553 finished rebalance phase with topology id 4
03:08:58,567 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=DefaultConsistentHash{ns=256, owners = (1)[fedora-27553: 256+0]}, pendingCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-27553: 128+128, fedora-21018: 128+128]}, unionCH=null, actualMembers=[fedora-27553, fedora-21018], persistentUUIDs=[cfafe099-bfe1-451c-a681-9789379c67ea, 6fe2e957-3ceb-4578-9281-d7bf15510ce3]}
03:08:58,568 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-27553]ISPN100002: Started rebalance with topology id 2
03:08:58,571 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t22) [Context=___counters][Scope=fedora-27553]ISPN100003: Node fedora-27553 finished rebalance phase with topology id 2
03:08:58,585 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-21018]ISPN100003: Node fedora-21018 finished rebalance phase with topology id 4
03:08:58,623 INFO  [org.radargun.Slave] (sc-main) Finished stage ServiceStart
03:08:58,624 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=DefaultConsistentHash{ns=512, owners = (1)[fedora-27553: 512+0]}, pendingCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-27553: 258+254, fedora-21018: 254+258]}, unionCH=null, actualMembers=[fedora-27553, fedora-21018], persistentUUIDs=[cfafe099-bfe1-451c-a681-9789379c67ea, 6fe2e957-3ceb-4578-9281-d7bf15510ce3]}
03:08:58,625 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-27553]ISPN100002: Started rebalance with topology id 2
03:08:58,628 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t3) [Context=testCache][Scope=fedora-27553]ISPN100003: Node fedora-27553 finished rebalance phase with topology id 2
03:08:58,646 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
03:08:58,661 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-21018]ISPN100003: Node fedora-21018 finished rebalance phase with topology id 2
03:08:58,661 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___counters, topology id = 2
03:08:58,663 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t4) [Context=___counters][Scope=fedora-27553]ISPN100003: Node fedora-27553 finished rebalance phase with topology id 3
03:08:58,671 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-21018]ISPN100003: Node fedora-21018 finished rebalance phase with topology id 2
03:08:58,672 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-21018]ISPN100003: Node fedora-21018 finished rebalance phase with topology id 3
03:08:58,673 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 2
03:08:58,677 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t10) [Context=___counters][Scope=fedora-27553]ISPN100003: Node fedora-27553 finished rebalance phase with topology id 4
03:08:58,678 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t12) [Context=___protobuf_metadata][Scope=fedora-27553]ISPN100003: Node fedora-27553 finished rebalance phase with topology id 3
03:08:58,686 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-21018]ISPN100003: Node fedora-21018 finished rebalance phase with topology id 3
03:08:58,686 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-21018]ISPN100003: Node fedora-21018 finished rebalance phase with topology id 4
03:08:58,687 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t16) [Context=___protobuf_metadata][Scope=fedora-27553]ISPN100003: Node fedora-27553 finished rebalance phase with topology id 4
03:08:58,713 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-21018]ISPN100003: Node fedora-21018 finished rebalance phase with topology id 4
03:08:58,751 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-21018]ISPN100003: Node fedora-21018 finished rebalance phase with topology id 2
03:08:58,752 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache testCache, topology id = 2
03:08:58,754 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=testCache][Scope=fedora-27553]ISPN100003: Node fedora-27553 finished rebalance phase with topology id 3
03:08:58,766 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-21018]ISPN100003: Node fedora-21018 finished rebalance phase with topology id 3
03:08:58,768 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t9) [Context=testCache][Scope=fedora-27553]ISPN100003: Node fedora-27553 finished rebalance phase with topology id 4
03:08:58,785 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-21018]ISPN100003: Node fedora-21018 finished rebalance phase with topology id 4
03:08:59,067 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-27553: 128, fedora-21018: 128]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-27553: 90, fedora-21018: 89, fedora-38777: 77]}, unionCH=null, actualMembers=[fedora-27553, fedora-21018, fedora-38777], persistentUUIDs=[cfafe099-bfe1-451c-a681-9789379c67ea, 6fe2e957-3ceb-4578-9281-d7bf15510ce3, 9a2ea660-a15a-447f-8afb-d6237986132d]}
03:08:59,068 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-27553]ISPN100002: Started rebalance with topology id 6
03:08:59,069 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t11) [Context=___counter_configuration][Scope=fedora-27553]ISPN100003: Node fedora-27553 finished rebalance phase with topology id 6
03:08:59,074 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-21018]ISPN100003: Node fedora-21018 finished rebalance phase with topology id 6
03:08:59,076 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-27553: 128, fedora-21018: 128]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-27553: 90, fedora-21018: 89, fedora-38777: 77]}, unionCH=null, actualMembers=[fedora-27553, fedora-21018, fedora-38777], persistentUUIDs=[cfafe099-bfe1-451c-a681-9789379c67ea, 6fe2e957-3ceb-4578-9281-d7bf15510ce3, 9a2ea660-a15a-447f-8afb-d6237986132d]}
03:08:59,085 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-27553]ISPN100002: Started rebalance with topology id 6
03:08:59,086 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t12) [Context=org.infinispan.CONFIG][Scope=fedora-27553]ISPN100003: Node fedora-27553 finished rebalance phase with topology id 6
03:08:59,088 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-21018]ISPN100003: Node fedora-21018 finished rebalance phase with topology id 6
03:08:59,207 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-38777]ISPN100003: Node fedora-38777 finished rebalance phase with topology id 6
03:08:59,208 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 6
03:08:59,213 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-38777]ISPN100003: Node fedora-38777 finished rebalance phase with topology id 6
03:08:59,209 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=org.infinispan.CONFIG][Scope=fedora-27553]ISPN100003: Node fedora-27553 finished rebalance phase with topology id 7
03:08:59,214 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 6
03:08:59,215 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t2) [Context=___counter_configuration][Scope=fedora-27553]ISPN100003: Node fedora-27553 finished rebalance phase with topology id 7
03:08:59,218 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-21018]ISPN100003: Node fedora-21018 finished rebalance phase with topology id 7
03:08:59,223 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-21018]ISPN100003: Node fedora-21018 finished rebalance phase with topology id 7
03:08:59,232 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-38777]ISPN100003: Node fedora-38777 finished rebalance phase with topology id 7
03:08:59,234 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t15) [Context=___counter_configuration][Scope=fedora-27553]ISPN100003: Node fedora-27553 finished rebalance phase with topology id 8
03:08:59,238 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-21018]ISPN100003: Node fedora-21018 finished rebalance phase with topology id 8
03:08:59,239 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-38777]ISPN100003: Node fedora-38777 finished rebalance phase with topology id 7
03:08:59,241 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=org.infinispan.CONFIG][Scope=fedora-27553]ISPN100003: Node fedora-27553 finished rebalance phase with topology id 8
03:08:59,242 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-21018]ISPN100003: Node fedora-21018 finished rebalance phase with topology id 8
03:08:59,245 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-38777]ISPN100003: Node fedora-38777 finished rebalance phase with topology id 8
03:08:59,255 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-38777]ISPN100003: Node fedora-38777 finished rebalance phase with topology id 8
03:08:59,275 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-27553: 128+128, fedora-21018: 128+128]}, pendingCH=DefaultConsistentHash{ns=256, owners = (3)[fedora-27553: 90+92, fedora-21018: 89+79, fedora-38777: 77+85]}, unionCH=null, actualMembers=[fedora-27553, fedora-21018, fedora-38777], persistentUUIDs=[cfafe099-bfe1-451c-a681-9789379c67ea, 6fe2e957-3ceb-4578-9281-d7bf15510ce3, 9a2ea660-a15a-447f-8afb-d6237986132d]}
03:08:59,275 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-27553]ISPN100002: Started rebalance with topology id 6
03:08:59,277 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t10) [Context=___counters][Scope=fedora-27553]ISPN100003: Node fedora-27553 finished rebalance phase with topology id 6
03:08:59,281 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-21018]ISPN100003: Node fedora-21018 finished rebalance phase with topology id 6
03:08:59,295 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-38777]ISPN100003: Node fedora-38777 finished rebalance phase with topology id 6
03:08:59,295 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___counters, topology id = 6
03:08:59,297 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t16) [Context=___counters][Scope=fedora-27553]ISPN100003: Node fedora-27553 finished rebalance phase with topology id 7
03:08:59,299 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-21018]ISPN100003: Node fedora-21018 finished rebalance phase with topology id 7
03:08:59,302 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-38777]ISPN100003: Node fedora-38777 finished rebalance phase with topology id 7
03:08:59,304 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=___counters][Scope=fedora-27553]ISPN100003: Node fedora-27553 finished rebalance phase with topology id 8
03:08:59,306 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-21018]ISPN100003: Node fedora-21018 finished rebalance phase with topology id 8
03:08:59,308 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-38777]ISPN100003: Node fedora-38777 finished rebalance phase with topology id 8
03:08:59,326 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-27553: 128, fedora-21018: 128]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-27553: 90, fedora-21018: 89, fedora-38777: 77]}, unionCH=null, actualMembers=[fedora-27553, fedora-21018, fedora-38777], persistentUUIDs=[cfafe099-bfe1-451c-a681-9789379c67ea, 6fe2e957-3ceb-4578-9281-d7bf15510ce3, 9a2ea660-a15a-447f-8afb-d6237986132d]}
03:08:59,327 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-27553]ISPN100002: Started rebalance with topology id 6
03:08:59,330 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t15) [Context=___protobuf_metadata][Scope=fedora-27553]ISPN100003: Node fedora-27553 finished rebalance phase with topology id 6
03:08:59,334 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-21018]ISPN100003: Node fedora-21018 finished rebalance phase with topology id 6
03:08:59,367 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-27553: 258+254, fedora-21018: 254+258]}, pendingCH=DefaultConsistentHash{ns=512, owners = (3)[fedora-27553: 167+168, fedora-21018: 180+171, fedora-38777: 165+173]}, unionCH=null, actualMembers=[fedora-27553, fedora-21018, fedora-38777], persistentUUIDs=[cfafe099-bfe1-451c-a681-9789379c67ea, 6fe2e957-3ceb-4578-9281-d7bf15510ce3, 9a2ea660-a15a-447f-8afb-d6237986132d]}
03:08:59,372 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-27553]ISPN100002: Started rebalance with topology id 6
03:08:59,376 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-38777]ISPN100003: Node fedora-38777 finished rebalance phase with topology id 6
03:08:59,377 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 6
03:08:59,377 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t9) [Context=testCache][Scope=fedora-27553]ISPN100003: Node fedora-27553 finished rebalance phase with topology id 6
03:08:59,378 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t4) [Context=___protobuf_metadata][Scope=fedora-27553]ISPN100003: Node fedora-27553 finished rebalance phase with topology id 7
03:08:59,384 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-21018]ISPN100003: Node fedora-21018 finished rebalance phase with topology id 7
03:08:59,386 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-21018]ISPN100003: Node fedora-21018 finished rebalance phase with topology id 6
03:08:59,387 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-38777]ISPN100003: Node fedora-38777 finished rebalance phase with topology id 7
03:08:59,389 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t18) [Context=___protobuf_metadata][Scope=fedora-27553]ISPN100003: Node fedora-27553 finished rebalance phase with topology id 8
03:08:59,391 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-21018]ISPN100003: Node fedora-21018 finished rebalance phase with topology id 8
03:08:59,399 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-38777]ISPN100003: Node fedora-38777 finished rebalance phase with topology id 8
03:08:59,412 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-38777]ISPN100003: Node fedora-38777 finished rebalance phase with topology id 6
03:08:59,412 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache testCache, topology id = 6
03:08:59,414 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t25) [Context=testCache][Scope=fedora-27553]ISPN100003: Node fedora-27553 finished rebalance phase with topology id 7
03:08:59,419 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-21018]ISPN100003: Node fedora-21018 finished rebalance phase with topology id 7
03:08:59,422 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-38777]ISPN100003: Node fedora-38777 finished rebalance phase with topology id 7
03:08:59,428 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=testCache][Scope=fedora-27553]ISPN100003: Node fedora-27553 finished rebalance phase with topology id 8
03:08:59,428 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-21018]ISPN100003: Node fedora-21018 finished rebalance phase with topology id 8
03:08:59,433 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-38777]ISPN100003: Node fedora-38777 finished rebalance phase with topology id 8
03:08:59,556 INFO  [org.radargun.Slave] (sc-main) Starting stage AfterServiceStart
03:08:59,557 INFO  [org.radargun.Slave] (sc-main) Finished stage AfterServiceStart
03:08:59,560 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
03:08:59,695 INFO  [org.radargun.Slave] (sc-main) Starting stage MonitorStart
03:08:59,708 INFO  [org.radargun.sysmonitor.AbstractMonitors] (sc-main) Gathering statistics every 1000 ms
03:08:59,709 INFO  [org.radargun.Slave] (sc-main) Finished stage MonitorStart
03:08:59,709 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
03:08:59,766 INFO  [org.radargun.Slave] (sc-main) Starting stage Load
03:09:07,960 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) This node loaded 10000 entries (~10000000 bytes)
03:09:13,866 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) This node loaded 20000 entries (~20000000 bytes)
03:09:17,640 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) This node loaded 30000 entries (~30000000 bytes)
03:09:18,565 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) Finished loading entries
03:09:18,645 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) Finished loading entries
03:09:18,645 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) Finished loading entries
03:09:18,652 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) Finished loading entries
03:09:18,737 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) Finished loading entries
03:09:18,741 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) Finished loading entries
03:09:18,754 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) Finished loading entries
03:09:18,795 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) Finished loading entries
03:09:18,804 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) Finished loading entries
03:09:18,807 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) Finished loading entries
03:09:18,808 INFO  [org.radargun.Slave] (sc-main) Finished stage Load
03:09:18,809 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
03:09:19,032 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.stages.cache.test.BasicOperationsTestStage.init() overrides public void org.radargun.stages.test.TestStage.init() but both are declared with @Init annotation: calling only once
03:09:19,038 INFO  [org.radargun.Slave] (sc-main) Starting stage BasicOperationsTest
03:09:19,039 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using key generator org.radargun.stages.cache.generators.StringKeyGenerator {format=null }
03:09:19,039 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using value generator org.radargun.stages.cache.generators.ByteArrayValueGenerator { }
03:09:19,044 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using cache selector Default { }
03:09:19,044 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Starting test warmup
03:09:19,108 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Started 4 stressor threads.
03:10:19,110 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Finished test. Test duration is: 1 mins 0 secs
03:10:19,112 INFO  [org.radargun.Slave] (sc-main) Finished stage BasicOperationsTest
03:10:19,118 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
03:10:19,128 INFO  [org.radargun.Slave] (sc-main) Starting stage Clear
03:10:19,133 INFO  [org.radargun.stages.cache.ClearStage] (sc-main) Before executing clear, memory looks like this: 
Runtime free: 527,395 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,590 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,700 kb
MX Metaspace(Non-heap memory): used: 36,016 kb, init: 0 kb, committed: 36,544 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 11,724 kb, init: 2,496 kb, committed: 11,776 kb, max: 120,028 kb
MX Compressed Class Space(Non-heap memory): used: 4,160 kb, init: 0 kb, committed: 4,416 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 706,560 kb, init: 69,632 kb, committed: 822,272 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 105,948 kb, init: 1,329,152 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 58,368 kb, init: 0 kb, committed: 58,368 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 6,373 kb, init: 2,496 kb, committed: 6,400 kb, max: 120,032 kb
03:10:19,282 INFO  [org.radargun.stages.cache.ClearStage] (sc-main) After executing clear, memory looks like this: 
Runtime free: 1,380,138 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,590 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,700 kb
MX Metaspace(Non-heap memory): used: 36,020 kb, init: 0 kb, committed: 36,608 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 11,587 kb, init: 2,496 kb, committed: 11,840 kb, max: 120,028 kb
MX Compressed Class Space(Non-heap memory): used: 4,156 kb, init: 0 kb, committed: 4,416 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 0 kb, init: 69,632 kb, committed: 880,640 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 18,133 kb, init: 1,329,152 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 0 kb, init: 0 kb, committed: 0 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 6,329 kb, init: 2,496 kb, committed: 6,400 kb, max: 120,032 kb
03:10:19,284 INFO  [org.radargun.Slave] (sc-main) Finished stage Clear
03:10:19,286 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
03:10:19,319 INFO  [org.radargun.Slave] (sc-main) Starting stage Load
03:10:21,877 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) This node loaded 10000 entries (~10000000 bytes)
03:10:24,252 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) This node loaded 20000 entries (~20000000 bytes)
03:10:26,548 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) This node loaded 30000 entries (~30000000 bytes)
03:10:27,287 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) Finished loading entries
03:10:27,289 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) Finished loading entries
03:10:27,306 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) Finished loading entries
03:10:27,306 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) Finished loading entries
03:10:27,310 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) Finished loading entries
03:10:27,321 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) Finished loading entries
03:10:27,326 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) Finished loading entries
03:10:27,327 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) Finished loading entries
03:10:27,330 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) Finished loading entries
03:10:27,331 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) Finished loading entries
03:10:27,332 INFO  [org.radargun.Slave] (sc-main) Finished stage Load
03:10:27,332 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
03:10:27,585 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.stages.cache.test.BasicOperationsTestStage.init() overrides public void org.radargun.stages.test.TestStage.init() but both are declared with @Init annotation: calling only once
03:10:27,589 INFO  [org.radargun.Slave] (sc-main) Starting stage BasicOperationsTest
03:10:27,590 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using key generator org.radargun.stages.cache.generators.StringKeyGenerator {format=null }
03:10:27,591 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using value generator org.radargun.stages.cache.generators.ByteArrayValueGenerator { }
03:10:27,591 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using cache selector Default { }
03:10:27,593 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Starting test stress-test
03:10:27,643 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Started 4 stressor threads.
03:20:27,646 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Finished test. Test duration is: 10 mins 0 secs
03:20:27,649 INFO  [org.radargun.Slave] (sc-main) Finished stage BasicOperationsTest
03:20:27,733 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
03:20:27,935 INFO  [org.radargun.Slave] (sc-main) Starting stage MonitorStop
03:20:27,937 INFO  [org.radargun.Slave] (sc-main) Finished stage MonitorStop
03:20:27,938 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
03:20:27,947 INFO  [org.radargun.Slave] (sc-main) Starting stage ScenarioDestroy
03:20:27,948 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Scenario finished, destroying...
03:20:27,950 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Memory before cleanup: 
Runtime free: 731,858 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,594 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,700 kb
MX Metaspace(Non-heap memory): used: 36,679 kb, init: 0 kb, committed: 37,248 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 13,499 kb, init: 2,496 kb, committed: 13,504 kb, max: 120,028 kb
MX Compressed Class Space(Non-heap memory): used: 4,194 kb, init: 0 kb, committed: 4,480 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 210,944 kb, init: 69,632 kb, committed: 825,344 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 399,061 kb, init: 1,329,152 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 55,296 kb, init: 0 kb, committed: 55,296 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 7,660 kb, init: 2,496 kb, committed: 7,680 kb, max: 120,032 kb
03:20:27,951 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) Stopping service.
03:20:27,960 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t11) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-27553: 242+93, fedora-21018: 270+81]}, pendingCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-27553: 258+254, fedora-21018: 254+258]}, unionCH=null, actualMembers=[fedora-27553, fedora-21018], persistentUUIDs=[cfafe099-bfe1-451c-a681-9789379c67ea, 6fe2e957-3ceb-4578-9281-d7bf15510ce3]}
03:20:27,968 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t11) [Context=testCache][Scope=fedora-27553]ISPN100002: Started rebalance with topology id 11
03:20:27,981 WARN  [org.infinispan.CLUSTER] (StopThread) [Context=testCache]ISPN000312: Lost data because of graceful leaver fedora-27553
03:20:28,017 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t11) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-27553: 127, fedora-21018: 129]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-27553: 128, fedora-21018: 128]}, unionCH=null, actualMembers=[fedora-27553, fedora-21018], persistentUUIDs=[cfafe099-bfe1-451c-a681-9789379c67ea, 6fe2e957-3ceb-4578-9281-d7bf15510ce3]}
03:20:28,017 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t11) [Context=___protobuf_metadata][Scope=fedora-27553]ISPN100002: Started rebalance with topology id 11
03:20:28,021 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t8) [Context=___protobuf_metadata][Scope=fedora-27553]ISPN100003: Node fedora-27553 finished rebalance phase with topology id 11
03:20:28,022 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t11) [Context=testCache][Scope=fedora-21018]ISPN100003: Node fedora-21018 finished rebalance phase with topology id 12
03:20:28,024 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t11) [Context=___protobuf_metadata][Scope=fedora-21018]ISPN100003: Node fedora-21018 finished rebalance phase with topology id 11
03:20:28,024 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t11) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 11
03:20:28,026 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t18) [Context=___protobuf_metadata][Scope=fedora-27553]ISPN100003: Node fedora-27553 finished rebalance phase with topology id 12
03:20:28,029 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t11) [Context=___protobuf_metadata][Scope=fedora-21018]ISPN100003: Node fedora-21018 finished rebalance phase with topology id 12
03:20:28,030 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t12) [Context=___protobuf_metadata][Scope=fedora-27553]ISPN100003: Node fedora-27553 finished rebalance phase with topology id 13
03:20:28,034 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t11) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-27553: 132+50, fedora-21018: 124+44]}, pendingCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-27553: 128+128, fedora-21018: 128+128]}, unionCH=null, actualMembers=[fedora-27553, fedora-21018], persistentUUIDs=[cfafe099-bfe1-451c-a681-9789379c67ea, 6fe2e957-3ceb-4578-9281-d7bf15510ce3]}
03:20:28,035 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t11) [Context=___counters][Scope=fedora-27553]ISPN100002: Started rebalance with topology id 11
03:20:28,034 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t29) [Context=___protobuf_metadata][Scope=fedora-21018]ISPN100003: Node fedora-21018 finished rebalance phase with topology id 13
03:20:28,046 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t11) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-27553: 127, fedora-21018: 129]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-27553: 128, fedora-21018: 128]}, unionCH=null, actualMembers=[fedora-27553, fedora-21018], persistentUUIDs=[cfafe099-bfe1-451c-a681-9789379c67ea, 6fe2e957-3ceb-4578-9281-d7bf15510ce3]}
03:20:28,046 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t11) [Context=org.infinispan.CONFIG][Scope=fedora-27553]ISPN100002: Started rebalance with topology id 11
03:20:28,047 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t8) [Context=org.infinispan.CONFIG][Scope=fedora-27553]ISPN100003: Node fedora-27553 finished rebalance phase with topology id 11
03:20:28,049 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t11) [Context=org.infinispan.CONFIG][Scope=fedora-21018]ISPN100003: Node fedora-21018 finished rebalance phase with topology id 11
03:20:28,049 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t11) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 11
03:20:28,051 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t14) [Context=org.infinispan.CONFIG][Scope=fedora-27553]ISPN100003: Node fedora-27553 finished rebalance phase with topology id 12
03:20:28,055 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t29) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=12, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-27553: 127, fedora-21018: 129]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-27553: 128, fedora-21018: 128]}, unionCH=null, actualMembers=[fedora-27553, fedora-21018], persistentUUIDs=[cfafe099-bfe1-451c-a681-9789379c67ea, 6fe2e957-3ceb-4578-9281-d7bf15510ce3]}
03:20:28,062 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t29) [Context=___counter_configuration][Scope=fedora-27553]ISPN100002: Started rebalance with topology id 12
03:20:28,060 WARN  [org.infinispan.CLUSTER] (StopThread) [Context=___counters]ISPN000312: Lost data because of graceful leaver fedora-27553
03:20:28,065 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t29) [Context=___counter_configuration][Scope=fedora-21018]ISPN100003: Node fedora-21018 finished rebalance phase with topology id 12
03:20:28,057 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t11) [Context=org.infinispan.CONFIG][Scope=fedora-21018]ISPN100003: Node fedora-21018 finished rebalance phase with topology id 12
03:20:28,069 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t2) [Context=org.infinispan.CONFIG][Scope=fedora-27553]ISPN100003: Node fedora-27553 finished rebalance phase with topology id 13
03:20:28,071 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t11) [Context=org.infinispan.CONFIG][Scope=fedora-21018]ISPN100003: Node fedora-21018 finished rebalance phase with topology id 13
03:20:28,064 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t22) [Context=___counter_configuration][Scope=fedora-27553]ISPN100003: Node fedora-27553 finished rebalance phase with topology id 12
03:20:28,062 WARN  [org.infinispan.statetransfer.InboundTransferTask] (stateTransferExecutor-thread--p6-t2) ISPN000210: Failed to request state of cache testCache from node fedora-21018, segments {11-17 20 26-29 41-46 49-52 61 83 95 98-99 104-106 113-119 122 125-126 131-132 141-143 150-151 154-157 176-185 190-194 209 227-228 231-234 244-248 251 254-257 263 266-267 271-272 280 283-286 289 293-296 303 308-310 316-318 321-326 344-349 352-364 370-379 382-384 390-393 397 411-412 428 431-432 441-451 462-463 481 484-486 490 496-498 503 510-511}
org.infinispan.remoting.transport.jgroups.SuspectException: ISPN000400: Node fedora-21018 was suspected
	at org.infinispan.remoting.transport.ResponseCollectors.remoteNodeSuspected(ResponseCollectors.java:33) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleResponseCollector.targetNotFound(SingleResponseCollector.java:31) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleResponseCollector.targetNotFound(SingleResponseCollector.java:17) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.ValidSingleResponseCollector.addResponse(ValidSingleResponseCollector.java:23) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleTargetRequest.receiveResponse(SingleTargetRequest.java:51) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleTargetRequest.onResponse(SingleTargetRequest.java:35) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.RequestRepository.addResponse(RequestRepository.java:53) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.processResponse(JGroupsTransport.java:1302) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.processMessage(JGroupsTransport.java:1205) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.access$200(JGroupsTransport.java:123) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport$ChannelCallbacks.receive(JGroupsTransport.java:1340) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.jgroups.JChannel.up(JChannel.java:819) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.stack.ProtocolStack.up(ProtocolStack.java:893) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FRAG3.up(FRAG3.java:171) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FlowControl.up(FlowControl.java:343) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FlowControl.up(FlowControl.java:343) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.GMS.up(GMS.java:864) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.STABLE.up(STABLE.java:240) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.deliverMessage(UNICAST3.java:1002) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.handleDataReceived(UNICAST3.java:728) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.up(UNICAST3.java:383) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.NAKACK2.up(NAKACK2.java:600) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.VERIFY_SUSPECT.up(VERIFY_SUSPECT.java:119) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FD_ALL.up(FD_ALL.java:199) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FD_SOCK.up(FD_SOCK.java:252) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.MERGE3.up(MERGE3.java:276) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.Discovery.up(Discovery.java:267) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.TP.passMessageUp(TP.java:1248) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.util.SubmitToThreadPool$SingleMessageHandler.run(SubmitToThreadPool.java:87) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
03:20:28,077 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t22) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 12
03:20:28,078 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t15) [Context=___counter_configuration][Scope=fedora-27553]ISPN100003: Node fedora-27553 finished rebalance phase with topology id 13
03:20:28,080 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t29) [Context=___counter_configuration][Scope=fedora-21018]ISPN100003: Node fedora-21018 finished rebalance phase with topology id 13
03:20:28,079 INFO  [org.infinispan.CLUSTER] (jgroups-45,fedora-27553) ISPN000094: Received new cluster view for channel results: [fedora-27553|3] (2) [fedora-27553, fedora-21018]
03:20:28,081 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t13) [Context=___counter_configuration][Scope=fedora-27553]ISPN100003: Node fedora-27553 finished rebalance phase with topology id 14
03:20:28,081 INFO  [org.infinispan.CLUSTER] (jgroups-45,fedora-27553) ISPN100001: Node fedora-38777 left the cluster
03:20:28,085 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t11) [Context=___counter_configuration][Scope=fedora-21018]ISPN100003: Node fedora-21018 finished rebalance phase with topology id 14
03:20:28,097 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (StopThread) ISPN000080: Disconnecting JGroups channel results
03:20:28,132 WARN  [org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler] (remote-thread--p2-t11) ISPN000219: Shutdown while handling command CacheTopologyControlCommand{cache=___counter_configuration, type=LEAVE, sender=fedora-21018, joinInfo=null, topologyId=0, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=3}
03:20:28,133 WARN  [org.infinispan.remoting.inboundhandler.TrianglePerCacheInboundInvocationHandler] (remote-thread--p2-t13) ISPN000071: Caught exception when handling command StateResponseCommand{cache=___counters, pushTransfer=false, stateChunks=[StateChunk{segmentId=2, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=6, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=7, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=21, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=22, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=23, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=24, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=45, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=48, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=57, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=58, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=59, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=60, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=70, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=71, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=88, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=89, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=90, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=91, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=92, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=95, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=96, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=97, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=100, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=104, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=114, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=115, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=116, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=117, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=118, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=122, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=123, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=127, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=132, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=133, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=134, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=135, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=136, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=142, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=143, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=144, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=145, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=146, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=147, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=171, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=172, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=173, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=176, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=177, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=178, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=179, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=180, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=181, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=182, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=183, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=184, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=185, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=186, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=187, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=188, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=189, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=194, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=195, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=196, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=197, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=198, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=205, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=219, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=220, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=221, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=222, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=223, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=224, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=225, cacheEntries=0, isLastChunk=true}], origin=fedora-21018, topologyId=11, applyState=true}
org.infinispan.commons.CacheException: java.lang.InterruptedException
	at org.infinispan.statetransfer.StateConsumerImpl.applyState(StateConsumerImpl.java:572) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.statetransfer.StateResponseCommand.invokeAsync(StateResponseCommand.java:88) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.BasePerCacheInboundInvocationHandler.invokeCommand(BasePerCacheInboundInvocationHandler.java:94) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.BaseBlockingRunnable.invoke(BaseBlockingRunnable.java:99) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.BaseBlockingRunnable.runAsync(BaseBlockingRunnable.java:71) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.BaseBlockingRunnable.run(BaseBlockingRunnable.java:40) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
Caused by: java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.tryAcquireSharedNanos(AbstractQueuedSynchronizer.java:1133) ~[?:?]
	at java.util.concurrent.CountDownLatch.await(CountDownLatch.java:276) ~[?:?]
	at org.infinispan.statetransfer.StateConsumerImpl.applyState(StateConsumerImpl.java:566) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	... 8 more
03:20:28,150 INFO  [org.radargun.service.Infinispan90Lifecycle] (StopThread) Stopped, previous view is [fedora-27553, fedora-21018, fedora-38777]
03:20:28,159 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Service successfully stopped.
03:20:28,159 INFO  [org.radargun.Slave] (sc-main) Finished stage ScenarioDestroy
03:20:28,160 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
03:20:28,173 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.service.Infinispan80EmbeddedService.destroy() overrides public void org.radargun.service.Infinispan60EmbeddedService.destroy() but both are declared with @Destroy annotation: calling only once
03:20:28,180 INFO  [org.radargun.Slave] (main) Starting stage ScenarioCleanup
03:20:28,233 INFO  [org.radargun.stages.ScenarioCleanupStage] (main) Memory after cleanup: 
Runtime free: 1,379,115 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,596 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,700 kb
MX Metaspace(Non-heap memory): used: 36,879 kb, init: 0 kb, committed: 37,376 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 10,085 kb, init: 2,496 kb, committed: 13,824 kb, max: 120,028 kb
MX Compressed Class Space(Non-heap memory): used: 4,220 kb, init: 0 kb, committed: 4,480 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 0 kb, init: 69,632 kb, committed: 880,640 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 19,156 kb, init: 1,329,152 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 0 kb, init: 0 kb, committed: 0 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 6,240 kb, init: 2,496 kb, committed: 7,744 kb, max: 120,032 kb
03:20:28,242 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
03:20:33,298 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
03:20:36,689 INFO  [org.radargun.Slave] (main) Master shutdown!
03:20:36,695 INFO  [org.radargun.ShutDownHook] (Thread-0) Slave process is being shutdown
