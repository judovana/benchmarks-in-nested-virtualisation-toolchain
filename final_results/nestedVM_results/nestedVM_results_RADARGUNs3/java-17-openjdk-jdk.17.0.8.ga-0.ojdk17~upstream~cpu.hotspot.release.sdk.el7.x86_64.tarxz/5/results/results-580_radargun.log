17:51:17,190 INFO  [org.radargun.RemoteMasterConnection] (main) Attempting to connect to master results:2103
17:51:17,197 INFO  [org.radargun.RemoteMasterConnection] (main) Successfully established connection with master at: results:2103
17:51:17,202 INFO  [org.radargun.Slave] (main) Received slave index 0
17:51:17,203 INFO  [org.radargun.Slave] (main) Received slave count 3
17:51:17,394 INFO  [org.radargun.ServiceHelper] (sc-main) ServiceContext properties: {}
17:51:17,573 INFO  [org.radargun.Slave] (sc-main) Eager Service Infinispan92EmbeddedService {batching=false, cache=testCache, channelRetrievalTimeout=2 mins 0 secs, enableDiagnostics=null, explicitLocking=false, file=/mnt/workspace/results/dist-sync.xml, internalsExpositionEnabled=false, jgroupsDumperEnabled=false, jgroupsDumperInterval=10.000 secs, keysPerThread=-1, mapReduceDistributedReducePhase=false, mapReduceUseIntermediateSharedCache=false, removedCaches=[  ], threadsPerNode=-1 } loaded.
17:51:19,846 INFO  [org.radargun.Slave] (sc-main) Starting stage ScenarioInit
17:51:19,879 INFO  [org.radargun.Slave] (sc-main) Finished stage ScenarioInit
17:51:19,884 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
17:51:20,069 INFO  [org.radargun.Slave] (sc-main) Starting stage BeforeServiceStart
17:51:20,076 INFO  [org.radargun.Slave] (sc-main) Finished stage BeforeServiceStart
17:51:20,078 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
17:51:20,093 INFO  [org.radargun.Slave] (sc-main) Starting stage ServiceStart
17:51:20,094 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Startup staggering, this is the slave with index 0, not sleeping
17:51:20,094 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 0
17:51:20,098 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) Infinispan version: Infinispan 'Gaina' 9.2.0.Final
17:51:20,138 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) JGroups version: JGroups 4.0.10.Final (Schiener Berg)
17:51:20,739 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (sc-main) ISPN000078: Starting JGroups channel results
17:51:20,833 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the send buffer of socket MulticastSocket was set to 1.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
17:51:20,834 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the receive buffer of socket MulticastSocket was set to 20.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
17:51:20,835 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the send buffer of socket MulticastSocket was set to 1.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
17:51:20,836 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the receive buffer of socket MulticastSocket was set to 25.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
17:51:25,856 INFO  [org.infinispan.CLUSTER] (sc-main) ISPN000094: Received new cluster view for channel results: [fedora-24869|0] (1) [fedora-24869]
17:51:26,005 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (sc-main) ISPN000079: Channel results local address is fedora-24869, physical addresses are [192.168.124.242:58139]
17:51:26,016 INFO  [org.infinispan.factories.GlobalComponentRegistry] (sc-main) ISPN000128: Infinispan version: Infinispan 'Gaina' 9.2.0.Final
17:51:27,223 INFO  [org.infinispan.CLUSTER] (jgroups-7,fedora-24869) ISPN000094: Received new cluster view for channel results: [fedora-24869|1] (2) [fedora-24869, fedora-58645]
17:51:27,231 INFO  [org.infinispan.CLUSTER] (jgroups-7,fedora-24869) ISPN100000: Node fedora-58645 joined the cluster
17:51:27,361 INFO  [org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup] (sc-main) ISPN000107: Retrieving transaction manager Transaction: unknown
17:51:27,578 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) No RELAY2 protocol in XS service
17:51:27,579 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) No RELAY2 protocol in XS service
17:51:27,581 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) ([fedora-24869(local=true, coord=true), fedora-58645(local=false, coord=false)]) Number of members=2 is not the one expected: 3
17:51:27,826 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-24869: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-24869: 128, fedora-58645: 128]}, unionCH=null, actualMembers=[fedora-24869, fedora-58645], persistentUUIDs=[010ca3ec-02cd-4601-9165-0c44d958a499, 9fecf55f-b33d-43e6-86f1-0859f578283f]}
17:51:27,828 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-24869]ISPN100002: Started rebalance with topology id 2
17:51:27,834 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-24869: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-24869: 128, fedora-58645: 128]}, unionCH=null, actualMembers=[fedora-24869, fedora-58645], persistentUUIDs=[010ca3ec-02cd-4601-9165-0c44d958a499, 9fecf55f-b33d-43e6-86f1-0859f578283f]}
17:51:27,836 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-24869]ISPN100002: Started rebalance with topology id 2
17:51:27,895 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t22) [Context=org.infinispan.CONFIG][Scope=fedora-24869]ISPN100003: Node fedora-24869 finished rebalance phase with topology id 2
17:51:27,896 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t23) [Context=___counter_configuration][Scope=fedora-24869]ISPN100003: Node fedora-24869 finished rebalance phase with topology id 2
17:51:28,158 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-58645]ISPN100003: Node fedora-58645 finished rebalance phase with topology id 2
17:51:28,159 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 2
17:51:28,165 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t3) [Context=org.infinispan.CONFIG][Scope=fedora-24869]ISPN100003: Node fedora-24869 finished rebalance phase with topology id 3
17:51:28,178 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-58645]ISPN100003: Node fedora-58645 finished rebalance phase with topology id 2
17:51:28,179 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 2
17:51:28,180 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t4) [Context=___counter_configuration][Scope=fedora-24869]ISPN100003: Node fedora-24869 finished rebalance phase with topology id 3
17:51:28,226 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-58645]ISPN100003: Node fedora-58645 finished rebalance phase with topology id 3
17:51:28,226 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-58645]ISPN100003: Node fedora-58645 finished rebalance phase with topology id 3
17:51:28,228 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t8) [Context=___counter_configuration][Scope=fedora-24869]ISPN100003: Node fedora-24869 finished rebalance phase with topology id 4
17:51:28,228 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=org.infinispan.CONFIG][Scope=fedora-24869]ISPN100003: Node fedora-24869 finished rebalance phase with topology id 4
17:51:28,249 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-58645]ISPN100003: Node fedora-58645 finished rebalance phase with topology id 4
17:51:28,250 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-58645]ISPN100003: Node fedora-58645 finished rebalance phase with topology id 4
17:51:28,275 INFO  [org.infinispan.CLUSTER] (jgroups-7,fedora-24869) ISPN000094: Received new cluster view for channel results: [fedora-24869|2] (3) [fedora-24869, fedora-58645, fedora-58967]
17:51:28,277 INFO  [org.infinispan.CLUSTER] (jgroups-7,fedora-24869) ISPN100000: Node fedora-58967 joined the cluster
17:51:28,338 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=DefaultConsistentHash{ns=256, owners = (1)[fedora-24869: 256+0]}, pendingCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-24869: 128+128, fedora-58645: 128+128]}, unionCH=null, actualMembers=[fedora-24869, fedora-58645], persistentUUIDs=[010ca3ec-02cd-4601-9165-0c44d958a499, 9fecf55f-b33d-43e6-86f1-0859f578283f]}
17:51:28,339 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-24869]ISPN100002: Started rebalance with topology id 2
17:51:28,341 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=___counters][Scope=fedora-24869]ISPN100003: Node fedora-24869 finished rebalance phase with topology id 2
17:51:28,388 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-58645]ISPN100003: Node fedora-58645 finished rebalance phase with topology id 2
17:51:28,390 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache ___counters, topology id = 2
17:51:28,393 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t25) [Context=___counters][Scope=fedora-24869]ISPN100003: Node fedora-24869 finished rebalance phase with topology id 3
17:51:28,412 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-58645]ISPN100003: Node fedora-58645 finished rebalance phase with topology id 3
17:51:28,415 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t1) [Context=___counters][Scope=fedora-24869]ISPN100003: Node fedora-24869 finished rebalance phase with topology id 4
17:51:28,430 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-58645]ISPN100003: Node fedora-58645 finished rebalance phase with topology id 4
17:51:28,480 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-24869: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-24869: 128, fedora-58645: 128]}, unionCH=null, actualMembers=[fedora-24869, fedora-58645], persistentUUIDs=[010ca3ec-02cd-4601-9165-0c44d958a499, 9fecf55f-b33d-43e6-86f1-0859f578283f]}
17:51:28,482 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-24869]ISPN100002: Started rebalance with topology id 2
17:51:28,492 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t12) [Context=___protobuf_metadata][Scope=fedora-24869]ISPN100003: Node fedora-24869 finished rebalance phase with topology id 2
17:51:28,526 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-58645]ISPN100003: Node fedora-58645 finished rebalance phase with topology id 2
17:51:28,527 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 2
17:51:28,531 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=___protobuf_metadata][Scope=fedora-24869]ISPN100003: Node fedora-24869 finished rebalance phase with topology id 3
17:51:28,539 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-58645]ISPN100003: Node fedora-58645 finished rebalance phase with topology id 3
17:51:28,543 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t18) [Context=___protobuf_metadata][Scope=fedora-24869]ISPN100003: Node fedora-24869 finished rebalance phase with topology id 4
17:51:28,569 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-58645]ISPN100003: Node fedora-58645 finished rebalance phase with topology id 4
17:51:28,574 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=DefaultConsistentHash{ns=512, owners = (1)[fedora-24869: 512+0]}, pendingCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-24869: 255+257, fedora-58645: 257+255]}, unionCH=null, actualMembers=[fedora-24869, fedora-58645], persistentUUIDs=[010ca3ec-02cd-4601-9165-0c44d958a499, 9fecf55f-b33d-43e6-86f1-0859f578283f]}
17:51:28,575 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-24869]ISPN100002: Started rebalance with topology id 2
17:51:28,578 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=testCache][Scope=fedora-24869]ISPN100003: Node fedora-24869 finished rebalance phase with topology id 2
17:51:28,587 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) Number of members is the one expected: 3
17:51:28,588 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Successfully started cache service infinispan92/embedded on slave 0
17:51:28,628 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-58645]ISPN100003: Node fedora-58645 finished rebalance phase with topology id 2
17:51:28,628 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache testCache, topology id = 2
17:51:28,633 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t5) [Context=testCache][Scope=fedora-24869]ISPN100003: Node fedora-24869 finished rebalance phase with topology id 3
17:51:28,637 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-58645]ISPN100003: Node fedora-58645 finished rebalance phase with topology id 3
17:51:28,640 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t4) [Context=testCache][Scope=fedora-24869]ISPN100003: Node fedora-24869 finished rebalance phase with topology id 4
17:51:28,643 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-58645]ISPN100003: Node fedora-58645 finished rebalance phase with topology id 4
17:51:28,670 ERROR [org.radargun.service.ConfigDumpHelper] (sc-main) Error while dumping ___protobuf_metadata cache config as properties
javax.management.AttributeNotFoundException: Unknown attribute 'configurationAsProperties'. Known attributes names are: [rebalancingEnabled, cacheStatus, cacheName, cacheAvailability, version, configurationAsProperties]
	at org.infinispan.jmx.ResourceDMBean.getAttribute(ResourceDMBean.java:181) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:644) ~[?:?]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:679) ~[?:?]
	at org.radargun.service.ConfigDumpHelper60.dumpCache(ConfigDumpHelper60.java:44) [plugin-infinispan60-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.service.EmbeddedConfigurationProvider.getNormalizedConfigs(EmbeddedConfigurationProvider.java:33) [plugin-infinispan52-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.stages.lifecycle.ServiceStartStage.executeOnSlave(ServiceStartStage.java:92) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase.scenarioLoop(SlaveBase.java:102) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase$ScenarioRunner.run(SlaveBase.java:203) [radargun-core-3.0.0-SNAPSHOT.jar:?]
17:51:28,681 ERROR [org.radargun.service.ConfigDumpHelper] (sc-main) Error while dumping ___protobuf_metadata cache config as properties
javax.management.AttributeNotFoundException: Unknown attribute 'configurationAsProperties'. Known attributes names are: [rebalancingEnabled, cacheStatus, cacheName, cacheAvailability, version, configurationAsProperties]
	at org.infinispan.jmx.ResourceDMBean.getAttribute(ResourceDMBean.java:181) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:644) ~[?:?]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:679) ~[?:?]
	at org.radargun.service.ConfigDumpHelper60.dumpCache(ConfigDumpHelper60.java:44) [plugin-infinispan60-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.service.EmbeddedConfigurationProvider.getNormalizedConfigs(EmbeddedConfigurationProvider.java:33) [plugin-infinispan52-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.stages.lifecycle.ServiceStartStage.executeOnSlave(ServiceStartStage.java:92) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase.scenarioLoop(SlaveBase.java:102) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase$ScenarioRunner.run(SlaveBase.java:203) [radargun-core-3.0.0-SNAPSHOT.jar:?]
17:51:28,705 INFO  [org.radargun.Slave] (sc-main) Finished stage ServiceStart
17:51:28,733 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
17:51:28,965 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-24869: 128, fedora-58645: 128]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-24869: 82, fedora-58645: 84, fedora-58967: 90]}, unionCH=null, actualMembers=[fedora-24869, fedora-58645, fedora-58967], persistentUUIDs=[010ca3ec-02cd-4601-9165-0c44d958a499, 9fecf55f-b33d-43e6-86f1-0859f578283f, 044133e7-62dc-4566-8620-c43a42515c34]}
17:51:28,967 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-24869]ISPN100002: Started rebalance with topology id 6
17:51:28,966 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-24869: 128, fedora-58645: 128]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-24869: 82, fedora-58645: 84, fedora-58967: 90]}, unionCH=null, actualMembers=[fedora-24869, fedora-58645, fedora-58967], persistentUUIDs=[010ca3ec-02cd-4601-9165-0c44d958a499, 9fecf55f-b33d-43e6-86f1-0859f578283f, 044133e7-62dc-4566-8620-c43a42515c34]}
17:51:28,968 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-24869]ISPN100002: Started rebalance with topology id 6
17:51:28,969 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t8) [Context=org.infinispan.CONFIG][Scope=fedora-24869]ISPN100003: Node fedora-24869 finished rebalance phase with topology id 6
17:51:28,969 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t12) [Context=___counter_configuration][Scope=fedora-24869]ISPN100003: Node fedora-24869 finished rebalance phase with topology id 6
17:51:28,976 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-58645]ISPN100003: Node fedora-58645 finished rebalance phase with topology id 6
17:51:28,976 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-58645]ISPN100003: Node fedora-58645 finished rebalance phase with topology id 6
17:51:29,152 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-58967]ISPN100003: Node fedora-58967 finished rebalance phase with topology id 6
17:51:29,153 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 6
17:51:29,155 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t18) [Context=___counter_configuration][Scope=fedora-24869]ISPN100003: Node fedora-24869 finished rebalance phase with topology id 7
17:51:29,160 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-58645]ISPN100003: Node fedora-58645 finished rebalance phase with topology id 7
17:51:29,167 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-58967]ISPN100003: Node fedora-58967 finished rebalance phase with topology id 7
17:51:29,172 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-58967]ISPN100003: Node fedora-58967 finished rebalance phase with topology id 6
17:51:29,172 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t14) [Context=___counter_configuration][Scope=fedora-24869]ISPN100003: Node fedora-24869 finished rebalance phase with topology id 8
17:51:29,172 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 6
17:51:29,174 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=org.infinispan.CONFIG][Scope=fedora-24869]ISPN100003: Node fedora-24869 finished rebalance phase with topology id 7
17:51:29,178 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-58967]ISPN100003: Node fedora-58967 finished rebalance phase with topology id 8
17:51:29,178 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-58645]ISPN100003: Node fedora-58645 finished rebalance phase with topology id 8
17:51:29,183 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-58645]ISPN100003: Node fedora-58645 finished rebalance phase with topology id 7
17:51:29,189 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-58967]ISPN100003: Node fedora-58967 finished rebalance phase with topology id 7
17:51:29,191 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t1) [Context=org.infinispan.CONFIG][Scope=fedora-24869]ISPN100003: Node fedora-24869 finished rebalance phase with topology id 8
17:51:29,195 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-58645]ISPN100003: Node fedora-58645 finished rebalance phase with topology id 8
17:51:29,213 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-58967]ISPN100003: Node fedora-58967 finished rebalance phase with topology id 8
17:51:29,238 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-24869: 128+128, fedora-58645: 128+128]}, pendingCH=DefaultConsistentHash{ns=256, owners = (3)[fedora-24869: 82+78, fedora-58645: 84+82, fedora-58967: 90+96]}, unionCH=null, actualMembers=[fedora-24869, fedora-58645, fedora-58967], persistentUUIDs=[010ca3ec-02cd-4601-9165-0c44d958a499, 9fecf55f-b33d-43e6-86f1-0859f578283f, 044133e7-62dc-4566-8620-c43a42515c34]}
17:51:29,243 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-24869]ISPN100002: Started rebalance with topology id 6
17:51:29,246 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=___counters][Scope=fedora-24869]ISPN100003: Node fedora-24869 finished rebalance phase with topology id 6
17:51:29,251 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-58645]ISPN100003: Node fedora-58645 finished rebalance phase with topology id 6
17:51:29,309 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-58967]ISPN100003: Node fedora-58967 finished rebalance phase with topology id 6
17:51:29,310 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___counters, topology id = 6
17:51:29,312 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t17) [Context=___counters][Scope=fedora-24869]ISPN100003: Node fedora-24869 finished rebalance phase with topology id 7
17:51:29,320 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-58645]ISPN100003: Node fedora-58645 finished rebalance phase with topology id 7
17:51:29,327 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-58967]ISPN100003: Node fedora-58967 finished rebalance phase with topology id 7
17:51:29,338 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-58645]ISPN100003: Node fedora-58645 finished rebalance phase with topology id 8
17:51:29,340 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-24869: 128, fedora-58645: 128]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-24869: 82, fedora-58645: 84, fedora-58967: 90]}, unionCH=null, actualMembers=[fedora-24869, fedora-58645, fedora-58967], persistentUUIDs=[010ca3ec-02cd-4601-9165-0c44d958a499, 9fecf55f-b33d-43e6-86f1-0859f578283f, 044133e7-62dc-4566-8620-c43a42515c34]}
17:51:29,332 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=___counters][Scope=fedora-24869]ISPN100003: Node fedora-24869 finished rebalance phase with topology id 8
17:51:29,341 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-24869]ISPN100002: Started rebalance with topology id 6
17:51:29,345 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t2) [Context=___protobuf_metadata][Scope=fedora-24869]ISPN100003: Node fedora-24869 finished rebalance phase with topology id 6
17:51:29,348 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-58645]ISPN100003: Node fedora-58645 finished rebalance phase with topology id 6
17:51:29,382 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-58967]ISPN100003: Node fedora-58967 finished rebalance phase with topology id 8
17:51:29,422 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-24869: 255+257, fedora-58645: 257+255]}, pendingCH=DefaultConsistentHash{ns=512, owners = (3)[fedora-24869: 161+155, fedora-58645: 176+170, fedora-58967: 175+187]}, unionCH=null, actualMembers=[fedora-24869, fedora-58645, fedora-58967], persistentUUIDs=[010ca3ec-02cd-4601-9165-0c44d958a499, 9fecf55f-b33d-43e6-86f1-0859f578283f, 044133e7-62dc-4566-8620-c43a42515c34]}
17:51:29,423 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-24869]ISPN100002: Started rebalance with topology id 6
17:51:29,432 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t6) [Context=testCache][Scope=fedora-24869]ISPN100003: Node fedora-24869 finished rebalance phase with topology id 6
17:51:29,436 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-58645]ISPN100003: Node fedora-58645 finished rebalance phase with topology id 6
17:51:29,458 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-58967]ISPN100003: Node fedora-58967 finished rebalance phase with topology id 6
17:51:29,459 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 6
17:51:29,462 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t10) [Context=___protobuf_metadata][Scope=fedora-24869]ISPN100003: Node fedora-24869 finished rebalance phase with topology id 7
17:51:29,466 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-58645]ISPN100003: Node fedora-58645 finished rebalance phase with topology id 7
17:51:29,471 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-58967]ISPN100003: Node fedora-58967 finished rebalance phase with topology id 7
17:51:29,473 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t15) [Context=___protobuf_metadata][Scope=fedora-24869]ISPN100003: Node fedora-24869 finished rebalance phase with topology id 8
17:51:29,474 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-58967]ISPN100003: Node fedora-58967 finished rebalance phase with topology id 6
17:51:29,474 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache testCache, topology id = 6
17:51:29,477 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-58645]ISPN100003: Node fedora-58645 finished rebalance phase with topology id 8
17:51:29,479 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-58967]ISPN100003: Node fedora-58967 finished rebalance phase with topology id 8
17:51:29,482 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=testCache][Scope=fedora-24869]ISPN100003: Node fedora-24869 finished rebalance phase with topology id 7
17:51:29,484 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-58645]ISPN100003: Node fedora-58645 finished rebalance phase with topology id 7
17:51:29,490 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-58967]ISPN100003: Node fedora-58967 finished rebalance phase with topology id 7
17:51:29,492 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t23) [Context=testCache][Scope=fedora-24869]ISPN100003: Node fedora-24869 finished rebalance phase with topology id 8
17:51:29,496 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-58645]ISPN100003: Node fedora-58645 finished rebalance phase with topology id 8
17:51:29,504 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-58967]ISPN100003: Node fedora-58967 finished rebalance phase with topology id 8
17:51:29,626 INFO  [org.radargun.Slave] (sc-main) Starting stage AfterServiceStart
17:51:29,626 INFO  [org.radargun.Slave] (sc-main) Finished stage AfterServiceStart
17:51:29,630 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
17:51:29,761 INFO  [org.radargun.Slave] (sc-main) Starting stage MonitorStart
17:51:29,770 INFO  [org.radargun.sysmonitor.AbstractMonitors] (sc-main) Gathering statistics every 1000 ms
17:51:29,770 INFO  [org.radargun.Slave] (sc-main) Finished stage MonitorStart
17:51:29,771 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
17:51:29,826 INFO  [org.radargun.Slave] (sc-main) Starting stage Load
17:51:38,793 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) This node loaded 10000 entries (~10000000 bytes)
17:51:45,652 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) This node loaded 20000 entries (~20000000 bytes)
17:51:49,717 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) This node loaded 30000 entries (~30000000 bytes)
17:51:50,850 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) Finished loading entries
17:51:50,893 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) Finished loading entries
17:51:50,903 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) Finished loading entries
17:51:50,918 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) Finished loading entries
17:51:50,929 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) Finished loading entries
17:51:50,932 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) Finished loading entries
17:51:50,935 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) Finished loading entries
17:51:50,946 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) Finished loading entries
17:51:50,959 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) Finished loading entries
17:51:50,960 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) Finished loading entries
17:51:50,961 INFO  [org.radargun.Slave] (sc-main) Finished stage Load
17:51:50,961 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
17:51:50,991 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.stages.cache.test.BasicOperationsTestStage.init() overrides public void org.radargun.stages.test.TestStage.init() but both are declared with @Init annotation: calling only once
17:51:50,993 INFO  [org.radargun.Slave] (sc-main) Starting stage BasicOperationsTest
17:51:50,994 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using key generator org.radargun.stages.cache.generators.StringKeyGenerator {format=null }
17:51:50,994 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using value generator org.radargun.stages.cache.generators.ByteArrayValueGenerator { }
17:51:50,995 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using cache selector Default { }
17:51:50,995 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Starting test warmup
17:51:51,033 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Started 4 stressor threads.
17:52:51,036 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Finished test. Test duration is: 1 mins 0 secs
17:52:51,040 INFO  [org.radargun.Slave] (sc-main) Finished stage BasicOperationsTest
17:52:51,052 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
17:52:51,216 INFO  [org.radargun.Slave] (sc-main) Starting stage Clear
17:52:51,219 INFO  [org.radargun.stages.cache.ClearStage] (sc-main) Before executing clear, memory looks like this: 
Runtime free: 1,097,092 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,309 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,700 kb
MX Metaspace(Non-heap memory): used: 34,743 kb, init: 0 kb, committed: 35,072 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 7,638 kb, init: 2,496 kb, committed: 10,304 kb, max: 120,028 kb
MX Compressed Class Space(Non-heap memory): used: 4,169 kb, init: 0 kb, committed: 4,352 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 118,784 kb, init: 73,728 kb, committed: 832,512 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 134,777 kb, init: 1,325,056 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 47,616 kb, init: 0 kb, committed: 48,128 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 4,609 kb, init: 2,496 kb, committed: 5,504 kb, max: 120,032 kb
17:52:51,313 INFO  [org.radargun.stages.cache.ClearStage] (sc-main) After executing clear, memory looks like this: 
Runtime free: 1,380,833 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,309 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,700 kb
MX Metaspace(Non-heap memory): used: 34,772 kb, init: 0 kb, committed: 35,136 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 7,708 kb, init: 2,496 kb, committed: 10,304 kb, max: 120,028 kb
MX Compressed Class Space(Non-heap memory): used: 4,171 kb, init: 0 kb, committed: 4,352 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 0 kb, init: 73,728 kb, committed: 880,640 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 17,438 kb, init: 1,325,056 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 0 kb, init: 0 kb, committed: 0 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 4,624 kb, init: 2,496 kb, committed: 5,504 kb, max: 120,032 kb
17:52:51,313 INFO  [org.radargun.Slave] (sc-main) Finished stage Clear
17:52:51,315 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
17:52:51,437 INFO  [org.radargun.Slave] (sc-main) Starting stage Load
17:52:54,181 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) This node loaded 10000 entries (~10000000 bytes)
17:52:56,587 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) This node loaded 20000 entries (~20000000 bytes)
17:52:59,182 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) This node loaded 30000 entries (~30000000 bytes)
17:52:59,794 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) Finished loading entries
17:52:59,827 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) Finished loading entries
17:52:59,845 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) Finished loading entries
17:52:59,849 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) Finished loading entries
17:52:59,855 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) Finished loading entries
17:52:59,860 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) Finished loading entries
17:52:59,874 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) Finished loading entries
17:52:59,882 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) Finished loading entries
17:52:59,886 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) Finished loading entries
17:52:59,889 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) Finished loading entries
17:52:59,889 INFO  [org.radargun.Slave] (sc-main) Finished stage Load
17:52:59,890 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
17:53:00,105 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.stages.cache.test.BasicOperationsTestStage.init() overrides public void org.radargun.stages.test.TestStage.init() but both are declared with @Init annotation: calling only once
17:53:00,105 INFO  [org.radargun.Slave] (sc-main) Starting stage BasicOperationsTest
17:53:00,106 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using key generator org.radargun.stages.cache.generators.StringKeyGenerator {format=null }
17:53:00,106 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using value generator org.radargun.stages.cache.generators.ByteArrayValueGenerator { }
17:53:00,106 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using cache selector Default { }
17:53:00,107 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Starting test stress-test
17:53:00,138 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Started 4 stressor threads.
18:03:00,140 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Finished test. Test duration is: 10 mins 0 secs
18:03:00,142 INFO  [org.radargun.Slave] (sc-main) Finished stage BasicOperationsTest
18:03:00,278 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
18:03:00,440 INFO  [org.radargun.Slave] (sc-main) Starting stage MonitorStop
18:03:00,441 INFO  [org.radargun.Slave] (sc-main) Finished stage MonitorStop
18:03:00,442 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
18:03:00,447 INFO  [org.radargun.Slave] (sc-main) Starting stage ScenarioDestroy
18:03:00,448 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Scenario finished, destroying...
18:03:00,449 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Memory before cleanup: 
Runtime free: 1,127,851 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,311 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,700 kb
MX Metaspace(Non-heap memory): used: 35,436 kb, init: 0 kb, committed: 35,840 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 9,771 kb, init: 2,496 kb, committed: 10,304 kb, max: 120,028 kb
MX Compressed Class Space(Non-heap memory): used: 4,205 kb, init: 0 kb, committed: 4,416 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 32,768 kb, init: 73,728 kb, committed: 821,248 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 178,770 kb, init: 1,325,056 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 59,392 kb, init: 0 kb, committed: 59,392 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 5,820 kb, init: 2,496 kb, committed: 5,824 kb, max: 120,032 kb
18:03:00,450 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) Stopping service.
18:03:00,460 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t30) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-24869: 238+78, fedora-58645: 274+72]}, pendingCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-24869: 255+257, fedora-58645: 257+255]}, unionCH=null, actualMembers=[fedora-24869, fedora-58645], persistentUUIDs=[010ca3ec-02cd-4601-9165-0c44d958a499, 9fecf55f-b33d-43e6-86f1-0859f578283f]}
18:03:00,467 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t30) [Context=testCache][Scope=fedora-24869]ISPN100002: Started rebalance with topology id 11
18:03:00,480 WARN  [org.infinispan.CLUSTER] (StopThread) [Context=testCache]ISPN000312: Lost data because of graceful leaver fedora-24869
18:03:00,523 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t30) [Context=testCache][Scope=fedora-58645]ISPN100003: Node fedora-58645 finished rebalance phase with topology id 12
18:03:00,532 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t30) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-24869: 126+34, fedora-58645: 130+36]}, pendingCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-24869: 128+128, fedora-58645: 128+128]}, unionCH=null, actualMembers=[fedora-24869, fedora-58645], persistentUUIDs=[010ca3ec-02cd-4601-9165-0c44d958a499, 9fecf55f-b33d-43e6-86f1-0859f578283f]}
18:03:00,536 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t30) [Context=___counters][Scope=fedora-24869]ISPN100002: Started rebalance with topology id 11
18:03:00,535 WARN  [org.infinispan.statetransfer.InboundTransferTask] (stateTransferExecutor-thread--p6-t1) ISPN000210: Failed to request state of cache testCache from node fedora-58645, segments {0 3 10-11 28 31-35 45 52-53 56-58 62-65 68-69 72-76 84-89 100-104 110-111 114-116 119 131-136 139-151 157-169 180 183-184 187-188 191 194-198 208-209 212-214 220-223 229-231 234-243 247 255-262 265-266 275-278 286-291 298-299 304-305 311-312 318-320 327-331 350 356 360-363 369-370 374 379 383-384 389-391 397-400 403-405 408-409 413-415 431-432 437-438 444 448-449 458-460 467-468 480 483-484 494-498 505-508 511}
org.infinispan.remoting.transport.jgroups.SuspectException: ISPN000400: Node fedora-58645 was suspected
	at org.infinispan.remoting.transport.ResponseCollectors.remoteNodeSuspected(ResponseCollectors.java:33) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleResponseCollector.targetNotFound(SingleResponseCollector.java:31) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleResponseCollector.targetNotFound(SingleResponseCollector.java:17) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.ValidSingleResponseCollector.addResponse(ValidSingleResponseCollector.java:23) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleTargetRequest.receiveResponse(SingleTargetRequest.java:51) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleTargetRequest.onResponse(SingleTargetRequest.java:35) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.RequestRepository.addResponse(RequestRepository.java:53) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.processResponse(JGroupsTransport.java:1302) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.processMessage(JGroupsTransport.java:1205) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.access$200(JGroupsTransport.java:123) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport$ChannelCallbacks.receive(JGroupsTransport.java:1340) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.jgroups.JChannel.up(JChannel.java:819) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.stack.ProtocolStack.up(ProtocolStack.java:893) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FRAG3.up(FRAG3.java:171) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FlowControl.up(FlowControl.java:343) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FlowControl.up(FlowControl.java:343) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.GMS.up(GMS.java:864) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.STABLE.up(STABLE.java:240) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.deliverMessage(UNICAST3.java:1002) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.handleDataReceived(UNICAST3.java:728) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.up(UNICAST3.java:383) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.NAKACK2.up(NAKACK2.java:600) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.VERIFY_SUSPECT.up(VERIFY_SUSPECT.java:119) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FD_ALL.up(FD_ALL.java:199) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FD_SOCK.up(FD_SOCK.java:252) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.MERGE3.up(MERGE3.java:276) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.Discovery.up(Discovery.java:267) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.TP.passMessageUp(TP.java:1248) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.util.SubmitToThreadPool$SingleMessageHandler.run(SubmitToThreadPool.java:87) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
18:03:00,562 WARN  [org.infinispan.CLUSTER] (remote-thread--p2-t5) [Context=___counters]ISPN000312: Lost data because of graceful leaver fedora-58645
18:03:00,565 ERROR [org.infinispan.statetransfer.StateConsumerImpl] (transport-thread--p4-t14) ISPN000208: No live owners found for segments {12-17 22-23 28-31 34-36 42-46 50-51 57 65-76 79-84 90-91 97 101 104 110 115-121 126-130 138-140 143-145 149 152-155 162-165 178-182 185 195 199-201 207 224 229 239-241 247-248 251-253} of cache ___counters. Excluded owners: []
18:03:00,566 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t14) [Context=___counters][Scope=fedora-24869]ISPN100003: Node fedora-24869 finished rebalance phase with topology id 12
18:03:00,567 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (transport-thread--p4-t14) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___counters, type=REBALANCE_PHASE_CONFIRM, sender=fedora-24869, joinInfo=null, topologyId=12, rebalanceId=4, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-24869 for cache ___counters, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.commands.ReplicableCommand.invoke(ReplicableCommand.java:44) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.LocalTopologyManagerImpl.lambda$executeOnCoordinatorAsync$4(LocalTopologyManagerImpl.java:717) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
18:03:00,571 INFO  [org.infinispan.CLUSTER] (jgroups-16,fedora-24869) ISPN000094: Received new cluster view for channel results: [fedora-24869|3] (2) [fedora-24869, fedora-58645]
18:03:00,572 INFO  [org.infinispan.CLUSTER] (jgroups-16,fedora-24869) ISPN100001: Node fedora-58967 left the cluster
18:03:00,608 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (StopThread) ISPN000080: Disconnecting JGroups channel results
18:03:00,608 INFO  [org.infinispan.CLUSTER] (jgroups-23,fedora-24869) ISPN000094: Received new cluster view for channel results: [fedora-24869|4] (1) [fedora-24869]
18:03:00,611 INFO  [org.infinispan.CLUSTER] (jgroups-23,fedora-24869) ISPN100001: Node fedora-58645 left the cluster
18:03:00,663 WARN  [org.infinispan.remoting.inboundhandler.TrianglePerCacheInboundInvocationHandler] (remote-thread--p2-t30) ISPN000071: Caught exception when handling command StateResponseCommand{cache=___counters, pushTransfer=false, stateChunks=[StateChunk{segmentId=2, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=12, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=13, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=14, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=15, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=16, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=17, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=22, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=23, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=28, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=29, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=30, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=31, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=34, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=35, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=36, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=42, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=43, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=44, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=45, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=46, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=50, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=51, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=57, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=65, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=66, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=67, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=68, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=69, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=70, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=71, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=72, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=73, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=74, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=75, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=76, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=79, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=80, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=81, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=82, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=83, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=84, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=90, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=91, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=97, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=101, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=104, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=110, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=115, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=116, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=117, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=118, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=119, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=120, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=121, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=126, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=127, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=128, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=129, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=130, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=138, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=139, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=140, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=143, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=144, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=145, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=149, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=152, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=153, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=154, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=155, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=162, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=163, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=164, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=165, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=178, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=179, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=180, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=181, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=182, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=185, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=195, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=199, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=200, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=201, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=207, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=224, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=229, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=239, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=240, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=241, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=247, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=248, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=251, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=252, cacheEntries=0, isLastChunk=true}, StateChunk{segmentId=253, cacheEntries=0, isLastChunk=true}], origin=fedora-58645, topologyId=11, applyState=true}
org.infinispan.commons.CacheException: java.lang.InterruptedException
	at org.infinispan.statetransfer.StateConsumerImpl.applyState(StateConsumerImpl.java:572) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.statetransfer.StateResponseCommand.invokeAsync(StateResponseCommand.java:88) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.BasePerCacheInboundInvocationHandler.invokeCommand(BasePerCacheInboundInvocationHandler.java:94) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.BaseBlockingRunnable.invoke(BaseBlockingRunnable.java:99) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.BaseBlockingRunnable.runAsync(BaseBlockingRunnable.java:71) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.BaseBlockingRunnable.run(BaseBlockingRunnable.java:40) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
Caused by: java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.tryAcquireSharedNanos(AbstractQueuedSynchronizer.java:1081) ~[?:?]
	at java.util.concurrent.CountDownLatch.await(CountDownLatch.java:276) ~[?:?]
	at org.infinispan.statetransfer.StateConsumerImpl.applyState(StateConsumerImpl.java:566) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	... 8 more
18:03:00,668 INFO  [org.radargun.service.Infinispan90Lifecycle] (StopThread) Stopped, previous view is [fedora-24869, fedora-58645, fedora-58967]
18:03:00,669 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Service successfully stopped.
18:03:00,670 INFO  [org.radargun.Slave] (sc-main) Finished stage ScenarioDestroy
18:03:00,670 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
18:03:00,676 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.service.Infinispan80EmbeddedService.destroy() overrides public void org.radargun.service.Infinispan60EmbeddedService.destroy() but both are declared with @Destroy annotation: calling only once
18:03:00,677 INFO  [org.radargun.Slave] (main) Starting stage ScenarioCleanup
18:03:00,714 INFO  [org.radargun.stages.ScenarioCleanupStage] (main) Memory after cleanup: 
Runtime free: 1,379,853 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,319 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,700 kb
MX Metaspace(Non-heap memory): used: 35,576 kb, init: 0 kb, committed: 35,968 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 9,895 kb, init: 2,496 kb, committed: 10,304 kb, max: 120,028 kb
MX Compressed Class Space(Non-heap memory): used: 4,231 kb, init: 0 kb, committed: 4,416 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 0 kb, init: 73,728 kb, committed: 880,640 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 18,418 kb, init: 1,325,056 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 0 kb, init: 0 kb, committed: 0 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 5,839 kb, init: 2,496 kb, committed: 5,888 kb, max: 120,032 kb
18:03:00,718 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
18:03:05,851 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
18:03:09,667 INFO  [org.radargun.Slave] (main) Master shutdown!
18:03:09,676 INFO  [org.radargun.ShutDownHook] (Thread-0) Slave process is being shutdown
