20:17:57,528 INFO  [org.radargun.RemoteMasterConnection] (main) Attempting to connect to master results:2103
20:17:57,533 INFO  [org.radargun.RemoteMasterConnection] (main) Successfully established connection with master at: results:2103
20:17:57,534 INFO  [org.radargun.Slave] (main) Received slave index 0
20:17:57,535 INFO  [org.radargun.Slave] (main) Received slave count 3
20:17:57,718 INFO  [org.radargun.ServiceHelper] (sc-main) ServiceContext properties: {}
20:17:57,926 INFO  [org.radargun.Slave] (sc-main) Eager Service Infinispan92EmbeddedService {batching=false, cache=testCache, channelRetrievalTimeout=2 mins 0 secs, enableDiagnostics=null, explicitLocking=false, file=/mnt/workspace/results/dist-sync.xml, internalsExpositionEnabled=false, jgroupsDumperEnabled=false, jgroupsDumperInterval=10.000 secs, keysPerThread=-1, mapReduceDistributedReducePhase=false, mapReduceUseIntermediateSharedCache=false, removedCaches=[  ], threadsPerNode=-1 } loaded.
20:18:00,467 INFO  [org.radargun.Slave] (sc-main) Starting stage ScenarioInit
20:18:00,978 INFO  [org.radargun.Slave] (sc-main) Finished stage ScenarioInit
20:18:00,982 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
20:18:00,988 INFO  [org.radargun.Slave] (sc-main) Starting stage BeforeServiceStart
20:18:00,988 INFO  [org.radargun.Slave] (sc-main) Finished stage BeforeServiceStart
20:18:00,991 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
20:18:01,000 INFO  [org.radargun.Slave] (sc-main) Starting stage ServiceStart
20:18:01,000 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Startup staggering, this is the slave with index 0, not sleeping
20:18:01,001 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 0
20:18:01,004 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) Infinispan version: Infinispan 'Gaina' 9.2.0.Final
20:18:01,020 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) JGroups version: JGroups 4.0.10.Final (Schiener Berg)
20:18:01,575 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (sc-main) ISPN000078: Starting JGroups channel results
20:18:01,664 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the send buffer of socket MulticastSocket was set to 1.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
20:18:01,665 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the receive buffer of socket MulticastSocket was set to 20.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
20:18:01,666 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the send buffer of socket MulticastSocket was set to 1.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
20:18:01,666 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the receive buffer of socket MulticastSocket was set to 25.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
20:18:06,710 INFO  [org.infinispan.CLUSTER] (sc-main) ISPN000094: Received new cluster view for channel results: [fedora-19031|0] (1) [fedora-19031]
20:18:06,800 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (sc-main) ISPN000079: Channel results local address is fedora-19031, physical addresses are [192.168.124.128:38041]
20:18:06,803 INFO  [org.infinispan.factories.GlobalComponentRegistry] (sc-main) ISPN000128: Infinispan version: Infinispan 'Gaina' 9.2.0.Final
20:18:07,550 INFO  [org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup] (sc-main) ISPN000107: Retrieving transaction manager Transaction: unknown
20:18:07,654 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) No RELAY2 protocol in XS service
20:18:07,655 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) No RELAY2 protocol in XS service
20:18:07,656 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) ([fedora-19031(local=true, coord=true)]) Number of members=1 is not the one expected: 3
20:18:07,931 INFO  [org.infinispan.CLUSTER] (jgroups-7,fedora-19031) ISPN000094: Received new cluster view for channel results: [fedora-19031|1] (2) [fedora-19031, fedora-55780]
20:18:07,940 INFO  [org.infinispan.CLUSTER] (jgroups-7,fedora-19031) ISPN100000: Node fedora-55780 joined the cluster
20:18:08,347 INFO  [org.infinispan.CLUSTER] (jgroups-6,fedora-19031) ISPN000094: Received new cluster view for channel results: [fedora-19031|2] (3) [fedora-19031, fedora-55780, fedora-26103]
20:18:08,356 INFO  [org.infinispan.CLUSTER] (jgroups-6,fedora-19031) ISPN100000: Node fedora-26103 joined the cluster
20:18:08,657 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) Number of members is the one expected: 3
20:18:08,657 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Successfully started cache service infinispan92/embedded on slave 0
20:18:08,728 ERROR [org.radargun.service.ConfigDumpHelper] (sc-main) Error while dumping ___protobuf_metadata cache config as properties
javax.management.AttributeNotFoundException: Unknown attribute 'configurationAsProperties'. Known attributes names are: [rebalancingEnabled, cacheStatus, cacheAvailability, cacheName, version, configurationAsProperties]
	at org.infinispan.jmx.ResourceDMBean.getAttribute(ResourceDMBean.java:181) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:647) ~[?:1.8.0_402-internal]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:678) ~[?:1.8.0_402-internal]
	at org.radargun.service.ConfigDumpHelper60.dumpCache(ConfigDumpHelper60.java:44) [plugin-infinispan60-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.service.EmbeddedConfigurationProvider.getNormalizedConfigs(EmbeddedConfigurationProvider.java:33) [plugin-infinispan52-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.stages.lifecycle.ServiceStartStage.executeOnSlave(ServiceStartStage.java:92) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase.scenarioLoop(SlaveBase.java:102) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase$ScenarioRunner.run(SlaveBase.java:203) [radargun-core-3.0.0-SNAPSHOT.jar:?]
20:18:08,736 ERROR [org.radargun.service.ConfigDumpHelper] (sc-main) Error while dumping ___protobuf_metadata cache config as properties
javax.management.AttributeNotFoundException: Unknown attribute 'configurationAsProperties'. Known attributes names are: [rebalancingEnabled, cacheStatus, cacheAvailability, cacheName, version, configurationAsProperties]
	at org.infinispan.jmx.ResourceDMBean.getAttribute(ResourceDMBean.java:181) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:647) ~[?:1.8.0_402-internal]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:678) ~[?:1.8.0_402-internal]
	at org.radargun.service.ConfigDumpHelper60.dumpCache(ConfigDumpHelper60.java:44) [plugin-infinispan60-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.service.EmbeddedConfigurationProvider.getNormalizedConfigs(EmbeddedConfigurationProvider.java:33) [plugin-infinispan52-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.stages.lifecycle.ServiceStartStage.executeOnSlave(ServiceStartStage.java:92) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase.scenarioLoop(SlaveBase.java:102) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase$ScenarioRunner.run(SlaveBase.java:203) [radargun-core-3.0.0-SNAPSHOT.jar:?]
20:18:08,782 INFO  [org.radargun.Slave] (sc-main) Finished stage ServiceStart
20:18:08,806 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
20:18:08,904 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-19031: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-19031: 125, fedora-55780: 131]}, unionCH=null, actualMembers=[fedora-19031, fedora-55780], persistentUUIDs=[89cb6f46-a638-49d1-9a3e-3a4a64d15be2, a0357ecb-bc15-4b0b-af7f-68825bcb18ed]}
20:18:08,907 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-19031]ISPN100002: Started rebalance with topology id 2
20:18:08,911 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-19031: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-19031: 125, fedora-55780: 131]}, unionCH=null, actualMembers=[fedora-19031, fedora-55780], persistentUUIDs=[89cb6f46-a638-49d1-9a3e-3a4a64d15be2, a0357ecb-bc15-4b0b-af7f-68825bcb18ed]}
20:18:08,912 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-19031]ISPN100002: Started rebalance with topology id 2
20:18:08,948 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t23) [Context=org.infinispan.CONFIG][Scope=fedora-19031]ISPN100003: Node fedora-19031 finished rebalance phase with topology id 2
20:18:08,949 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t24) [Context=___counter_configuration][Scope=fedora-19031]ISPN100003: Node fedora-19031 finished rebalance phase with topology id 2
20:18:09,093 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-55780]ISPN100003: Node fedora-55780 finished rebalance phase with topology id 2
20:18:09,094 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 2
20:18:09,099 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t3) [Context=org.infinispan.CONFIG][Scope=fedora-19031]ISPN100003: Node fedora-19031 finished rebalance phase with topology id 3
20:18:09,131 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-55780]ISPN100003: Node fedora-55780 finished rebalance phase with topology id 3
20:18:09,131 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-55780]ISPN100003: Node fedora-55780 finished rebalance phase with topology id 2
20:18:09,132 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 2
20:18:09,135 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t6) [Context=___counter_configuration][Scope=fedora-19031]ISPN100003: Node fedora-19031 finished rebalance phase with topology id 3
20:18:09,138 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=org.infinispan.CONFIG][Scope=fedora-19031]ISPN100003: Node fedora-19031 finished rebalance phase with topology id 4
20:18:09,147 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-55780]ISPN100003: Node fedora-55780 finished rebalance phase with topology id 4
20:18:09,153 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-55780]ISPN100003: Node fedora-55780 finished rebalance phase with topology id 3
20:18:09,155 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t15) [Context=___counter_configuration][Scope=fedora-19031]ISPN100003: Node fedora-19031 finished rebalance phase with topology id 4
20:18:09,164 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-55780]ISPN100003: Node fedora-55780 finished rebalance phase with topology id 4
20:18:09,213 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=DefaultConsistentHash{ns=256, owners = (1)[fedora-19031: 256+0]}, pendingCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-19031: 125+131, fedora-55780: 131+125]}, unionCH=null, actualMembers=[fedora-19031, fedora-55780], persistentUUIDs=[89cb6f46-a638-49d1-9a3e-3a4a64d15be2, a0357ecb-bc15-4b0b-af7f-68825bcb18ed]}
20:18:09,214 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-19031]ISPN100002: Started rebalance with topology id 2
20:18:09,218 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t24) [Context=___counters][Scope=fedora-19031]ISPN100003: Node fedora-19031 finished rebalance phase with topology id 2
20:18:09,287 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-19031: 125, fedora-55780: 131]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-19031: 82, fedora-55780: 90, fedora-26103: 84]}, unionCH=null, actualMembers=[fedora-19031, fedora-55780, fedora-26103], persistentUUIDs=[89cb6f46-a638-49d1-9a3e-3a4a64d15be2, a0357ecb-bc15-4b0b-af7f-68825bcb18ed, 4c9d74cc-ff23-43c2-b605-6dd9d948cd07]}
20:18:09,288 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-19031]ISPN100002: Started rebalance with topology id 6
20:18:09,290 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t1) [Context=___counter_configuration][Scope=fedora-19031]ISPN100003: Node fedora-19031 finished rebalance phase with topology id 6
20:18:09,297 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-19031: 125, fedora-55780: 131]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-19031: 82, fedora-55780: 90, fedora-26103: 84]}, unionCH=null, actualMembers=[fedora-19031, fedora-55780, fedora-26103], persistentUUIDs=[89cb6f46-a638-49d1-9a3e-3a4a64d15be2, a0357ecb-bc15-4b0b-af7f-68825bcb18ed, 4c9d74cc-ff23-43c2-b605-6dd9d948cd07]}
20:18:09,308 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-19031]ISPN100002: Started rebalance with topology id 6
20:18:09,310 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t3) [Context=org.infinispan.CONFIG][Scope=fedora-19031]ISPN100003: Node fedora-19031 finished rebalance phase with topology id 6
20:18:09,329 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-55780]ISPN100003: Node fedora-55780 finished rebalance phase with topology id 6
20:18:09,332 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-55780]ISPN100003: Node fedora-55780 finished rebalance phase with topology id 6
20:18:09,391 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-55780]ISPN100003: Node fedora-55780 finished rebalance phase with topology id 2
20:18:09,394 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache ___counters, topology id = 2
20:18:09,402 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t6) [Context=___counters][Scope=fedora-19031]ISPN100003: Node fedora-19031 finished rebalance phase with topology id 3
20:18:09,414 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-55780]ISPN100003: Node fedora-55780 finished rebalance phase with topology id 3
20:18:09,420 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=___counters][Scope=fedora-19031]ISPN100003: Node fedora-19031 finished rebalance phase with topology id 4
20:18:09,427 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-19031: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-19031: 125, fedora-55780: 131]}, unionCH=null, actualMembers=[fedora-19031, fedora-55780], persistentUUIDs=[89cb6f46-a638-49d1-9a3e-3a4a64d15be2, a0357ecb-bc15-4b0b-af7f-68825bcb18ed]}
20:18:09,428 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-19031]ISPN100002: Started rebalance with topology id 2
20:18:09,428 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-55780]ISPN100003: Node fedora-55780 finished rebalance phase with topology id 4
20:18:09,435 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t17) [Context=___protobuf_metadata][Scope=fedora-19031]ISPN100003: Node fedora-19031 finished rebalance phase with topology id 2
20:18:09,470 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-55780]ISPN100003: Node fedora-55780 finished rebalance phase with topology id 2
20:18:09,471 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 2
20:18:09,474 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=___protobuf_metadata][Scope=fedora-19031]ISPN100003: Node fedora-19031 finished rebalance phase with topology id 3
20:18:09,477 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=DefaultConsistentHash{ns=512, owners = (1)[fedora-19031: 512+0]}, pendingCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-19031: 243+269, fedora-55780: 269+243]}, unionCH=null, actualMembers=[fedora-19031, fedora-55780], persistentUUIDs=[89cb6f46-a638-49d1-9a3e-3a4a64d15be2, a0357ecb-bc15-4b0b-af7f-68825bcb18ed]}
20:18:09,474 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-55780]ISPN100003: Node fedora-55780 finished rebalance phase with topology id 3
20:18:09,478 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-19031]ISPN100002: Started rebalance with topology id 2
20:18:09,485 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-55780]ISPN100003: Node fedora-55780 finished rebalance phase with topology id 4
20:18:09,485 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t1) [Context=testCache][Scope=fedora-19031]ISPN100003: Node fedora-19031 finished rebalance phase with topology id 2
20:18:09,487 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t25) [Context=___protobuf_metadata][Scope=fedora-19031]ISPN100003: Node fedora-19031 finished rebalance phase with topology id 4
20:18:09,511 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-55780]ISPN100003: Node fedora-55780 finished rebalance phase with topology id 2
20:18:09,512 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache testCache, topology id = 2
20:18:09,515 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t10) [Context=testCache][Scope=fedora-19031]ISPN100003: Node fedora-19031 finished rebalance phase with topology id 3
20:18:09,519 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-55780]ISPN100003: Node fedora-55780 finished rebalance phase with topology id 3
20:18:09,525 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t12) [Context=testCache][Scope=fedora-19031]ISPN100003: Node fedora-19031 finished rebalance phase with topology id 4
20:18:09,529 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-55780]ISPN100003: Node fedora-55780 finished rebalance phase with topology id 4
20:18:09,591 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-26103]ISPN100003: Node fedora-26103 finished rebalance phase with topology id 6
20:18:09,591 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 6
20:18:09,593 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t23) [Context=org.infinispan.CONFIG][Scope=fedora-19031]ISPN100003: Node fedora-19031 finished rebalance phase with topology id 7
20:18:09,599 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-55780]ISPN100003: Node fedora-55780 finished rebalance phase with topology id 7
20:18:09,616 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-26103]ISPN100003: Node fedora-26103 finished rebalance phase with topology id 6
20:18:09,618 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 6
20:18:09,619 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t2) [Context=___counter_configuration][Scope=fedora-19031]ISPN100003: Node fedora-19031 finished rebalance phase with topology id 7
20:18:09,627 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-55780]ISPN100003: Node fedora-55780 finished rebalance phase with topology id 7
20:18:09,630 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-26103]ISPN100003: Node fedora-26103 finished rebalance phase with topology id 7
20:18:09,630 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-26103]ISPN100003: Node fedora-26103 finished rebalance phase with topology id 7
20:18:09,633 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t24) [Context=org.infinispan.CONFIG][Scope=fedora-19031]ISPN100003: Node fedora-19031 finished rebalance phase with topology id 8
20:18:09,633 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=___counter_configuration][Scope=fedora-19031]ISPN100003: Node fedora-19031 finished rebalance phase with topology id 8
20:18:09,635 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-55780]ISPN100003: Node fedora-55780 finished rebalance phase with topology id 8
20:18:09,637 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-26103]ISPN100003: Node fedora-26103 finished rebalance phase with topology id 8
20:18:09,637 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-55780]ISPN100003: Node fedora-55780 finished rebalance phase with topology id 8
20:18:09,644 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-26103]ISPN100003: Node fedora-26103 finished rebalance phase with topology id 8
20:18:09,671 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-19031: 125+131, fedora-55780: 131+125]}, pendingCH=DefaultConsistentHash{ns=256, owners = (3)[fedora-19031: 82+87, fedora-55780: 90+85, fedora-26103: 84+84]}, unionCH=null, actualMembers=[fedora-19031, fedora-55780, fedora-26103], persistentUUIDs=[89cb6f46-a638-49d1-9a3e-3a4a64d15be2, a0357ecb-bc15-4b0b-af7f-68825bcb18ed, 4c9d74cc-ff23-43c2-b605-6dd9d948cd07]}
20:18:09,674 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-19031]ISPN100002: Started rebalance with topology id 6
20:18:09,677 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t12) [Context=___counters][Scope=fedora-19031]ISPN100003: Node fedora-19031 finished rebalance phase with topology id 6
20:18:09,681 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-55780]ISPN100003: Node fedora-55780 finished rebalance phase with topology id 6
20:18:09,761 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-26103]ISPN100003: Node fedora-26103 finished rebalance phase with topology id 6
20:18:09,761 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___counters, topology id = 6
20:18:09,763 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t19) [Context=___counters][Scope=fedora-19031]ISPN100003: Node fedora-19031 finished rebalance phase with topology id 7
20:18:09,766 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-55780]ISPN100003: Node fedora-55780 finished rebalance phase with topology id 7
20:18:09,769 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-26103]ISPN100003: Node fedora-26103 finished rebalance phase with topology id 7
20:18:09,773 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=___counters][Scope=fedora-19031]ISPN100003: Node fedora-19031 finished rebalance phase with topology id 8
20:18:09,777 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-55780]ISPN100003: Node fedora-55780 finished rebalance phase with topology id 8
20:18:09,782 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-19031: 125, fedora-55780: 131]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-19031: 82, fedora-55780: 90, fedora-26103: 84]}, unionCH=null, actualMembers=[fedora-19031, fedora-55780, fedora-26103], persistentUUIDs=[89cb6f46-a638-49d1-9a3e-3a4a64d15be2, a0357ecb-bc15-4b0b-af7f-68825bcb18ed, 4c9d74cc-ff23-43c2-b605-6dd9d948cd07]}
20:18:09,783 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-26103]ISPN100003: Node fedora-26103 finished rebalance phase with topology id 8
20:18:09,783 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-19031]ISPN100002: Started rebalance with topology id 6
20:18:09,793 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=___protobuf_metadata][Scope=fedora-19031]ISPN100003: Node fedora-19031 finished rebalance phase with topology id 6
20:18:09,795 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-55780]ISPN100003: Node fedora-55780 finished rebalance phase with topology id 6
20:18:09,820 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-26103]ISPN100003: Node fedora-26103 finished rebalance phase with topology id 6
20:18:09,820 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 6
20:18:09,822 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t3) [Context=___protobuf_metadata][Scope=fedora-19031]ISPN100003: Node fedora-19031 finished rebalance phase with topology id 7
20:18:09,825 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-55780]ISPN100003: Node fedora-55780 finished rebalance phase with topology id 7
20:18:09,826 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-26103]ISPN100003: Node fedora-26103 finished rebalance phase with topology id 7
20:18:09,828 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=___protobuf_metadata][Scope=fedora-19031]ISPN100003: Node fedora-19031 finished rebalance phase with topology id 8
20:18:09,831 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-55780]ISPN100003: Node fedora-55780 finished rebalance phase with topology id 8
20:18:09,833 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-26103]ISPN100003: Node fedora-26103 finished rebalance phase with topology id 8
20:18:09,848 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-19031: 243+269, fedora-55780: 269+243]}, pendingCH=DefaultConsistentHash{ns=512, owners = (3)[fedora-19031: 159+193, fedora-55780: 180+165, fedora-26103: 173+154]}, unionCH=null, actualMembers=[fedora-19031, fedora-55780, fedora-26103], persistentUUIDs=[89cb6f46-a638-49d1-9a3e-3a4a64d15be2, a0357ecb-bc15-4b0b-af7f-68825bcb18ed, 4c9d74cc-ff23-43c2-b605-6dd9d948cd07]}
20:18:09,848 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-19031]ISPN100002: Started rebalance with topology id 6
20:18:09,854 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t13) [Context=testCache][Scope=fedora-19031]ISPN100003: Node fedora-19031 finished rebalance phase with topology id 6
20:18:09,856 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-55780]ISPN100003: Node fedora-55780 finished rebalance phase with topology id 6
20:18:09,877 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-26103]ISPN100003: Node fedora-26103 finished rebalance phase with topology id 6
20:18:09,877 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache testCache, topology id = 6
20:18:09,880 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t23) [Context=testCache][Scope=fedora-19031]ISPN100003: Node fedora-19031 finished rebalance phase with topology id 7
20:18:09,886 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-55780]ISPN100003: Node fedora-55780 finished rebalance phase with topology id 7
20:18:09,887 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-26103]ISPN100003: Node fedora-26103 finished rebalance phase with topology id 7
20:18:09,889 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t1) [Context=testCache][Scope=fedora-19031]ISPN100003: Node fedora-19031 finished rebalance phase with topology id 8
20:18:09,894 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-55780]ISPN100003: Node fedora-55780 finished rebalance phase with topology id 8
20:18:09,897 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-26103]ISPN100003: Node fedora-26103 finished rebalance phase with topology id 8
20:18:10,002 INFO  [org.radargun.Slave] (sc-main) Starting stage AfterServiceStart
20:18:10,002 INFO  [org.radargun.Slave] (sc-main) Finished stage AfterServiceStart
20:18:10,007 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
20:18:10,071 INFO  [org.radargun.Slave] (sc-main) Starting stage MonitorStart
20:18:10,078 INFO  [org.radargun.sysmonitor.AbstractMonitors] (sc-main) Gathering statistics every 1000 ms
20:18:10,080 INFO  [org.radargun.Slave] (sc-main) Finished stage MonitorStart
20:18:10,082 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
20:18:10,111 INFO  [org.radargun.Slave] (sc-main) Starting stage Load
20:18:18,546 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) This node loaded 10000 entries (~10000000 bytes)
20:18:22,937 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) This node loaded 20000 entries (~20000000 bytes)
20:18:26,974 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) This node loaded 30000 entries (~30000000 bytes)
20:18:27,874 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) Finished loading entries
20:18:27,886 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) Finished loading entries
20:18:27,892 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) Finished loading entries
20:18:27,903 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) Finished loading entries
20:18:27,907 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) Finished loading entries
20:18:27,913 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) Finished loading entries
20:18:27,919 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) Finished loading entries
20:18:27,929 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) Finished loading entries
20:18:27,937 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) Finished loading entries
20:18:27,940 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) Finished loading entries
20:18:27,941 INFO  [org.radargun.Slave] (sc-main) Finished stage Load
20:18:27,942 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
20:18:27,984 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.stages.cache.test.BasicOperationsTestStage.init() overrides public void org.radargun.stages.test.TestStage.init() but both are declared with @Init annotation: calling only once
20:18:28,003 INFO  [org.radargun.Slave] (sc-main) Starting stage BasicOperationsTest
20:18:28,004 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using key generator org.radargun.stages.cache.generators.StringKeyGenerator {format=null }
20:18:28,005 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using value generator org.radargun.stages.cache.generators.ByteArrayValueGenerator { }
20:18:28,008 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using cache selector Default { }
20:18:28,009 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Starting test warmup
20:18:28,024 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Started 4 stressor threads.
20:19:28,036 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Finished test. Test duration is: 1 mins 0 secs
20:19:28,038 INFO  [org.radargun.Slave] (sc-main) Finished stage BasicOperationsTest
20:19:28,044 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
20:19:28,054 INFO  [org.radargun.Slave] (sc-main) Starting stage Clear
20:19:28,056 INFO  [org.radargun.stages.cache.ClearStage] (sc-main) Before executing clear, memory looks like this: 
Runtime free: 971,517 kb
Runtime max:1,294,848 kb
Runtime total:1,294,848 kb
MX Code Cache(Non-heap memory): used: 13,370 kb, init: 2,496 kb, committed: 13,952 kb, max: 245,760 kb
MX Metaspace(Non-heap memory): used: 37,870 kb, init: 0 kb, committed: 39,808 kb, max: 0 kb
MX Compressed Class Space(Non-heap memory): used: 4,572 kb, init: 0 kb, committed: 4,992 kb, max: 1,048,576 kb
MX PS Eden Space(Heap memory): used: 187,869 kb, init: 350,208 kb, committed: 259,072 kb, max: 259,584 kb
MX PS Survivor Space(Heap memory): used: 76,832 kb, init: 57,856 kb, committed: 102,912 kb, max: 102,912 kb
MX PS Old Gen(Heap memory): used: 58,629 kb, init: 932,864 kb, committed: 932,864 kb, max: 932,864 kb
20:19:28,351 INFO  [org.radargun.stages.cache.ClearStage] (sc-main) After executing clear, memory looks like this: 
Runtime free: 1,216,257 kb
Runtime max:1,243,648 kb
Runtime total:1,229,824 kb
MX Code Cache(Non-heap memory): used: 13,584 kb, init: 2,496 kb, committed: 14,016 kb, max: 245,760 kb
MX Metaspace(Non-heap memory): used: 37,855 kb, init: 0 kb, committed: 39,808 kb, max: 0 kb
MX Compressed Class Space(Non-heap memory): used: 4,558 kb, init: 0 kb, committed: 4,992 kb, max: 1,048,576 kb
MX PS Eden Space(Heap memory): used: 995 kb, init: 350,208 kb, committed: 259,072 kb, max: 323,584 kb
MX PS Survivor Space(Heap memory): used: 0 kb, init: 57,856 kb, committed: 37,888 kb, max: 37,888 kb
MX PS Old Gen(Heap memory): used: 12,571 kb, init: 932,864 kb, committed: 932,864 kb, max: 932,864 kb
20:19:28,352 INFO  [org.radargun.Slave] (sc-main) Finished stage Clear
20:19:28,353 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
20:19:28,356 INFO  [org.radargun.Slave] (sc-main) Starting stage Load
20:19:31,877 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) This node loaded 10000 entries (~10000000 bytes)
20:19:35,463 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) This node loaded 20000 entries (~20000000 bytes)
20:19:38,875 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) This node loaded 30000 entries (~30000000 bytes)
20:19:39,898 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) Finished loading entries
20:19:39,916 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) Finished loading entries
20:19:39,923 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) Finished loading entries
20:19:39,947 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) Finished loading entries
20:19:39,947 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) Finished loading entries
20:19:39,961 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) Finished loading entries
20:19:39,972 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) Finished loading entries
20:19:39,975 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) Finished loading entries
20:19:39,981 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) Finished loading entries
20:19:40,014 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) Finished loading entries
20:19:40,014 INFO  [org.radargun.Slave] (sc-main) Finished stage Load
20:19:40,015 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
20:19:40,544 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.stages.cache.test.BasicOperationsTestStage.init() overrides public void org.radargun.stages.test.TestStage.init() but both are declared with @Init annotation: calling only once
20:19:40,545 INFO  [org.radargun.Slave] (sc-main) Starting stage BasicOperationsTest
20:19:40,546 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using key generator org.radargun.stages.cache.generators.StringKeyGenerator {format=null }
20:19:40,552 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using value generator org.radargun.stages.cache.generators.ByteArrayValueGenerator { }
20:19:40,553 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using cache selector Default { }
20:19:40,554 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Starting test stress-test
20:19:40,629 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Started 4 stressor threads.
20:29:40,634 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Finished test. Test duration is: 10 mins 0 secs
20:29:40,635 INFO  [org.radargun.Slave] (sc-main) Finished stage BasicOperationsTest
20:29:40,781 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
20:29:40,934 INFO  [org.radargun.Slave] (sc-main) Starting stage MonitorStop
20:29:40,936 INFO  [org.radargun.Slave] (sc-main) Finished stage MonitorStop
20:29:40,938 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
20:29:40,948 INFO  [org.radargun.Slave] (sc-main) Starting stage ScenarioDestroy
20:29:40,949 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Scenario finished, destroying...
20:29:40,949 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Memory before cleanup: 
Runtime free: 962,004 kb
Runtime max:1,326,592 kb
Runtime total:1,326,592 kb
MX Code Cache(Non-heap memory): used: 15,180 kb, init: 2,496 kb, committed: 15,360 kb, max: 245,760 kb
MX Metaspace(Non-heap memory): used: 38,402 kb, init: 0 kb, committed: 40,320 kb, max: 0 kb
MX Compressed Class Space(Non-heap memory): used: 4,594 kb, init: 0 kb, committed: 4,992 kb, max: 1,048,576 kb
MX PS Eden Space(Heap memory): used: 255,911 kb, init: 350,208 kb, committed: 321,536 kb, max: 321,536 kb
MX PS Survivor Space(Heap memory): used: 71,584 kb, init: 57,856 kb, committed: 72,192 kb, max: 72,192 kb
MX PS Old Gen(Heap memory): used: 37,091 kb, init: 932,864 kb, committed: 932,864 kb, max: 932,864 kb
20:29:40,951 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) Stopping service.
20:29:40,961 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t9) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-19031: 251+101, fedora-55780: 261+84]}, pendingCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-19031: 243+269, fedora-55780: 269+243]}, unionCH=null, actualMembers=[fedora-19031, fedora-55780], persistentUUIDs=[89cb6f46-a638-49d1-9a3e-3a4a64d15be2, a0357ecb-bc15-4b0b-af7f-68825bcb18ed]}
20:29:40,977 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t9) [Context=testCache][Scope=fedora-19031]ISPN100002: Started rebalance with topology id 11
20:29:40,981 WARN  [org.infinispan.CLUSTER] (remote-thread--p2-t10) [Context=testCache]ISPN000312: Lost data because of graceful leaver fedora-55780
20:29:41,018 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t3) [Context=testCache][Scope=fedora-19031]ISPN100003: Node fedora-19031 finished rebalance phase with topology id 11
20:29:41,019 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t9) [Context=testCache][Scope=fedora-19031]ISPN100003: Node fedora-19031 finished rebalance phase with topology id 12
20:29:41,047 INFO  [org.infinispan.CLUSTER] (StopThread) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-55780: 131+44, fedora-26103: 125+43]}, pendingCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-55780: 134+122, fedora-26103: 122+134]}, unionCH=null, actualMembers=[fedora-55780, fedora-26103], persistentUUIDs=[a0357ecb-bc15-4b0b-af7f-68825bcb18ed, 4c9d74cc-ff23-43c2-b605-6dd9d948cd07]}
20:29:41,047 INFO  [org.infinispan.CLUSTER] (StopThread) [Context=___counters][Scope=fedora-19031]ISPN100002: Started rebalance with topology id 11
20:29:41,049 WARN  [org.infinispan.CLUSTER] (remote-thread--p2-t10) [Context=___counters]ISPN000312: Lost data because of graceful leaver fedora-55780
20:29:41,061 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (StopThread) ISPN000080: Disconnecting JGroups channel results
20:29:41,140 WARN  [org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler] (remote-thread--p2-t10) ISPN000219: Shutdown while handling command CacheTopologyControlCommand{cache=___counters, type=REBALANCE_PHASE_CONFIRM, sender=fedora-26103, joinInfo=null, topologyId=12, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
20:29:41,140 WARN  [org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler] (remote-thread--p2-t9) ISPN000219: Shutdown while handling command CacheTopologyControlCommand{cache=___protobuf_metadata, type=LEAVE, sender=fedora-55780, joinInfo=null, topologyId=0, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
20:29:41,145 INFO  [org.radargun.service.Infinispan90Lifecycle] (StopThread) Stopped, previous view is [fedora-19031, fedora-55780, fedora-26103]
20:29:41,145 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Service successfully stopped.
20:29:41,145 INFO  [org.radargun.Slave] (sc-main) Finished stage ScenarioDestroy
20:29:41,146 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
20:29:41,176 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.service.Infinispan80EmbeddedService.destroy() overrides public void org.radargun.service.Infinispan60EmbeddedService.destroy() but both are declared with @Destroy annotation: calling only once
20:29:41,177 INFO  [org.radargun.Slave] (main) Starting stage ScenarioCleanup
20:29:41,178 WARN  [org.radargun.stages.ScenarioCleanupStage] (main) Unfinished thread VERIFY_SUSPECT.TimerThread-43,fedora-19031 (id=161, state=TIMED_WAITING)
	at sun.misc.Unsafe.park(Native Method)
	at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
	at java.util.concurrent.DelayQueue.poll(DelayQueue.java:273)
	at org.jgroups.protocols.VERIFY_SUSPECT.run(VERIFY_SUSPECT.java:162)
	at java.lang.Thread.run(Thread.java:750)
20:29:41,179 INFO  [org.radargun.stages.ScenarioCleanupStage] (main) Interrupting thread VERIFY_SUSPECT.TimerThread-43,fedora-19031 (id=161, state=TIMED_WAITING)
20:29:46,096 INFO  [org.radargun.stages.ScenarioCleanupStage] (main) Is thread VERIFY_SUSPECT.TimerThread-43,fedora-19031 (id=161, state=TERMINATED)) alive? false
20:29:46,295 INFO  [org.radargun.stages.ScenarioCleanupStage] (main) Memory after cleanup: 
Runtime free: 1,308,514 kb
Runtime max:1,325,568 kb
Runtime total:1,325,568 kb
MX Code Cache(Non-heap memory): used: 15,268 kb, init: 2,496 kb, committed: 15,424 kb, max: 245,760 kb
MX Metaspace(Non-heap memory): used: 38,558 kb, init: 0 kb, committed: 40,320 kb, max: 0 kb
MX Compressed Class Space(Non-heap memory): used: 4,621 kb, init: 0 kb, committed: 4,992 kb, max: 1,048,576 kb
MX PS Eden Space(Heap memory): used: 4,470 kb, init: 350,208 kb, committed: 320,512 kb, max: 321,024 kb
MX PS Survivor Space(Heap memory): used: 0 kb, init: 57,856 kb, committed: 72,192 kb, max: 72,192 kb
MX PS Old Gen(Heap memory): used: 12,583 kb, init: 932,864 kb, committed: 932,864 kb, max: 932,864 kb
20:29:46,297 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
20:29:46,410 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
20:29:51,234 INFO  [org.radargun.Slave] (main) Master shutdown!
20:29:51,241 INFO  [org.radargun.ShutDownHook] (Thread-0) Slave process is being shutdown
