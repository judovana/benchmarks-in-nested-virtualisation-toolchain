16:58:08,230 INFO  [org.radargun.RemoteMasterConnection] (main) Attempting to connect to master results:2103
16:58:08,239 INFO  [org.radargun.RemoteMasterConnection] (main) Successfully established connection with master at: results:2103
16:58:08,241 INFO  [org.radargun.Slave] (main) Received slave index 0
16:58:08,241 INFO  [org.radargun.Slave] (main) Received slave count 3
16:58:08,664 INFO  [org.radargun.ServiceHelper] (sc-main) ServiceContext properties: {}
16:58:08,746 INFO  [org.radargun.Slave] (sc-main) Eager Service Infinispan92EmbeddedService {batching=false, cache=testCache, channelRetrievalTimeout=2 mins 0 secs, enableDiagnostics=null, explicitLocking=false, file=/mnt/workspace/results/dist-sync.xml, internalsExpositionEnabled=false, jgroupsDumperEnabled=false, jgroupsDumperInterval=10.000 secs, keysPerThread=-1, mapReduceDistributedReducePhase=false, mapReduceUseIntermediateSharedCache=false, removedCaches=[  ], threadsPerNode=-1 } loaded.
16:58:10,460 INFO  [org.radargun.Slave] (sc-main) Starting stage ScenarioInit
16:58:10,478 INFO  [org.radargun.Slave] (sc-main) Finished stage ScenarioInit
16:58:10,481 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
16:58:10,637 INFO  [org.radargun.Slave] (sc-main) Starting stage BeforeServiceStart
16:58:10,637 INFO  [org.radargun.Slave] (sc-main) Finished stage BeforeServiceStart
16:58:10,637 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
16:58:10,644 INFO  [org.radargun.Slave] (sc-main) Starting stage ServiceStart
16:58:10,645 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Startup staggering, this is the slave with index 0, not sleeping
16:58:10,645 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 0
16:58:10,648 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) Infinispan version: Infinispan 'Gaina' 9.2.0.Final
16:58:10,668 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) JGroups version: JGroups 4.0.10.Final (Schiener Berg)
16:58:11,221 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (sc-main) ISPN000078: Starting JGroups channel results
16:58:11,298 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the send buffer of socket MulticastSocket was set to 1.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
16:58:11,298 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the receive buffer of socket MulticastSocket was set to 20.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
16:58:11,298 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the send buffer of socket MulticastSocket was set to 1.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
16:58:11,299 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the receive buffer of socket MulticastSocket was set to 25.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
16:58:16,314 INFO  [org.infinispan.CLUSTER] (sc-main) ISPN000094: Received new cluster view for channel results: [fedora-31026|0] (1) [fedora-31026]
16:58:16,372 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (sc-main) ISPN000079: Channel results local address is fedora-31026, physical addresses are [192.168.121.141:34362]
16:58:16,375 INFO  [org.infinispan.factories.GlobalComponentRegistry] (sc-main) ISPN000128: Infinispan version: Infinispan 'Gaina' 9.2.0.Final
16:58:16,930 INFO  [org.infinispan.CLUSTER] (jgroups-6,fedora-31026) ISPN000094: Received new cluster view for channel results: [fedora-31026|1] (2) [fedora-31026, fedora-4043]
16:58:16,942 INFO  [org.infinispan.CLUSTER] (jgroups-6,fedora-31026) ISPN100000: Node fedora-4043 joined the cluster
16:58:16,985 INFO  [org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup] (sc-main) ISPN000107: Retrieving transaction manager Transaction: unknown
16:58:17,148 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) No RELAY2 protocol in XS service
16:58:17,149 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) No RELAY2 protocol in XS service
16:58:17,151 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) ([fedora-31026(local=true, coord=true), fedora-4043(local=false, coord=false)]) Number of members=2 is not the one expected: 3
16:58:17,504 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-31026: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-31026: 134, fedora-4043: 122]}, unionCH=null, actualMembers=[fedora-31026, fedora-4043], persistentUUIDs=[ed8d4875-f029-446c-b013-801fd0f3f85e, 74708012-a33d-4977-92c8-5bd451e10475]}
16:58:17,506 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-31026]ISPN100002: Started rebalance with topology id 2
16:58:17,516 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=org.infinispan.CONFIG][Scope=fedora-31026]ISPN100003: Node fedora-31026 finished rebalance phase with topology id 2
16:58:17,520 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-31026: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-31026: 134, fedora-4043: 122]}, unionCH=null, actualMembers=[fedora-31026, fedora-4043], persistentUUIDs=[ed8d4875-f029-446c-b013-801fd0f3f85e, 74708012-a33d-4977-92c8-5bd451e10475]}
16:58:17,521 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-31026]ISPN100002: Started rebalance with topology id 2
16:58:17,528 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t23) [Context=___counter_configuration][Scope=fedora-31026]ISPN100003: Node fedora-31026 finished rebalance phase with topology id 2
16:58:17,656 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-4043]ISPN100003: Node fedora-4043 finished rebalance phase with topology id 2
16:58:17,656 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 2
16:58:17,661 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t1) [Context=org.infinispan.CONFIG][Scope=fedora-31026]ISPN100003: Node fedora-31026 finished rebalance phase with topology id 3
16:58:17,678 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-4043]ISPN100003: Node fedora-4043 finished rebalance phase with topology id 2
16:58:17,679 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 2
16:58:17,681 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t6) [Context=___counter_configuration][Scope=fedora-31026]ISPN100003: Node fedora-31026 finished rebalance phase with topology id 3
16:58:17,688 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-4043]ISPN100003: Node fedora-4043 finished rebalance phase with topology id 3
16:58:17,690 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=org.infinispan.CONFIG][Scope=fedora-31026]ISPN100003: Node fedora-31026 finished rebalance phase with topology id 4
16:58:17,693 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-4043]ISPN100003: Node fedora-4043 finished rebalance phase with topology id 3
16:58:17,694 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t13) [Context=___counter_configuration][Scope=fedora-31026]ISPN100003: Node fedora-31026 finished rebalance phase with topology id 4
16:58:17,703 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-4043]ISPN100003: Node fedora-4043 finished rebalance phase with topology id 4
16:58:17,707 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-4043]ISPN100003: Node fedora-4043 finished rebalance phase with topology id 4
16:58:17,713 INFO  [org.infinispan.CLUSTER] (jgroups-12,fedora-31026) ISPN000094: Received new cluster view for channel results: [fedora-31026|2] (3) [fedora-31026, fedora-4043, fedora-4717]
16:58:17,714 INFO  [org.infinispan.CLUSTER] (jgroups-12,fedora-31026) ISPN100000: Node fedora-4717 joined the cluster
16:58:17,773 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=DefaultConsistentHash{ns=256, owners = (1)[fedora-31026: 256+0]}, pendingCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-31026: 134+122, fedora-4043: 122+134]}, unionCH=null, actualMembers=[fedora-31026, fedora-4043], persistentUUIDs=[ed8d4875-f029-446c-b013-801fd0f3f85e, 74708012-a33d-4977-92c8-5bd451e10475]}
16:58:17,773 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-31026]ISPN100002: Started rebalance with topology id 2
16:58:17,777 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=___counters][Scope=fedora-31026]ISPN100003: Node fedora-31026 finished rebalance phase with topology id 2
16:58:17,841 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-31026: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-31026: 134, fedora-4043: 122]}, unionCH=null, actualMembers=[fedora-31026, fedora-4043], persistentUUIDs=[ed8d4875-f029-446c-b013-801fd0f3f85e, 74708012-a33d-4977-92c8-5bd451e10475]}
16:58:17,842 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-31026]ISPN100002: Started rebalance with topology id 2
16:58:17,852 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t1) [Context=___protobuf_metadata][Scope=fedora-31026]ISPN100003: Node fedora-31026 finished rebalance phase with topology id 2
16:58:17,888 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-4043]ISPN100003: Node fedora-4043 finished rebalance phase with topology id 2
16:58:17,902 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache ___counters, topology id = 2
16:58:17,903 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t6) [Context=___counters][Scope=fedora-31026]ISPN100003: Node fedora-31026 finished rebalance phase with topology id 3
16:58:17,910 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=DefaultConsistentHash{ns=512, owners = (1)[fedora-31026: 512+0]}, pendingCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-31026: 264+248, fedora-4043: 248+264]}, unionCH=null, actualMembers=[fedora-31026, fedora-4043], persistentUUIDs=[ed8d4875-f029-446c-b013-801fd0f3f85e, 74708012-a33d-4977-92c8-5bd451e10475]}
16:58:17,911 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-31026]ISPN100002: Started rebalance with topology id 2
16:58:17,927 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-4043]ISPN100003: Node fedora-4043 finished rebalance phase with topology id 2
16:58:17,929 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 2
16:58:17,932 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t13) [Context=___protobuf_metadata][Scope=fedora-31026]ISPN100003: Node fedora-31026 finished rebalance phase with topology id 3
16:58:17,931 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t10) [Context=testCache][Scope=fedora-31026]ISPN100003: Node fedora-31026 finished rebalance phase with topology id 2
16:58:17,931 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=fedora-4043]ISPN100003: Node fedora-4043 finished rebalance phase with topology id 3
16:58:17,943 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t11) [Context=___counters][Scope=fedora-31026]ISPN100003: Node fedora-31026 finished rebalance phase with topology id 4
16:58:17,950 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-4043]ISPN100003: Node fedora-4043 finished rebalance phase with topology id 3
16:58:17,953 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t19) [Context=___protobuf_metadata][Scope=fedora-31026]ISPN100003: Node fedora-31026 finished rebalance phase with topology id 4
16:58:17,953 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-4043]ISPN100003: Node fedora-4043 finished rebalance phase with topology id 4
16:58:17,956 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-4043]ISPN100003: Node fedora-4043 finished rebalance phase with topology id 4
16:58:17,971 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-4043]ISPN100003: Node fedora-4043 finished rebalance phase with topology id 2
16:58:17,971 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache testCache, topology id = 2
16:58:17,973 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t4) [Context=testCache][Scope=fedora-31026]ISPN100003: Node fedora-31026 finished rebalance phase with topology id 3
16:58:17,979 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-4043]ISPN100003: Node fedora-4043 finished rebalance phase with topology id 3
16:58:17,982 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t9) [Context=testCache][Scope=fedora-31026]ISPN100003: Node fedora-31026 finished rebalance phase with topology id 4
16:58:17,985 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-4043]ISPN100003: Node fedora-4043 finished rebalance phase with topology id 4
16:58:18,154 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) Number of members is the one expected: 3
16:58:18,155 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Successfully started cache service infinispan92/embedded on slave 0
16:58:18,191 ERROR [org.radargun.service.ConfigDumpHelper] (sc-main) Error while dumping ___protobuf_metadata cache config as properties
javax.management.AttributeNotFoundException: Unknown attribute 'configurationAsProperties'. Known attributes names are: [rebalancingEnabled, cacheStatus, cacheAvailability, cacheName, version, configurationAsProperties]
	at org.infinispan.jmx.ResourceDMBean.getAttribute(ResourceDMBean.java:181) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:641) ~[?:?]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:678) ~[?:?]
	at org.radargun.service.ConfigDumpHelper60.dumpCache(ConfigDumpHelper60.java:44) [plugin-infinispan60-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.service.EmbeddedConfigurationProvider.getNormalizedConfigs(EmbeddedConfigurationProvider.java:33) [plugin-infinispan52-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.stages.lifecycle.ServiceStartStage.executeOnSlave(ServiceStartStage.java:92) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase.scenarioLoop(SlaveBase.java:102) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase$ScenarioRunner.run(SlaveBase.java:203) [radargun-core-3.0.0-SNAPSHOT.jar:?]
16:58:18,203 ERROR [org.radargun.service.ConfigDumpHelper] (sc-main) Error while dumping ___protobuf_metadata cache config as properties
javax.management.AttributeNotFoundException: Unknown attribute 'configurationAsProperties'. Known attributes names are: [rebalancingEnabled, cacheStatus, cacheAvailability, cacheName, version, configurationAsProperties]
	at org.infinispan.jmx.ResourceDMBean.getAttribute(ResourceDMBean.java:181) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:641) ~[?:?]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:678) ~[?:?]
	at org.radargun.service.ConfigDumpHelper60.dumpCache(ConfigDumpHelper60.java:44) [plugin-infinispan60-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.service.EmbeddedConfigurationProvider.getNormalizedConfigs(EmbeddedConfigurationProvider.java:33) [plugin-infinispan52-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.stages.lifecycle.ServiceStartStage.executeOnSlave(ServiceStartStage.java:92) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase.scenarioLoop(SlaveBase.java:102) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase$ScenarioRunner.run(SlaveBase.java:203) [radargun-core-3.0.0-SNAPSHOT.jar:?]
16:58:18,228 INFO  [org.radargun.Slave] (sc-main) Finished stage ServiceStart
16:58:18,234 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-31026: 134, fedora-4043: 122]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-31026: 90, fedora-4043: 77, fedora-4717: 89]}, unionCH=null, actualMembers=[fedora-31026, fedora-4043, fedora-4717], persistentUUIDs=[ed8d4875-f029-446c-b013-801fd0f3f85e, 74708012-a33d-4977-92c8-5bd451e10475, 24417ea3-e1c0-4f87-86ce-cf06c57ada41]}
16:58:18,235 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-31026]ISPN100002: Started rebalance with topology id 6
16:58:18,236 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t10) [Context=org.infinispan.CONFIG][Scope=fedora-31026]ISPN100003: Node fedora-31026 finished rebalance phase with topology id 6
16:58:18,238 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
16:58:18,239 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-4043]ISPN100003: Node fedora-4043 finished rebalance phase with topology id 6
16:58:18,246 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-31026: 134, fedora-4043: 122]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-31026: 90, fedora-4043: 77, fedora-4717: 89]}, unionCH=null, actualMembers=[fedora-31026, fedora-4043, fedora-4717], persistentUUIDs=[ed8d4875-f029-446c-b013-801fd0f3f85e, 74708012-a33d-4977-92c8-5bd451e10475, 24417ea3-e1c0-4f87-86ce-cf06c57ada41]}
16:58:18,246 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-31026]ISPN100002: Started rebalance with topology id 6
16:58:18,248 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t11) [Context=___counter_configuration][Scope=fedora-31026]ISPN100003: Node fedora-31026 finished rebalance phase with topology id 6
16:58:18,249 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-4043]ISPN100003: Node fedora-4043 finished rebalance phase with topology id 6
16:58:18,303 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-4717]ISPN100003: Node fedora-4717 finished rebalance phase with topology id 6
16:58:18,304 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 6
16:58:18,305 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t19) [Context=___counter_configuration][Scope=fedora-31026]ISPN100003: Node fedora-31026 finished rebalance phase with topology id 7
16:58:18,308 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-4043]ISPN100003: Node fedora-4043 finished rebalance phase with topology id 7
16:58:18,310 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-4717]ISPN100003: Node fedora-4717 finished rebalance phase with topology id 6
16:58:18,310 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 6
16:58:18,312 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=org.infinispan.CONFIG][Scope=fedora-31026]ISPN100003: Node fedora-31026 finished rebalance phase with topology id 7
16:58:18,312 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-4043]ISPN100003: Node fedora-4043 finished rebalance phase with topology id 7
16:58:18,315 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-4717]ISPN100003: Node fedora-4717 finished rebalance phase with topology id 7
16:58:18,316 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t25) [Context=___counter_configuration][Scope=fedora-31026]ISPN100003: Node fedora-31026 finished rebalance phase with topology id 8
16:58:18,317 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-4043]ISPN100003: Node fedora-4043 finished rebalance phase with topology id 8
16:58:18,318 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=org.infinispan.CONFIG][Scope=fedora-4717]ISPN100003: Node fedora-4717 finished rebalance phase with topology id 7
16:58:18,319 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t5) [Context=org.infinispan.CONFIG][Scope=fedora-31026]ISPN100003: Node fedora-31026 finished rebalance phase with topology id 8
16:58:18,320 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counter_configuration][Scope=fedora-4717]ISPN100003: Node fedora-4717 finished rebalance phase with topology id 8
16:58:18,321 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-4043]ISPN100003: Node fedora-4043 finished rebalance phase with topology id 8
16:58:18,325 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-4717]ISPN100003: Node fedora-4717 finished rebalance phase with topology id 8
16:58:18,347 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-31026: 134+122, fedora-4043: 122+134]}, pendingCH=DefaultConsistentHash{ns=256, owners = (3)[fedora-31026: 90+89, fedora-4043: 77+79, fedora-4717: 89+88]}, unionCH=null, actualMembers=[fedora-31026, fedora-4043, fedora-4717], persistentUUIDs=[ed8d4875-f029-446c-b013-801fd0f3f85e, 74708012-a33d-4977-92c8-5bd451e10475, 24417ea3-e1c0-4f87-86ce-cf06c57ada41]}
16:58:18,348 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-31026]ISPN100002: Started rebalance with topology id 6
16:58:18,351 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-4043]ISPN100003: Node fedora-4043 finished rebalance phase with topology id 6
16:58:18,351 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t15) [Context=___counters][Scope=fedora-31026]ISPN100003: Node fedora-31026 finished rebalance phase with topology id 6
16:58:18,384 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=fedora-4717]ISPN100003: Node fedora-4717 finished rebalance phase with topology id 6
16:58:18,384 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000336: Finished cluster-wide rebalance for cache ___counters, topology id = 6
16:58:18,385 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t18) [Context=___counters][Scope=fedora-31026]ISPN100003: Node fedora-31026 finished rebalance phase with topology id 7
16:58:18,387 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=fedora-4043]ISPN100003: Node fedora-4043 finished rebalance phase with topology id 7
16:58:18,390 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=fedora-4717]ISPN100003: Node fedora-4717 finished rebalance phase with topology id 7
16:58:18,391 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t23) [Context=___counters][Scope=fedora-31026]ISPN100003: Node fedora-31026 finished rebalance phase with topology id 8
16:58:18,393 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=fedora-4043]ISPN100003: Node fedora-4043 finished rebalance phase with topology id 8
16:58:18,394 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-4717]ISPN100003: Node fedora-4717 finished rebalance phase with topology id 8
16:58:18,507 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-31026: 134, fedora-4043: 122]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-31026: 90, fedora-4043: 77, fedora-4717: 89]}, unionCH=null, actualMembers=[fedora-31026, fedora-4043, fedora-4717], persistentUUIDs=[ed8d4875-f029-446c-b013-801fd0f3f85e, 74708012-a33d-4977-92c8-5bd451e10475, 24417ea3-e1c0-4f87-86ce-cf06c57ada41]}
16:58:18,507 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-31026]ISPN100002: Started rebalance with topology id 6
16:58:18,509 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t25) [Context=___protobuf_metadata][Scope=fedora-31026]ISPN100003: Node fedora-31026 finished rebalance phase with topology id 6
16:58:18,514 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-4043]ISPN100003: Node fedora-4043 finished rebalance phase with topology id 6
16:58:18,530 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-4717]ISPN100003: Node fedora-4717 finished rebalance phase with topology id 6
16:58:18,531 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 6
16:58:18,532 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t9) [Context=___protobuf_metadata][Scope=fedora-31026]ISPN100003: Node fedora-31026 finished rebalance phase with topology id 7
16:58:18,534 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-4717]ISPN100003: Node fedora-4717 finished rebalance phase with topology id 7
16:58:18,534 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=fedora-4043]ISPN100003: Node fedora-4043 finished rebalance phase with topology id 7
16:58:18,536 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t6) [Context=___protobuf_metadata][Scope=fedora-31026]ISPN100003: Node fedora-31026 finished rebalance phase with topology id 8
16:58:18,539 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=fedora-4043]ISPN100003: Node fedora-4043 finished rebalance phase with topology id 8
16:58:18,540 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-4717]ISPN100003: Node fedora-4717 finished rebalance phase with topology id 8
16:58:18,554 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-31026: 264+248, fedora-4043: 248+264]}, pendingCH=DefaultConsistentHash{ns=512, owners = (3)[fedora-31026: 180+164, fedora-4043: 163+178, fedora-4717: 169+170]}, unionCH=null, actualMembers=[fedora-31026, fedora-4043, fedora-4717], persistentUUIDs=[ed8d4875-f029-446c-b013-801fd0f3f85e, 74708012-a33d-4977-92c8-5bd451e10475, 24417ea3-e1c0-4f87-86ce-cf06c57ada41]}
16:58:18,555 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-31026]ISPN100002: Started rebalance with topology id 6
16:58:18,558 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t14) [Context=testCache][Scope=fedora-31026]ISPN100003: Node fedora-31026 finished rebalance phase with topology id 6
16:58:18,562 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-4043]ISPN100003: Node fedora-4043 finished rebalance phase with topology id 6
16:58:18,573 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-4717]ISPN100003: Node fedora-4717 finished rebalance phase with topology id 6
16:58:18,573 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache testCache, topology id = 6
16:58:18,576 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t22) [Context=testCache][Scope=fedora-31026]ISPN100003: Node fedora-31026 finished rebalance phase with topology id 7
16:58:18,579 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-4043]ISPN100003: Node fedora-4043 finished rebalance phase with topology id 7
16:58:18,579 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-4717]ISPN100003: Node fedora-4717 finished rebalance phase with topology id 7
16:58:18,581 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t3) [Context=testCache][Scope=fedora-31026]ISPN100003: Node fedora-31026 finished rebalance phase with topology id 8
16:58:18,583 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-4717]ISPN100003: Node fedora-4717 finished rebalance phase with topology id 8
16:58:18,585 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-4043]ISPN100003: Node fedora-4043 finished rebalance phase with topology id 8
16:58:18,696 INFO  [org.radargun.Slave] (sc-main) Starting stage AfterServiceStart
16:58:18,697 INFO  [org.radargun.Slave] (sc-main) Finished stage AfterServiceStart
16:58:18,699 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
16:58:18,809 INFO  [org.radargun.Slave] (sc-main) Starting stage MonitorStart
16:58:18,817 INFO  [org.radargun.sysmonitor.AbstractMonitors] (sc-main) Gathering statistics every 1000 ms
16:58:18,818 INFO  [org.radargun.Slave] (sc-main) Finished stage MonitorStart
16:58:18,819 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
16:58:18,852 INFO  [org.radargun.Slave] (sc-main) Starting stage Load
16:58:24,085 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) This node loaded 10000 entries (~10000000 bytes)
16:58:27,826 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) This node loaded 20000 entries (~20000000 bytes)
16:58:29,604 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) This node loaded 30000 entries (~30000000 bytes)
16:58:30,084 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) Finished loading entries
16:58:30,097 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) Finished loading entries
16:58:30,131 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) Finished loading entries
16:58:30,136 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) Finished loading entries
16:58:30,141 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) Finished loading entries
16:58:30,160 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) Finished loading entries
16:58:30,163 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) Finished loading entries
16:58:30,182 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) Finished loading entries
16:58:30,185 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) Finished loading entries
16:58:30,192 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) Finished loading entries
16:58:30,193 INFO  [org.radargun.Slave] (sc-main) Finished stage Load
16:58:30,194 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
16:58:30,252 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.stages.cache.test.BasicOperationsTestStage.init() overrides public void org.radargun.stages.test.TestStage.init() but both are declared with @Init annotation: calling only once
16:58:30,256 INFO  [org.radargun.Slave] (sc-main) Starting stage BasicOperationsTest
16:58:30,257 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using key generator org.radargun.stages.cache.generators.StringKeyGenerator {format=null }
16:58:30,257 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using value generator org.radargun.stages.cache.generators.ByteArrayValueGenerator { }
16:58:30,257 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using cache selector Default { }
16:58:30,258 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Starting test warmup
16:58:30,285 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Started 4 stressor threads.
16:59:30,291 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Finished test. Test duration is: 1 mins 0 secs
16:59:30,293 INFO  [org.radargun.Slave] (sc-main) Finished stage BasicOperationsTest
16:59:30,301 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
16:59:30,340 INFO  [org.radargun.Slave] (sc-main) Starting stage Clear
16:59:30,343 INFO  [org.radargun.stages.cache.ClearStage] (sc-main) Before executing clear, memory looks like this: 
Runtime free: 952,645 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,328 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,696 kb
MX Metaspace(Non-heap memory): used: 44,020 kb, init: 0 kb, committed: 45,340 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 12,963 kb, init: 2,496 kb, committed: 12,992 kb, max: 120,032 kb
MX Compressed Class Space(Non-heap memory): used: 4,976 kb, init: 0 kb, committed: 5,484 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 246,784 kb, init: 73,728 kb, committed: 822,272 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 139,962 kb, init: 1,325,056 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 58,368 kb, init: 0 kb, committed: 58,368 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 5,291 kb, init: 2,496 kb, committed: 5,312 kb, max: 120,032 kb
16:59:30,476 INFO  [org.radargun.stages.cache.ClearStage] (sc-main) After executing clear, memory looks like this: 
Runtime free: 1,381,569 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,328 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,696 kb
MX Metaspace(Non-heap memory): used: 43,942 kb, init: 0 kb, committed: 45,468 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 13,029 kb, init: 2,496 kb, committed: 13,056 kb, max: 120,032 kb
MX Compressed Class Space(Non-heap memory): used: 4,946 kb, init: 0 kb, committed: 5,612 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 0 kb, init: 73,728 kb, committed: 880,640 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 16,702 kb, init: 1,325,056 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 0 kb, init: 0 kb, committed: 0 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 5,305 kb, init: 2,496 kb, committed: 5,312 kb, max: 120,032 kb
16:59:30,476 INFO  [org.radargun.Slave] (sc-main) Finished stage Clear
16:59:30,477 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
16:59:30,522 INFO  [org.radargun.Slave] (sc-main) Starting stage Load
16:59:31,896 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) This node loaded 10000 entries (~10000000 bytes)
16:59:33,264 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) This node loaded 20000 entries (~20000000 bytes)
16:59:34,587 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) This node loaded 30000 entries (~30000000 bytes)
16:59:34,982 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) Finished loading entries
16:59:35,006 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) Finished loading entries
16:59:35,010 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) Finished loading entries
16:59:35,028 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) Finished loading entries
16:59:35,042 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) Finished loading entries
16:59:35,053 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) Finished loading entries
16:59:35,055 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) Finished loading entries
16:59:35,068 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) Finished loading entries
16:59:35,079 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) Finished loading entries
16:59:35,118 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) Finished loading entries
16:59:35,119 INFO  [org.radargun.Slave] (sc-main) Finished stage Load
16:59:35,119 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
16:59:35,364 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.stages.cache.test.BasicOperationsTestStage.init() overrides public void org.radargun.stages.test.TestStage.init() but both are declared with @Init annotation: calling only once
16:59:35,366 INFO  [org.radargun.Slave] (sc-main) Starting stage BasicOperationsTest
16:59:35,367 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using key generator org.radargun.stages.cache.generators.StringKeyGenerator {format=null }
16:59:35,369 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using value generator org.radargun.stages.cache.generators.ByteArrayValueGenerator { }
16:59:35,369 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using cache selector Default { }
16:59:35,372 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Starting test stress-test
16:59:35,429 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Started 4 stressor threads.
17:09:35,432 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Finished test. Test duration is: 10 mins 0 secs
17:09:35,433 INFO  [org.radargun.Slave] (sc-main) Finished stage BasicOperationsTest
17:09:35,556 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
17:09:35,812 INFO  [org.radargun.Slave] (sc-main) Starting stage MonitorStop
17:09:35,815 INFO  [org.radargun.Slave] (sc-main) Finished stage MonitorStop
17:09:35,815 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
17:09:35,840 INFO  [org.radargun.Slave] (sc-main) Starting stage ScenarioDestroy
17:09:35,841 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Scenario finished, destroying...
17:09:35,841 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Memory before cleanup: 
Runtime free: 724,156 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,330 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,696 kb
MX Metaspace(Non-heap memory): used: 44,642 kb, init: 0 kb, committed: 46,236 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 14,946 kb, init: 2,496 kb, committed: 14,976 kb, max: 120,032 kb
MX Compressed Class Space(Non-heap memory): used: 4,987 kb, init: 0 kb, committed: 5,612 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 343,040 kb, init: 73,728 kb, committed: 821,248 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 270,654 kb, init: 1,325,056 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 59,392 kb, init: 0 kb, committed: 59,392 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 6,311 kb, init: 2,496 kb, committed: 6,336 kb, max: 120,032 kb
17:09:35,842 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) Stopping service.
17:09:35,849 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t35) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-31026: 258+86, fedora-4717: 254+85]}, pendingCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-31026: 269+243, fedora-4717: 243+269]}, unionCH=null, actualMembers=[fedora-31026, fedora-4717], persistentUUIDs=[ed8d4875-f029-446c-b013-801fd0f3f85e, 24417ea3-e1c0-4f87-86ce-cf06c57ada41]}
17:09:35,850 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t35) [Context=testCache][Scope=fedora-31026]ISPN100002: Started rebalance with topology id 11
17:09:35,863 WARN  [org.infinispan.CLUSTER] (StopThread) [Context=testCache]ISPN000312: Lost data because of graceful leaver fedora-31026
17:09:35,889 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t35) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-31026: 129, fedora-4717: 127]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-31026: 130, fedora-4717: 126]}, unionCH=null, actualMembers=[fedora-31026, fedora-4717], persistentUUIDs=[ed8d4875-f029-446c-b013-801fd0f3f85e, 24417ea3-e1c0-4f87-86ce-cf06c57ada41]}
17:09:35,890 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t35) [Context=___protobuf_metadata][Scope=fedora-31026]ISPN100002: Started rebalance with topology id 11
17:09:35,891 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t12) [Context=___protobuf_metadata][Scope=fedora-31026]ISPN100003: Node fedora-31026 finished rebalance phase with topology id 11
17:09:35,902 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t35) [Context=___protobuf_metadata][Scope=fedora-4717]ISPN100003: Node fedora-4717 finished rebalance phase with topology id 11
17:09:35,904 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t28) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-31026: 128+51, fedora-4717: 128+49]}, pendingCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-31026: 130+126, fedora-4717: 126+130]}, unionCH=null, actualMembers=[fedora-31026, fedora-4717], persistentUUIDs=[ed8d4875-f029-446c-b013-801fd0f3f85e, 24417ea3-e1c0-4f87-86ce-cf06c57ada41]}
17:09:35,904 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t28) [Context=___counters][Scope=fedora-31026]ISPN100002: Started rebalance with topology id 11
17:09:35,904 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (remote-thread--p2-t35) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___protobuf_metadata, type=REBALANCE_PHASE_CONFIRM, sender=fedora-4717, joinInfo=null, topologyId=11, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-4717 for cache ___protobuf_metadata, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.invokeReplicableCommand(GlobalInboundInvocationHandler.java:169) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.runReplicableCommand(GlobalInboundInvocationHandler.java:150) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.lambda$handleReplicableCommand$1(GlobalInboundInvocationHandler.java:144) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.util.concurrent.BlockingTaskAwareExecutorServiceImpl$RunnableWrapper.run(BlockingTaskAwareExecutorServiceImpl.java:212) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
17:09:35,908 WARN  [org.infinispan.CLUSTER] (StopThread) [Context=___counters]ISPN000312: Lost data because of graceful leaver fedora-31026
17:09:35,915 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t22) [Context=testCache][Scope=fedora-31026]ISPN100003: Node fedora-31026 finished rebalance phase with topology id 11
17:09:35,911 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t35) [Context=___protobuf_metadata][Scope=fedora-4717]ISPN100003: Node fedora-4717 finished rebalance phase with topology id 12
17:09:35,916 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t33) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-31026: 129, fedora-4717: 127]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-31026: 130, fedora-4717: 126]}, unionCH=null, actualMembers=[fedora-31026, fedora-4717], persistentUUIDs=[ed8d4875-f029-446c-b013-801fd0f3f85e, 24417ea3-e1c0-4f87-86ce-cf06c57ada41]}
17:09:35,910 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t28) [Context=testCache][Scope=fedora-4717]ISPN100003: Node fedora-4717 finished rebalance phase with topology id 12
17:09:35,916 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (remote-thread--p2-t35) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___protobuf_metadata, type=REBALANCE_PHASE_CONFIRM, sender=fedora-4717, joinInfo=null, topologyId=12, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-4717 for cache ___protobuf_metadata, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.invokeReplicableCommand(GlobalInboundInvocationHandler.java:169) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.runReplicableCommand(GlobalInboundInvocationHandler.java:150) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.lambda$handleReplicableCommand$1(GlobalInboundInvocationHandler.java:144) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.util.concurrent.BlockingTaskAwareExecutorServiceImpl$RunnableWrapper.run(BlockingTaskAwareExecutorServiceImpl.java:212) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
17:09:35,916 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t33) [Context=org.infinispan.CONFIG][Scope=fedora-31026]ISPN100002: Started rebalance with topology id 11
17:09:35,917 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t2) [Context=org.infinispan.CONFIG][Scope=fedora-31026]ISPN100003: Node fedora-31026 finished rebalance phase with topology id 11
17:09:35,921 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t33) [Context=org.infinispan.CONFIG][Scope=fedora-4717]ISPN100003: Node fedora-4717 finished rebalance phase with topology id 11
17:09:35,922 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t33) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 11
17:09:35,923 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t4) [Context=org.infinispan.CONFIG][Scope=fedora-31026]ISPN100003: Node fedora-31026 finished rebalance phase with topology id 12
17:09:35,923 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t33) [Context=___counters][Scope=fedora-4717]ISPN100003: Node fedora-4717 finished rebalance phase with topology id 12
17:09:35,924 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t35) [Context=org.infinispan.CONFIG][Scope=fedora-4717]ISPN100003: Node fedora-4717 finished rebalance phase with topology id 12
17:09:35,923 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (remote-thread--p2-t33) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___counters, type=REBALANCE_PHASE_CONFIRM, sender=fedora-4717, joinInfo=null, topologyId=12, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-4717 for cache ___counters, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.invokeReplicableCommand(GlobalInboundInvocationHandler.java:169) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.runReplicableCommand(GlobalInboundInvocationHandler.java:150) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.lambda$handleReplicableCommand$1(GlobalInboundInvocationHandler.java:144) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.util.concurrent.BlockingTaskAwareExecutorServiceImpl$RunnableWrapper.run(BlockingTaskAwareExecutorServiceImpl.java:212) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
17:09:35,937 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t33) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=12, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-31026: 129, fedora-4717: 127]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-31026: 130, fedora-4717: 126]}, unionCH=null, actualMembers=[fedora-31026, fedora-4717], persistentUUIDs=[ed8d4875-f029-446c-b013-801fd0f3f85e, 24417ea3-e1c0-4f87-86ce-cf06c57ada41]}
17:09:35,938 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t33) [Context=___counter_configuration][Scope=fedora-31026]ISPN100002: Started rebalance with topology id 12
17:09:35,944 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t35) [Context=___counter_configuration][Scope=fedora-4717]ISPN100003: Node fedora-4717 finished rebalance phase with topology id 14
17:09:35,944 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (remote-thread--p2-t35) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___counter_configuration, type=REBALANCE_PHASE_CONFIRM, sender=fedora-4717, joinInfo=null, topologyId=14, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-4717 for cache ___counter_configuration, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.invokeReplicableCommand(GlobalInboundInvocationHandler.java:169) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.runReplicableCommand(GlobalInboundInvocationHandler.java:150) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.lambda$handleReplicableCommand$1(GlobalInboundInvocationHandler.java:144) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.util.concurrent.BlockingTaskAwareExecutorServiceImpl$RunnableWrapper.run(BlockingTaskAwareExecutorServiceImpl.java:212) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
17:09:35,944 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t33) [Context=org.infinispan.CONFIG][Scope=fedora-4717]ISPN100003: Node fedora-4717 finished rebalance phase with topology id 14
17:09:35,945 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (StopThread) ISPN000080: Disconnecting JGroups channel results
17:09:35,953 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (remote-thread--p2-t33) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=org.infinispan.CONFIG, type=REBALANCE_PHASE_CONFIRM, sender=fedora-4717, joinInfo=null, topologyId=14, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-4717 for cache org.infinispan.CONFIG, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.invokeReplicableCommand(GlobalInboundInvocationHandler.java:169) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.runReplicableCommand(GlobalInboundInvocationHandler.java:150) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.lambda$handleReplicableCommand$1(GlobalInboundInvocationHandler.java:144) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.util.concurrent.BlockingTaskAwareExecutorServiceImpl$RunnableWrapper.run(BlockingTaskAwareExecutorServiceImpl.java:212) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
17:09:35,978 INFO  [org.radargun.service.Infinispan90Lifecycle] (StopThread) Stopped, previous view is [fedora-31026, fedora-4043, fedora-4717]
17:09:35,979 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Service successfully stopped.
17:09:35,979 INFO  [org.radargun.Slave] (sc-main) Finished stage ScenarioDestroy
17:09:35,980 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
17:10:05,888 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.service.Infinispan80EmbeddedService.destroy() overrides public void org.radargun.service.Infinispan60EmbeddedService.destroy() but both are declared with @Destroy annotation: calling only once
17:10:05,892 INFO  [org.radargun.Slave] (main) Starting stage ScenarioCleanup
17:10:05,894 WARN  [org.radargun.stages.ScenarioCleanupStage] (main) Unfinished thread ForkJoinPool.commonPool-worker-3 (id=33, state=WAITING)
	at java.base@11.0.17-internal/jdk.internal.misc.Unsafe.park(Native Method)
	at java.base@11.0.17-internal/java.util.concurrent.locks.LockSupport.park(LockSupport.java:194)
	at java.base@11.0.17-internal/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1628)
	at java.base@11.0.17-internal/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
17:10:05,895 INFO  [org.radargun.stages.ScenarioCleanupStage] (main) Interrupting thread ForkJoinPool.commonPool-worker-3 (id=33, state=WAITING)
17:10:10,897 INFO  [org.radargun.stages.ScenarioCleanupStage] (main) Stopping thread ForkJoinPool.commonPool-worker-3 (id=33, state=WAITING)
17:10:10,899 INFO  [org.radargun.stages.ScenarioCleanupStage] (main) Is thread ForkJoinPool.commonPool-worker-3 (id=33, state=TERMINATED)) alive? false
17:10:10,998 INFO  [org.radargun.stages.ScenarioCleanupStage] (main) Memory after cleanup: 
Runtime free: 1,380,525 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,331 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,696 kb
MX Metaspace(Non-heap memory): used: 44,810 kb, init: 0 kb, committed: 46,236 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 15,128 kb, init: 2,496 kb, committed: 15,168 kb, max: 120,032 kb
MX Compressed Class Space(Non-heap memory): used: 5,008 kb, init: 0 kb, committed: 5,612 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 0 kb, init: 73,728 kb, committed: 880,640 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 17,746 kb, init: 1,325,056 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 0 kb, init: 0 kb, committed: 0 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 6,431 kb, init: 2,496 kb, committed: 6,464 kb, max: 120,032 kb
17:10:11,000 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
17:10:16,228 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
17:10:19,640 INFO  [org.radargun.Slave] (main) Master shutdown!
17:10:19,641 INFO  [org.radargun.ShutDownHook] (Thread-0) Slave process is being shutdown
