09:12:42,779 INFO  [org.radargun.RemoteMasterConnection] (main) Attempting to connect to master results:2103
09:12:42,785 INFO  [org.radargun.RemoteMasterConnection] (main) Successfully established connection with master at: results:2103
09:12:42,786 INFO  [org.radargun.Slave] (main) Received slave index 0
09:12:42,787 INFO  [org.radargun.Slave] (main) Received slave count 3
09:12:42,985 INFO  [org.radargun.ServiceHelper] (sc-main) ServiceContext properties: {}
09:12:43,134 INFO  [org.radargun.Slave] (sc-main) Eager Service Infinispan92EmbeddedService {batching=false, cache=testCache, channelRetrievalTimeout=2 mins 0 secs, enableDiagnostics=null, explicitLocking=false, file=/mnt/workspace/results/dist-sync.xml, internalsExpositionEnabled=false, jgroupsDumperEnabled=false, jgroupsDumperInterval=10.000 secs, keysPerThread=-1, mapReduceDistributedReducePhase=false, mapReduceUseIntermediateSharedCache=false, removedCaches=[  ], threadsPerNode=-1 } loaded.
09:12:44,746 INFO  [org.radargun.Slave] (sc-main) Starting stage ScenarioInit
09:12:44,772 INFO  [org.radargun.Slave] (sc-main) Finished stage ScenarioInit
09:12:44,781 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
09:12:44,786 INFO  [org.radargun.Slave] (sc-main) Starting stage BeforeServiceStart
09:12:44,786 INFO  [org.radargun.Slave] (sc-main) Finished stage BeforeServiceStart
09:12:44,788 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
09:12:44,805 INFO  [org.radargun.Slave] (sc-main) Starting stage ServiceStart
09:12:44,805 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Startup staggering, this is the slave with index 0, not sleeping
09:12:44,805 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 0
09:12:44,808 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) Infinispan version: Infinispan 'Gaina' 9.2.0.Final
09:12:44,818 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) JGroups version: JGroups 4.0.10.Final (Schiener Berg)
09:12:45,209 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (sc-main) ISPN000078: Starting JGroups channel results
09:12:45,287 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the send buffer of socket MulticastSocket was set to 1.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
09:12:45,287 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the receive buffer of socket MulticastSocket was set to 20.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
09:12:45,288 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the send buffer of socket MulticastSocket was set to 1.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
09:12:45,288 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the receive buffer of socket MulticastSocket was set to 25.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
09:12:50,342 INFO  [org.infinispan.CLUSTER] (sc-main) ISPN000094: Received new cluster view for channel results: [fedora-40478|0] (1) [fedora-40478]
09:12:50,483 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (sc-main) ISPN000079: Channel results local address is fedora-40478, physical addresses are [192.168.121.239:36417]
09:12:50,485 INFO  [org.infinispan.factories.GlobalComponentRegistry] (sc-main) ISPN000128: Infinispan version: Infinispan 'Gaina' 9.2.0.Final
09:12:50,873 INFO  [org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup] (sc-main) ISPN000107: Retrieving transaction manager Transaction: unknown
09:12:50,967 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) No RELAY2 protocol in XS service
09:12:50,967 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) No RELAY2 protocol in XS service
09:12:50,969 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) ([fedora-40478(local=true, coord=true)]) Number of members=1 is not the one expected: 3
09:12:51,279 INFO  [org.infinispan.CLUSTER] (jgroups-6,fedora-40478) ISPN000094: Received new cluster view for channel results: [fedora-40478|1] (2) [fedora-40478, fedora-6342]
09:12:51,286 INFO  [org.infinispan.CLUSTER] (jgroups-6,fedora-40478) ISPN100000: Node fedora-6342 joined the cluster
09:12:51,602 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-40478: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-40478: 132, fedora-6342: 124]}, unionCH=null, actualMembers=[fedora-40478, fedora-6342], persistentUUIDs=[fa8f8f83-9431-49dc-b6b4-0dde42727f1b, 3819d3b4-6328-4fb1-9680-e2afb018268f]}
09:12:51,604 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-40478]ISPN100002: Started rebalance with topology id 2
09:12:51,622 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-40478: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-40478: 132, fedora-6342: 124]}, unionCH=null, actualMembers=[fedora-40478, fedora-6342], persistentUUIDs=[fa8f8f83-9431-49dc-b6b4-0dde42727f1b, 3819d3b4-6328-4fb1-9680-e2afb018268f]}
09:12:51,624 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-40478]ISPN100002: Started rebalance with topology id 2
09:12:51,626 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=___counter_configuration][Scope=fedora-40478]ISPN100003: Node fedora-40478 finished rebalance phase with topology id 2
09:12:51,644 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t23) [Context=org.infinispan.CONFIG][Scope=fedora-40478]ISPN100003: Node fedora-40478 finished rebalance phase with topology id 2
09:12:51,713 INFO  [org.infinispan.CLUSTER] (jgroups-6,fedora-40478) ISPN000094: Received new cluster view for channel results: [fedora-40478|2] (3) [fedora-40478, fedora-6342, fedora-26640]
09:12:51,714 INFO  [org.infinispan.CLUSTER] (jgroups-6,fedora-40478) ISPN100000: Node fedora-26640 joined the cluster
09:12:51,748 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-6342]ISPN100003: Node fedora-6342 finished rebalance phase with topology id 2
09:12:51,749 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 2
09:12:51,753 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t2) [Context=___counter_configuration][Scope=fedora-40478]ISPN100003: Node fedora-40478 finished rebalance phase with topology id 3
09:12:51,773 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-6342]ISPN100003: Node fedora-6342 finished rebalance phase with topology id 3
09:12:51,775 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-6342]ISPN100003: Node fedora-6342 finished rebalance phase with topology id 2
09:12:51,776 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 2
09:12:51,775 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t5) [Context=___counter_configuration][Scope=fedora-40478]ISPN100003: Node fedora-40478 finished rebalance phase with topology id 4
09:12:51,777 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t8) [Context=org.infinispan.CONFIG][Scope=fedora-40478]ISPN100003: Node fedora-40478 finished rebalance phase with topology id 3
09:12:51,787 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-6342]ISPN100003: Node fedora-6342 finished rebalance phase with topology id 4
09:12:51,787 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-6342]ISPN100003: Node fedora-6342 finished rebalance phase with topology id 3
09:12:51,790 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t12) [Context=org.infinispan.CONFIG][Scope=fedora-40478]ISPN100003: Node fedora-40478 finished rebalance phase with topology id 4
09:12:51,796 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-6342]ISPN100003: Node fedora-6342 finished rebalance phase with topology id 4
09:12:51,827 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=DefaultConsistentHash{ns=256, owners = (1)[fedora-40478: 256+0]}, pendingCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-40478: 132+124, fedora-6342: 124+132]}, unionCH=null, actualMembers=[fedora-40478, fedora-6342], persistentUUIDs=[fa8f8f83-9431-49dc-b6b4-0dde42727f1b, 3819d3b4-6328-4fb1-9680-e2afb018268f]}
09:12:51,827 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-40478]ISPN100002: Started rebalance with topology id 2
09:12:51,831 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=___counters][Scope=fedora-40478]ISPN100003: Node fedora-40478 finished rebalance phase with topology id 2
09:12:51,876 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-6342]ISPN100003: Node fedora-6342 finished rebalance phase with topology id 2
09:12:51,876 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache ___counters, topology id = 2
09:12:51,878 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t3) [Context=___counters][Scope=fedora-40478]ISPN100003: Node fedora-40478 finished rebalance phase with topology id 3
09:12:51,880 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-6342]ISPN100003: Node fedora-6342 finished rebalance phase with topology id 3
09:12:51,883 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-6342]ISPN100003: Node fedora-6342 finished rebalance phase with topology id 4
09:12:51,883 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t25) [Context=___counters][Scope=fedora-40478]ISPN100003: Node fedora-40478 finished rebalance phase with topology id 4
09:12:51,914 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-40478: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-40478: 132, fedora-6342: 124]}, unionCH=null, actualMembers=[fedora-40478, fedora-6342], persistentUUIDs=[fa8f8f83-9431-49dc-b6b4-0dde42727f1b, 3819d3b4-6328-4fb1-9680-e2afb018268f]}
09:12:51,915 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-40478]ISPN100002: Started rebalance with topology id 2
09:12:51,919 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t11) [Context=___protobuf_metadata][Scope=fedora-40478]ISPN100003: Node fedora-40478 finished rebalance phase with topology id 2
09:12:51,961 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-6342]ISPN100003: Node fedora-6342 finished rebalance phase with topology id 2
09:12:51,963 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 2
09:12:51,966 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t14) [Context=___protobuf_metadata][Scope=fedora-40478]ISPN100003: Node fedora-40478 finished rebalance phase with topology id 3
09:12:51,969 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) Number of members is the one expected: 3
09:12:51,970 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Successfully started cache service infinispan92/embedded on slave 0
09:12:51,973 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-6342]ISPN100003: Node fedora-6342 finished rebalance phase with topology id 3
09:12:51,975 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=DefaultConsistentHash{ns=512, owners = (1)[fedora-40478: 512+0]}, pendingCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-40478: 252+260, fedora-6342: 260+252]}, unionCH=null, actualMembers=[fedora-40478, fedora-6342], persistentUUIDs=[fa8f8f83-9431-49dc-b6b4-0dde42727f1b, 3819d3b4-6328-4fb1-9680-e2afb018268f]}
09:12:51,976 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-6342]ISPN100003: Node fedora-6342 finished rebalance phase with topology id 4
09:12:51,977 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-40478]ISPN100002: Started rebalance with topology id 2
09:12:51,976 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t19) [Context=___protobuf_metadata][Scope=fedora-40478]ISPN100003: Node fedora-40478 finished rebalance phase with topology id 4
09:12:51,979 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t24) [Context=testCache][Scope=fedora-40478]ISPN100003: Node fedora-40478 finished rebalance phase with topology id 2
09:12:52,006 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-6342]ISPN100003: Node fedora-6342 finished rebalance phase with topology id 2
09:12:52,006 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache testCache, topology id = 2
09:12:52,008 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t2) [Context=testCache][Scope=fedora-40478]ISPN100003: Node fedora-40478 finished rebalance phase with topology id 3
09:12:52,012 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-6342]ISPN100003: Node fedora-6342 finished rebalance phase with topology id 3
09:12:52,017 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=testCache][Scope=fedora-40478]ISPN100003: Node fedora-40478 finished rebalance phase with topology id 4
09:12:52,018 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-6342]ISPN100003: Node fedora-6342 finished rebalance phase with topology id 4
09:12:52,133 ERROR [org.radargun.service.ConfigDumpHelper] (sc-main) Error while dumping ___protobuf_metadata cache config as properties
javax.management.AttributeNotFoundException: Unknown attribute 'configurationAsProperties'. Known attributes names are: [rebalancingEnabled, cacheStatus, cacheName, cacheAvailability, version, configurationAsProperties]
	at org.infinispan.jmx.ResourceDMBean.getAttribute(ResourceDMBean.java:181) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:636) ~[?:?]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:679) ~[?:?]
	at org.radargun.service.ConfigDumpHelper60.dumpCache(ConfigDumpHelper60.java:44) [plugin-infinispan60-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.service.EmbeddedConfigurationProvider.getNormalizedConfigs(EmbeddedConfigurationProvider.java:33) [plugin-infinispan52-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.stages.lifecycle.ServiceStartStage.executeOnSlave(ServiceStartStage.java:92) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase.scenarioLoop(SlaveBase.java:102) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase$ScenarioRunner.run(SlaveBase.java:203) [radargun-core-3.0.0-SNAPSHOT.jar:?]
09:12:52,144 ERROR [org.radargun.service.ConfigDumpHelper] (sc-main) Error while dumping ___protobuf_metadata cache config as properties
javax.management.AttributeNotFoundException: Unknown attribute 'configurationAsProperties'. Known attributes names are: [rebalancingEnabled, cacheStatus, cacheName, cacheAvailability, version, configurationAsProperties]
	at org.infinispan.jmx.ResourceDMBean.getAttribute(ResourceDMBean.java:181) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:636) ~[?:?]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:679) ~[?:?]
	at org.radargun.service.ConfigDumpHelper60.dumpCache(ConfigDumpHelper60.java:44) [plugin-infinispan60-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.service.EmbeddedConfigurationProvider.getNormalizedConfigs(EmbeddedConfigurationProvider.java:33) [plugin-infinispan52-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.stages.lifecycle.ServiceStartStage.executeOnSlave(ServiceStartStage.java:92) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase.scenarioLoop(SlaveBase.java:102) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase$ScenarioRunner.run(SlaveBase.java:203) [radargun-core-3.0.0-SNAPSHOT.jar:?]
09:12:52,202 INFO  [org.radargun.Slave] (sc-main) Finished stage ServiceStart
09:12:52,210 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
09:12:52,248 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-40478: 132, fedora-6342: 124]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-40478: 89, fedora-6342: 87, fedora-26640: 80]}, unionCH=null, actualMembers=[fedora-40478, fedora-6342, fedora-26640], persistentUUIDs=[fa8f8f83-9431-49dc-b6b4-0dde42727f1b, 3819d3b4-6328-4fb1-9680-e2afb018268f, 6b4e9071-c55f-4107-a99b-9739dde5f57e]}
09:12:52,248 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-40478: 132, fedora-6342: 124]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-40478: 89, fedora-6342: 87, fedora-26640: 80]}, unionCH=null, actualMembers=[fedora-40478, fedora-6342, fedora-26640], persistentUUIDs=[fa8f8f83-9431-49dc-b6b4-0dde42727f1b, 3819d3b4-6328-4fb1-9680-e2afb018268f, 6b4e9071-c55f-4107-a99b-9739dde5f57e]}
09:12:52,248 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-40478]ISPN100002: Started rebalance with topology id 6
09:12:52,248 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-40478]ISPN100002: Started rebalance with topology id 6
09:12:52,250 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t11) [Context=org.infinispan.CONFIG][Scope=fedora-40478]ISPN100003: Node fedora-40478 finished rebalance phase with topology id 6
09:12:52,250 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t13) [Context=___counter_configuration][Scope=fedora-40478]ISPN100003: Node fedora-40478 finished rebalance phase with topology id 6
09:12:52,255 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-6342]ISPN100003: Node fedora-6342 finished rebalance phase with topology id 6
09:12:52,255 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-6342]ISPN100003: Node fedora-6342 finished rebalance phase with topology id 6
09:12:52,321 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-26640]ISPN100003: Node fedora-26640 finished rebalance phase with topology id 6
09:12:52,322 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 6
09:12:52,323 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t19) [Context=___counter_configuration][Scope=fedora-40478]ISPN100003: Node fedora-40478 finished rebalance phase with topology id 7
09:12:52,325 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-6342]ISPN100003: Node fedora-6342 finished rebalance phase with topology id 7
09:12:52,329 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-26640]ISPN100003: Node fedora-26640 finished rebalance phase with topology id 7
09:12:52,330 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=___counter_configuration][Scope=fedora-40478]ISPN100003: Node fedora-40478 finished rebalance phase with topology id 8
09:12:52,332 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-6342]ISPN100003: Node fedora-6342 finished rebalance phase with topology id 8
09:12:52,334 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-26640]ISPN100003: Node fedora-26640 finished rebalance phase with topology id 8
09:12:52,364 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-40478: 132+124, fedora-6342: 124+132]}, pendingCH=DefaultConsistentHash{ns=256, owners = (3)[fedora-40478: 89+94, fedora-6342: 87+85, fedora-26640: 80+77]}, unionCH=null, actualMembers=[fedora-40478, fedora-6342, fedora-26640], persistentUUIDs=[fa8f8f83-9431-49dc-b6b4-0dde42727f1b, 3819d3b4-6328-4fb1-9680-e2afb018268f, 6b4e9071-c55f-4107-a99b-9739dde5f57e]}
09:12:52,365 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-40478]ISPN100002: Started rebalance with topology id 6
09:12:52,366 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t2) [Context=___counters][Scope=fedora-40478]ISPN100003: Node fedora-40478 finished rebalance phase with topology id 6
09:12:52,371 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-6342]ISPN100003: Node fedora-6342 finished rebalance phase with topology id 6
09:12:52,384 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-26640]ISPN100003: Node fedora-26640 finished rebalance phase with topology id 6
09:12:52,384 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache ___counters, topology id = 6
09:12:52,386 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t8) [Context=___counters][Scope=fedora-40478]ISPN100003: Node fedora-40478 finished rebalance phase with topology id 7
09:12:52,388 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-6342]ISPN100003: Node fedora-6342 finished rebalance phase with topology id 7
09:12:52,389 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-26640]ISPN100003: Node fedora-26640 finished rebalance phase with topology id 7
09:12:52,390 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t1) [Context=___counters][Scope=fedora-40478]ISPN100003: Node fedora-40478 finished rebalance phase with topology id 8
09:12:52,392 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-6342]ISPN100003: Node fedora-6342 finished rebalance phase with topology id 8
09:12:52,395 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-26640]ISPN100003: Node fedora-26640 finished rebalance phase with topology id 8
09:12:52,449 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-40478: 132, fedora-6342: 124]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-40478: 89, fedora-6342: 87, fedora-26640: 80]}, unionCH=null, actualMembers=[fedora-40478, fedora-6342, fedora-26640], persistentUUIDs=[fa8f8f83-9431-49dc-b6b4-0dde42727f1b, 3819d3b4-6328-4fb1-9680-e2afb018268f, 6b4e9071-c55f-4107-a99b-9739dde5f57e]}
09:12:52,449 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-40478]ISPN100002: Started rebalance with topology id 6
09:12:52,451 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t17) [Context=___protobuf_metadata][Scope=fedora-40478]ISPN100003: Node fedora-40478 finished rebalance phase with topology id 6
09:12:52,457 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-6342]ISPN100003: Node fedora-6342 finished rebalance phase with topology id 6
09:12:52,473 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-26640]ISPN100003: Node fedora-26640 finished rebalance phase with topology id 6
09:12:52,474 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 6
09:12:52,476 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t24) [Context=___protobuf_metadata][Scope=fedora-40478]ISPN100003: Node fedora-40478 finished rebalance phase with topology id 7
09:12:52,478 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-6342]ISPN100003: Node fedora-6342 finished rebalance phase with topology id 7
09:12:52,479 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-26640]ISPN100003: Node fedora-26640 finished rebalance phase with topology id 7
09:12:52,485 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-40478: 252+260, fedora-6342: 260+252]}, pendingCH=DefaultConsistentHash{ns=512, owners = (3)[fedora-40478: 178+198, fedora-6342: 173+157, fedora-26640: 161+157]}, unionCH=null, actualMembers=[fedora-40478, fedora-6342, fedora-26640], persistentUUIDs=[fa8f8f83-9431-49dc-b6b4-0dde42727f1b, 3819d3b4-6328-4fb1-9680-e2afb018268f, 6b4e9071-c55f-4107-a99b-9739dde5f57e]}
09:12:52,485 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-26640]ISPN100003: Node fedora-26640 finished rebalance phase with topology id 8
09:12:52,485 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-40478]ISPN100002: Started rebalance with topology id 6
09:12:52,487 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-6342]ISPN100003: Node fedora-6342 finished rebalance phase with topology id 8
09:12:52,488 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t6) [Context=___protobuf_metadata][Scope=fedora-40478]ISPN100003: Node fedora-40478 finished rebalance phase with topology id 8
09:12:52,495 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t3) [Context=testCache][Scope=fedora-40478]ISPN100003: Node fedora-40478 finished rebalance phase with topology id 6
09:12:52,496 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-6342]ISPN100003: Node fedora-6342 finished rebalance phase with topology id 6
09:12:52,496 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-26640]ISPN100003: Node fedora-26640 finished rebalance phase with topology id 6
09:12:52,497 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 6
09:12:52,498 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t8) [Context=org.infinispan.CONFIG][Scope=fedora-40478]ISPN100003: Node fedora-40478 finished rebalance phase with topology id 7
09:12:52,499 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-6342]ISPN100003: Node fedora-6342 finished rebalance phase with topology id 7
09:12:52,517 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-26640]ISPN100003: Node fedora-26640 finished rebalance phase with topology id 7
09:12:52,518 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-26640]ISPN100003: Node fedora-26640 finished rebalance phase with topology id 6
09:12:52,518 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache testCache, topology id = 6
09:12:52,519 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t11) [Context=org.infinispan.CONFIG][Scope=fedora-40478]ISPN100003: Node fedora-40478 finished rebalance phase with topology id 8
09:12:52,521 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-6342]ISPN100003: Node fedora-6342 finished rebalance phase with topology id 8
09:12:52,522 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t14) [Context=testCache][Scope=fedora-40478]ISPN100003: Node fedora-40478 finished rebalance phase with topology id 7
09:12:52,523 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-6342]ISPN100003: Node fedora-6342 finished rebalance phase with topology id 7
09:12:52,525 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-26640]ISPN100003: Node fedora-26640 finished rebalance phase with topology id 7
09:12:52,525 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-26640]ISPN100003: Node fedora-26640 finished rebalance phase with topology id 8
09:12:52,528 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t13) [Context=testCache][Scope=fedora-40478]ISPN100003: Node fedora-40478 finished rebalance phase with topology id 8
09:12:52,530 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-6342]ISPN100003: Node fedora-6342 finished rebalance phase with topology id 8
09:12:52,532 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-26640]ISPN100003: Node fedora-26640 finished rebalance phase with topology id 8
09:12:52,661 INFO  [org.radargun.Slave] (sc-main) Starting stage AfterServiceStart
09:12:52,661 INFO  [org.radargun.Slave] (sc-main) Finished stage AfterServiceStart
09:12:52,664 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
09:12:52,776 INFO  [org.radargun.Slave] (sc-main) Starting stage MonitorStart
09:12:52,781 INFO  [org.radargun.sysmonitor.AbstractMonitors] (sc-main) Gathering statistics every 1000 ms
09:12:52,781 INFO  [org.radargun.Slave] (sc-main) Finished stage MonitorStart
09:12:52,782 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
09:12:52,813 INFO  [org.radargun.Slave] (sc-main) Starting stage Load
09:12:57,996 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) This node loaded 10000 entries (~10000000 bytes)
09:13:00,954 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) This node loaded 20000 entries (~20000000 bytes)
09:13:03,799 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) This node loaded 30000 entries (~30000000 bytes)
09:13:04,330 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) Finished loading entries
09:13:04,337 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) Finished loading entries
09:13:04,380 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) Finished loading entries
09:13:04,394 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) Finished loading entries
09:13:04,399 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) Finished loading entries
09:13:04,409 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) Finished loading entries
09:13:04,425 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) Finished loading entries
09:13:04,440 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) Finished loading entries
09:13:04,440 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) Finished loading entries
09:13:04,455 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) Finished loading entries
09:13:04,456 INFO  [org.radargun.Slave] (sc-main) Finished stage Load
09:13:04,457 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
09:13:04,725 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.stages.cache.test.BasicOperationsTestStage.init() overrides public void org.radargun.stages.test.TestStage.init() but both are declared with @Init annotation: calling only once
09:13:04,729 INFO  [org.radargun.Slave] (sc-main) Starting stage BasicOperationsTest
09:13:04,729 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using key generator org.radargun.stages.cache.generators.StringKeyGenerator {format=null }
09:13:04,729 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using value generator org.radargun.stages.cache.generators.ByteArrayValueGenerator { }
09:13:04,729 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using cache selector Default { }
09:13:04,730 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Starting test warmup
09:13:04,735 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Started 4 stressor threads.
09:14:04,737 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Finished test. Test duration is: 1 mins 0 secs
09:14:04,739 INFO  [org.radargun.Slave] (sc-main) Finished stage BasicOperationsTest
09:14:04,760 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
09:14:04,793 INFO  [org.radargun.Slave] (sc-main) Starting stage Clear
09:14:04,798 INFO  [org.radargun.stages.cache.ClearStage] (sc-main) Before executing clear, memory looks like this: 
Runtime free: 1,060,730 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,598 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,700 kb
MX Metaspace(Non-heap memory): used: 35,995 kb, init: 0 kb, committed: 36,544 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 11,809 kb, init: 2,496 kb, committed: 11,840 kb, max: 120,028 kb
MX Compressed Class Space(Non-heap memory): used: 4,211 kb, init: 0 kb, committed: 4,480 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 100,352 kb, init: 69,632 kb, committed: 818,176 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 174,612 kb, init: 1,329,152 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 62,464 kb, init: 0 kb, committed: 62,464 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 6,535 kb, init: 2,496 kb, committed: 6,592 kb, max: 120,032 kb
09:14:04,926 INFO  [org.radargun.stages.cache.ClearStage] (sc-main) After executing clear, memory looks like this: 
Runtime free: 1,380,179 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,619 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,700 kb
MX Metaspace(Non-heap memory): used: 35,995 kb, init: 0 kb, committed: 36,608 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 11,671 kb, init: 2,496 kb, committed: 11,904 kb, max: 120,028 kb
MX Compressed Class Space(Non-heap memory): used: 4,207 kb, init: 0 kb, committed: 4,480 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 0 kb, init: 69,632 kb, committed: 880,640 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 18,092 kb, init: 1,329,152 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 0 kb, init: 0 kb, committed: 0 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 6,489 kb, init: 2,496 kb, committed: 6,592 kb, max: 120,032 kb
09:14:04,927 INFO  [org.radargun.Slave] (sc-main) Finished stage Clear
09:14:04,928 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
09:14:04,974 INFO  [org.radargun.Slave] (sc-main) Starting stage Load
09:14:06,332 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) This node loaded 10000 entries (~10000000 bytes)
09:14:07,659 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) This node loaded 20000 entries (~20000000 bytes)
09:14:08,987 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) This node loaded 30000 entries (~30000000 bytes)
09:14:09,302 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) Finished loading entries
09:14:09,345 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) Finished loading entries
09:14:09,377 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) Finished loading entries
09:14:09,384 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) Finished loading entries
09:14:09,388 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) Finished loading entries
09:14:09,392 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) Finished loading entries
09:14:09,407 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) Finished loading entries
09:14:09,427 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) Finished loading entries
09:14:09,440 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) Finished loading entries
09:14:09,478 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) Finished loading entries
09:14:09,478 INFO  [org.radargun.Slave] (sc-main) Finished stage Load
09:14:09,479 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
09:14:09,734 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.stages.cache.test.BasicOperationsTestStage.init() overrides public void org.radargun.stages.test.TestStage.init() but both are declared with @Init annotation: calling only once
09:14:09,735 INFO  [org.radargun.Slave] (sc-main) Starting stage BasicOperationsTest
09:14:09,739 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using key generator org.radargun.stages.cache.generators.StringKeyGenerator {format=null }
09:14:09,739 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using value generator org.radargun.stages.cache.generators.ByteArrayValueGenerator { }
09:14:09,739 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using cache selector Default { }
09:14:09,740 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Starting test stress-test
09:14:09,765 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Started 4 stressor threads.
09:24:09,766 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Finished test. Test duration is: 10 mins 0 secs
09:24:09,768 INFO  [org.radargun.Slave] (sc-main) Finished stage BasicOperationsTest
09:24:09,841 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
09:24:10,203 INFO  [org.radargun.Slave] (sc-main) Starting stage MonitorStop
09:24:10,204 INFO  [org.radargun.Slave] (sc-main) Finished stage MonitorStop
09:24:10,206 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
09:24:10,211 INFO  [org.radargun.Slave] (sc-main) Starting stage ScenarioDestroy
09:24:10,212 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Scenario finished, destroying...
09:24:10,213 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Memory before cleanup: 
Runtime free: 352,116 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,601 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,700 kb
MX Metaspace(Non-heap memory): used: 36,687 kb, init: 0 kb, committed: 37,248 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 9,794 kb, init: 2,496 kb, committed: 13,376 kb, max: 120,028 kb
MX Compressed Class Space(Non-heap memory): used: 4,242 kb, init: 0 kb, committed: 4,480 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 710,656 kb, init: 69,632 kb, committed: 818,176 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 273,033 kb, init: 1,329,152 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 62,464 kb, init: 0 kb, committed: 62,464 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 5,874 kb, init: 2,496 kb, committed: 7,552 kb, max: 120,032 kb
09:24:10,214 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) Stopping service.
09:24:10,220 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t45) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-40478: 290+86, fedora-26640: 222+96]}, pendingCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-40478: 263+249, fedora-26640: 249+263]}, unionCH=null, actualMembers=[fedora-40478, fedora-26640], persistentUUIDs=[fa8f8f83-9431-49dc-b6b4-0dde42727f1b, 6b4e9071-c55f-4107-a99b-9739dde5f57e]}
09:24:10,221 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t45) [Context=testCache][Scope=fedora-40478]ISPN100002: Started rebalance with topology id 11
09:24:10,223 WARN  [org.infinispan.CLUSTER] (remote-thread--p2-t42) [Context=testCache]ISPN000312: Lost data because of graceful leaver fedora-26640
09:24:10,272 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t42) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-40478: 141+42, fedora-26640: 115+42]}, pendingCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-40478: 134+122, fedora-26640: 122+134]}, unionCH=null, actualMembers=[fedora-40478, fedora-26640], persistentUUIDs=[fa8f8f83-9431-49dc-b6b4-0dde42727f1b, 6b4e9071-c55f-4107-a99b-9739dde5f57e]}
09:24:10,272 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t42) [Context=___counters][Scope=fedora-40478]ISPN100002: Started rebalance with topology id 11
09:24:10,297 WARN  [org.infinispan.statetransfer.InboundTransferTask] (stateTransferExecutor-thread--p6-t2) ISPN000210: Failed to request state of cache testCache from node fedora-26640, segments {0 19 22-23 36 39 49 73-75 81 84 89 92-95 98-100 105-108 111-115 131-132 136-138 143 150 153-154 157-159 170-172 182 187 194-197 200 207-208 214 219-222 240-243 246 256-258 265 273 278-279 293-294 302-304 315-316 322-327 332-335 338-340 353-354 361-363 369-370 378-380 392-397 409-411 414-417 428 431-434 447-448 457-459 472-473 476 483-485 488-489 498 507-508 510-511}
org.infinispan.remoting.transport.jgroups.SuspectException: ISPN000400: Node fedora-26640 was suspected
	at org.infinispan.remoting.transport.ResponseCollectors.remoteNodeSuspected(ResponseCollectors.java:33) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleResponseCollector.targetNotFound(SingleResponseCollector.java:31) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleResponseCollector.targetNotFound(SingleResponseCollector.java:17) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.ValidSingleResponseCollector.addResponse(ValidSingleResponseCollector.java:23) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleTargetRequest.receiveResponse(SingleTargetRequest.java:51) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleTargetRequest.onResponse(SingleTargetRequest.java:35) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.RequestRepository.addResponse(RequestRepository.java:53) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.processResponse(JGroupsTransport.java:1302) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.processMessage(JGroupsTransport.java:1205) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.access$200(JGroupsTransport.java:123) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport$ChannelCallbacks.receive(JGroupsTransport.java:1340) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.jgroups.JChannel.up(JChannel.java:819) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.stack.ProtocolStack.up(ProtocolStack.java:893) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FRAG3.up(FRAG3.java:171) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FlowControl.up(FlowControl.java:343) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FlowControl.up(FlowControl.java:343) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.GMS.up(GMS.java:864) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.STABLE.up(STABLE.java:240) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.deliverMessage(UNICAST3.java:1002) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.handleDataReceived(UNICAST3.java:728) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.up(UNICAST3.java:383) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.NAKACK2.up(NAKACK2.java:600) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.VERIFY_SUSPECT.up(VERIFY_SUSPECT.java:119) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FD_ALL.up(FD_ALL.java:199) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FD_SOCK.up(FD_SOCK.java:252) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.MERGE3.up(MERGE3.java:276) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.Discovery.up(Discovery.java:267) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.TP.passMessageUp(TP.java:1248) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.util.SubmitToThreadPool$SingleMessageHandler.run(SubmitToThreadPool.java:87) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
09:24:10,309 WARN  [org.infinispan.CLUSTER] (remote-thread--p2-t43) [Context=___counters]ISPN000312: Lost data because of graceful leaver fedora-26640
09:24:10,312 ERROR [org.infinispan.statetransfer.StateConsumerImpl] (transport-thread--p4-t17) ISPN000208: No live owners found for segments {8-9 11 16-26 37 41 49 53 56-61 66-69 91 107-111 120-122 128 133 139 142 145-147 161-168 177 184 189 196-197 201-204 207-209 216-217 229 247-248 254-255} of cache ___counters. Excluded owners: []
09:24:10,313 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t12) [Context=___counters][Scope=fedora-40478]ISPN100003: Node fedora-40478 finished rebalance phase with topology id 12
09:24:10,314 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (transport-thread--p4-t12) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___counters, type=REBALANCE_PHASE_CONFIRM, sender=fedora-40478, joinInfo=null, topologyId=12, rebalanceId=4, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-40478 for cache ___counters, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.commands.ReplicableCommand.invoke(ReplicableCommand.java:44) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.LocalTopologyManagerImpl.lambda$executeOnCoordinatorAsync$4(LocalTopologyManagerImpl.java:717) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
09:24:10,332 INFO  [org.infinispan.CLUSTER] (jgroups-38,fedora-40478) ISPN000094: Received new cluster view for channel results: [fedora-40478|3] (2) [fedora-40478, fedora-6342]
09:24:10,333 INFO  [org.infinispan.CLUSTER] (jgroups-38,fedora-40478) ISPN100001: Node fedora-26640 left the cluster
09:24:10,343 INFO  [org.infinispan.CLUSTER] (jgroups-38,fedora-40478) ISPN000094: Received new cluster view for channel results: [fedora-40478|4] (1) [fedora-40478]
09:24:10,344 INFO  [org.infinispan.CLUSTER] (jgroups-38,fedora-40478) ISPN100001: Node fedora-6342 left the cluster
09:24:10,367 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (StopThread) ISPN000080: Disconnecting JGroups channel results
09:24:10,397 INFO  [org.radargun.service.Infinispan90Lifecycle] (StopThread) Stopped, previous view is [fedora-40478, fedora-6342, fedora-26640]
09:24:10,398 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Service successfully stopped.
09:24:10,398 INFO  [org.radargun.Slave] (sc-main) Finished stage ScenarioDestroy
09:24:10,398 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
09:24:10,408 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.service.Infinispan80EmbeddedService.destroy() overrides public void org.radargun.service.Infinispan60EmbeddedService.destroy() but both are declared with @Destroy annotation: calling only once
09:24:10,410 INFO  [org.radargun.Slave] (main) Starting stage ScenarioCleanup
09:24:10,440 INFO  [org.radargun.stages.ScenarioCleanupStage] (main) Memory after cleanup: 
Runtime free: 1,379,199 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,603 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,700 kb
MX Metaspace(Non-heap memory): used: 36,826 kb, init: 0 kb, committed: 37,376 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 9,112 kb, init: 2,496 kb, committed: 13,376 kb, max: 120,028 kb
MX Compressed Class Space(Non-heap memory): used: 4,270 kb, init: 0 kb, committed: 4,544 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 0 kb, init: 69,632 kb, committed: 880,640 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 19,072 kb, init: 1,329,152 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 0 kb, init: 0 kb, committed: 0 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 5,767 kb, init: 2,496 kb, committed: 7,552 kb, max: 120,032 kb
09:24:10,442 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
09:24:15,522 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
09:24:18,609 INFO  [org.radargun.Slave] (main) Master shutdown!
09:24:18,611 INFO  [org.radargun.ShutDownHook] (Thread-0) Slave process is being shutdown
