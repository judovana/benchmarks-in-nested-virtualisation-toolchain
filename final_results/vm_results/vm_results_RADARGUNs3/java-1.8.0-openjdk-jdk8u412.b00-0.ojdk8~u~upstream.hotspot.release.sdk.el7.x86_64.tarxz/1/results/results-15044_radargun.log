14:54:45,830 INFO  [org.radargun.RemoteMasterConnection] (main) Attempting to connect to master results:2103
14:54:45,835 INFO  [org.radargun.RemoteMasterConnection] (main) Successfully established connection with master at: results:2103
14:54:45,836 INFO  [org.radargun.Slave] (main) Received slave index 0
14:54:45,836 INFO  [org.radargun.Slave] (main) Received slave count 3
14:54:45,983 INFO  [org.radargun.ServiceHelper] (sc-main) ServiceContext properties: {}
14:54:46,088 INFO  [org.radargun.Slave] (sc-main) Eager Service Infinispan92EmbeddedService {batching=false, cache=testCache, channelRetrievalTimeout=2 mins 0 secs, enableDiagnostics=null, explicitLocking=false, file=/mnt/workspace/results/dist-sync.xml, internalsExpositionEnabled=false, jgroupsDumperEnabled=false, jgroupsDumperInterval=10.000 secs, keysPerThread=-1, mapReduceDistributedReducePhase=false, mapReduceUseIntermediateSharedCache=false, removedCaches=[  ], threadsPerNode=-1 } loaded.
14:54:47,871 INFO  [org.radargun.Slave] (sc-main) Starting stage ScenarioInit
14:54:48,024 INFO  [org.radargun.Slave] (sc-main) Finished stage ScenarioInit
14:54:48,028 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
14:54:48,041 INFO  [org.radargun.Slave] (sc-main) Starting stage BeforeServiceStart
14:54:48,042 INFO  [org.radargun.Slave] (sc-main) Finished stage BeforeServiceStart
14:54:48,042 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
14:54:48,049 INFO  [org.radargun.Slave] (sc-main) Starting stage ServiceStart
14:54:48,049 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Startup staggering, this is the slave with index 0, not sleeping
14:54:48,053 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 0
14:54:48,055 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) Infinispan version: Infinispan 'Gaina' 9.2.0.Final
14:54:48,068 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) JGroups version: JGroups 4.0.10.Final (Schiener Berg)
14:54:48,576 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (sc-main) ISPN000078: Starting JGroups channel results
14:54:48,667 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the send buffer of socket MulticastSocket was set to 1.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
14:54:48,668 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the receive buffer of socket MulticastSocket was set to 20.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
14:54:48,668 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the send buffer of socket MulticastSocket was set to 1.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
14:54:48,669 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the receive buffer of socket MulticastSocket was set to 25.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
14:54:53,699 INFO  [org.infinispan.CLUSTER] (sc-main) ISPN000094: Received new cluster view for channel results: [fedora-37482|0] (1) [fedora-37482]
14:54:53,765 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (sc-main) ISPN000079: Channel results local address is fedora-37482, physical addresses are [192.168.121.15:50879]
14:54:53,768 INFO  [org.infinispan.factories.GlobalComponentRegistry] (sc-main) ISPN000128: Infinispan version: Infinispan 'Gaina' 9.2.0.Final
14:54:54,295 INFO  [org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup] (sc-main) ISPN000107: Retrieving transaction manager Transaction: unknown
14:54:54,356 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) No RELAY2 protocol in XS service
14:54:54,356 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) No RELAY2 protocol in XS service
14:54:54,358 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) ([fedora-37482(local=true, coord=true)]) Number of members=1 is not the one expected: 3
14:54:54,631 INFO  [org.infinispan.CLUSTER] (jgroups-6,fedora-37482) ISPN000094: Received new cluster view for channel results: [fedora-37482|1] (2) [fedora-37482, fedora-38253]
14:54:54,637 INFO  [org.infinispan.CLUSTER] (jgroups-6,fedora-37482) ISPN100000: Node fedora-38253 joined the cluster
14:54:54,967 INFO  [org.infinispan.CLUSTER] (jgroups-12,fedora-37482) ISPN000094: Received new cluster view for channel results: [fedora-37482|2] (3) [fedora-37482, fedora-38253, fedora-48305]
14:54:54,968 INFO  [org.infinispan.CLUSTER] (jgroups-12,fedora-37482) ISPN100000: Node fedora-48305 joined the cluster
14:54:55,260 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-37482: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-37482: 130, fedora-38253: 126]}, unionCH=null, actualMembers=[fedora-37482, fedora-38253], persistentUUIDs=[5f87ed87-1e5e-4dc3-8971-dde31a185f6b, 080d3f39-fc6a-47da-ab47-8f7de179c750]}
14:54:55,263 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-37482]ISPN100002: Started rebalance with topology id 2
14:54:55,263 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-37482: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-37482: 130, fedora-38253: 126]}, unionCH=null, actualMembers=[fedora-37482, fedora-38253], persistentUUIDs=[5f87ed87-1e5e-4dc3-8971-dde31a185f6b, 080d3f39-fc6a-47da-ab47-8f7de179c750]}
14:54:55,265 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-37482]ISPN100002: Started rebalance with topology id 2
14:54:55,305 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t23) [Context=org.infinispan.CONFIG][Scope=fedora-37482]ISPN100003: Node fedora-37482 finished rebalance phase with topology id 2
14:54:55,306 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t24) [Context=___counter_configuration][Scope=fedora-37482]ISPN100003: Node fedora-37482 finished rebalance phase with topology id 2
14:54:55,358 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) Number of members is the one expected: 3
14:54:55,359 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Successfully started cache service infinispan92/embedded on slave 0
14:54:55,392 ERROR [org.radargun.service.ConfigDumpHelper] (sc-main) Error while dumping ___protobuf_metadata cache config as properties
javax.management.AttributeNotFoundException: Unknown attribute 'configurationAsProperties'. Known attributes names are: [rebalancingEnabled, cacheStatus, cacheName, cacheAvailability, version, configurationAsProperties]
	at org.infinispan.jmx.ResourceDMBean.getAttribute(ResourceDMBean.java:181) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:647) ~[?:1.8.0_402-internal]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:678) ~[?:1.8.0_402-internal]
	at org.radargun.service.ConfigDumpHelper60.dumpCache(ConfigDumpHelper60.java:44) [plugin-infinispan60-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.service.EmbeddedConfigurationProvider.getNormalizedConfigs(EmbeddedConfigurationProvider.java:33) [plugin-infinispan52-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.stages.lifecycle.ServiceStartStage.executeOnSlave(ServiceStartStage.java:92) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase.scenarioLoop(SlaveBase.java:102) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase$ScenarioRunner.run(SlaveBase.java:203) [radargun-core-3.0.0-SNAPSHOT.jar:?]
14:54:55,400 ERROR [org.radargun.service.ConfigDumpHelper] (sc-main) Error while dumping ___protobuf_metadata cache config as properties
javax.management.AttributeNotFoundException: Unknown attribute 'configurationAsProperties'. Known attributes names are: [rebalancingEnabled, cacheStatus, cacheName, cacheAvailability, version, configurationAsProperties]
	at org.infinispan.jmx.ResourceDMBean.getAttribute(ResourceDMBean.java:181) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:647) ~[?:1.8.0_402-internal]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:678) ~[?:1.8.0_402-internal]
	at org.radargun.service.ConfigDumpHelper60.dumpCache(ConfigDumpHelper60.java:44) [plugin-infinispan60-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.service.EmbeddedConfigurationProvider.getNormalizedConfigs(EmbeddedConfigurationProvider.java:33) [plugin-infinispan52-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.stages.lifecycle.ServiceStartStage.executeOnSlave(ServiceStartStage.java:92) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase.scenarioLoop(SlaveBase.java:102) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase$ScenarioRunner.run(SlaveBase.java:203) [radargun-core-3.0.0-SNAPSHOT.jar:?]
14:54:55,418 INFO  [org.radargun.Slave] (sc-main) Finished stage ServiceStart
14:54:55,426 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
14:54:55,466 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-38253]ISPN100003: Node fedora-38253 finished rebalance phase with topology id 2
14:54:55,473 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 2
14:54:55,478 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t2) [Context=org.infinispan.CONFIG][Scope=fedora-37482]ISPN100003: Node fedora-37482 finished rebalance phase with topology id 3
14:54:55,488 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-38253]ISPN100003: Node fedora-38253 finished rebalance phase with topology id 3
14:54:55,489 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-38253]ISPN100003: Node fedora-38253 finished rebalance phase with topology id 2
14:54:55,490 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 2
14:54:55,491 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t5) [Context=org.infinispan.CONFIG][Scope=fedora-37482]ISPN100003: Node fedora-37482 finished rebalance phase with topology id 4
14:54:55,491 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t6) [Context=___counter_configuration][Scope=fedora-37482]ISPN100003: Node fedora-37482 finished rebalance phase with topology id 3
14:54:55,500 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-38253]ISPN100003: Node fedora-38253 finished rebalance phase with topology id 4
14:54:55,512 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-38253]ISPN100003: Node fedora-38253 finished rebalance phase with topology id 3
14:54:55,519 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t14) [Context=___counter_configuration][Scope=fedora-37482]ISPN100003: Node fedora-37482 finished rebalance phase with topology id 4
14:54:55,526 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-38253]ISPN100003: Node fedora-38253 finished rebalance phase with topology id 4
14:54:55,603 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=DefaultConsistentHash{ns=256, owners = (1)[fedora-37482: 256+0]}, pendingCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-37482: 130+126, fedora-38253: 126+130]}, unionCH=null, actualMembers=[fedora-37482, fedora-38253], persistentUUIDs=[5f87ed87-1e5e-4dc3-8971-dde31a185f6b, 080d3f39-fc6a-47da-ab47-8f7de179c750]}
14:54:55,603 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-37482]ISPN100002: Started rebalance with topology id 2
14:54:55,606 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=___counters][Scope=fedora-37482]ISPN100003: Node fedora-37482 finished rebalance phase with topology id 2
14:54:55,726 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-37482: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-37482: 130, fedora-38253: 126]}, unionCH=null, actualMembers=[fedora-37482, fedora-38253], persistentUUIDs=[5f87ed87-1e5e-4dc3-8971-dde31a185f6b, 080d3f39-fc6a-47da-ab47-8f7de179c750]}
14:54:55,727 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-37482]ISPN100002: Started rebalance with topology id 2
14:54:55,735 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t3) [Context=___protobuf_metadata][Scope=fedora-37482]ISPN100003: Node fedora-37482 finished rebalance phase with topology id 2
14:54:55,755 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-38253]ISPN100003: Node fedora-38253 finished rebalance phase with topology id 2
14:54:55,756 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___counters, topology id = 2
14:54:55,758 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t4) [Context=___counters][Scope=fedora-37482]ISPN100003: Node fedora-37482 finished rebalance phase with topology id 3
14:54:55,775 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-38253]ISPN100003: Node fedora-38253 finished rebalance phase with topology id 3
14:54:55,780 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t25) [Context=___counters][Scope=fedora-37482]ISPN100003: Node fedora-37482 finished rebalance phase with topology id 4
14:54:55,795 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-38253]ISPN100003: Node fedora-38253 finished rebalance phase with topology id 4
14:54:55,811 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-38253]ISPN100003: Node fedora-38253 finished rebalance phase with topology id 2
14:54:55,812 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 2
14:54:55,813 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t13) [Context=___protobuf_metadata][Scope=fedora-37482]ISPN100003: Node fedora-37482 finished rebalance phase with topology id 3
14:54:55,818 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-37482: 130, fedora-38253: 126]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-37482: 82, fedora-38253: 84, fedora-48305: 90]}, unionCH=null, actualMembers=[fedora-37482, fedora-38253, fedora-48305], persistentUUIDs=[5f87ed87-1e5e-4dc3-8971-dde31a185f6b, 080d3f39-fc6a-47da-ab47-8f7de179c750, 0506b52a-8bfc-474b-8e92-8e610130b04f]}
14:54:55,818 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-37482]ISPN100002: Started rebalance with topology id 6
14:54:55,820 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t16) [Context=org.infinispan.CONFIG][Scope=fedora-37482]ISPN100003: Node fedora-37482 finished rebalance phase with topology id 6
14:54:55,824 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-38253]ISPN100003: Node fedora-38253 finished rebalance phase with topology id 3
14:54:55,825 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t17) [Context=___protobuf_metadata][Scope=fedora-37482]ISPN100003: Node fedora-37482 finished rebalance phase with topology id 4
14:54:55,827 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-37482: 130, fedora-38253: 126]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-37482: 82, fedora-38253: 84, fedora-48305: 90]}, unionCH=null, actualMembers=[fedora-37482, fedora-38253, fedora-48305], persistentUUIDs=[5f87ed87-1e5e-4dc3-8971-dde31a185f6b, 080d3f39-fc6a-47da-ab47-8f7de179c750, 0506b52a-8bfc-474b-8e92-8e610130b04f]}
14:54:55,828 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-37482]ISPN100002: Started rebalance with topology id 6
14:54:55,829 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=___counter_configuration][Scope=fedora-37482]ISPN100003: Node fedora-37482 finished rebalance phase with topology id 6
14:54:55,834 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-38253]ISPN100003: Node fedora-38253 finished rebalance phase with topology id 4
14:54:55,844 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=DefaultConsistentHash{ns=512, owners = (1)[fedora-37482: 512+0]}, pendingCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-37482: 261+251, fedora-38253: 251+261]}, unionCH=null, actualMembers=[fedora-37482, fedora-38253], persistentUUIDs=[5f87ed87-1e5e-4dc3-8971-dde31a185f6b, 080d3f39-fc6a-47da-ab47-8f7de179c750]}
14:54:55,845 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-37482]ISPN100002: Started rebalance with topology id 2
14:54:55,852 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t24) [Context=testCache][Scope=fedora-37482]ISPN100003: Node fedora-37482 finished rebalance phase with topology id 2
14:54:55,853 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-38253]ISPN100003: Node fedora-38253 finished rebalance phase with topology id 6
14:54:55,855 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counter_configuration][Scope=fedora-38253]ISPN100003: Node fedora-38253 finished rebalance phase with topology id 6
14:54:55,874 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-38253]ISPN100003: Node fedora-38253 finished rebalance phase with topology id 2
14:54:55,875 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache testCache, topology id = 2
14:54:55,877 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t5) [Context=testCache][Scope=fedora-37482]ISPN100003: Node fedora-37482 finished rebalance phase with topology id 3
14:54:55,880 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-38253]ISPN100003: Node fedora-38253 finished rebalance phase with topology id 3
14:54:55,883 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t8) [Context=testCache][Scope=fedora-37482]ISPN100003: Node fedora-37482 finished rebalance phase with topology id 4
14:54:55,886 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-38253]ISPN100003: Node fedora-38253 finished rebalance phase with topology id 4
14:54:56,008 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=org.infinispan.CONFIG][Scope=fedora-48305]ISPN100003: Node fedora-48305 finished rebalance phase with topology id 6
14:54:56,008 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-48305]ISPN100003: Node fedora-48305 finished rebalance phase with topology id 6
14:54:56,008 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 6
14:54:56,008 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 6
14:54:56,009 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t18) [Context=org.infinispan.CONFIG][Scope=fedora-37482]ISPN100003: Node fedora-37482 finished rebalance phase with topology id 7
14:54:56,009 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t22) [Context=___counter_configuration][Scope=fedora-37482]ISPN100003: Node fedora-37482 finished rebalance phase with topology id 7
14:54:56,012 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counter_configuration][Scope=fedora-38253]ISPN100003: Node fedora-38253 finished rebalance phase with topology id 7
14:54:56,012 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-38253]ISPN100003: Node fedora-38253 finished rebalance phase with topology id 7
14:54:56,015 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=org.infinispan.CONFIG][Scope=fedora-48305]ISPN100003: Node fedora-48305 finished rebalance phase with topology id 7
14:54:56,015 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-48305]ISPN100003: Node fedora-48305 finished rebalance phase with topology id 7
14:54:56,016 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=org.infinispan.CONFIG][Scope=fedora-37482]ISPN100003: Node fedora-37482 finished rebalance phase with topology id 8
14:54:56,017 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t23) [Context=___counter_configuration][Scope=fedora-37482]ISPN100003: Node fedora-37482 finished rebalance phase with topology id 8
14:54:56,020 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=org.infinispan.CONFIG][Scope=fedora-38253]ISPN100003: Node fedora-38253 finished rebalance phase with topology id 8
14:54:56,020 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-38253]ISPN100003: Node fedora-38253 finished rebalance phase with topology id 8
14:54:56,022 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counter_configuration][Scope=fedora-48305]ISPN100003: Node fedora-48305 finished rebalance phase with topology id 8
14:54:56,022 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-48305]ISPN100003: Node fedora-48305 finished rebalance phase with topology id 8
14:54:56,057 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-37482: 130+126, fedora-38253: 126+130]}, pendingCH=DefaultConsistentHash{ns=256, owners = (3)[fedora-37482: 82+84, fedora-38253: 84+98, fedora-48305: 90+74]}, unionCH=null, actualMembers=[fedora-37482, fedora-38253, fedora-48305], persistentUUIDs=[5f87ed87-1e5e-4dc3-8971-dde31a185f6b, 080d3f39-fc6a-47da-ab47-8f7de179c750, 0506b52a-8bfc-474b-8e92-8e610130b04f]}
14:54:56,058 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-37482]ISPN100002: Started rebalance with topology id 6
14:54:56,061 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t13) [Context=___counters][Scope=fedora-37482]ISPN100003: Node fedora-37482 finished rebalance phase with topology id 6
14:54:56,062 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-38253]ISPN100003: Node fedora-38253 finished rebalance phase with topology id 6
14:54:56,097 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-48305]ISPN100003: Node fedora-48305 finished rebalance phase with topology id 6
14:54:56,098 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___counters, topology id = 6
14:54:56,100 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t18) [Context=___counters][Scope=fedora-37482]ISPN100003: Node fedora-37482 finished rebalance phase with topology id 7
14:54:56,101 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-38253]ISPN100003: Node fedora-38253 finished rebalance phase with topology id 7
14:54:56,109 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-48305]ISPN100003: Node fedora-48305 finished rebalance phase with topology id 7
14:54:56,112 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t17) [Context=___counters][Scope=fedora-37482]ISPN100003: Node fedora-37482 finished rebalance phase with topology id 8
14:54:56,117 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-38253]ISPN100003: Node fedora-38253 finished rebalance phase with topology id 8
14:54:56,123 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-48305]ISPN100003: Node fedora-48305 finished rebalance phase with topology id 8
14:54:56,160 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-37482: 130, fedora-38253: 126]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-37482: 82, fedora-38253: 84, fedora-48305: 90]}, unionCH=null, actualMembers=[fedora-37482, fedora-38253, fedora-48305], persistentUUIDs=[5f87ed87-1e5e-4dc3-8971-dde31a185f6b, 080d3f39-fc6a-47da-ab47-8f7de179c750, 0506b52a-8bfc-474b-8e92-8e610130b04f]}
14:54:56,160 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-37482]ISPN100002: Started rebalance with topology id 6
14:54:56,163 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=___protobuf_metadata][Scope=fedora-37482]ISPN100003: Node fedora-37482 finished rebalance phase with topology id 6
14:54:56,167 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-38253]ISPN100003: Node fedora-38253 finished rebalance phase with topology id 6
14:54:56,194 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=fedora-48305]ISPN100003: Node fedora-48305 finished rebalance phase with topology id 6
14:54:56,194 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 6
14:54:56,195 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-37482: 261+251, fedora-38253: 251+261]}, pendingCH=DefaultConsistentHash{ns=512, owners = (3)[fedora-37482: 167+158, fedora-38253: 165+181, fedora-48305: 180+173]}, unionCH=null, actualMembers=[fedora-37482, fedora-38253, fedora-48305], persistentUUIDs=[5f87ed87-1e5e-4dc3-8971-dde31a185f6b, 080d3f39-fc6a-47da-ab47-8f7de179c750, 0506b52a-8bfc-474b-8e92-8e610130b04f]}
14:54:56,196 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-37482]ISPN100002: Started rebalance with topology id 6
14:54:56,196 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t6) [Context=___protobuf_metadata][Scope=fedora-37482]ISPN100003: Node fedora-37482 finished rebalance phase with topology id 7
14:54:56,199 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=fedora-38253]ISPN100003: Node fedora-38253 finished rebalance phase with topology id 7
14:54:56,202 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-48305]ISPN100003: Node fedora-48305 finished rebalance phase with topology id 7
14:54:56,203 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-38253]ISPN100003: Node fedora-38253 finished rebalance phase with topology id 6
14:54:56,204 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t25) [Context=testCache][Scope=fedora-37482]ISPN100003: Node fedora-37482 finished rebalance phase with topology id 6
14:54:56,206 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t14) [Context=___protobuf_metadata][Scope=fedora-37482]ISPN100003: Node fedora-37482 finished rebalance phase with topology id 8
14:54:56,209 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=fedora-38253]ISPN100003: Node fedora-38253 finished rebalance phase with topology id 8
14:54:56,209 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-48305]ISPN100003: Node fedora-48305 finished rebalance phase with topology id 8
14:54:56,225 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-48305]ISPN100003: Node fedora-48305 finished rebalance phase with topology id 6
14:54:56,226 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache testCache, topology id = 6
14:54:56,228 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=testCache][Scope=fedora-37482]ISPN100003: Node fedora-37482 finished rebalance phase with topology id 7
14:54:56,230 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-38253]ISPN100003: Node fedora-38253 finished rebalance phase with topology id 7
14:54:56,231 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-48305]ISPN100003: Node fedora-48305 finished rebalance phase with topology id 7
14:54:56,232 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t3) [Context=testCache][Scope=fedora-37482]ISPN100003: Node fedora-37482 finished rebalance phase with topology id 8
14:54:56,235 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-48305]ISPN100003: Node fedora-48305 finished rebalance phase with topology id 8
14:54:56,237 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=fedora-38253]ISPN100003: Node fedora-38253 finished rebalance phase with topology id 8
14:54:56,326 INFO  [org.radargun.Slave] (sc-main) Starting stage AfterServiceStart
14:54:56,326 INFO  [org.radargun.Slave] (sc-main) Finished stage AfterServiceStart
14:54:56,328 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
14:54:56,382 INFO  [org.radargun.Slave] (sc-main) Starting stage MonitorStart
14:54:56,393 INFO  [org.radargun.sysmonitor.AbstractMonitors] (sc-main) Gathering statistics every 1000 ms
14:54:56,394 INFO  [org.radargun.Slave] (sc-main) Finished stage MonitorStart
14:54:56,394 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
14:54:56,420 INFO  [org.radargun.Slave] (sc-main) Starting stage Load
14:55:01,244 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) This node loaded 10000 entries (~10000000 bytes)
14:55:03,258 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) This node loaded 20000 entries (~20000000 bytes)
14:55:04,949 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) This node loaded 30000 entries (~30000000 bytes)
14:55:05,403 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) Finished loading entries
14:55:05,416 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) Finished loading entries
14:55:05,422 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) Finished loading entries
14:55:05,425 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) Finished loading entries
14:55:05,431 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) Finished loading entries
14:55:05,435 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) Finished loading entries
14:55:05,445 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) Finished loading entries
14:55:05,447 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) Finished loading entries
14:55:05,452 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) Finished loading entries
14:55:05,456 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) Finished loading entries
14:55:05,456 INFO  [org.radargun.Slave] (sc-main) Finished stage Load
14:55:05,457 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
14:55:05,478 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.stages.cache.test.BasicOperationsTestStage.init() overrides public void org.radargun.stages.test.TestStage.init() but both are declared with @Init annotation: calling only once
14:55:05,482 INFO  [org.radargun.Slave] (sc-main) Starting stage BasicOperationsTest
14:55:05,483 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using key generator org.radargun.stages.cache.generators.StringKeyGenerator {format=null }
14:55:05,483 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using value generator org.radargun.stages.cache.generators.ByteArrayValueGenerator { }
14:55:05,484 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using cache selector Default { }
14:55:05,484 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Starting test warmup
14:55:05,498 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Started 4 stressor threads.
14:56:05,502 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Finished test. Test duration is: 1 mins 0 secs
14:56:05,504 INFO  [org.radargun.Slave] (sc-main) Finished stage BasicOperationsTest
14:56:05,519 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
14:56:05,536 INFO  [org.radargun.Slave] (sc-main) Starting stage Clear
14:56:05,540 INFO  [org.radargun.stages.cache.ClearStage] (sc-main) Before executing clear, memory looks like this: 
Runtime free: 1,165,919 kb
Runtime max:1,319,936 kb
Runtime total:1,319,936 kb
MX Code Cache(Non-heap memory): used: 13,343 kb, init: 2,496 kb, committed: 14,720 kb, max: 245,760 kb
MX Metaspace(Non-heap memory): used: 38,004 kb, init: 0 kb, committed: 40,064 kb, max: 0 kb
MX Compressed Class Space(Non-heap memory): used: 4,597 kb, init: 0 kb, committed: 4,992 kb, max: 1,048,576 kb
MX PS Eden Space(Heap memory): used: 24,904 kb, init: 350,208 kb, committed: 306,688 kb, max: 306,688 kb
MX PS Survivor Space(Heap memory): used: 65,792 kb, init: 57,856 kb, committed: 80,384 kb, max: 80,384 kb
MX PS Old Gen(Heap memory): used: 63,319 kb, init: 932,864 kb, committed: 932,864 kb, max: 932,864 kb
14:56:05,829 INFO  [org.radargun.stages.cache.ClearStage] (sc-main) After executing clear, memory looks like this: 
Runtime free: 1,303,952 kb
Runtime max:1,318,400 kb
Runtime total:1,318,400 kb
MX Code Cache(Non-heap memory): used: 13,531 kb, init: 2,496 kb, committed: 14,784 kb, max: 245,760 kb
MX Metaspace(Non-heap memory): used: 37,904 kb, init: 0 kb, committed: 40,064 kb, max: 0 kb
MX Compressed Class Space(Non-heap memory): used: 4,557 kb, init: 0 kb, committed: 4,992 kb, max: 1,048,576 kb
MX PS Eden Space(Heap memory): used: 1,763 kb, init: 350,208 kb, committed: 306,688 kb, max: 309,248 kb
MX PS Survivor Space(Heap memory): used: 0 kb, init: 57,856 kb, committed: 78,848 kb, max: 78,848 kb
MX PS Old Gen(Heap memory): used: 12,683 kb, init: 932,864 kb, committed: 932,864 kb, max: 932,864 kb
14:56:05,829 INFO  [org.radargun.Slave] (sc-main) Finished stage Clear
14:56:05,830 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
14:56:05,834 INFO  [org.radargun.Slave] (sc-main) Starting stage Load
14:56:07,408 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) This node loaded 10000 entries (~10000000 bytes)
14:56:08,843 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) This node loaded 20000 entries (~20000000 bytes)
14:56:10,317 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) This node loaded 30000 entries (~30000000 bytes)
14:56:10,587 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) Finished loading entries
14:56:10,592 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) Finished loading entries
14:56:10,596 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) Finished loading entries
14:56:10,599 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) Finished loading entries
14:56:10,599 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) Finished loading entries
14:56:10,599 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) Finished loading entries
14:56:10,602 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) Finished loading entries
14:56:10,612 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) Finished loading entries
14:56:10,612 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) Finished loading entries
14:56:10,614 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) Finished loading entries
14:56:10,614 INFO  [org.radargun.Slave] (sc-main) Finished stage Load
14:56:10,614 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
14:56:11,041 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.stages.cache.test.BasicOperationsTestStage.init() overrides public void org.radargun.stages.test.TestStage.init() but both are declared with @Init annotation: calling only once
14:56:11,041 INFO  [org.radargun.Slave] (sc-main) Starting stage BasicOperationsTest
14:56:11,042 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using key generator org.radargun.stages.cache.generators.StringKeyGenerator {format=null }
14:56:11,042 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using value generator org.radargun.stages.cache.generators.ByteArrayValueGenerator { }
14:56:11,042 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using cache selector Default { }
14:56:11,042 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Starting test stress-test
14:56:11,080 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Started 4 stressor threads.
15:06:11,082 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Finished test. Test duration is: 10 mins 0 secs
15:06:11,083 INFO  [org.radargun.Slave] (sc-main) Finished stage BasicOperationsTest
15:06:11,156 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
15:06:11,288 INFO  [org.radargun.Slave] (sc-main) Starting stage MonitorStop
15:06:11,290 INFO  [org.radargun.Slave] (sc-main) Finished stage MonitorStop
15:06:11,291 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
15:06:11,296 INFO  [org.radargun.Slave] (sc-main) Starting stage ScenarioDestroy
15:06:11,296 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Scenario finished, destroying...
15:06:11,297 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Memory before cleanup: 
Runtime free: 947,761 kb
Runtime max:1,330,688 kb
Runtime total:1,330,688 kb
MX Code Cache(Non-heap memory): used: 15,017 kb, init: 2,496 kb, committed: 15,168 kb, max: 245,760 kb
MX Metaspace(Non-heap memory): used: 38,497 kb, init: 0 kb, committed: 40,704 kb, max: 0 kb
MX Compressed Class Space(Non-heap memory): used: 4,593 kb, init: 0 kb, committed: 5,120 kb, max: 1,048,576 kb
MX PS Eden Space(Heap memory): used: 273,874 kb, init: 350,208 kb, committed: 329,728 kb, max: 329,728 kb
MX PS Survivor Space(Heap memory): used: 65,824 kb, init: 57,856 kb, committed: 68,096 kb, max: 68,096 kb
MX PS Old Gen(Heap memory): used: 43,227 kb, init: 932,864 kb, committed: 932,864 kb, max: 932,864 kb
15:06:11,298 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) Stopping service.
15:06:11,305 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t34) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-37482: 250+75, fedora-38253: 262+84]}, pendingCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-37482: 261+251, fedora-38253: 251+261]}, unionCH=null, actualMembers=[fedora-37482, fedora-38253], persistentUUIDs=[5f87ed87-1e5e-4dc3-8971-dde31a185f6b, 080d3f39-fc6a-47da-ab47-8f7de179c750]}
15:06:11,305 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t34) [Context=testCache][Scope=fedora-37482]ISPN100002: Started rebalance with topology id 11
15:06:11,329 WARN  [org.infinispan.CLUSTER] (remote-thread--p2-t34) [Context=testCache]ISPN000312: Lost data because of graceful leaver fedora-38253
15:06:11,359 ERROR [org.infinispan.statetransfer.StateConsumerImpl] (transport-thread--p4-t2) ISPN000208: No live owners found for segments {3 15-19 22-24 31-33 37-39 43 52-55 59-62 78-81 85 90 96 103-104 107-109 113-118 122-131 138 142-144 149 154 157-170 173-174 197-203 206 211-212 216-217 234-238 246-248 254-260 263-264 276-282 295 304-305 312-315 322-323 330-336 345-346 350-352 363-366 373 383-385 389-395 403-404 412-421 424 427-428 435 439 445-447 452-455 458 462 467-468 475 479-480 483 486 492 499-502 506-508} of cache testCache. Excluded owners: []
15:06:11,360 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t5) [Context=testCache][Scope=fedora-37482]ISPN100003: Node fedora-37482 finished rebalance phase with topology id 12
15:06:11,367 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (transport-thread--p4-t5) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=testCache, type=REBALANCE_PHASE_CONFIRM, sender=fedora-37482, joinInfo=null, topologyId=12, rebalanceId=4, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-37482 for cache testCache, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.commands.ReplicableCommand.invoke(ReplicableCommand.java:44) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.LocalTopologyManagerImpl.lambda$executeOnCoordinatorAsync$4(LocalTopologyManagerImpl.java:717) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_402-internal]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_402-internal]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_402-internal]
15:06:11,371 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t36) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-37482: 118+48, fedora-38253: 138+44]}, pendingCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-37482: 130+126, fedora-38253: 126+130]}, unionCH=null, actualMembers=[fedora-37482, fedora-38253], persistentUUIDs=[5f87ed87-1e5e-4dc3-8971-dde31a185f6b, 080d3f39-fc6a-47da-ab47-8f7de179c750]}
15:06:11,365 WARN  [org.infinispan.statetransfer.InboundTransferTask] (stateTransferExecutor-thread--p6-t1) ISPN000210: Failed to request state of cache testCache from node fedora-38253, segments {3 15-19 22-24 31-33 37-39 43 52-55 59-62 78-81 85 90 96 103-104 107-109 113-118 122-131 138 142-144 149 154 157-170 173-174 197-203 206 211-212 216-217 234-238 246-248 254-260 263-264 276-282 295 304-305 312-315 322-323 330-336 345-346 350-352 363-366 373 383-385 389-395 403-404 412-421 424 427-428 435 439 445-447 452-455 458 462 467-468 475 479-480 483 486 492 499-502 506-508}
org.infinispan.remoting.transport.jgroups.SuspectException: ISPN000400: Node fedora-38253 was suspected
	at org.infinispan.remoting.transport.ResponseCollectors.remoteNodeSuspected(ResponseCollectors.java:33) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleResponseCollector.targetNotFound(SingleResponseCollector.java:31) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleResponseCollector.targetNotFound(SingleResponseCollector.java:17) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.ValidSingleResponseCollector.addResponse(ValidSingleResponseCollector.java:23) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleTargetRequest.receiveResponse(SingleTargetRequest.java:51) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleTargetRequest.onResponse(SingleTargetRequest.java:35) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.RequestRepository.addResponse(RequestRepository.java:53) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.processResponse(JGroupsTransport.java:1302) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.processMessage(JGroupsTransport.java:1205) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.access$200(JGroupsTransport.java:123) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport$ChannelCallbacks.receive(JGroupsTransport.java:1340) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.jgroups.JChannel.up(JChannel.java:819) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.stack.ProtocolStack.up(ProtocolStack.java:893) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FRAG3.up(FRAG3.java:171) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FlowControl.up(FlowControl.java:343) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FlowControl.up(FlowControl.java:343) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.GMS.up(GMS.java:864) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.STABLE.up(STABLE.java:240) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.deliverMessage(UNICAST3.java:1002) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.handleDataReceived(UNICAST3.java:728) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.up(UNICAST3.java:383) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.NAKACK2.up(NAKACK2.java:600) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.VERIFY_SUSPECT.up(VERIFY_SUSPECT.java:119) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FD_ALL.up(FD_ALL.java:199) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FD_SOCK.up(FD_SOCK.java:252) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.MERGE3.up(MERGE3.java:276) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.Discovery.up(Discovery.java:267) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.TP.passMessageUp(TP.java:1248) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.util.SubmitToThreadPool$SingleMessageHandler.run(SubmitToThreadPool.java:87) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_402-internal]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_402-internal]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_402-internal]
15:06:11,376 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t36) [Context=___counters][Scope=fedora-37482]ISPN100002: Started rebalance with topology id 11
15:06:11,412 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t36) [Context=___counters][Scope=fedora-38253]ISPN100003: Node fedora-38253 finished rebalance phase with topology id 11
15:06:11,418 INFO  [org.infinispan.CLUSTER] (jgroups-35,fedora-37482) ISPN000094: Received new cluster view for channel results: [fedora-37482|3] (2) [fedora-37482, fedora-38253]
15:06:11,424 INFO  [org.infinispan.CLUSTER] (jgroups-35,fedora-37482) ISPN100001: Node fedora-48305 left the cluster
15:06:11,434 WARN  [org.infinispan.CLUSTER] (remote-thread--p2-t33) [Context=___counters]ISPN000312: Lost data because of graceful leaver fedora-38253
15:06:11,466 ERROR [org.infinispan.statetransfer.StateConsumerImpl] (transport-thread--p4-t22) ISPN000208: No live owners found for segments {30-33 39-41 57-65 68 74 79-81 87 99-100 108 117 122-123 127-129 138 141 147-153 161-162 165-172 179-183 189-196 200 206-209 214 226-231 237 240 248-250} of cache ___counters. Excluded owners: []
15:06:11,467 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t15) [Context=___counters][Scope=fedora-37482]ISPN100003: Node fedora-37482 finished rebalance phase with topology id 12
15:06:11,469 INFO  [org.infinispan.CLUSTER] (jgroups-12,fedora-37482) ISPN000094: Received new cluster view for channel results: [fedora-37482|4] (1) [fedora-37482]
15:06:11,471 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (transport-thread--p4-t15) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___counters, type=REBALANCE_PHASE_CONFIRM, sender=fedora-37482, joinInfo=null, topologyId=12, rebalanceId=4, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=3}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from fedora-37482 for cache ___counters, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.commands.ReplicableCommand.invoke(ReplicableCommand.java:44) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.LocalTopologyManagerImpl.lambda$executeOnCoordinatorAsync$4(LocalTopologyManagerImpl.java:717) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_402-internal]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_402-internal]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_402-internal]
15:06:11,471 INFO  [org.infinispan.CLUSTER] (jgroups-12,fedora-37482) ISPN100001: Node fedora-38253 left the cluster
15:06:11,479 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (StopThread) ISPN000080: Disconnecting JGroups channel results
15:06:11,496 INFO  [org.radargun.service.Infinispan90Lifecycle] (StopThread) Stopped, previous view is [fedora-37482, fedora-38253, fedora-48305]
15:06:11,496 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Service successfully stopped.
15:06:11,497 INFO  [org.radargun.Slave] (sc-main) Finished stage ScenarioDestroy
15:06:11,497 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
15:06:11,504 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.service.Infinispan80EmbeddedService.destroy() overrides public void org.radargun.service.Infinispan60EmbeddedService.destroy() but both are declared with @Destroy annotation: calling only once
15:06:11,506 INFO  [org.radargun.Slave] (main) Starting stage ScenarioCleanup
15:06:11,603 INFO  [org.radargun.stages.ScenarioCleanupStage] (main) Memory after cleanup: 
Runtime free: 1,310,447 kb
Runtime max:1,328,640 kb
Runtime total:1,328,640 kb
MX Code Cache(Non-heap memory): used: 15,252 kb, init: 2,496 kb, committed: 15,488 kb, max: 245,760 kb
MX Metaspace(Non-heap memory): used: 38,626 kb, init: 0 kb, committed: 40,704 kb, max: 0 kb
MX Compressed Class Space(Non-heap memory): used: 4,618 kb, init: 0 kb, committed: 5,120 kb, max: 1,048,576 kb
MX PS Eden Space(Heap memory): used: 5,711 kb, init: 350,208 kb, committed: 327,680 kb, max: 328,704 kb
MX PS Survivor Space(Heap memory): used: 0 kb, init: 57,856 kb, committed: 68,096 kb, max: 68,096 kb
MX PS Old Gen(Heap memory): used: 12,481 kb, init: 932,864 kb, committed: 932,864 kb, max: 932,864 kb
15:06:11,606 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
15:06:16,776 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
15:06:20,394 INFO  [org.radargun.Slave] (main) Master shutdown!
15:06:20,395 INFO  [org.radargun.ShutDownHook] (Thread-0) Slave process is being shutdown
