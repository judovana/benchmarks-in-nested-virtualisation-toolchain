04:44:34,106 INFO  [org.radargun.RemoteMasterConnection] (main) Attempting to connect to master results:2103
04:44:34,112 INFO  [org.radargun.RemoteMasterConnection] (main) Successfully established connection with master at: results:2103
04:44:34,114 INFO  [org.radargun.Slave] (main) Received slave index 0
04:44:34,114 INFO  [org.radargun.Slave] (main) Received slave count 3
04:44:34,442 INFO  [org.radargun.ServiceHelper] (sc-main) ServiceContext properties: {}
04:44:34,543 INFO  [org.radargun.Slave] (sc-main) Eager Service Infinispan92EmbeddedService {batching=false, cache=testCache, channelRetrievalTimeout=2 mins 0 secs, enableDiagnostics=null, explicitLocking=false, file=/mnt/workspace/results/dist-sync.xml, internalsExpositionEnabled=false, jgroupsDumperEnabled=false, jgroupsDumperInterval=10.000 secs, keysPerThread=-1, mapReduceDistributedReducePhase=false, mapReduceUseIntermediateSharedCache=false, removedCaches=[  ], threadsPerNode=-1 } loaded.
04:44:36,098 INFO  [org.radargun.Slave] (sc-main) Starting stage ScenarioInit
04:44:36,139 INFO  [org.radargun.Slave] (sc-main) Finished stage ScenarioInit
04:44:36,143 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
04:44:36,251 INFO  [org.radargun.Slave] (sc-main) Starting stage BeforeServiceStart
04:44:36,251 INFO  [org.radargun.Slave] (sc-main) Finished stage BeforeServiceStart
04:44:36,252 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
04:44:36,275 INFO  [org.radargun.Slave] (sc-main) Starting stage ServiceStart
04:44:36,276 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Startup staggering, this is the slave with index 0, not sleeping
04:44:36,277 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 0
04:44:36,279 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) Infinispan version: Infinispan 'Gaina' 9.2.0.Final
04:44:36,291 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) JGroups version: JGroups 4.0.10.Final (Schiener Berg)
04:44:36,690 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (sc-main) ISPN000078: Starting JGroups channel results
04:44:36,760 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the send buffer of socket MulticastSocket was set to 1.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
04:44:36,761 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the receive buffer of socket MulticastSocket was set to 20.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
04:44:36,761 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the send buffer of socket MulticastSocket was set to 1.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
04:44:36,761 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the receive buffer of socket MulticastSocket was set to 25.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
04:44:41,804 INFO  [org.infinispan.CLUSTER] (sc-main) ISPN000094: Received new cluster view for channel results: [fedora-61972|0] (1) [fedora-61972]
04:44:41,923 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (sc-main) ISPN000079: Channel results local address is fedora-61972, physical addresses are [192.168.121.165:50272]
04:44:41,926 INFO  [org.infinispan.factories.GlobalComponentRegistry] (sc-main) ISPN000128: Infinispan version: Infinispan 'Gaina' 9.2.0.Final
04:44:42,269 INFO  [org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup] (sc-main) ISPN000107: Retrieving transaction manager Transaction: unknown
04:44:42,328 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) No RELAY2 protocol in XS service
04:44:42,328 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) No RELAY2 protocol in XS service
04:44:42,330 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) ([fedora-61972(local=true, coord=true)]) Number of members=1 is not the one expected: 3
04:44:42,570 INFO  [org.infinispan.CLUSTER] (jgroups-6,fedora-61972) ISPN000094: Received new cluster view for channel results: [fedora-61972|1] (2) [fedora-61972, fedora-25162]
04:44:42,582 INFO  [org.infinispan.CLUSTER] (jgroups-6,fedora-61972) ISPN100000: Node fedora-25162 joined the cluster
04:44:42,972 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-61972: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-61972: 124, fedora-25162: 132]}, unionCH=null, actualMembers=[fedora-61972, fedora-25162], persistentUUIDs=[7bebc057-d23f-4568-a13f-8ca3b39166b8, c6ebeaa3-2b17-4a88-95c6-eda0fb0fd7d4]}
04:44:42,975 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-61972]ISPN100002: Started rebalance with topology id 2
04:44:42,976 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-61972: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-61972: 124, fedora-25162: 132]}, unionCH=null, actualMembers=[fedora-61972, fedora-25162], persistentUUIDs=[7bebc057-d23f-4568-a13f-8ca3b39166b8, c6ebeaa3-2b17-4a88-95c6-eda0fb0fd7d4]}
04:44:42,978 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-61972]ISPN100002: Started rebalance with topology id 2
04:44:43,001 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=___counter_configuration][Scope=fedora-61972]ISPN100003: Node fedora-61972 finished rebalance phase with topology id 2
04:44:43,004 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t23) [Context=org.infinispan.CONFIG][Scope=fedora-61972]ISPN100003: Node fedora-61972 finished rebalance phase with topology id 2
04:44:43,086 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-25162]ISPN100003: Node fedora-25162 finished rebalance phase with topology id 2
04:44:43,087 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 2
04:44:43,091 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t1) [Context=org.infinispan.CONFIG][Scope=fedora-61972]ISPN100003: Node fedora-61972 finished rebalance phase with topology id 3
04:44:43,100 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-25162]ISPN100003: Node fedora-25162 finished rebalance phase with topology id 3
04:44:43,102 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t4) [Context=org.infinispan.CONFIG][Scope=fedora-61972]ISPN100003: Node fedora-61972 finished rebalance phase with topology id 4
04:44:43,113 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-25162]ISPN100003: Node fedora-25162 finished rebalance phase with topology id 4
04:44:43,129 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-25162]ISPN100003: Node fedora-25162 finished rebalance phase with topology id 2
04:44:43,130 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 2
04:44:43,137 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-25162]ISPN100003: Node fedora-25162 finished rebalance phase with topology id 3
04:44:43,135 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t10) [Context=___counter_configuration][Scope=fedora-61972]ISPN100003: Node fedora-61972 finished rebalance phase with topology id 3
04:44:43,142 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t10) [Context=___counter_configuration][Scope=fedora-61972]ISPN100003: Node fedora-61972 finished rebalance phase with topology id 4
04:44:43,157 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-25162]ISPN100003: Node fedora-25162 finished rebalance phase with topology id 4
04:44:43,191 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=DefaultConsistentHash{ns=256, owners = (1)[fedora-61972: 256+0]}, pendingCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-61972: 124+132, fedora-25162: 132+124]}, unionCH=null, actualMembers=[fedora-61972, fedora-25162], persistentUUIDs=[7bebc057-d23f-4568-a13f-8ca3b39166b8, c6ebeaa3-2b17-4a88-95c6-eda0fb0fd7d4]}
04:44:43,192 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-61972]ISPN100002: Started rebalance with topology id 2
04:44:43,194 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t19) [Context=___counters][Scope=fedora-61972]ISPN100003: Node fedora-61972 finished rebalance phase with topology id 2
04:44:43,232 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-25162]ISPN100003: Node fedora-25162 finished rebalance phase with topology id 2
04:44:43,233 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___counters, topology id = 2
04:44:43,236 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t23) [Context=___counters][Scope=fedora-61972]ISPN100003: Node fedora-61972 finished rebalance phase with topology id 3
04:44:43,238 INFO  [org.infinispan.CLUSTER] (jgroups-6,fedora-61972) ISPN000094: Received new cluster view for channel results: [fedora-61972|2] (3) [fedora-61972, fedora-25162, fedora-32303]
04:44:43,239 INFO  [org.infinispan.CLUSTER] (jgroups-6,fedora-61972) ISPN100000: Node fedora-32303 joined the cluster
04:44:43,249 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-25162]ISPN100003: Node fedora-25162 finished rebalance phase with topology id 3
04:44:43,250 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t1) [Context=___counters][Scope=fedora-61972]ISPN100003: Node fedora-61972 finished rebalance phase with topology id 4
04:44:43,261 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=fedora-25162]ISPN100003: Node fedora-25162 finished rebalance phase with topology id 4
04:44:43,306 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[fedora-61972: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-61972: 124, fedora-25162: 132]}, unionCH=null, actualMembers=[fedora-61972, fedora-25162], persistentUUIDs=[7bebc057-d23f-4568-a13f-8ca3b39166b8, c6ebeaa3-2b17-4a88-95c6-eda0fb0fd7d4]}
04:44:43,306 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-61972]ISPN100002: Started rebalance with topology id 2
04:44:43,311 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t12) [Context=___protobuf_metadata][Scope=fedora-61972]ISPN100003: Node fedora-61972 finished rebalance phase with topology id 2
04:44:43,330 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) Number of members is the one expected: 3
04:44:43,331 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Successfully started cache service infinispan92/embedded on slave 0
04:44:43,343 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-25162]ISPN100003: Node fedora-25162 finished rebalance phase with topology id 2
04:44:43,344 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 2
04:44:43,346 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t15) [Context=___protobuf_metadata][Scope=fedora-61972]ISPN100003: Node fedora-61972 finished rebalance phase with topology id 3
04:44:43,350 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-25162]ISPN100003: Node fedora-25162 finished rebalance phase with topology id 3
04:44:43,352 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t17) [Context=___protobuf_metadata][Scope=fedora-61972]ISPN100003: Node fedora-61972 finished rebalance phase with topology id 4
04:44:43,355 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=DefaultConsistentHash{ns=512, owners = (1)[fedora-61972: 512+0]}, pendingCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-61972: 253+259, fedora-25162: 259+253]}, unionCH=null, actualMembers=[fedora-61972, fedora-25162], persistentUUIDs=[7bebc057-d23f-4568-a13f-8ca3b39166b8, c6ebeaa3-2b17-4a88-95c6-eda0fb0fd7d4]}
04:44:43,357 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-61972]ISPN100002: Started rebalance with topology id 2
04:44:43,360 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t19) [Context=testCache][Scope=fedora-61972]ISPN100003: Node fedora-61972 finished rebalance phase with topology id 2
04:44:43,360 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-25162]ISPN100003: Node fedora-25162 finished rebalance phase with topology id 4
04:44:43,403 ERROR [org.radargun.service.ConfigDumpHelper] (sc-main) Error while dumping ___protobuf_metadata cache config as properties
javax.management.AttributeNotFoundException: Unknown attribute 'configurationAsProperties'. Known attributes names are: [rebalancingEnabled, cacheStatus, cacheName, cacheAvailability, version, configurationAsProperties]
	at org.infinispan.jmx.ResourceDMBean.getAttribute(ResourceDMBean.java:181) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:636) ~[?:?]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:679) ~[?:?]
	at org.radargun.service.ConfigDumpHelper60.dumpCache(ConfigDumpHelper60.java:44) [plugin-infinispan60-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.service.EmbeddedConfigurationProvider.getNormalizedConfigs(EmbeddedConfigurationProvider.java:33) [plugin-infinispan52-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.stages.lifecycle.ServiceStartStage.executeOnSlave(ServiceStartStage.java:92) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase.scenarioLoop(SlaveBase.java:102) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase$ScenarioRunner.run(SlaveBase.java:203) [radargun-core-3.0.0-SNAPSHOT.jar:?]
04:44:43,415 ERROR [org.radargun.service.ConfigDumpHelper] (sc-main) Error while dumping ___protobuf_metadata cache config as properties
javax.management.AttributeNotFoundException: Unknown attribute 'configurationAsProperties'. Known attributes names are: [rebalancingEnabled, cacheStatus, cacheName, cacheAvailability, version, configurationAsProperties]
	at org.infinispan.jmx.ResourceDMBean.getAttribute(ResourceDMBean.java:181) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:636) ~[?:?]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:679) ~[?:?]
	at org.radargun.service.ConfigDumpHelper60.dumpCache(ConfigDumpHelper60.java:44) [plugin-infinispan60-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.service.EmbeddedConfigurationProvider.getNormalizedConfigs(EmbeddedConfigurationProvider.java:33) [plugin-infinispan52-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.stages.lifecycle.ServiceStartStage.executeOnSlave(ServiceStartStage.java:92) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase.scenarioLoop(SlaveBase.java:102) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase$ScenarioRunner.run(SlaveBase.java:203) [radargun-core-3.0.0-SNAPSHOT.jar:?]
04:44:43,434 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-25162]ISPN100003: Node fedora-25162 finished rebalance phase with topology id 2
04:44:43,435 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache testCache, topology id = 2
04:44:43,437 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t6) [Context=testCache][Scope=fedora-61972]ISPN100003: Node fedora-61972 finished rebalance phase with topology id 3
04:44:43,443 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-25162]ISPN100003: Node fedora-25162 finished rebalance phase with topology id 3
04:44:43,446 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t4) [Context=testCache][Scope=fedora-61972]ISPN100003: Node fedora-61972 finished rebalance phase with topology id 4
04:44:43,450 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-25162]ISPN100003: Node fedora-25162 finished rebalance phase with topology id 4
04:44:43,487 INFO  [org.radargun.Slave] (sc-main) Finished stage ServiceStart
04:44:43,500 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
04:44:43,688 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-61972: 124, fedora-25162: 132]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-61972: 82, fedora-25162: 90, fedora-32303: 84]}, unionCH=null, actualMembers=[fedora-61972, fedora-25162, fedora-32303], persistentUUIDs=[7bebc057-d23f-4568-a13f-8ca3b39166b8, c6ebeaa3-2b17-4a88-95c6-eda0fb0fd7d4, 9c58dbf7-362a-4b0e-9754-6275a6df8fc2]}
04:44:43,688 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-61972: 124, fedora-25162: 132]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-61972: 82, fedora-25162: 90, fedora-32303: 84]}, unionCH=null, actualMembers=[fedora-61972, fedora-25162, fedora-32303], persistentUUIDs=[7bebc057-d23f-4568-a13f-8ca3b39166b8, c6ebeaa3-2b17-4a88-95c6-eda0fb0fd7d4, 9c58dbf7-362a-4b0e-9754-6275a6df8fc2]}
04:44:43,688 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-61972]ISPN100002: Started rebalance with topology id 6
04:44:43,688 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-61972]ISPN100002: Started rebalance with topology id 6
04:44:43,690 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t10) [Context=org.infinispan.CONFIG][Scope=fedora-61972]ISPN100003: Node fedora-61972 finished rebalance phase with topology id 6
04:44:43,691 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-25162]ISPN100003: Node fedora-25162 finished rebalance phase with topology id 6
04:44:43,690 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t14) [Context=___counter_configuration][Scope=fedora-61972]ISPN100003: Node fedora-61972 finished rebalance phase with topology id 6
04:44:43,693 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-25162]ISPN100003: Node fedora-25162 finished rebalance phase with topology id 6
04:44:43,764 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-32303]ISPN100003: Node fedora-32303 finished rebalance phase with topology id 6
04:44:43,765 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 6
04:44:43,766 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=org.infinispan.CONFIG][Scope=fedora-61972]ISPN100003: Node fedora-61972 finished rebalance phase with topology id 7
04:44:43,768 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=fedora-25162]ISPN100003: Node fedora-25162 finished rebalance phase with topology id 7
04:44:43,771 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-32303]ISPN100003: Node fedora-32303 finished rebalance phase with topology id 6
04:44:43,775 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 6
04:44:43,776 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-32303]ISPN100003: Node fedora-32303 finished rebalance phase with topology id 7
04:44:43,777 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t23) [Context=___counter_configuration][Scope=fedora-61972]ISPN100003: Node fedora-61972 finished rebalance phase with topology id 7
04:44:43,777 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t19) [Context=org.infinispan.CONFIG][Scope=fedora-61972]ISPN100003: Node fedora-61972 finished rebalance phase with topology id 8
04:44:43,779 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-25162]ISPN100003: Node fedora-25162 finished rebalance phase with topology id 7
04:44:43,779 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-25162]ISPN100003: Node fedora-25162 finished rebalance phase with topology id 8
04:44:43,789 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=fedora-32303]ISPN100003: Node fedora-32303 finished rebalance phase with topology id 8
04:44:43,789 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-32303]ISPN100003: Node fedora-32303 finished rebalance phase with topology id 7
04:44:43,790 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t9) [Context=___counter_configuration][Scope=fedora-61972]ISPN100003: Node fedora-61972 finished rebalance phase with topology id 8
04:44:43,794 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=fedora-25162]ISPN100003: Node fedora-25162 finished rebalance phase with topology id 8
04:44:43,796 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=fedora-32303]ISPN100003: Node fedora-32303 finished rebalance phase with topology id 8
04:44:43,818 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-61972: 124+132, fedora-25162: 132+124]}, pendingCH=DefaultConsistentHash{ns=256, owners = (3)[fedora-61972: 82+76, fedora-25162: 90+98, fedora-32303: 84+82]}, unionCH=null, actualMembers=[fedora-61972, fedora-25162, fedora-32303], persistentUUIDs=[7bebc057-d23f-4568-a13f-8ca3b39166b8, c6ebeaa3-2b17-4a88-95c6-eda0fb0fd7d4, 9c58dbf7-362a-4b0e-9754-6275a6df8fc2]}
04:44:43,819 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-61972]ISPN100002: Started rebalance with topology id 6
04:44:43,820 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t15) [Context=___counters][Scope=fedora-61972]ISPN100003: Node fedora-61972 finished rebalance phase with topology id 6
04:44:43,823 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-25162]ISPN100003: Node fedora-25162 finished rebalance phase with topology id 6
04:44:43,841 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-32303]ISPN100003: Node fedora-32303 finished rebalance phase with topology id 6
04:44:43,841 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache ___counters, topology id = 6
04:44:43,843 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t14) [Context=___counters][Scope=fedora-61972]ISPN100003: Node fedora-61972 finished rebalance phase with topology id 7
04:44:43,845 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-25162]ISPN100003: Node fedora-25162 finished rebalance phase with topology id 7
04:44:43,847 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-32303]ISPN100003: Node fedora-32303 finished rebalance phase with topology id 7
04:44:43,848 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t22) [Context=___counters][Scope=fedora-61972]ISPN100003: Node fedora-61972 finished rebalance phase with topology id 8
04:44:43,850 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-32303]ISPN100003: Node fedora-32303 finished rebalance phase with topology id 8
04:44:43,854 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=fedora-25162]ISPN100003: Node fedora-25162 finished rebalance phase with topology id 8
04:44:43,880 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[fedora-61972: 124, fedora-25162: 132]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[fedora-61972: 82, fedora-25162: 90, fedora-32303: 84]}, unionCH=null, actualMembers=[fedora-61972, fedora-25162, fedora-32303], persistentUUIDs=[7bebc057-d23f-4568-a13f-8ca3b39166b8, c6ebeaa3-2b17-4a88-95c6-eda0fb0fd7d4, 9c58dbf7-362a-4b0e-9754-6275a6df8fc2]}
04:44:43,880 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-61972]ISPN100002: Started rebalance with topology id 6
04:44:43,882 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t19) [Context=___protobuf_metadata][Scope=fedora-61972]ISPN100003: Node fedora-61972 finished rebalance phase with topology id 6
04:44:43,887 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-25162]ISPN100003: Node fedora-25162 finished rebalance phase with topology id 6
04:44:43,904 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-32303]ISPN100003: Node fedora-32303 finished rebalance phase with topology id 6
04:44:43,904 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 6
04:44:43,906 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t4) [Context=___protobuf_metadata][Scope=fedora-61972]ISPN100003: Node fedora-61972 finished rebalance phase with topology id 7
04:44:43,908 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-32303]ISPN100003: Node fedora-32303 finished rebalance phase with topology id 7
04:44:43,909 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-61972: 253+259, fedora-25162: 259+253]}, pendingCH=DefaultConsistentHash{ns=512, owners = (3)[fedora-61972: 173+159, fedora-25162: 167+186, fedora-32303: 172+167]}, unionCH=null, actualMembers=[fedora-61972, fedora-25162, fedora-32303], persistentUUIDs=[7bebc057-d23f-4568-a13f-8ca3b39166b8, c6ebeaa3-2b17-4a88-95c6-eda0fb0fd7d4, 9c58dbf7-362a-4b0e-9754-6275a6df8fc2]}
04:44:43,909 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-61972]ISPN100002: Started rebalance with topology id 6
04:44:43,912 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t12) [Context=testCache][Scope=fedora-61972]ISPN100003: Node fedora-61972 finished rebalance phase with topology id 6
04:44:43,913 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=fedora-25162]ISPN100003: Node fedora-25162 finished rebalance phase with topology id 7
04:44:43,914 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t13) [Context=___protobuf_metadata][Scope=fedora-61972]ISPN100003: Node fedora-61972 finished rebalance phase with topology id 8
04:44:43,916 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=fedora-25162]ISPN100003: Node fedora-25162 finished rebalance phase with topology id 6
04:44:43,916 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-25162]ISPN100003: Node fedora-25162 finished rebalance phase with topology id 8
04:44:43,918 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=fedora-32303]ISPN100003: Node fedora-32303 finished rebalance phase with topology id 8
04:44:43,928 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-32303]ISPN100003: Node fedora-32303 finished rebalance phase with topology id 6
04:44:43,928 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache testCache, topology id = 6
04:44:43,930 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t14) [Context=testCache][Scope=fedora-61972]ISPN100003: Node fedora-61972 finished rebalance phase with topology id 7
04:44:43,933 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-25162]ISPN100003: Node fedora-25162 finished rebalance phase with topology id 7
04:44:43,935 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-32303]ISPN100003: Node fedora-32303 finished rebalance phase with topology id 7
04:44:43,937 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t3) [Context=testCache][Scope=fedora-61972]ISPN100003: Node fedora-61972 finished rebalance phase with topology id 8
04:44:43,940 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-32303]ISPN100003: Node fedora-32303 finished rebalance phase with topology id 8
04:44:43,942 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=fedora-25162]ISPN100003: Node fedora-25162 finished rebalance phase with topology id 8
04:44:44,047 INFO  [org.radargun.Slave] (sc-main) Starting stage AfterServiceStart
04:44:44,047 INFO  [org.radargun.Slave] (sc-main) Finished stage AfterServiceStart
04:44:44,052 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
04:44:44,162 INFO  [org.radargun.Slave] (sc-main) Starting stage MonitorStart
04:44:44,176 INFO  [org.radargun.sysmonitor.AbstractMonitors] (sc-main) Gathering statistics every 1000 ms
04:44:44,177 INFO  [org.radargun.Slave] (sc-main) Finished stage MonitorStart
04:44:44,177 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
04:44:44,193 INFO  [org.radargun.Slave] (sc-main) Starting stage Load
04:44:49,273 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) This node loaded 10000 entries (~10000000 bytes)
04:44:52,834 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) This node loaded 20000 entries (~20000000 bytes)
04:44:54,732 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) This node loaded 30000 entries (~30000000 bytes)
04:44:55,149 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) Finished loading entries
04:44:55,185 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) Finished loading entries
04:44:55,193 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) Finished loading entries
04:44:55,210 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) Finished loading entries
04:44:55,214 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) Finished loading entries
04:44:55,224 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) Finished loading entries
04:44:55,240 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) Finished loading entries
04:44:55,258 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) Finished loading entries
04:44:55,286 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) Finished loading entries
04:44:55,305 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) Finished loading entries
04:44:55,306 INFO  [org.radargun.Slave] (sc-main) Finished stage Load
04:44:55,306 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
04:44:55,461 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.stages.cache.test.BasicOperationsTestStage.init() overrides public void org.radargun.stages.test.TestStage.init() but both are declared with @Init annotation: calling only once
04:44:55,465 INFO  [org.radargun.Slave] (sc-main) Starting stage BasicOperationsTest
04:44:55,465 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using key generator org.radargun.stages.cache.generators.StringKeyGenerator {format=null }
04:44:55,465 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using value generator org.radargun.stages.cache.generators.ByteArrayValueGenerator { }
04:44:55,466 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using cache selector Default { }
04:44:55,466 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Starting test warmup
04:44:55,476 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Started 4 stressor threads.
04:45:55,484 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Finished test. Test duration is: 1 mins 0 secs
04:45:55,486 INFO  [org.radargun.Slave] (sc-main) Finished stage BasicOperationsTest
04:45:55,492 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
04:45:55,504 INFO  [org.radargun.Slave] (sc-main) Starting stage Clear
04:45:55,508 INFO  [org.radargun.stages.cache.ClearStage] (sc-main) Before executing clear, memory looks like this: 
Runtime free: 879,308 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,589 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,700 kb
MX Metaspace(Non-heap memory): used: 35,953 kb, init: 0 kb, committed: 36,480 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 11,904 kb, init: 2,496 kb, committed: 11,968 kb, max: 120,028 kb
MX Compressed Class Space(Non-heap memory): used: 4,226 kb, init: 0 kb, committed: 4,480 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 323,584 kb, init: 69,632 kb, committed: 823,296 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 138,033 kb, init: 1,329,152 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 57,344 kb, init: 0 kb, committed: 57,344 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 6,172 kb, init: 2,496 kb, committed: 6,208 kb, max: 120,032 kb
04:45:55,660 INFO  [org.radargun.stages.cache.ClearStage] (sc-main) After executing clear, memory looks like this: 
Runtime free: 1,380,127 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,589 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,700 kb
MX Metaspace(Non-heap memory): used: 35,942 kb, init: 0 kb, committed: 36,480 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 11,768 kb, init: 2,496 kb, committed: 11,968 kb, max: 120,028 kb
MX Compressed Class Space(Non-heap memory): used: 4,219 kb, init: 0 kb, committed: 4,480 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 0 kb, init: 69,632 kb, committed: 880,640 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 18,144 kb, init: 1,329,152 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 0 kb, init: 0 kb, committed: 0 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 6,161 kb, init: 2,496 kb, committed: 6,272 kb, max: 120,032 kb
04:45:55,660 INFO  [org.radargun.Slave] (sc-main) Finished stage Clear
04:45:55,662 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
04:45:55,667 INFO  [org.radargun.Slave] (sc-main) Starting stage Load
04:45:56,995 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) This node loaded 10000 entries (~10000000 bytes)
04:45:58,282 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) This node loaded 20000 entries (~20000000 bytes)
04:45:59,558 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) This node loaded 30000 entries (~30000000 bytes)
04:45:59,910 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) Finished loading entries
04:45:59,925 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) Finished loading entries
04:45:59,926 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) Finished loading entries
04:45:59,960 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) Finished loading entries
04:45:59,964 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) Finished loading entries
04:45:59,965 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) Finished loading entries
04:45:59,967 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) Finished loading entries
04:45:59,970 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) Finished loading entries
04:45:59,974 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) Finished loading entries
04:45:59,977 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) Finished loading entries
04:45:59,977 INFO  [org.radargun.Slave] (sc-main) Finished stage Load
04:45:59,977 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
04:46:00,174 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.stages.cache.test.BasicOperationsTestStage.init() overrides public void org.radargun.stages.test.TestStage.init() but both are declared with @Init annotation: calling only once
04:46:00,182 INFO  [org.radargun.Slave] (sc-main) Starting stage BasicOperationsTest
04:46:00,182 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using key generator org.radargun.stages.cache.generators.StringKeyGenerator {format=null }
04:46:00,185 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using value generator org.radargun.stages.cache.generators.ByteArrayValueGenerator { }
04:46:00,186 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using cache selector Default { }
04:46:00,187 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Starting test stress-test
04:46:00,225 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Started 4 stressor threads.
04:56:00,227 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Finished test. Test duration is: 10 mins 0 secs
04:56:00,228 INFO  [org.radargun.Slave] (sc-main) Finished stage BasicOperationsTest
04:56:00,319 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
04:56:00,511 INFO  [org.radargun.Slave] (sc-main) Starting stage MonitorStop
04:56:00,513 INFO  [org.radargun.Slave] (sc-main) Finished stage MonitorStop
04:56:00,513 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
04:56:00,517 INFO  [org.radargun.Slave] (sc-main) Starting stage ScenarioDestroy
04:56:00,517 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Scenario finished, destroying...
04:56:00,518 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Memory before cleanup: 
Runtime free: 769,838 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,593 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,700 kb
MX Metaspace(Non-heap memory): used: 36,631 kb, init: 0 kb, committed: 37,184 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 9,668 kb, init: 2,496 kb, committed: 13,568 kb, max: 120,028 kb
MX Compressed Class Space(Non-heap memory): used: 4,257 kb, init: 0 kb, committed: 4,544 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 391,168 kb, init: 69,632 kb, committed: 823,296 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 178,897 kb, init: 1,329,152 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 56,832 kb, init: 0 kb, committed: 57,344 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 5,773 kb, init: 2,496 kb, committed: 7,168 kb, max: 120,032 kb
04:56:00,518 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) Stopping service.
04:56:00,525 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t22) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-61972: 260+72, fedora-32303: 252+87]}, pendingCH=DefaultConsistentHash{ns=512, owners = (2)[fedora-61972: 260+252, fedora-32303: 252+260]}, unionCH=null, actualMembers=[fedora-61972, fedora-32303], persistentUUIDs=[7bebc057-d23f-4568-a13f-8ca3b39166b8, 9c58dbf7-362a-4b0e-9754-6275a6df8fc2]}
04:56:00,526 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t22) [Context=testCache][Scope=fedora-61972]ISPN100002: Started rebalance with topology id 11
04:56:00,540 WARN  [org.infinispan.CLUSTER] (StopThread) [Context=testCache]ISPN000312: Lost data because of graceful leaver fedora-61972
04:56:00,592 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t22) [Context=testCache][Scope=fedora-32303]ISPN100003: Node fedora-32303 finished rebalance phase with topology id 12
04:56:00,603 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t22) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-61972: 130+28, fedora-32303: 126+40]}, pendingCH=DefaultConsistentHash{ns=256, owners = (2)[fedora-61972: 123+133, fedora-32303: 133+123]}, unionCH=null, actualMembers=[fedora-61972, fedora-32303], persistentUUIDs=[7bebc057-d23f-4568-a13f-8ca3b39166b8, 9c58dbf7-362a-4b0e-9754-6275a6df8fc2]}
04:56:00,604 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t22) [Context=___counters][Scope=fedora-61972]ISPN100002: Started rebalance with topology id 11
04:56:00,610 WARN  [org.infinispan.statetransfer.InboundTransferTask] (stateTransferExecutor-thread--p6-t1) ISPN000210: Failed to request state of cache testCache from node fedora-32303, segments {3-7 15-19 26-27 34-35 48-49 53-55 59 64-74 79 82-83 91-95 104-109 113-118 122-124 127-128 131 146-148 160 165-167 170-172 175-179 199 202-205 208-209 213-215 218 228 235-238 243-244 252 255-257 272-273 276-278 281-285 288 291 294 297-299 303 309-311 314-315 321-323 326 329-330 333-334 346-349 352-355 359 369-370 374-376 379-382 386-387 390-393 401 406 412-415 418-419 427 446-447 451-452 459-467 476 480-485 494-496}
org.infinispan.remoting.transport.jgroups.SuspectException: ISPN000400: Node fedora-32303 was suspected
	at org.infinispan.remoting.transport.ResponseCollectors.remoteNodeSuspected(ResponseCollectors.java:33) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleResponseCollector.targetNotFound(SingleResponseCollector.java:31) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleResponseCollector.targetNotFound(SingleResponseCollector.java:17) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.ValidSingleResponseCollector.addResponse(ValidSingleResponseCollector.java:23) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleTargetRequest.receiveResponse(SingleTargetRequest.java:51) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleTargetRequest.onResponse(SingleTargetRequest.java:35) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.RequestRepository.addResponse(RequestRepository.java:53) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.processResponse(JGroupsTransport.java:1302) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.processMessage(JGroupsTransport.java:1205) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.access$200(JGroupsTransport.java:123) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport$ChannelCallbacks.receive(JGroupsTransport.java:1340) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.jgroups.JChannel.up(JChannel.java:819) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.stack.ProtocolStack.up(ProtocolStack.java:893) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FRAG3.up(FRAG3.java:171) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FlowControl.up(FlowControl.java:343) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FlowControl.up(FlowControl.java:343) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.GMS.up(GMS.java:864) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.STABLE.up(STABLE.java:240) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.deliverMessage(UNICAST3.java:1002) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.handleDataReceived(UNICAST3.java:728) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.up(UNICAST3.java:383) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.NAKACK2.up(NAKACK2.java:600) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.VERIFY_SUSPECT.up(VERIFY_SUSPECT.java:119) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FD_ALL.up(FD_ALL.java:199) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FD_SOCK.up(FD_SOCK.java:252) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.MERGE3.up(MERGE3.java:276) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.Discovery.up(Discovery.java:267) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.TP.passMessageUp(TP.java:1248) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.util.SubmitToThreadPool$SingleMessageHandler.run(SubmitToThreadPool.java:87) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
04:56:00,617 WARN  [org.infinispan.CLUSTER] (remote-thread--p2-t22) [Context=___counters]ISPN000312: Lost data because of graceful leaver fedora-32303
04:56:00,619 WARN  [org.infinispan.statetransfer.InboundTransferTask] (stateTransferExecutor-thread--p6-t2) ISPN000210: Failed to request state of cache ___counters from node fedora-32303, segments {0-3 8-9 13 27-28 32-36 41 52-55 61-62 73 79-88 97-98 104-106 116-118 124-125 128 136-144 147-149 152-154 159-163 171-177 187 190 195-200 203-207 210-213 221-225 230-232 240-241 247}
org.infinispan.remoting.transport.jgroups.SuspectException: ISPN000400: Node fedora-32303 was suspected
	at org.infinispan.remoting.transport.ResponseCollectors.remoteNodeSuspected(ResponseCollectors.java:33) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleResponseCollector.targetNotFound(SingleResponseCollector.java:31) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleResponseCollector.targetNotFound(SingleResponseCollector.java:17) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.ValidSingleResponseCollector.addResponse(ValidSingleResponseCollector.java:23) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleTargetRequest.receiveResponse(SingleTargetRequest.java:51) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleTargetRequest.onResponse(SingleTargetRequest.java:35) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.RequestRepository.addResponse(RequestRepository.java:53) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.processResponse(JGroupsTransport.java:1302) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.processMessage(JGroupsTransport.java:1205) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.access$200(JGroupsTransport.java:123) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport$ChannelCallbacks.receive(JGroupsTransport.java:1340) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.jgroups.JChannel.up(JChannel.java:819) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.stack.ProtocolStack.up(ProtocolStack.java:893) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FRAG3.up(FRAG3.java:171) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FlowControl.up(FlowControl.java:343) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FlowControl.up(FlowControl.java:343) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.GMS.up(GMS.java:864) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.STABLE.up(STABLE.java:240) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.deliverMessage(UNICAST3.java:1002) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.handleDataReceived(UNICAST3.java:728) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.up(UNICAST3.java:383) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.NAKACK2.up(NAKACK2.java:600) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.VERIFY_SUSPECT.up(VERIFY_SUSPECT.java:119) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FD_ALL.up(FD_ALL.java:199) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FD_SOCK.up(FD_SOCK.java:252) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.MERGE3.up(MERGE3.java:276) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.Discovery.up(Discovery.java:267) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.TP.passMessageUp(TP.java:1248) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.util.SubmitToThreadPool$SingleMessageHandler.run(SubmitToThreadPool.java:87) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
04:56:00,634 INFO  [org.infinispan.CLUSTER] (jgroups-32,fedora-61972) ISPN000094: Received new cluster view for channel results: [fedora-61972|3] (2) [fedora-61972, fedora-32303]
04:56:00,638 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (StopThread) ISPN000080: Disconnecting JGroups channel results
04:56:00,640 INFO  [org.infinispan.CLUSTER] (jgroups-32,fedora-61972) ISPN100001: Node fedora-25162 left the cluster
04:56:00,679 INFO  [org.radargun.service.Infinispan90Lifecycle] (StopThread) Stopped, previous view is [fedora-61972, fedora-25162, fedora-32303]
04:56:00,680 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Service successfully stopped.
04:56:00,680 INFO  [org.radargun.Slave] (sc-main) Finished stage ScenarioDestroy
04:56:00,680 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
04:56:01,690 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.service.Infinispan80EmbeddedService.destroy() overrides public void org.radargun.service.Infinispan60EmbeddedService.destroy() but both are declared with @Destroy annotation: calling only once
04:56:01,692 INFO  [org.radargun.Slave] (main) Starting stage ScenarioCleanup
04:56:01,755 INFO  [org.radargun.stages.ScenarioCleanupStage] (main) Memory after cleanup: 
Runtime free: 1,379,111 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,595 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,700 kb
MX Metaspace(Non-heap memory): used: 36,762 kb, init: 0 kb, committed: 37,312 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 9,007 kb, init: 2,496 kb, committed: 13,568 kb, max: 120,028 kb
MX Compressed Class Space(Non-heap memory): used: 4,281 kb, init: 0 kb, committed: 4,544 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 0 kb, init: 69,632 kb, committed: 880,640 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 19,157 kb, init: 1,329,152 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 0 kb, init: 0 kb, committed: 0 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 5,649 kb, init: 2,496 kb, committed: 7,168 kb, max: 120,032 kb
04:56:01,760 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
04:56:06,809 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
04:56:10,157 INFO  [org.radargun.Slave] (main) Master shutdown!
04:56:10,168 INFO  [org.radargun.ShutDownHook] (Thread-0) Slave process is being shutdown
